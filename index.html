<!DOCTYPE html>
<html lang="en">

<head>
    <title>MyArxiv</title>
    <meta charset="utf-8"/>
    <meta http-equiv="X-UA-Compatible" content="IE=edge"/>
    <meta name="robots" content="noindex, nofollow"/>
    <meta name="viewport" content="width=device-width, initial-scale=1"/>
    <link rel="shortcut icon" type="image/x-icon" href="favicon.ico"/>
    <link href="index.css" rel="stylesheet"/>
    <link href="https://cdn.jsdelivr.net/npm/remixicon@2.5.0/fonts/remixicon.css" rel="stylesheet">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.css"
          integrity="sha384-R4558gYOUz8mP9YWpZJjofhk+zx0AS11p36HnD2ZKj/6JR5z27gSSULCNHIRReVs" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.css"
          integrity="sha384-R4558gYOUz8mP9YWpZJjofhk+zx0AS11p36HnD2ZKj/6JR5z27gSSULCNHIRReVs" crossorigin="anonymous">
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.js"
            integrity="sha384-z1fJDqw8ZApjGO3/unPWUPsIymfsJmyrDVWC8Tv/a1HeOtGmkwNd/7xUS0Xcnvsx"
            crossorigin="anonymous"></script>
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/contrib/auto-render.min.js"
            integrity="sha384-+XBljXPPiv+OzfbB3cVmLHf4hdUFHlWNZN5spNQ7rmHTXpd7WvJum6fIACpNNfIR"
            crossorigin="anonymous"></script>
    <script>
        document.addEventListener("DOMContentLoaded", function () {
            renderMathInElement(document.body, {
                // customised options
                // • auto-render specific keys, e.g.:
                delimiters: [
                    {left: '$$', right: '$$', display: true},
                    {left: '$', right: '$', display: false},
                    {left: '\\(', right: '\\)', display: false},
                    {left: '\\[', right: '\\]', display: true},
                    {left: "\\begin{equation}", right: "\\end{equation}", display: true},
                    {left: "\\begin{align}", right: "\\end{align}", display: true},
                    {left: "\\begin{alignat}", right: "\\end{alignat}", display: true},
                    {left: "\\begin{gather}", right: "\\end{gather}", display: true},
                    {left: "\\begin{CD}", right: "\\end{CD}", display: true},
                ],
                // • rendering keys, e.g.:
                throwOnError: false
            });
        });
    </script>
</head>

<body>
<section class="header-container">
    <div style="display:flex; justify-content:space-between; align-items:flex-end;">
        <div>
            <div class="header-title">
                MyArxiv
            </div>
        </div>

        <div class=icons>
            <label class="theme-switch" for="checkbox">
                <input type="checkbox" id="checkbox"/>
                <i id="theme-icon" class="ri-moon-line" style="font-size: 32px" rel="noopener noreferrer"></i>
            </label>
        </div>
    </div>
</section>

    <section class="day-container">
        <div class="date">
            <time datetime="2024-10-18T00:00:00Z">2024-10-18</time>
        </div>
            <article>
                <details>
                    <Summary>
                        Computation and Language <span class="chip" style="font-size: 60%">150</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Are AI Detectors Good Enough? A <span class="highlight-title">Survey</span> on Quality of <span class="highlight-title">Dataset</span>s With
  Machine-Generated Texts 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14677v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14677v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        German Gritsai, Anastasia Voznyuk, Andrey Grabovoy, Yury Chekhovich
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The rapid development of autoregressive Large Language Models (LLMs) has
significantly improved the quality of generated texts, necessitating reliable
machine-generated text detectors. A huge number of detectors and collections
with AI fragments have emerged, and several detection methods even showed
recognition quality up to 99.9% according to the target metrics in such
collections. However, the quality of such detectors tends to drop dramatically
in the wild, posing a question: Are detectors actually highly trustworthy or do
their high benchmark scores come from the poor quality of evaluation datasets?
In this paper, we emphasise the need for robust and qualitative methods for
evaluating generated data to be secure against bias and low generalising
ability of future model. We present a systematic review of datasets from
competitions dedicated to AI-generated content detection and propose methods
for evaluating the quality of datasets containing AI-generated fragments. In
addition, we discuss the possibility of using high-quality generated data to
achieve two goals: improving the training of detection models and improving the
training datasets themselves. Our contribution aims to facilitate a better
understanding of the dynamics between human and machine text, which will
ultimately support the integrity of information in an increasingly automated
world.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ SudoLM: Learning Access Control of Parametric Knowledge with
  Authorization Alignment 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14676v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14676v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Qin Liu, Fei Wang, Chaowei Xiao, Muhao Chen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Existing preference alignment is a one-size-fits-all alignment mechanism,
where the part of the large language model (LLM) parametric knowledge with
non-preferred features is uniformly blocked to all the users. However, this
part of knowledge can be useful to advanced users whose expertise qualifies
them to handle these information. The one-size-fits-all alignment mechanism
undermines LLM's utility for these qualified users. To address this problem, we
propose SudoLM, a framework that lets LLMs learn access control over specific
parametric knowledge for users with different credentials via authorization
alignment. SudoLM allows authorized users to unlock their access to all the
parametric knowledge with an assigned SUDO key while blocking access to
non-qualified users. Experiments on two application scenarios demonstrate that
SudoLM effectively controls the user's access to the parametric knowledge and
maintains its general utility.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Enhancing Large Language Models' Situated Faithfulness to External
  Contexts 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14675v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14675v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yukun Huang, Sanxing Chen, Hongyi Cai, Bhuwan Dhingra
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large Language Models (LLMs) are often augmented with external information as
contexts, but this external information can sometimes be inaccurate or even
intentionally misleading. We argue that robust LLMs should demonstrate situated
faithfulness, dynamically calibrating their trust in external information based
on their confidence in the internal knowledge and the external context. To
benchmark this capability, we evaluate LLMs across several QA datasets,
including a newly created dataset called RedditQA featuring in-the-wild
incorrect contexts sourced from Reddit posts. We show that when provided with
both correct and incorrect contexts, both open-source and proprietary models
tend to overly rely on external information, regardless of its factual
accuracy. To enhance situated faithfulness, we propose two approaches:
Self-Guided Confidence Reasoning (SCR) and Rule-Based Confidence Reasoning
(RCR). SCR enables models to self-access the confidence of external information
relative to their own internal knowledge to produce the most accurate answer.
RCR, in contrast, extracts explicit confidence signals from the LLM and
determines the final answer using predefined rules. Our results show that for
LLMs with strong reasoning capabilities, such as GPT-4o and GPT-4o mini, SCR
outperforms RCR, achieving improvements of up to 24.2% over a direct input
augmentation baseline. Conversely, for a smaller model like Llama-3-8B, RCR
outperforms SCR. Fine-tuning SCR with our proposed Confidence Reasoning Direct
Preference Optimization (CR-DPO) method improves performance on both seen and
unseen datasets, yielding an average improvement of 8.9% on Llama-3-8B. In
addition to quantitative results, we offer insights into the relative strengths
of SCR and RCR. Our findings highlight promising avenues for improving situated
faithfulness in LLMs. The data and code are released.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ NaturalBench: Evaluating Vision-Language Models on Natural Adversarial
  Samples <span class="chip">NeurIPS 24</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14669v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14669v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Baiqi Li, Zhiqiu Lin, Wenxuan Peng, Jean de Dieu Nyandwi, Daniel Jiang, Zixian Ma, Simran Khanuja, Ranjay Krishna, Graham Neubig, Deva Ramanan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Vision-language models (VLMs) have made significant progress in recent
visual-question-answering (VQA) benchmarks that evaluate complex
visio-linguistic reasoning. However, are these models truly effective? In this
work, we show that VLMs still struggle with natural images and questions that
humans can easily answer, which we term natural adversarial samples. We also
find it surprisingly easy to generate these VQA samples from natural image-text
corpora using off-the-shelf models like CLIP and ChatGPT. We propose a
semi-automated approach to collect a new benchmark, NaturalBench, for reliably
evaluating VLMs with 10,000 human-verified VQA samples. Crucially, we adopt a
$\textbf{vision-centric}$ design by pairing each question with two images that
yield different answers, preventing blind solutions from answering without
using the images. This makes NaturalBench more challenging than previous
benchmarks that can be solved with commonsense priors. We evaluate 53
state-of-the-art VLMs on NaturalBench, showing that models like
LLaVA-OneVision, Cambrian-1, Llama3.2-Vision, Molmo, Qwen2-VL, and even GPT-4o
lag 50%-70% behind human performance (over 90%). We analyze why NaturalBench is
hard from two angles: (1) Compositionality: Solving NaturalBench requires
diverse visio-linguistic skills, including understanding attribute bindings,
object relationships, and advanced reasoning like logic and counting. To this
end, unlike prior work that uses a single tag per sample, we tag each
NaturalBench sample with 1 to 8 skill tags for fine-grained evaluation. (2)
Biases: NaturalBench exposes severe biases in VLMs, as models often choose the
same answer regardless of the image. Lastly, we apply our benchmark curation
method to diverse data sources, including long captions (over 100 words) and
non-English languages like Chinese and Hindi, highlighting its potential for
dynamic evaluations of VLMs.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to NeurIPS 24; We open-source our dataset at:
  https://huggingface.co/datasets/BaiqiL/NaturalBench; Project page at:
  https://linzhiqiu.github.io/papers/naturalbench/</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ MiCEval: Unveiling Multimodal Chain of Thought's Quality via Image
  Description and Reasoning Steps 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14668v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14668v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xiongtao Zhou, Jie He, Lanyu Chen, jingyu li, Haojing Chen, Victor Gutierrez Basulto, Jeff Z. Pan, Hanjie Chen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Multimodal Chain of Thought (MCoT) is a popular prompting strategy for
improving the performance of multimodal large language models (MLLMs) across a
range of complex reasoning tasks. Despite its popularity, there is a notable
absence of automated methods for evaluating the quality of reasoning steps in
MCoT. To address this gap, we propose Multimodal Chain-of-Thought Evaluation
(MiCEval), a framework designed to assess the correctness of reasoning chains
by evaluating the quality of both the description and each reasoning step. The
evaluation of the description component focuses on the accuracy of the image
descriptions, while the reasoning step evaluates the quality of each step as it
is conditionally generated based on the preceding steps. MiCEval is built upon
a fine-grained dataset with annotations that rate each step according to
correctness, relevance, and informativeness. Extensive experiments on four
state-of-the-art MLLMs show that step-wise evaluations using MiCEval align more
closely with human judgments compared to existing methods based on cosine
similarity or fine-tuning approaches. MiCEval datasets and code can be found in
https://github.com/alenai97/MiCEval.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>40 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ DiscoGraMS: Enhancing Movie Screen-Play Summarization using Movie
  Character-Aware Discourse Graph 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14666v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14666v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Maitreya Prafulla Chitale, Uday Bindal, Rajakrishnan Rajkumar, Rahul Mishra
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Summarizing movie screenplays presents a unique set of challenges compared to
standard document summarization. Screenplays are not only lengthy, but also
feature a complex interplay of characters, dialogues, and scenes, with numerous
direct and subtle relationships and contextual nuances that are difficult for
machine learning models to accurately capture and comprehend. Recent attempts
at screenplay summarization focus on fine-tuning transformer-based pre-trained
models, but these models often fall short in capturing long-term dependencies
and latent relationships, and frequently encounter the "lost in the middle"
issue. To address these challenges, we introduce DiscoGraMS, a novel resource
that represents movie scripts as a movie character-aware discourse graph (CaD
Graph). This approach is well-suited for various downstream tasks, such as
summarization, question-answering, and salience detection. The model aims to
preserve all salient information, offering a more comprehensive and faithful
representation of the screenplay's content. We further explore a baseline
method that combines the CaD Graph with the corresponding movie script through
a late fusion of graph and text modalities, and we present very initial
promising results.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Real-time Fake News from Adversarial Feedback 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14651v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14651v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Sanxing Chen, Yukun Huang, Bhuwan Dhingra
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We show that existing evaluations for fake news detection based on
conventional sources, such as claims on fact-checking websites, result in an
increasing accuracy over time for LLM-based detectors -- even after their
knowledge cutoffs. This suggests that recent popular political claims, which
form the majority of fake news on such sources, are easily classified using
surface-level shallow patterns. Instead, we argue that a proper fake news
detection dataset should test a model's ability to reason factually about the
current world by retrieving and reading related evidence. To this end, we
develop a novel pipeline that leverages natural language feedback from a
RAG-based detector to iteratively modify real-time news into deceptive fake
news that challenges LLMs. Our iterative rewrite decreases the binary
classification AUC by an absolute 17.5 percent for a strong RAG GPT-4o
detector. Our experiments reveal the important role of RAG in both detecting
and generating fake news, as retrieval-free LLM detectors are vulnerable to
unseen events and adversarial attacks, while feedback from RAG detection helps
discover more deceitful patterns in fake news.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Distance between Relevant Information Pieces Causes Bias in Long-Context
  LLMs 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14641v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14641v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Runchu Tian, Yanghao Li, Yuepeng Fu, Siyang Deng, Qinyu Luo, Cheng Qian, Shuo Wang, Xin Cong, Zhong Zhang, Yesai Wu, Yankai Lin, Huadong Wang, Xiaojiang Liu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Positional bias in large language models (LLMs) hinders their ability to
effectively process long inputs. A prominent example is the "lost in the
middle" phenomenon, where LLMs struggle to utilize relevant information
situated in the middle of the input. While prior research primarily focuses on
single pieces of relevant information, real-world applications often involve
multiple relevant information pieces. To bridge this gap, we present
LongPiBench, a benchmark designed to assess positional bias involving multiple
pieces of relevant information. Thorough experiments are conducted with five
commercial and six open-source models. These experiments reveal that while most
current models are robust against the "lost in the middle" issue, there exist
significant biases related to the spacing of relevant information pieces. These
findings highlight the importance of evaluating and reducing positional biases
to advance LLM's capabilities.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>work in progress</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ GenEOL: Harnessing the Generative Power of LLMs for Training-Free
  Sentence Embeddings 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14635v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14635v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Raghuveer Thirukovalluru, Bhuwan Dhingra
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Training-free embedding methods directly leverage pretrained large language
models (LLMs) to embed text, bypassing the costly and complex procedure of
contrastive learning. Previous training-free embedding methods have mainly
focused on optimizing embedding prompts and have overlooked the benefits of
utilizing the generative abilities of LLMs. We propose a novel method, GenEOL,
which uses LLMs to generate diverse transformations of a sentence that preserve
its meaning, and aggregates the resulting embeddings of these transformations
to enhance the overall sentence embedding. GenEOL significantly outperforms the
existing training-free embedding methods by an average of 2.85 points across
several LLMs on the sentence semantic text similarity (STS) benchmark. Our
analysis shows that GenEOL stabilizes representation quality across LLM layers
and is robust to perturbations of embedding prompts. GenEOL also achieves
notable gains on multiple clustering, reranking and pair-classification tasks
from the MTEB benchmark.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Diverging Preferences: When do Annotators Disagree and do Models Know? 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14632v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14632v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Michael JQ Zhang, Zhilin Wang, Jena D. Hwang, Yi Dong, Olivier Delalleau, Yejin Choi, Eunsol Choi, Xiang Ren, Valentina Pyatkin
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We examine diverging preferences in human-labeled preference datasets. We
develop a taxonomy of disagreement sources spanning 10 categories across four
high-level classes -- task underspecification, response style, refusals, and
annotation errors. We find that the majority of disagreements are in opposition
with standard reward modeling approaches, which are designed with the
assumption that annotator disagreement is noise. We then explore how these
findings impact two areas of LLM development: reward modeling and evaluation.
In our experiments, we demonstrate how standard reward modeling methods, like
the Bradley-Terry model, fail to differentiate whether a given preference
judgment is the result of unanimous agreement among annotators or the majority
opinion among diverging user preferences. We also find that these tendencies
are also echoed by popular LLM-as-Judge evaluation methods, which consistently
identify a winning response in cases of diverging preferences. These findings
highlight remaining challenges in LLM evaluations, which are greatly influenced
by divisive features like response style, and in developing pluralistically
aligned LLMs. To address these issues, we develop methods for identifying
diverging preferences to mitigate their influence on evaluation and training.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ CELI: Controller-Embedded Language Model Interactions 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14627v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14627v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jan-Samuel Wagner, Dave DeCaprio, Abishek Chiffon Muthu Raja, Jonathan M. Holman, Lauren K. Brady, Sky C. Cheung, Hosein Barzekar, Eric Yang, Mark Anthony Martinez II, David Soong, Sriram Sridhar, Han Si, Brandon W. Higgs, Hisham Hamadeh, Scott Ogden
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We introduce Controller-Embedded Language Model Interactions (CELI), a
framework that integrates control logic directly within language model (LM)
prompts, facilitating complex, multi-stage task execution. CELI addresses
limitations of existing prompt engineering and workflow optimization techniques
by embedding control logic directly within the operational context of language
models, enabling dynamic adaptation to evolving task requirements. Our
framework transfers control from the traditional programming execution
environment to the LMs, allowing them to autonomously manage computational
workflows while maintaining seamless interaction with external systems and
functions. CELI supports arbitrary function calls with variable arguments,
bridging the gap between LMs' adaptive reasoning capabilities and conventional
software paradigms' structured control mechanisms. To evaluate CELI's
versatility and effectiveness, we conducted case studies in two distinct
domains: code generation (HumanEval benchmark) and multi-stage content
generation (Wikipedia-style articles). The results demonstrate notable
performance improvements across a range of domains. CELI achieved a 4.9
percentage point improvement over the best reported score of the baseline GPT-4
model on the HumanEval code generation benchmark. In multi-stage content
generation, 94.4% of CELI-produced Wikipedia-style articles met or exceeded
first draft quality when optimally configured, with 44.4% achieving high
quality. These outcomes underscore CELI's potential for optimizing AI-driven
workflows across diverse computational domains.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>26 pages, 2 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ You Shall Know a Tool by the Traces it Leaves: The Predictability of
  Sentiment Analysis Tools 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14626v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14626v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Daniel Baumartz, Mevlüt Bagci, Alexander Henlein, Maxim Konca, Andy Lücking, Alexander Mehler
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  If sentiment analysis tools were valid classifiers, one would expect them to
provide comparable results for sentiment classification on different kinds of
corpora and for different languages. In line with results of previous studies
we show that sentiment analysis tools disagree on the same dataset. Going
beyond previous studies we show that the sentiment tool used for sentiment
annotation can even be predicted from its outcome, revealing an algorithmic
bias of sentiment analysis. Based on Twitter, Wikipedia and different news
corpora from the English, German and French languages, our classifiers separate
sentiment tools with an averaged F1-score of 0.89 (for the English corpora). We
therefore warn against taking sentiment annotations as face value and argue for
the need of more and systematic NLP evaluation studies.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ DiSCo Meets LLMs: A Unified Approach for Sparse Retrieval and Contextual
  Distillation in Conversational Search 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14609v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14609v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Simon Lupart, Mohammad Aliannejadi, Evangelos Kanoulas
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Conversational Search (CS) is the task of retrieving relevant documents from
a corpus within a conversational context, combining retrieval with
conversational context modeling. With the explosion of Large Language Models
(LLMs), the CS field has seen major improvements with LLMs rewriting user
queries, accounting for conversational context. However, engaging LLMs at
inference time harms efficiency. Current methods address this by distilling
embeddings from human-rewritten queries to learn the context modeling task.
Yet, these approaches predominantly focus on context modeling, and only treat
the contrastive component of the retrieval task within a
distillation-independent loss term. To address these limitations, we propose a
new distillation method, as a relaxation of the previous objective, unifying
retrieval and context modeling. We relax the existing training objectives by
distilling similarity scores between conversations and documents, rather than
relying solely on representation learning. Our proposed distillation objective
allows for more freedom in the representation space and leverages the
contrastive nature of document relevance. Through experiments on Learned Sparse
Retrieval (LSR) across 5 CS datasets, our approach demonstrates substantial
improvements in both in-domain and out-of-domain retrieval performance,
outperforming state-of-the-art with gains of up to 6 points in recall for
out-of-domain datasets. Additionally, through the relaxation of the objective,
we propose a multi-teacher distillation, using multiple LLMs as teachers,
yielding additional gains, and outperforming the teachers themselves in
in-domain experiments. Finally, analysis of the sparsity of the models reveals
that our distillation allows for better control over the sparsity of the
trained models.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Teaching Models to Balance Resisting and Accepting Persuasion 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14596v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14596v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Elias Stengel-Eskin, Peter Hase, Mohit Bansal
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large language models (LLMs) are susceptible to persuasion, which can pose
risks when models are faced with an adversarial interlocutor. We take a first
step towards defending models against persuasion while also arguing that
defense against adversarial (i.e. negative) persuasion is only half of the
equation: models should also be able to accept beneficial (i.e. positive)
persuasion to improve their answers. We show that optimizing models for only
one side results in poor performance on the other. In order to balance positive
and negative persuasion, we introduce Persuasion-Balanced Training (or PBT),
which leverages multi-agent recursive dialogue trees to create data and trains
models via preference optimization to accept persuasion when appropriate. PBT
consistently improves resistance to misinformation and resilience to being
challenged while also resulting in the best overall performance on holistic
data containing both positive and negative persuasion. Crucially, we show that
PBT models are better teammates in multi-agent debates. We find that without
PBT, pairs of stronger and weaker models have unstable performance, with the
order in which the models present their answers determining whether the team
obtains the stronger or weaker model's performance. PBT leads to better and
more stable results and less order dependence, with the stronger model
consistently pulling the weaker one up.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Code: https://github.com/esteng/persuasion_balanced_training</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Toolshed: Scale Tool-Equipped Agents with Advanced RAG-Tool Fusion and
  Tool Knowledge Bases 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14594v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14594v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Elias Lumer
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent advancements in tool-equipped Agents (LLMs) have enabled complex tasks
like secure database interactions and multi-agent code development. However,
scaling tool capacity beyond agent reasoning or model limits remains a
challenge. In this paper, we address these challenges by introducing Toolshed
Knowledge Bases, a tool knowledge base (vector database) designed to store
enhanced tool representations and optimize tool selection for large-scale
tool-equipped Agents. Additionally, we propose Advanced RAG-Tool Fusion, a
novel ensemble of tool-applied advanced retrieval-augmented generation (RAG)
techniques across the pre-retrieval, intra-retrieval, and post-retrieval
phases, without requiring model fine-tuning. During pre-retrieval, tool
documents are enhanced with key information and stored in the Toolshed
Knowledge Base. Intra-retrieval focuses on query planning and transformation to
increase retrieval accuracy. Post-retrieval refines the retrieved tool
documents and enables self-reflection. Furthermore, by varying both the total
number of tools (tool-M) an Agent has access to and the tool selection
threshold (top-k), we address trade-offs between retrieval accuracy, agent
performance, and token cost. Our approach achieves 46%, 56%, and 47% absolute
improvements on the ToolE single-tool, ToolE multi-tool and Seal-Tools
benchmark datasets, respectively (Recall@5).
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Dialetto, ma Quanto Dialetto? Transcribing and Evaluating Dialects on a
  Continuum 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14589v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14589v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ryan Soh-Eun Shim, Barbara Plank
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  There is increasing interest in looking at dialects in NLP. However, most
work to date still treats dialects as discrete categories. For instance,
evaluative work in variation-oriented NLP for English often works with Indian
English or African-American Venacular English as homogeneous categories (Faisal
et al., 2024; Ziems et al., 2023), yet even within one variety there is
substantial variation. We examine within-dialect variation and show that
performance critically varies within categories. We measure speech-to-text
performance on Italian dialects, and empirically observe a geographical
performance disparity. This disparity correlates substantially (-0.5) with
linguistic similarity to the highest performing dialect variety. We
cross-examine our results against dialectometry methods, and interpret the
performance disparity to be due to a bias towards dialects that are more
similar to the standard variety in the speech-to-text model examined. We
additionally leverage geostatistical methods to predict zero-shot performance
at unseen sites, and find the incorporation of geographical information to
substantially improve prediction performance, indicating there to be
geographical structure in the performance distribution.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Do LLMs estimate uncertainty well in instruction-following? 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14582v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14582v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Juyeon Heo, Miao Xiong, Christina Heinze-Deml, Jaya Narain
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large language models (LLMs) could be valuable personal AI agents across
various domains, provided they can precisely follow user instructions. However,
recent studies have shown significant limitations in LLMs'
instruction-following capabilities, raising concerns about their reliability in
high-stakes applications. Accurately estimating LLMs' uncertainty in adhering
to instructions is critical to mitigating deployment risks. We present, to our
knowledge, the first systematic evaluation of the uncertainty estimation
abilities of LLMs in the context of instruction-following. Our study identifies
key challenges with existing instruction-following benchmarks, where multiple
factors are entangled with uncertainty stems from instruction-following,
complicating the isolation and comparison across methods and models. To address
these issues, we introduce a controlled evaluation setup with two benchmark
versions of data, enabling a comprehensive comparison of uncertainty estimation
methods under various conditions. Our findings show that existing uncertainty
methods struggle, particularly when models make subtle errors in instruction
following. While internal model states provide some improvement, they remain
inadequate in more complex scenarios. The insights from our controlled
evaluation setups provide a crucial understanding of LLMs' limitations and
potential for uncertainty estimation in instruction-following tasks, paving the
way for more trustworthy AI agents.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Optimizing Attention with Mirror Descent: Generalized Max-Margin Token
  Selection 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14581v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14581v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Aaron Alvarado Kristanto Julistiono, Davoud Ataee Tarzanagh, Navid Azizan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Attention mechanisms have revolutionized several domains of artificial
intelligence, such as natural language processing and computer vision, by
enabling models to selectively focus on relevant parts of the input data. While
recent work has characterized the optimization dynamics of gradient descent
(GD) in attention-based models and the structural properties of its preferred
solutions, less is known about more general optimization algorithms such as
mirror descent (MD). In this paper, we investigate the convergence properties
and implicit biases of a family of MD algorithms tailored for softmax attention
mechanisms, with the potential function chosen as the $p$-th power of the
$\ell_p$-norm. Specifically, we show that these algorithms converge in
direction to a generalized hard-margin SVM with an $\ell_p$-norm objective when
applied to a classification problem using a softmax attention model. Notably,
our theoretical results reveal that the convergence rate is comparable to that
of traditional GD in simpler models, despite the highly nonlinear and nonconvex
nature of the present problem. Additionally, we delve into the joint
optimization dynamics of the key-query matrix and the decoder, establishing
conditions under which this complex joint optimization converges to their
respective hard-margin SVM solutions. Lastly, our numerical experiments on real
data demonstrate that MD algorithms improve generalization over standard GD and
excel in optimal token selection.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Large Language Models Are Overparameterized Text Encoders 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14578v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14578v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Thennal D K, Tim Fischer, Chris Biemann
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large language models (LLMs) demonstrate strong performance as text embedding
models when finetuned with supervised contrastive training. However, their
large size balloons inference time and memory requirements. In this paper, we
show that by pruning the last $p\%$ layers of an LLM before supervised training
for only 1000 steps, we can achieve a proportional reduction in memory and
inference time. We evaluate four different state-of-the-art LLMs on text
embedding tasks and find that our method can prune up to 30\% of layers with
negligible impact on performance and up to 80\% with only a modest drop. With
only three lines of code, our method is easily implemented in any pipeline for
transforming LLMs to text encoders. We also propose $\text{L}^3 \text{Prune}$,
a novel layer-pruning strategy based on the model's initial loss that provides
two optimal pruning configurations: a large variant with negligible performance
loss and a small variant for resource-constrained settings. On average, the
large variant prunes 21\% of the parameters with a $-0.3$ performance drop, and
the small variant only suffers from a $-5.1$ decrease while pruning 74\% of the
model. We consider these results strong evidence that LLMs are
overparameterized for text embedding tasks, and can be easily pruned.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>8 pages of content + 1 for limitations and ethical considerations, 14
  pages in total including references and appendix, 5+1 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ MomentumSMoE: Integrating Momentum into Sparse Mixture of Experts <span class="chip">NeurIPS 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14574v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14574v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Rachel S. Y. Teo, Tan M. Nguyen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Sparse Mixture of Experts (SMoE) has become the key to unlocking unparalleled
scalability in deep learning. SMoE has the potential to exponentially increase
parameter count while maintaining the efficiency of the model by only
activating a small subset of these parameters for a given sample. However, it
has been observed that SMoE suffers from unstable training and has difficulty
adapting to new distributions, leading to the model's lack of robustness to
data contamination. To overcome these limitations, we first establish a
connection between the dynamics of the expert representations in SMoEs and
gradient descent on a multi-objective optimization problem. Leveraging our
framework, we then integrate momentum into SMoE and propose a new family of
SMoEs named MomentumSMoE. We theoretically prove and numerically demonstrate
that MomentumSMoE is more stable and robust than SMoE. In particular, we verify
the advantages of MomentumSMoE over SMoE on a variety of practical tasks
including ImageNet-1K object recognition and WikiText-103 language modeling. We
demonstrate the applicability of MomentumSMoE to many types of SMoE models,
including those in the Sparse MoE model for vision (V-MoE) and the Generalist
Language Model (GLaM). We also show that other advanced momentum-based
optimization methods, such as Adam, can be easily incorporated into the
MomentumSMoE framework for designing new SMoE models with even better
performance, almost negligible additional computation cost, and simple
implementations.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>10 pages in the main text. Published at NeurIPS 2024. The code is
  available at https://github.com/rachtsy/MomentumSMoE</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ RAG-ConfusionQA: A Benchmark for Evaluating LLMs on Confusing Questions 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14567v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14567v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zhiyuan Peng, Jinming Nian, Alexandre Evfimievski, Yi Fang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Conversational AI agents use Retrieval Augmented Generation (RAG) to provide
verifiable document-grounded responses to user inquiries. However, many natural
questions do not have good answers: about 25\% contain false
assumptions~\cite{Yu2023:CREPE}, and over 50\% are
ambiguous~\cite{Min2020:AmbigQA}. RAG agents need high-quality data to improve
their responses to confusing questions. This paper presents a novel synthetic
data generation method to efficiently create a diverse set of context-grounded
confusing questions from a given document corpus. We conduct an empirical
comparative evaluation of several large language models as RAG agents to
measure the accuracy of confusion detection and appropriate response
generation. We contribute a benchmark dataset to the public domain.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>under review</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Tell me what I need to know: Exploring LLM-based (Personalized)
  Abstractive Multi-Source Meeting Summarization 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14545v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14545v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Frederic Kirstein, Terry Ruas, Robert Kratel, Bela Gipp
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Meeting summarization is crucial in digital communication, but existing
solutions struggle with salience identification to generate personalized,
workable summaries, and context understanding to fully comprehend the meetings'
content. Previous attempts to address these issues by considering related
supplementary resources (e.g., presentation slides) alongside transcripts are
hindered by models' limited context sizes and handling the additional
complexities of the multi-source tasks, such as identifying relevant
information in additional files and seamlessly aligning it with the meeting
content. This work explores multi-source meeting summarization considering
supplementary materials through a three-stage large language model approach:
identifying transcript passages needing additional context, inferring relevant
details from supplementary materials and inserting them into the transcript,
and generating a summary from this enriched transcript. Our multi-source
approach enhances model understanding, increasing summary relevance by ~9% and
producing more content-rich outputs. We introduce a personalization protocol
that extracts participant characteristics and tailors summaries accordingly,
improving informativeness by ~10%. This work further provides insights on
performance-cost trade-offs across four leading model families, including
edge-device capable options. Our approach can be extended to similar complex
generative tasks benefitting from additional resources and personalization,
such as dialogue systems and action planning.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Do LLMs "know" internally when they follow instructions? 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14516v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14516v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Juyeon Heo, Christina Heinze-Deml, Oussama Elachqar, Shirley Ren, Udhay Nallasamy, Andy Miller, Kwan Ho Ryan Chan, Jaya Narain
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Instruction-following is crucial for building AI agents with large language
models (LLMs), as these models must adhere strictly to user-provided
constraints and guidelines. However, LLMs often fail to follow even simple and
clear instructions. To improve instruction-following behavior and prevent
undesirable outputs, a deeper understanding of how LLMs' internal states relate
to these outcomes is required. Our analysis of LLM internal states reveal a
dimension in the input embedding space linked to successful
instruction-following. We demonstrate that modifying representations along this
dimension improves instruction-following success rates compared to random
changes, without compromising response quality. Further investigation reveals
that this dimension is more closely related to the phrasing of prompts rather
than the inherent difficulty of the task or instructions. This discovery also
suggests explanations for why LLMs sometimes fail to follow clear instructions
and why prompt engineering is often effective, even when the content remains
largely unchanged. This work provides insight into the internal workings of
LLMs' instruction-following, paving the way for reliable LLM agents.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ SignAttention: On the Interpretability of <span class="highlight-title">Transformer</span> Models for Sign
  Language Translation <span class="chip">NeurIPS 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14506v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14506v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Pedro Alejandro Dal Bianco, Oscar Agustín Stanchi, Facundo Manuel Quiroga, Franco Ronchetti, Enzo Ferrante
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper presents the first comprehensive interpretability analysis of a
Transformer-based Sign Language Translation (SLT) model, focusing on the
translation from video-based Greek Sign Language to glosses and text.
Leveraging the Greek Sign Language Dataset, we examine the attention mechanisms
within the model to understand how it processes and aligns visual input with
sequential glosses. Our analysis reveals that the model pays attention to
clusters of frames rather than individual ones, with a diagonal alignment
pattern emerging between poses and glosses, which becomes less distinct as the
number of glosses increases. We also explore the relative contributions of
cross-attention and self-attention at each decoding step, finding that the
model initially relies on video frames but shifts its focus to previously
predicted tokens as the translation progresses. This work contributes to a
deeper understanding of SLT models, paving the way for the development of more
transparent and reliable translation systems essential for real-world
applications.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted at IAI Workshop @ NeurIPS 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Combining Entropy and Matrix Nuclear Norm for Enhanced Evaluation of
  Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14480v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14480v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        James Vo
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  As large language models (LLMs) continue to advance, the need for precise and
efficient evaluation metrics becomes more pressing. Traditional approaches,
while informative, often face limitations in computational demands and
interpretability. In this paper, we introduce a novel hybrid evaluation method
that integrates two established techniques: entropy derived from covariance
matrices and the Matrix Nuclear Norm (MNN). Our method begins by normalizing
hidden states from LLMs, then computes the covariance matrix and MNN from these
representations. We further calculate the entropy of the covariance matrix to
capture uncertainty and redundancy in the model's outputs. By combining these
metrics into a composite score, we offer a comprehensive evaluation framework
that balances accuracy with computational efficiency. Additionally, our
approach allows for flexibility in adjusting the weightings between entropy and
MNN, tailoring the evaluation for different objectives. Through a series of
experiments on various LLMs, we demonstrate the robustness and efficacy of our
method, offering deeper insights into model performance. This work contributes
to the ongoing development of LLM evaluation and opens avenues for future
innovations in model assessment techniques.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>The method is currently under experimentation</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ A Systematic Study of Cross-Layer KV Sharing for Efficient LLM Inference 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14442v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14442v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        You Wu, Haoyi Wu, Kewei Tu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recently, sharing key-value (KV) cache across layers has been found effective
in efficient inference of large language models (LLMs). To systematically
investigate different techniques of cross-layer KV sharing, we propose a
unified framework that covers several recent methods and their novel variants.
We conduct comprehensive experiments on all the configurations of the
framework, evaluating their generation throughput and performance in language
modeling and downstream tasks. We find that when reducing the size of the KV
cache by 2x, most configurations can achieve competitive performance to and
higher throughput than standard transformers, but when further reducing the
size of the KV cache, pairing queries of all layers with KVs of upper layers
can better maintain performance, although it also introduces additional
training cost and prefilling latency. We hope that this work will help users
choose the appropriate approach according to their requirements and facilitate
research on the acceleration of LLM inference.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Unlearning Backdoor Attacks for LLMs with Weak-to-Strong Knowledge
  Distillation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14425v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14425v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Shuai Zhao, Xiaobao Wu, Cong-Duy Nguyen, Meihuizi Jia, Yichao Feng, Luu Anh Tuan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Parameter-efficient fine-tuning (PEFT) can bridge the gap between large
language models (LLMs) and downstream tasks. However, PEFT has been proven
vulnerable to malicious attacks. Research indicates that poisoned LLMs, even
after PEFT, retain the capability to activate internalized backdoors when input
samples contain predefined triggers. In this paper, we introduce a novel
weak-to-strong unlearning algorithm to defend against backdoor attacks based on
feature alignment knowledge distillation, named W2SDefense. Specifically, we
first train a small-scale language model through full-parameter fine-tuning to
serve as the clean teacher model. Then, this teacher model guides the
large-scale poisoned student model in unlearning the backdoor, leveraging PEFT.
Theoretical analysis suggests that W2SDefense has the potential to enhance the
student model's ability to unlearn backdoor features, preventing the activation
of the backdoor. We conduct experiments on text classification tasks involving
three state-of-the-art language models and three different backdoor attack
algorithms. Our empirical results demonstrate the outstanding performance of
W2SDefense in defending against backdoor attacks without compromising model
performance.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Fact Recall, Heuristics or Pure Guesswork? Precise Interpretations of
  Language Models for Fact Completion 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14405v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14405v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Denitsa Saynova, Lovisa Hagström, Moa Johansson, Richard Johansson, Marco Kuhlmann
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Previous interpretations of language models (LMs) miss important distinctions
in how these models process factual information. For example, given the query
"Astrid Lindgren was born in" with the corresponding completion "Sweden", no
difference is made between whether the prediction was based on having the exact
knowledge of the birthplace of the Swedish author or assuming that a person
with a Swedish-sounding name was born in Sweden. In this paper, we investigate
four different prediction scenarios for which the LM can be expected to show
distinct behaviors. These scenarios correspond to different levels of model
reliability and types of information being processed - some being less
desirable for factual predictions. To facilitate precise interpretations of LMs
for fact completion, we propose a model-specific recipe called PrISM for
constructing datasets with examples of each scenario based on a set of
diagnostic criteria. We apply a popular interpretability method, causal tracing
(CT), to the four prediction scenarios and find that while CT produces
different results for each scenario, aggregations over a set of mixed examples
may only represent the results from the scenario with the strongest measured
signal. In summary, we contribute tools for a more granular study of fact
completion in language models and analyses that provide a more nuanced
understanding of how LMs process fact-related queries.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ SylloBio-NLI: Evaluating Large Language Models on Biomedical Syllogistic
  Reasoning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14399v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14399v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Magdalena Wysocka, Danilo S. Carvalho, Oskar Wysocki, Marco Valentino, Andre Freitas
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Syllogistic reasoning is crucial for Natural Language Inference (NLI). This
capability is particularly significant in specialized domains such as
biomedicine, where it can support automatic evidence interpretation and
scientific discovery. This paper presents SylloBio-NLI, a novel framework that
leverages external ontologies to systematically instantiate diverse syllogistic
arguments for biomedical NLI. We employ SylloBio-NLI to evaluate Large Language
Models (LLMs) on identifying valid conclusions and extracting supporting
evidence across 28 syllogistic schemes instantiated with human genome pathways.
Extensive experiments reveal that biomedical syllogistic reasoning is
particularly challenging for zero-shot LLMs, which achieve an average accuracy
between 70% on generalized modus ponens and 23% on disjunctive syllogism. At
the same time, we found that few-shot prompting can boost the performance of
different LLMs, including Gemma (+14%) and LLama-3 (+43%). However, a deeper
analysis shows that both techniques exhibit high sensitivity to superficial
lexical variations, highlighting a dependency between reliability, models'
architecture, and pre-training regime. Overall, our results indicate that,
while in-context examples have the potential to elicit syllogistic reasoning in
LLMs, existing models are still far from achieving the robustness and
consistency required for safe biomedical NLI applications.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Generative AI, Pragmatics, and Authenticity in Second Language Learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14395v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14395v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Robert Godwin-Jones`
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  There are obvious benefits to integrating generative AI (artificial
intelligence) into language learning and teaching. Those include using AI as a
language tutor, creating learning materials, or assessing learner output.
However, due to how AI systems under-stand human language, based on a
mathematical model using statistical probability, they lack the lived
experience to be able to use language with the same social aware-ness as
humans. Additionally, there are built-in linguistic and cultural biases based
on their training data which is mostly in English and predominantly from
Western sources. Those facts limit AI suitability for some language learning
interactions. Stud-ies have clearly shown that systems such as ChatGPT often do
not produce language that is pragmatically appropriate. The lack of linguistic
and cultural authenticity has important implications for how AI is integrated
into second language acquisition as well as in instruction targeting
development of intercultural communication compe-tence.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Analyzing Context Utilization of LLMs in Document-Level Translation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14391v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14391v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Wafaa Mohammed, Vlad Niculae
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large language models (LLM) are increasingly strong contenders in machine
translation. We study document-level translation, where some words cannot be
translated without context from outside the sentence. We investigate the
ability of prominent LLMs to utilize context by analyzing models' robustness to
perturbed and randomized document context. We find that LLMs' improved
document-translation performance is not always reflected in pronoun translation
performance. We highlight the need for context-aware finetuning of LLMs with a
focus on relevant parts of the context to improve their reliability for
document-level translation.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>4 pages, 2 figures, 2 tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ How Do Multilingual Models Remember? Investigating Multilingual Factual
  Recall Mechanisms 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14387v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14387v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Constanza Fierro, Negar Foroutan, Desmond Elliott, Anders Søgaard
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large Language Models (LLMs) store and retrieve vast amounts of factual
knowledge acquired during pre-training. Prior research has localized and
identified mechanisms behind knowledge recall; however, it has primarily
focused on English monolingual models. The question of how these processes
generalize to other languages and multilingual LLMs remains unexplored. In this
paper, we address this gap by conducting a comprehensive analysis of two highly
multilingual LLMs. We assess the extent to which previously identified
components and mechanisms of factual recall in English apply to a multilingual
context. Then, we examine when language plays a role in the recall process,
uncovering evidence of language-independent and language-dependent mechanisms.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Fine-Tuning <span class="highlight-title">Pre-train</span>ed Language Models for Robust Causal Representation
  Learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14375v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14375v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jialin Yu, Yuxiang Zhou, Yulan He, Nevin L. Zhang, Ricardo Silva
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The fine-tuning of pre-trained language models (PLMs) has been shown to be
effective across various domains. By using domain-specific supervised data, the
general-purpose representation derived from PLMs can be transformed into a
domain-specific representation. However, these methods often fail to generalize
to out-of-domain (OOD) data due to their reliance on non-causal
representations, often described as spurious features. Existing methods either
make use of adjustments with strong assumptions about lack of hidden common
causes, or mitigate the effect of spurious features using multi-domain data. In
this work, we investigate how fine-tuned pre-trained language models aid
generalizability from single-domain scenarios under mild assumptions, targeting
more general and practical real-world scenarios. We show that a robust
representation can be derived through a so-called causal front-door adjustment,
based on a decomposition assumption, using fine-tuned representations as a
source of data augmentation. Comprehensive experiments in both synthetic and
real-world settings demonstrate the superior generalizability of the proposed
method compared to existing approaches. Our work thus sheds light on the domain
generalization problem by introducing links between fine-tuning and causal
mechanisms into representation learning.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Efficiently Computing Susceptibility to Context in Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14361v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14361v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Tianyu Liu, Kevin Du, Mrinmaya Sachan, Ryan Cotterell
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  One strength of modern language models is their ability to incorporate
information from a user-input context when answering queries. However, they are
not equally sensitive to the subtle changes to that context. To quantify this,
Du et al. (2024) gives an information-theoretic metric to measure such
sensitivity. Their metric, susceptibility, is defined as the degree to which
contexts can influence a model's response to a query at a distributional level.
However, exactly computing susceptibility is difficult and, thus, Du et al.
(2024) falls back on a Monte Carlo approximation. Due to the large number of
samples required, the Monte Carlo approximation is inefficient in practice. As
a faster alternative, we propose Fisher susceptibility, an efficient method to
estimate the susceptibility based on Fisher information. Empirically, we
validate that Fisher susceptibility is comparable to Monte Carlo estimated
susceptibility across a diverse set of query domains despite its being
$70\times$ faster. Exploiting the improved efficiency, we apply Fisher
susceptibility to analyze factors affecting the susceptibility of language
models. We observe that larger models are as susceptible as smaller ones.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Critical Questions Generation: Motivation and Challenges <span class="chip">CoNLL 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14335v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14335v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Blanca Calvo Figueras, Rodrigo Agerri
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The development of Large Language Models (LLMs) has brought impressive
performances on mitigation strategies against misinformation, such as
counterargument generation. However, LLMs are still seriously hindered by
outdated knowledge and by their tendency to generate hallucinated content. In
order to circumvent these issues, we propose a new task, namely, Critical
Questions Generation, consisting of processing an argumentative text to
generate the critical questions (CQs) raised by it. In argumentation theory CQs
are tools designed to lay bare the blind spots of an argument by pointing at
the information it could be missing. Thus, instead of trying to deploy LLMs to
produce knowledgeable and relevant counterarguments, we use them to question
arguments, without requiring any external knowledge. Research on CQs Generation
using LLMs requires a reference dataset for large scale experimentation. Thus,
in this work we investigate two complementary methods to create such a
resource: (i) instantiating CQs templates as defined by Walton's argumentation
theory and (ii), using LLMs as CQs generators. By doing so, we contribute with
a procedure to establish what is a valid CQ and conclude that, while LLMs are
reasonable CQ generators, they still have a wide margin for improvement in this
task.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>14 pages, 3 figures, 7 tables, to be published in the 28th Conference
  on Computational Natural Language Learning (CoNLL 2024)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ LoGU: Long-form Generation with Uncertainty Expressions 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14309v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14309v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ruihan Yang, Caiqi Zhang, Zhisong Zhang, Xinting Huang, Sen Yang, Nigel Collier, Dong Yu, Deqing Yang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  While Large Language Models (LLMs) demonstrate impressive capabilities, they
still struggle with generating factually incorrect content (i.e.,
hallucinations). A promising approach to mitigate this issue is enabling models
to express uncertainty when unsure. Previous research on uncertainty modeling
has primarily focused on short-form QA, but realworld applications often
require much longer responses. In this work, we introduce the task of Long-form
Generation with Uncertainty(LoGU). We identify two key challenges: Uncertainty
Suppression, where models hesitate to express uncertainty, and Uncertainty
Misalignment, where models convey uncertainty inaccurately. To tackle these
challenges, we propose a refinement-based data collection framework and a
two-stage training pipeline. Our framework adopts a divide-and-conquer
strategy, refining uncertainty based on atomic claims. The collected data are
then used in training through supervised fine-tuning (SFT) and direct
preference optimization (DPO) to enhance uncertainty expression. Extensive
experiments on three long-form instruction following datasets show that our
method significantly improves accuracy, reduces hallucinations, and maintains
the comprehensiveness of responses.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ SwaQuAD-24: QA Benchmark <span class="highlight-title">Dataset</span> in Swahili 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14289v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14289v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Alfred Malengo Kondoro
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper proposes the creation of a Swahili Question Answering (QA)
benchmark dataset, aimed at addressing the underrepresentation of Swahili in
natural language processing (NLP). Drawing from established benchmarks like
SQuAD, GLUE, KenSwQuAD, and KLUE, the dataset will focus on providing
high-quality, annotated question-answer pairs that capture the linguistic
diversity and complexity of Swahili. The dataset is designed to support a
variety of applications, including machine translation, information retrieval,
and social services like healthcare chatbots. Ethical considerations, such as
data privacy, bias mitigation, and inclusivity, are central to the dataset
development. Additionally, the paper outlines future expansion plans to include
domain-specific content, multimodal integration, and broader crowdsourcing
efforts. The Swahili QA dataset aims to foster technological innovation in East
Africa and provide an essential resource for NLP research and applications in
low-resource languages.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ EcomEdit: An Automated E-commerce Knowledge Editing Framework for
  Enhanced Product and Purchase Intention Understanding 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14276v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14276v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ching Ming Samuel Lau, Weiqi Wang, Haochen Shi, Baixuan Xu, Jiaxin Bai, Yangqiu Song
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Knowledge Editing (KE) aims to correct and update factual information in
Large Language Models (LLMs) to ensure accuracy and relevance without
computationally expensive fine-tuning. Though it has been proven effective in
several domains, limited work has focused on its application within the
e-commerce sector. However, there are naturally occurring scenarios that make
KE necessary in this domain, such as the timely updating of product features
and trending purchase intentions by customers, which necessitate further
exploration. In this paper, we pioneer the application of KE in the e-commerce
domain by presenting ECOMEDIT, an automated e-commerce knowledge editing
framework tailored for e-commerce-related knowledge and tasks. Our framework
leverages more powerful LLMs as judges to enable automatic knowledge conflict
detection and incorporates conceptualization to enhance the semantic coverage
of the knowledge to be edited. Through extensive experiments, we demonstrate
the effectiveness of ECOMEDIT in improving LLMs' understanding of product
descriptions and purchase intentions. We also show that LLMs, after our
editing, can achieve stronger performance on downstream e-commerce tasks.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ REEF: Representation Encoding Fingerprints for Large Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14273v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14273v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jie Zhang, Dongrui Liu, Chen Qian, Linfeng Zhang, Yong Liu, Yu Qiao, Jing Shao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Protecting the intellectual property of open-source Large Language Models
(LLMs) is very important, because training LLMs costs extensive computational
resources and data. Therefore, model owners and third parties need to identify
whether a suspect model is a subsequent development of the victim model. To
this end, we propose a training-free REEF to identify the relationship between
the suspect and victim models from the perspective of LLMs' feature
representations. Specifically, REEF computes and compares the centered kernel
alignment similarity between the representations of a suspect model and a
victim model on the same samples. This training-free REEF does not impair the
model's general capabilities and is robust to sequential fine-tuning, pruning,
model merging, and permutations. In this way, REEF provides a simple and
effective way for third parties and models' owners to protect LLMs'
intellectual property together. The code is available at
https://github.com/tmylla/REEF.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ MoDification: Mixture of Depths Made Easy 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14268v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14268v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Chen Zhang, Meizhi Zhong, Qimeng Wang, Xuantao Lu, Zheyu Ye, Chengqiang Lu, Yan Gao, Yao Hu, Kehai Chen, Min Zhang, Dawei Song
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Long-context efficiency has recently become a trending topic in serving large
language models (LLMs). And mixture of depths (MoD) is proposed as a perfect
fit to bring down both latency and memory. In this paper, however, we discover
that MoD can barely transform existing LLMs without costly training over an
extensive number of tokens. To enable the transformations from any LLMs to MoD
ones, we showcase top-k operator in MoD should be promoted to threshold-p
operator, and refinement to architecture and data should also be crafted along.
All these designs form our method termed MoDification. Through a comprehensive
set of experiments covering model scales from 3B to 70B, we exhibit
MoDification strikes an excellent balance between efficiency and effectiveness.
MoDification can achieve up to ~1.2x speedup in latency and ~1.8x reduction in
memory compared to original LLMs especially in long-context applications.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>12 pages, 9 figures, 5 tables, work in progress</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Good Parenting is all you need -- Multi-agentic LLM Hallucination
  Mitigation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14262v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14262v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                         Edward,  Kwartler, Matthew Berman, Alan Aqrawi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This study explores the ability of Large Language Model (LLM) agents to
detect and correct hallucinations in AI-generated content. A primary agent was
tasked with creating a blog about a fictional Danish artist named Flipfloppidy,
which was then reviewed by another agent for factual inaccuracies. Most LLMs
hallucinated the existence of this artist. Across 4,900 test runs involving
various combinations of primary and reviewing agents, advanced AI models such
as Llama3-70b and GPT-4 variants demonstrated near-perfect accuracy in
identifying hallucinations and successfully revised outputs in 85% to 100% of
cases following feedback. These findings underscore the potential of advanced
AI models to significantly enhance the accuracy and reliability of generated
content, providing a promising approach to improving AI workflow orchestration.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Beyond Binary: Towards Fine-Grained LLM-Generated Text Detection via
  Role Recognition and Involvement Measurement 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14259v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14259v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zihao Cheng, Li Zhou, Feng Jiang, Benyou Wang, Haizhou Li
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The rapid development of large language models (LLMs), like ChatGPT, has
resulted in the widespread presence of LLM-generated content on social media
platforms, raising concerns about misinformation, data biases, and privacy
violations, which can undermine trust in online discourse. While detecting
LLM-generated content is crucial for mitigating these risks, current methods
often focus on binary classification, failing to address the complexities of
real-world scenarios like human-AI collaboration. To move beyond binary
classification and address these challenges, we propose a new paradigm for
detecting LLM-generated content. This approach introduces two novel tasks: LLM
Role Recognition (LLM-RR), a multi-class classification task that identifies
specific roles of LLM in content generation, and LLM Influence Measurement
(LLM-IM), a regression task that quantifies the extent of LLM involvement in
content creation. To support these tasks, we propose LLMDetect, a benchmark
designed to evaluate detectors' performance on these new tasks. LLMDetect
includes the Hybrid News Detection Corpus (HNDC) for training detectors, as
well as DetectEval, a comprehensive evaluation suite that considers five
distinct cross-context variations and multi-intensity variations within the
same LLM role. This allows for a thorough assessment of detectors'
generalization and robustness across diverse contexts. Our empirical validation
of 10 baseline detection methods demonstrates that fine-tuned PLM-based models
consistently outperform others on both tasks, while advanced LLMs face
challenges in accurately detecting their own generated content. Our
experimental results and analysis offer insights for developing more effective
detection models for LLM-generated content. This research enhances the
understanding of LLM-generated content and establishes a foundation for more
nuanced detection methodologies.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Social Media, Large Language Models, LLM-generated Text Detection,
  AI-assisted News Detection</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Nova: An Iterative Planning and Search Approach to Enhance Novelty and
  Diversity of LLM Generated Ideas 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14255v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14255v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xiang Hu, Hongyu Fu, Jinge Wang, Yifeng Wang, Zhikun Li, Renjun Xu, Yu Lu, Yaochu Jin, Lili Pan, Zhenzhong Lan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Scientific innovation is pivotal for humanity, and harnessing large language
models (LLMs) to generate research ideas could transform discovery. However,
existing LLMs often produce simplistic and repetitive suggestions due to their
limited ability in acquiring external knowledge for innovation. To address this
problem, we introduce an enhanced planning and search methodology designed to
boost the creative potential of LLM-based systems. Our approach involves an
iterative process to purposely plan the retrieval of external knowledge,
progressively enriching the idea generation with broader and deeper insights.
Validation through automated and human assessments indicates that our framework
substantially elevates the quality of generated ideas, particularly in novelty
and diversity. The number of unique novel ideas produced by our framework is
3.4 times higher than without it. Moreover, our method outperforms the current
state-of-the-art, generating at least 2.5 times more top-rated ideas based on
170 seed papers in a Swiss Tournament evaluation.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Synthesizing Post-Training Data for LLMs through Multi-Agent Simulation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14251v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14251v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Shuo Tang, Xianghe Pang, Zexi Liu, Bohan Tang, Rui Ye, Xiaowen Dong, Yanfeng Wang, Siheng Chen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Post-training is essential for enabling large language models (LLMs) to
follow human instructions. Inspired by the recent success of using LLMs to
simulate human society, we leverage multi-agent simulation to automatically
generate diverse text-based scenarios, capturing a wide range of real-world
human needs. We propose MATRIX, a multi-agent simulator that creates realistic
and scalable scenarios. Leveraging these outputs, we introduce a novel
scenario-driven instruction generator MATRIX-Gen for controllable and highly
realistic data synthesis. Extensive experiments demonstrate that our framework
effectively generates both general and domain-specific data. Notably, on
AlpacaEval 2 and Arena-Hard benchmarks, Llama-3-8B-Base, post-trained on
datasets synthesized by MATRIX-Gen with just 20K instruction-response pairs,
outperforms Meta's Llama-3-8B-Instruct model, which was trained on over 10M
pairs; see our project at https://github.com/ShuoTang123/MATRIX-Gen.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Addressing Blind Guessing: Calibration of Selection Bias in
  Multiple-Choice Question Answering by Video Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14248v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14248v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Olga Loginova, Oleksandr Bezrukov, Alexey Kravets
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Evaluating Video Language Models (VLMs) is a challenging task. Due to its
transparency, Multiple-Choice Question Answering (MCQA) is widely used to
measure the performance of these models through accuracy. However, existing
MCQA benchmarks fail to capture the full reasoning capabilities of VLMs due to
selection bias, when models disproportionately favor certain answer options
based on positional patterns observed during training. In this work, we conduct
a comprehensive empirical analysis of several VLM architectures across major
datasets designed to assess complex video-focused reasoning. We identify where
the bias is most pronounced and demonstrate to what extent model responses
reflect genuine understanding of video content and related questions, as
opposed to reliance on arbitrary patterns or superficial cues, such as answer
position. By decomposing the MCQA task and adapting fairness bias metrics to
VLMs, we introduce a post-processing calibration technique BOLD to balance this
bias. Our results show that reducing selection bias improves not only debiasing
metrics but also overall model performance, including Accuracy and F1 Mean
score. Our method, by suppressing "blind guessing", offers a more cost- and
time-effective approach to mitigating selection bias compared to existing
techniques. This study represents the first focused investigation of selection
bias in video-to-text LLM-powered models.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ A Novel Method to Metigate Demographic and Expert Bias in ICD Coding
  with Causal Inference 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14236v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14236v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Bin Zhang, Junli Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  ICD(International Classification of Diseases) coding involves assigning ICD
codes to patients visit based on their medical notes. Considering ICD coding as
a multi-label text classification task, researchers have developed
sophisticated methods. Despite progress, these models often suffer from label
imbalance and may develop spurious correlations with demographic factors.
Additionally, while human coders assign ICD codes, the inclusion of irrelevant
information from unrelated experts introduces biases. To combat these issues,
we propose a novel method to mitigate Demographic and Expert biases in ICD
coding through Causal Inference (DECI). We provide a novel causality-based
interpretation in ICD Coding that models make predictions by three distinct
pathways. And based counterfactual reasoning, DECI mitigate demographic and
expert biases. Experimental results show that DECI outperforms state-of-the-art
models, offering a significant advancement in accurate and unbiased ICD coding.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Towards Robust Knowledge Representations in Multilingual LLMs for
  Equivalence and Inheritance based Consistent Reasoning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14235v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14235v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Gaurav Arora, Srujana Merugu, Shreya Jain, Vaibhav Saxena
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Reasoning and linguistic skills form the cornerstone of human intelligence,
facilitating problem-solving and decision-making. Recent advances in Large
Language Models (LLMs) have led to impressive linguistic capabilities and
emergent reasoning behaviors, fueling widespread adoption across application
domains. However, LLMs still struggle with complex reasoning tasks,
highlighting their systemic limitations. In this work, we focus on evaluating
whether LLMs have the requisite representations to reason using two
foundational relationships: "equivalence" and "inheritance". We introduce novel
tasks and benchmarks spanning six languages and observe that current SOTA LLMs
often produce conflicting answers to the same questions across languages in
17.3-57.5% of cases and violate inheritance constraints in up to 37.2% cases.
To enhance consistency across languages, we propose novel "Compositional
Representations" where tokens are represented as composition of equivalent
tokens across languages, with resulting conflict reduction (up to -4.7%)
indicating benefits of shared LLM representations.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Unveiling Large Language Models Generated Texts: A Multi-Level
  Fine-Grained Detection Framework 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14231v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14231v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zhen Tao, Zhiyu Li, Runyu Chen, Dinghao Xi, Wei Xu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large language models (LLMs) have transformed human writing by enhancing
grammar correction, content expansion, and stylistic refinement. However, their
widespread use raises concerns about authorship, originality, and ethics, even
potentially threatening scholarly integrity. Existing detection methods, which
mainly rely on single-feature analysis and binary classification, often fail to
effectively identify LLM-generated text in academic contexts. To address these
challenges, we propose a novel Multi-level Fine-grained Detection (MFD)
framework that detects LLM-generated text by integrating low-level structural,
high-level semantic, and deep-level linguistic features, while conducting
sentence-level evaluations of lexicon, grammar, and syntax for comprehensive
analysis. To improve detection of subtle differences in LLM-generated text and
enhance robustness against paraphrasing, we apply two mainstream evasion
techniques to rewrite the text. These variations, along with original texts,
are used to train a text encoder via contrastive learning, extracting
high-level semantic features of sentence to boost detection generalization.
Furthermore, we leverage advanced LLM to analyze the entire text and extract
deep-level linguistic features, enhancing the model's ability to capture
complex patterns and nuances while effectively incorporating contextual
information. Extensive experiments on public datasets show that the MFD model
outperforms existing methods, achieving an MAE of 0.1346 and an accuracy of
88.56%. Our research provides institutions and publishers with an effective
mechanism to detect LLM-generated text, mitigating risks of compromised
authorship. Educators and editors can use the model's predictions to refine
verification and plagiarism prevention protocols, ensuring adherence to
standards.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Few-Shot Joint Multimodal Entity-Relation Extraction via
  Knowledge-Enhanced Cross-modal <span class="highlight-title">Prompt</span> Model <span class="chip">ACM MM 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14225v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14225v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Li Yuan, Yi Cai, Junsheng Huang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Joint Multimodal Entity-Relation Extraction (JMERE) is a challenging task
that aims to extract entities and their relations from text-image pairs in
social media posts. Existing methods for JMERE require large amounts of labeled
data. However, gathering and annotating fine-grained multimodal data for JMERE
poses significant challenges. Initially, we construct diverse and comprehensive
multimodal few-shot datasets fitted to the original data distribution. To
address the insufficient information in the few-shot setting, we introduce the
\textbf{K}nowledge-\textbf{E}nhanced \textbf{C}ross-modal \textbf{P}rompt
\textbf{M}odel (KECPM) for JMERE. This method can effectively address the
problem of insufficient information in the few-shot setting by guiding a large
language model to generate supplementary background knowledge. Our proposed
method comprises two stages: (1) a knowledge ingestion stage that dynamically
formulates prompts based on semantic similarity guide ChatGPT generating
relevant knowledge and employs self-reflection to refine the knowledge; (2) a
knowledge-enhanced language model stage that merges the auxiliary knowledge
with the original input and utilizes a transformer-based model to align with
JMERE's required output format. We extensively evaluate our approach on a
few-shot dataset derived from the JMERE dataset, demonstrating its superiority
over strong baselines in terms of both micro and macro F$_1$ scores.
Additionally, we present qualitative analyses and case studies to elucidate the
effectiveness of our model.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>accepted by ACM MM 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Paths-over-Graph: Knowledge Graph Enpowered Large Language Model
  Reasoning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14211v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14211v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xingyu Tan, Xiaoyang Wang, Qing Liu, Xiwei Xu, Xin Yuan, Wenjie Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large Language Models (LLMs) have achieved impressive results in various
tasks but struggle with hallucination problems and lack of relevant knowledge,
especially in deep complex reasoning and knowledge-intensive tasks. Knowledge
Graphs (KGs), which capture vast amounts of facts in a structured format, offer
a reliable source of knowledge for reasoning. However, existing KG-based LLM
reasoning methods face challenges like handling multi-hop reasoning,
multi-entity questions, and effectively utilizing graph structures. To address
these issues, we propose Paths-over-Graph (PoG), a novel method that enhances
LLM reasoning by integrating knowledge reasoning paths from KGs, improving the
interpretability and faithfulness of LLM outputs. PoG tackles multi-hop and
multi-entity questions through a three-phase dynamic multi-hop path
exploration, which combines the inherent knowledge of LLMs with factual
knowledge from KGs. In order to improve the efficiency, PoG prunes irrelevant
information from the graph exploration first and introduces efficient
three-step pruning techniques that incorporate graph structures, LLM prompting,
and a pre-trained language model (e.g., SBERT) to effectively narrow down the
explored candidate paths. This ensures all reasoning paths contain highly
relevant information captured from KGs, making the reasoning faithful and
interpretable in problem-solving. PoG innovatively utilizes graph structure to
prune the irrelevant noise and represents the first method to implement
multi-entity deep path detection on KGs for LLM reasoning tasks. Comprehensive
experiments on five benchmark KGQA datasets demonstrate PoG outperforms the
state-of-the-art method ToG across GPT-3.5-Turbo and GPT-4, achieving an
average accuracy improvement of 18.9%. Notably, PoG with GPT-3.5-Turbo
surpasses ToG with GPT-4 by up to 23.9%.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Montessori-Instruct: Generate Influential Training Data Tailored for
  Student Learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14208v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14208v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xiaochuan Li, Zichun Yu, Chenyan Xiong
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Synthetic data has been widely used to train large language models, but their
generative nature inevitably introduces noisy, non-informative, and misleading
learning signals. In this paper, we propose Montessori-Instruct, a novel data
synthesis framework that tailors the data synthesis ability of the teacher
language model toward the student language model's learning process.
Specifically, we utilize local data influence of synthetic training data points
on students to characterize students' learning preferences. Then, we train the
teacher model with Direct Preference Optimization (DPO) to generate synthetic
data tailored toward student learning preferences. Experiments with
Llama3-8B-Instruct (teacher) and Llama3-8B (student) on Alpaca Eval and
MT-Bench demonstrate that Montessori-Instruct significantly outperforms
standard synthesis methods by 18.35\% and 46.24\% relatively. Our method also
beats data synthesized by a stronger teacher model, GPT-4o. Further analysis
confirms the benefits of teacher's learning to generate more influential
training data in the student's improved learning, the advantages of local data
influence in accurately measuring student preferences, and the robustness of
Montessori-Instruct across different student models. Our code and data are
open-sourced at https://github.com/cxcscmu/Montessori-Instruct.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Codes and data are open-sourced at
  https://github.com/cxcscmu/Montessori-Instruct</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ MediTOD: An English Dialogue <span class="highlight-title">Dataset</span> for Medical History Taking with
  Comprehensive Annotations <span class="chip">EMNLP2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14204v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14204v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Vishal Vivek Saley, Goonjan Saha, Rocktim Jyoti Das, Dinesh Raghu,  Mausam
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Medical task-oriented dialogue systems can assist doctors by collecting
patient medical history, aiding in diagnosis, or guiding treatment selection,
thereby reducing doctor burnout and expanding access to medical services.
However, doctor-patient dialogue datasets are not readily available, primarily
due to privacy regulations. Moreover, existing datasets lack comprehensive
annotations involving medical slots and their different attributes, such as
symptoms and their onset, progression, and severity. These comprehensive
annotations are crucial for accurate diagnosis. Finally, most existing datasets
are non-English, limiting their utility for the larger research community.
  In response, we introduce MediTOD, a new dataset of doctor-patient dialogues
in English for the medical history-taking task. Collaborating with doctors, we
devise a questionnaire-based labeling scheme tailored to the medical domain.
Then, medical professionals create the dataset with high-quality comprehensive
annotations, capturing medical slots and their attributes. We establish
benchmarks in supervised and few-shot settings on MediTOD for natural language
understanding, policy learning, and natural language generation subtasks,
evaluating models from both TOD and biomedical domains. We make MediTOD
publicly available for future research.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>EMNLP2024 Camera Ready Version</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Rationale Behind Essay Scores: Enhancing S-LLM's Multi-Trait Essay
  Scoring with Rationale Generated by LLMs 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14202v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14202v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        SeongYeub Chu, JongWoo Kim, Bryan Wong, MunYong Yi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Existing automated essay scoring (AES) has solely relied on essay text
without using explanatory rationales for the scores, thereby forgoing an
opportunity to capture the specific aspects evaluated by rubric indicators in a
fine-grained manner. This paper introduces Rationale-based Multiple Trait
Scoring (RMTS), a novel approach for multi-trait essay scoring that integrates
prompt-engineering-based large language models (LLMs) with a fine-tuning-based
essay scoring model using a smaller large language model (S-LLM). RMTS uses an
LLM-based trait-wise rationale generation system where a separate LLM agent
generates trait-specific rationales based on rubric guidelines, which the
scoring model uses to accurately predict multi-trait scores. Extensive
experiments on benchmark datasets, including ASAP, ASAP++, and Feedback Prize,
show that RMTS significantly outperforms state-of-the-art models and vanilla
S-LLMs in trait-specific scoring. By assisting quantitative assessment with
fine-grained qualitative rationales, RMTS enhances the trait-wise reliability,
providing partial explanations about essays.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ E3D-<span class="highlight-title">GPT</span>: Enhanced 3D Visual Foundation for Medical Vision-Language Model 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14200v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14200v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Haoran Lai, Zihang Jiang, Qingsong Yao, Rongsheng Wang, Zhiyang He, Xiaodong Tao, Wei Wei, Weifu Lv, S. Kevin Zhou
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The development of 3D medical vision-language models holds significant
potential for disease diagnosis and patient treatment. However, compared to 2D
medical images, 3D medical images, such as CT scans, face challenges related to
limited training data and high dimension, which severely restrict the progress
of 3D medical vision-language models. To address these issues, we collect a
large amount of unlabeled 3D CT data and utilize self-supervised learning to
construct a 3D visual foundation model for extracting 3D visual features. Then,
we apply 3D spatial convolutions to aggregate and project high-level image
features, reducing computational complexity while preserving spatial
information. We also construct two instruction-tuning datasets based on BIMCV-R
and CT-RATE to fine-tune the 3D vision-language model. Our model demonstrates
superior performance compared to existing methods in report generation, visual
question answering, and disease diagnosis. Code and data will be made publicly
available soon.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Supervised Chain of Thought 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14198v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14198v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xiang Zhang, Dujian Ding
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large Language Models (LLMs) have revolutionized natural language processing
and hold immense potential for advancing Artificial Intelligence. However, the
core architecture of most mainstream LLMs -- the Transformer -- has inherent
limitations in computational depth, rendering them theoretically incapable of
solving many reasoning tasks that demand increasingly deep computations. Chain
of Thought (CoT) prompting has emerged as a technique to address these
architectural limitations, as evidenced by several theoretical studies. It
offers a promising approach to solving complex reasoning tasks that were
previously beyond the capabilities of these models. Despite its successes, CoT
and its variants (such as Tree of Thought, Graph of Thought, etc.) rely on a
"one-prompt-for-all" approach, using a single prompt structure (e.g., "think
step by step") for a wide range of tasks -- from counting and sorting to
solving mathematical and algorithmic problems. This approach poses significant
challenges for models to generate the correct reasoning steps, as the model
must navigate through a vast prompt template space to find the appropriate
template for each task. In this work, we build upon previous theoretical
analyses of CoT to demonstrate how the one-prompt-for-all approach can
negatively affect the computability of LLMs. We partition the solution search
space into two: the prompt space and the answer space. Our findings show that
task-specific supervision is essential for navigating the prompt space
accurately and achieving optimal performance. Through experiments with
state-of-the-art LLMs, we reveal a gap in reasoning performance when
supervision is applied versus when it is not.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Speciesism in Natural Language Processing Research 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14194v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14194v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Masashi Takeshita, Rafal Rzepka
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Natural Language Processing (NLP) research on AI Safety and social bias in AI
has focused on safety for humans and social bias against human minorities.
However, some AI ethicists have argued that the moral significance of nonhuman
animals has been ignored in AI research. Therefore, the purpose of this study
is to investigate whether there is speciesism, i.e., discrimination against
nonhuman animals, in NLP research. First, we explain why nonhuman animals are
relevant in NLP research. Next, we survey the findings of existing research on
speciesism in NLP researchers, data, and models and further investigate this
problem in this study. The findings of this study suggest that speciesism
exists within researchers, data, and models, respectively. Specifically, our
survey and experiments show that (a) among NLP researchers, even those who
study social bias in AI, do not recognize speciesism or speciesist bias; (b)
among NLP data, speciesist bias is inherent in the data annotated in the
datasets used to evaluate NLP models; (c) OpenAI GPTs, recent NLP models,
exhibit speciesist bias by default. Finally, we discuss how we can reduce
speciesism in NLP research.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>This article is a preprint and has not been peer-reviewed. The
  postprint has been accepted for publication in AI and Ethics. Please cite the
  final version of the article once it is published</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ MetaAlign: Align Large Language Models with Diverse Preferences during
  Inference Time 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14184v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14184v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mozhi Zhang, Pengyu Wang, Chenkun Tan, Mianqiu Huang, Dong Zhang, Yaqian Zhou, Xipeng Qiu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large Language Models (LLMs) acquire extensive knowledge and remarkable
abilities from extensive text corpora, making them powerful tools for various
applications. To make LLMs more usable, aligning them with human preferences is
essential. Existing alignment techniques, such as Reinforcement Learning from
Human Feedback (RLHF) and Direct Preference Optimization (DPO), typically embed
predefined preferences directly within the model's parameters. These methods,
however, often result in a static alignment that can not account for the
diversity of human preferences in practical applications. In response to this
challenge, we propose an effective method, \textbf{MetaAlign}, which aims to
help LLMs dynamically align with various explicit or implicit preferences
specified at inference time. Experimental results show that LLMs optimized on
our meticulously constructed MetaAlign Dataset can effectively align with any
preferences specified at the inference stage, validating the feasibility of
MetaAlign. We hope that our work can provide some insights into the alignment
of language models.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>19 pages, 6 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ LabSafety Bench: Benchmarking LLMs on Safety Issues in Scientific Labs 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14182v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14182v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yujun Zhou, Jingdong Yang, Kehan Guo, Pin-Yu Chen, Tian Gao, Werner Geyer, Nuno Moniz, Nitesh V Chawla, Xiangliang Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Laboratory accidents pose significant risks to human life and property,
underscoring the importance of robust safety protocols. Despite advancements in
safety training, laboratory personnel may still unknowingly engage in unsafe
practices. With the increasing reliance on large language models (LLMs) for
guidance in various fields, including laboratory settings, there is a growing
concern about their reliability in critical safety-related decision-making.
Unlike trained human researchers, LLMs lack formal lab safety education,
raising questions about their ability to provide safe and accurate guidance.
Existing research on LLM trustworthiness primarily focuses on issues such as
ethical compliance, truthfulness, and fairness but fails to fully cover
safety-critical real-world applications, like lab safety. To address this gap,
we propose the Laboratory Safety Benchmark (LabSafety Bench), a comprehensive
evaluation framework based on a new taxonomy aligned with Occupational Safety
and Health Administration (OSHA) protocols. This benchmark includes 765
multiple-choice questions verified by human experts, assessing LLMs and vision
language models (VLMs) performance in lab safety contexts. Our evaluations
demonstrate that while GPT-4o outperforms human participants, it is still prone
to critical errors, highlighting the risks of relying on LLMs in
safety-critical environments. Our findings emphasize the need for specialized
benchmarks to accurately assess the trustworthiness of LLMs in real-world
safety applications.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>50 pages, 19 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ XForecast: Evaluating Natural Language Explanations for Time Series
  Forecasting 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14180v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14180v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Taha Aksu, Chenghao Liu, Amrita Saha, Sarah Tan, Caiming Xiong, Doyen Sahoo
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Time series forecasting aids decision-making, especially for stakeholders who
rely on accurate predictions, making it very important to understand and
explain these models to ensure informed decisions. Traditional explainable AI
(XAI) methods, which underline feature or temporal importance, often require
expert knowledge. In contrast, natural language explanations (NLEs) are more
accessible to laypeople. However, evaluating forecast NLEs is difficult due to
the complex causal relationships in time series data. To address this, we
introduce two new performance metrics based on simulatability, assessing how
well a human surrogate can predict model forecasts using the explanations.
Experiments show these metrics differentiate good from poor explanations and
align with human judgments. Utilizing these metrics, we further evaluate the
ability of state-of-the-art large language models (LLMs) to generate
explanations for time series data, finding that numerical reasoning, rather
than model size, is the main factor influencing explanation quality.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ MultiChartQA: Benchmarking Vision-Language Models on Multi-Chart
  Problems 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14179v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14179v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zifeng Zhu, Mengzhao Jia, Zhihan Zhang, Lang Li, Meng Jiang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Multimodal Large Language Models (MLLMs) have demonstrated impressive
abilities across various tasks, including visual question answering and chart
comprehension, yet existing benchmarks for chart-related tasks fall short in
capturing the complexity of real-world multi-chart scenarios. Current
benchmarks primarily focus on single-chart tasks, neglecting the multi-hop
reasoning required to extract and integrate information from multiple charts,
which is essential in practical applications. To fill this gap, we introduce
MultiChartQA, a benchmark that evaluates MLLMs' capabilities in four key areas:
direct question answering, parallel question answering, comparative reasoning,
and sequential reasoning. Our evaluation of a wide range of MLLMs reveals
significant performance gaps compared to humans. These results highlight the
challenges in multi-chart comprehension and the potential of MultiChartQA to
drive advancements in this field. Our code and data are available at
https://github.com/Zivenzhu/Multi-chart-QA
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>18 pages, 9 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ LLM The Genius Paradox: A Linguistic and Math Expert's Struggle with
  Simple Word-based Counting Problems 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14166v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14166v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Nan Xu, Xuezhe Ma
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Interestingly, LLMs yet struggle with some basic tasks that humans find
trivial to handle, e.g., counting the number of character r's in the word
"strawberry". There are several popular conjectures (e.g., tokenization,
architecture and training data) regarding the reason for deficiency of LLMs in
simple word-based counting problems, sharing the similar belief that such
failure stems from model pretraining hence probably inevitable during
deployment. In this paper, we carefully design multiple evaluation settings to
investigate validity of prevalent conjectures. Meanwhile, we measure
transferability of advanced mathematical and coding reasoning capabilities from
specialized LLMs to simple counting tasks. Although specialized LLMs suffer
from counting problems as well, we find conjectures about inherent deficiency
of LLMs invalid and further seek opportunities to elicit knowledge and
capabilities from LLMs that are beneficial to counting tasks. Compared with
strategies such as finetuning and in-context learning that are commonly adopted
to enhance performance on new or challenging tasks, we show that engaging
reasoning is the most robust and efficient way to help LLMs better perceive
tasks with more accurate responses.
  We hope our conjecture validation design could provide insights into the
study of future critical failure modes of LLMs. Based on challenges in
transferring advanced capabilities to much simpler tasks, we call for more
attention to model capability acquisition and evaluation. We also highlight the
importance of cultivating consciousness of "reasoning before responding" during
model pretraining.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Automated Genre-Aware Article Scoring and Feedback Using Large Language
  Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14165v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14165v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Chihang Wang, Yuxin Dong, Zhenhong Zhang, Ruotong Wang, Shuo Wang, Jiajing Chen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper focuses on the development of an advanced intelligent article
scoring system that not only assesses the overall quality of written work but
also offers detailed feature-based scoring tailored to various article genres.
By integrating the pre-trained BERT model with the large language model
Chat-GPT, the system gains a deep understanding of both the content and
structure of the text, enabling it to provide a thorough evaluation along with
targeted suggestions for improvement. Experimental results demonstrate that
this system outperforms traditional scoring methods across multiple public
datasets, particularly in feature-based assessments, offering a more accurate
reflection of the quality of different article types. Moreover, the system
generates personalized feedback to assist users in enhancing their writing
skills, underscoring the potential and practical value of automated scoring
technologies in educational contexts.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Beyond Autoregression: Discrete Diffusion for Complex Reasoning and
  Planning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14157v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14157v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jiacheng Ye, Jiahui Gao, Shansan Gong, Lin Zheng, Xin Jiang, Zhenguo Li, Lingpeng Kong
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Autoregressive language models, despite their impressive capabilities,
struggle with complex reasoning and long-term planning tasks. We introduce
discrete diffusion models as a novel solution to these challenges. Through the
lens of subgoal imbalance, we demonstrate how diffusion models effectively
learn difficult subgoals that elude autoregressive approaches. We propose
Multi-granularity Diffusion Modeling (MDM), which prioritizes subgoals based on
difficulty during learning. On complex tasks like Countdown, Sudoku, and
Boolean Satisfiability Problems, MDM significantly outperforms autoregressive
models without using search techniques. For instance, MDM achieves 91.5\% and
100\% accuracy on Countdown and Sudoku, respectively, compared to 45.8\% and
20.7\% for autoregressive models. Our work highlights the potential of
diffusion-based approaches in advancing AI capabilities for sophisticated
language understanding and problem-solving tasks.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Towards Faithful Natural Language Explanations: A Study Using Activation
  Patching in Large Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14155v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14155v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Wei Jie Yeo, Ranjan Satapthy, Erik Cambria
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large Language Models (LLMs) are capable of generating persuasive Natural
Language Explanations (NLEs) to justify their answers. However, the
faithfulness of these explanations should not be readily trusted at face value.
Recent studies have proposed various methods to measure the faithfulness of
NLEs, typically by inserting perturbations at the explanation or feature level.
We argue that these approaches are neither comprehensive nor correctly designed
according to the established definition of faithfulness. Moreover, we highlight
the risks of grounding faithfulness findings on out-of-distribution samples. In
this work, we leverage a causal mediation technique called activation patching,
to measure the faithfulness of an explanation towards supporting the explained
answer. Our proposed metric, Causal Faithfulness quantifies the consistency of
causal attributions between explanations and the corresponding model outputs as
the indicator of faithfulness. We experimented across models varying from 2B to
27B parameters and found that models that underwent alignment tuning tend to
produce more faithful and plausible explanations. We find that Causal
Faithfulness is a promising improvement over existing faithfulness tests by
taking into account the model's internal computations and avoiding out of
distribution concerns that could otherwise undermine the validity of
faithfulness assessments. We release the code in
\url{https://github.com/wj210/Causal-Faithfulness}
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Under review</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ SRAP-Agent: Simulating and Optimizing Scarce Resource Allocation Policy
  with LLM-based Agent 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14152v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14152v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jiarui Ji, Yang Li, Hongtao Liu, Zhicheng Du, Zhewei Wei, Weiran Shen, Qi Qi, Yankai Lin
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Public scarce resource allocation plays a crucial role in economics as it
directly influences the efficiency and equity in society. Traditional studies
including theoretical model-based, empirical study-based and simulation-based
methods encounter limitations due to the idealized assumption of complete
information and individual rationality, as well as constraints posed by limited
available data. In this work, we propose an innovative framework, SRAP-Agent
(Simulating and Optimizing Scarce Resource Allocation Policy with LLM-based
Agent), which integrates Large Language Models (LLMs) into economic
simulations, aiming to bridge the gap between theoretical models and real-world
dynamics. Using public housing allocation scenarios as a case study, we conduct
extensive policy simulation experiments to verify the feasibility and
effectiveness of the SRAP-Agent and employ the Policy Optimization Algorithm
with certain optimization objectives. The source code can be found in
https://github.com/jijiarui-cather/SRAPAgent_Framework
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Utilizing Large Language Models for Event Deconstruction to Enhance
  Multimodal Aspect-Based Sentiment Analysis 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14150v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14150v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xiaoyong Huang, Heli Sun, Qunshu Gao, Wenjie Huang, Ruichen Cao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  With the rapid development of the internet, the richness of User-Generated
Contentcontinues to increase, making Multimodal Aspect-Based Sentiment Analysis
(MABSA) a research hotspot. Existing studies have achieved certain results in
MABSA, but they have not effectively addressed the analytical challenges in
scenarios where multiple entities and sentiments coexist. This paper
innovatively introduces Large Language Models (LLMs) for event decomposition
and proposes a reinforcement learning framework for Multimodal Aspect-based
Sentiment Analysis (MABSA-RL) framework. This framework decomposes the original
text into a set of events using LLMs, reducing the complexity of analysis,
introducing reinforcement learning to optimize model parameters. Experimental
results show that MABSA-RL outperforms existing advanced methods on two
benchmark datasets. This paper provides a new research perspective and method
for multimodal aspect-level sentiment analysis.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Fine-Grained Verifiers: Preference Modeling as Next-token Prediction in
  Vision-Language Alignment 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14148v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14148v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Chenhang Cui, An Zhang, Yiyang Zhou, Zhaorun Chen, Gelei Deng, Huaxiu Yao, Tat-Seng Chua
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The recent advancements in large language models (LLMs) and pre-trained
vision models have accelerated the development of vision-language large models
(VLLMs), enhancing the interaction between visual and linguistic modalities.
Despite their notable success across various domains, VLLMs face challenges in
modality alignment, which can lead to issues like hallucinations and unsafe
content generation. Current alignment techniques often rely on coarse feedback
and external datasets, limiting scalability and performance. In this paper, we
propose FiSAO (Fine-Grained Self-Alignment Optimization), a novel
self-alignment method that utilizes the model's own visual encoder as a
fine-grained verifier to improve vision-language alignment without the need for
additional data. By leveraging token-level feedback from the vision encoder,
FiSAO significantly improves vision-language alignment, even surpassing
traditional preference tuning methods that require additional data. Through
both theoretical analysis and experimental validation, we demonstrate that
FiSAO effectively addresses the misalignment problem in VLLMs, marking the
first instance of token-level rewards being applied to such models.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>23 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ CAPE: A Chinese <span class="highlight-title">Dataset</span> for Appraisal-based Emotional Generation using
  Large Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14145v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14145v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        June M. Liu, He Cao, Renliang Sun, Rui Wang, Yu Li, Jiaxing Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Generating emotionally appropriate responses in conversations with large
language models presents a significant challenge due to the complexities of
human emotions and cognitive processes, which remain largely underexplored in
their critical role in social interactions. In this study, we introduce a
two-stage automatic data generation framework to create CAPE, a Chinese dataset
named Cognitive Appraisal theory-based Emotional corpus. This corpus
facilitates the generation of dialogues with contextually appropriate emotional
responses by accounting for diverse personal and situational factors. We
propose two tasks utilizing this dataset: emotion prediction and next utterance
prediction. Both automated and human evaluations demonstrate that agents
trained on our dataset can deliver responses that are more aligned with human
emotional expressions. Our study shows the potential for advancing emotional
expression in conversational agents, paving the way for more nuanced and
meaningful human-computer interactions.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ A Lightweight Multi Aspect Controlled Text Generation Solution For Large
  Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14144v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14144v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Chenyang Zhang, Jiayi Lin, Haibo Tong, Bingxuan Hou, Dongyu Zhang, Jialin Li, Junli Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large language models (LLMs) show remarkable abilities with instruction
tuning. However, they fail to achieve ideal tasks when lacking high-quality
instruction tuning data on target tasks. Multi-Aspect Controllable Text
Generation (MCTG) is a representative task for this dilemma, where aspect
datasets are usually biased and correlated. Existing work exploits additional
model structures and strategies for solutions, limiting adaptability to LLMs.
To activate MCTG ability of LLMs, we propose a lightweight MCTG pipeline based
on data augmentation. We analyze bias and correlations in traditional datasets,
and address these concerns with augmented control attributes and sentences.
Augmented datasets are feasible for instruction tuning. In our experiments,
LLMs perform better in MCTG after data augmentation, with a 20% accuracy rise
and less aspect correlations.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Coherence-Driven Multimodal Safety Dialogue with Active Learning for
  Embodied Agents 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14141v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14141v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Sabit Hassan, Hye-Young Chung, Xiang Zhi Tan, Malihe Alikhani
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  When assisting people in daily tasks, robots need to accurately interpret
visual cues and respond effectively in diverse safety-critical situations, such
as sharp objects on the floor. In this context, we present M-CoDAL, a
multimodal-dialogue system specifically designed for embodied agents to better
understand and communicate in safety-critical situations. The system leverages
discourse coherence relations to enhance its contextual understanding and
communication abilities. To train this system, we introduce a novel
clustering-based active learning mechanism that utilizes an external Large
Language Model (LLM) to identify informative instances. Our approach is
evaluated using a newly created multimodal dataset comprising 1K safety
violations extracted from 2K Reddit images. These violations are annotated
using a Large Multimodal Model (LMM) and verified by human annotators. Results
with this dataset demonstrate that our approach improves resolution of safety
situations, user sentiment, as well as safety of the conversation. Next, we
deploy our dialogue system on a Hello Robot Stretch robot and conduct a
within-subject user study with real-world participants. In the study,
participants role-play two safety scenarios with different levels of severity
with the robot and receive interventions from our model and a baseline system
powered by OpenAI's ChatGPT. The study results corroborate and extend the
findings from automated evaluation, showing that our proposed system is more
persuasive and competent in a real-world embodied agent setting.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ ViConsFormer: Constituting Meaningful Phrases of Scene Texts using
  <span class="highlight-title">Transformer</span>-based Method in Vietnamese Text-based Visual Question Answering 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14132v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14132v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Nghia Hieu Nguyen, Tho Thanh Quan, Ngan Luu-Thuy Nguyen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Text-based VQA is a challenging task that requires machines to use scene
texts in given images to yield the most appropriate answer for the given
question. The main challenge of text-based VQA is exploiting the meaning and
information from scene texts. Recent studies tackled this challenge by
considering the spatial information of scene texts in images via embedding 2D
coordinates of their bounding boxes. In this study, we follow the definition of
meaning from linguistics to introduce a novel method that effectively exploits
the information from scene texts written in Vietnamese. Experimental results
show that our proposed method obtains state-of-the-art results on two
large-scale Vietnamese Text-based VQA datasets. The implementation can be found
at this link.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Locate-then-edit for Multi-hop Factual Recall under Knowledge Editing 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.06331v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.06331v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zhuoran Zhang, Yongxiang Li, Zijian Kan, Keyuan Cheng, Lijie Hu, Di Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The locate-then-edit paradigm has shown significant promise for knowledge
editing (KE) in Large Language Models (LLMs). While previous methods perform
well on single-hop fact recall tasks, they consistently struggle with multi-hop
factual recall tasks involving newly edited knowledge. In this paper,
leveraging tools in mechanistic interpretability, we first identify that in
multi-hop tasks, LLMs tend to retrieve implicit subject knowledge from deeper
MLP layers, unlike single-hop tasks, which rely on earlier layers. This
distinction explains the poor performance of current methods in multi-hop
queries, as they primarily focus on editing shallow layers, leaving deeper
layers unchanged. To address this, we propose IFMET, a novel locate-then-edit
KE approach designed to edit both shallow and deep MLP layers. IFMET employs
multi-hop editing prompts and supplementary sets to locate and modify knowledge
across different reasoning stages. Experimental results demonstrate that IFMET
significantly improves performance on multi-hop factual recall tasks,
effectively overcoming the limitations of previous locate-then-edit methods.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>21 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ System 2 thinking in OpenAI's o1-p<span class="highlight-title">review</span> model: Near-perfect performance
  on a mathematics exam 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.07114v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.07114v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Joost de Winter, Dimitra Dodou, Yke Bauke Eisma
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The processes underlying human cognition are often divided into System 1,
which involves fast, intuitive thinking, and System 2, which involves slow,
deliberate reasoning. Previously, large language models were criticized for
lacking the deeper, more analytical capabilities of System 2. In September
2024, OpenAI introduced the o1 model series, designed to handle System 2-like
reasoning. While OpenAI's benchmarks are promising, independent validation is
still needed. In this study, we tested the o1-preview model twice on the Dutch
'Mathematics B' final exam. It scored a near-perfect 76 and 74 out of 76
points. For context, only 24 out of 16,414 students in the Netherlands achieved
a perfect score. By comparison, the GPT-4o model scored 66 and 62 out of 76,
well above the Dutch average of 40.63 points. Neither model had access to the
exam figures. Since there was a risk of model contamination (i.e., the
knowledge cutoff of o1-preview and GPT-4o was after the exam was published
online), we repeated the procedure with a new Mathematics B exam that was
published after the cutoff date. The results again indicated that o1-preview
performed strongly (97.8th percentile), which suggests that contamination was
not a factor. We also show that there is some variability in the output of
o1-preview, which means that sometimes there is 'luck' (the answer is correct)
or 'bad luck' (the output has diverged into something that is incorrect). We
demonstrate that a self-consistency approach, where repeated prompts are given
and the most common answer is selected, is a useful strategy for identifying
the correct answer. It is concluded that while OpenAI's new model series holds
great potential, certain risks must be considered.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Liger Kernel: Efficient Triton Kernels for LLM Training 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.10989v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.10989v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Pin-Lun Hsu, Yun Dai, Vignesh Kothapalli, Qingquan Song, Shao Tang, Siyu Zhu, Steven Shimizu, Shivam Sahni, Haowen Ning, Yanning Chen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Training Large Language Models (LLMs) efficiently at scale presents a
formidable challenge, driven by their ever-increasing computational demands and
the need for enhanced performance. In this work, we introduce Liger-Kernel, an
open-sourced set of Triton kernels developed specifically for LLM training.
With kernel optimization techniques like kernel operation fusing and input
chunking, our kernels achieve on average a 20% increase in training throughput
and a 60% reduction in GPU memory usage for popular LLMs compared to
HuggingFace implementations. In addition, Liger-Kernel is designed with
modularity, accessibility, and adaptability in mind, catering to both casual
and expert users. Comprehensive benchmarks and integration tests are built in
to ensure compatibility, performance, correctness, and convergence across
diverse computing environments and model architectures.
  The source code is available under a permissive license at:
github.com/linkedin/Liger-Kernel.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>17 pages, 12 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Contextual Document Embeddings 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.02525v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.02525v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        John X. Morris, Alexander M. Rush
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Dense document embeddings are central to neural retrieval. The dominant
paradigm is to train and construct embeddings by running encoders directly on
individual documents. In this work, we argue that these embeddings, while
effective, are implicitly out-of-context for targeted use cases of retrieval,
and that a contextualized document embedding should take into account both the
document and neighboring documents in context - analogous to contextualized
word embeddings. We propose two complementary methods for contextualized
document embeddings: first, an alternative contrastive learning objective that
explicitly incorporates the document neighbors into the intra-batch contextual
loss; second, a new contextual architecture that explicitly encodes neighbor
document information into the encoded representation. Results show that both
methods achieve better performance than biencoders in several settings, with
differences especially pronounced out-of-domain. We achieve state-of-the-art
results on the MTEB benchmark with no hard negative mining, score distillation,
dataset-specific instructions, intra-GPU example-sharing, or extremely large
batch sizes. Our method can be applied to improve performance on any
contrastive learning dataset and any biencoder.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Learning Linear Attention in Polynomial Time 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.10101v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.10101v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Morris Yau, Ekin Akyürek, Jiayuan Mao, Joshua B. Tenenbaum, Stefanie Jegelka, Jacob Andreas
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Previous research has explored the computational expressivity of Transformer
models in simulating Boolean circuits or Turing machines. However, the
learnability of these simulators from observational data has remained an open
question. Our study addresses this gap by providing the first polynomial-time
learnability results (specifically strong, agnostic PAC learning) for
single-layer Transformers with linear attention. We show that linear attention
may be viewed as a linear predictor in a suitably defined RKHS. As a
consequence, the problem of learning any linear transformer may be converted
into the problem of learning an ordinary linear predictor in an expanded
feature space, and any such predictor may be converted back into a multiheaded
linear transformer. Moving to generalization, we show how to efficiently
identify training datasets for which every empirical risk minimizer is
equivalent (up to trivial symmetries) to the linear Transformer that generated
the data, thereby guaranteeing the learned model will correctly generalize
across all inputs. Finally, we provide examples of computations expressible via
linear attention and therefore polynomial-time learnable, including associative
memories, finite automata, and a class of Universal Turing Machine (UTMs) with
polynomially bounded computation histories. We empirically validate our
theoretical findings on three tasks: learning random linear attention networks,
key--value associations, and learning to execute finite automata. Our findings
bridge a critical gap between theoretical expressivity and learnability of
Transformers, and show that flexible and general models of computation are
efficiently learnable.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ One size doesn't fit all: Predicting the Number of Examples for
  In-Context Learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2403.06402v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2403.06402v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Manish Chandra, Debasis Ganguly, Iadh Ounis
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In-context learning (ICL) refers to the process of adding a small number of
localized examples (ones that are semantically similar to the input) from a
training set of labelled data to an LLM's prompt with an objective to
effectively control the generative process seeking to improve the downstream
task performance. Existing ICL approaches use an identical number of examples
(a pre-configured hyper-parameter) for each data instance. Our work alleviates
the limitations of this 'one fits all' approach by dynamically predicting the
number of examples for each data instance to be used in few-shot inference with
LLMs. In particular, we employ a multi-label classifier, the parameters of
which are fitted using a training set, where the label for each instance in the
training set indicates if using a specific value of k (number of most similar
examples from 0 up to a maximum value) leads to correct k-shot downstream
predictions. Our experiments on a number of text classification benchmarks show
that AICL substantially outperforms standard ICL by up to 17%.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Movie101v2: Improved Movie Narration Benchmark 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2404.13370v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2404.13370v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zihao Yue, Yepeng Zhang, Ziheng Wang, Qin Jin
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Automatic movie narration aims to generate video-aligned plot descriptions to
assist visually impaired audiences. Unlike standard video captioning, it
involves not only describing key visual details but also inferring plots that
unfold across multiple movie shots, presenting distinct and complex challenges.
To advance this field, we introduce Movie101v2, a large-scale, bilingual
dataset with enhanced data quality specifically designed for movie narration.
Revisiting the task, we propose breaking down the ultimate goal of automatic
movie narration into three progressive stages, offering a clear roadmap with
corresponding evaluation metrics. Based on our new benchmark, we baseline a
range of large vision-language models, including GPT-4V, and conduct an
in-depth analysis of the challenges in narration generation. Our findings
highlight that achieving applicable movie narration generation is a fascinating
goal that requires significant research.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ MCQG-SRefine: Multiple Choice Question Generation and Evaluation with
  Iterative Self-Critique, Correction, and Comparison Feedback 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.13191v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.13191v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zonghai Yao, Aditya Parashar, Huixue Zhou, Won Seok Jang, Feiyun Ouyang, Zhichao Yang, Hong Yu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Automatic question generation (QG) is essential for AI and NLP, particularly
in intelligent tutoring, dialogue systems, and fact verification. Generating
multiple-choice questions (MCQG) for professional exams, like the United States
Medical Licensing Examination (USMLE), is particularly challenging, requiring
domain expertise and complex multi-hop reasoning for high-quality questions.
However, current large language models (LLMs) like GPT-4 struggle with
professional MCQG due to outdated knowledge, hallucination issues, and prompt
sensitivity, resulting in unsatisfactory quality and difficulty. To address
these challenges, we propose MCQG-SRefine, an LLM self-refine-based (Critique
and Correction) framework for converting medical cases into high-quality
USMLE-style questions. By integrating expert-driven prompt engineering with
iterative self-critique and self-correction feedback, MCQG-SRefine
significantly enhances human expert satisfaction regarding both the quality and
difficulty of the questions. Furthermore, we introduce an LLM-as-Judge-based
automatic metric to replace the complex and costly expert evaluation process,
ensuring reliable and expert-aligned assessments.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Equal contribution for the first two authors</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Advocating Character Error Rate for Multilingual ASR Evaluation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.07400v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.07400v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Thennal D K, Jesin James, Deepa P Gopinath, Muhammed Ashraf K
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Automatic speech recognition (ASR) systems have traditionally been evaluated
using English datasets, with the word error rate (WER) serving as the
predominant metric. WER's simplicity and ease of interpretation have
contributed to its widespread adoption, particularly for English. However, as
ASR systems expand to multilingual contexts, WER fails in various ways,
particularly with morphologically complex languages or those without clear word
boundaries. Our work documents the limitations of WER as an evaluation metric
and advocates for the character error rate (CER) as the primary metric in
multilingual ASR evaluation. We show that CER avoids many of the challenges WER
faces and exhibits greater consistency across writing systems. We support our
proposition by conducting human evaluations of ASR transcriptions in three
languages: Malayalam, English, and Arabic, which exhibit distinct morphological
characteristics. We show that CER correlates more closely with human judgments
than WER, even for English. To facilitate further research, we release our
human evaluation dataset for future benchmarking of ASR metrics. Our findings
suggest that CER should be prioritized, or at least supplemented, in
multilingual ASR evaluations to account for the varying linguistic
characteristics of different languages.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>4 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ English offensive text detection using CNN based Bi-GRU model 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.15652v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.15652v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Tonmoy Roy, Md Robiul Islam, Asif Ahammad Miazee, Anika Antara, Al Amin, Sunjim Hossain
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Over the years, the number of users of social media has increased
drastically. People frequently share their thoughts through social platforms,
and this leads to an increase in hate content. In this virtual community,
individuals share their views, express their feelings, and post photos, videos,
blogs, and more. Social networking sites like Facebook and Twitter provide
platforms to share vast amounts of content with a single click. However, these
platforms do not impose restrictions on the uploaded content, which may include
abusive language and explicit images unsuitable for social media. To resolve
this issue, a new idea must be implemented to divide the inappropriate content.
Numerous studies have been done to automate the process. In this paper, we
propose a new Bi-GRU-CNN model to classify whether the text is offensive or
not. The combination of the Bi-GRU and CNN models outperforms the existing
model.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>5 pages and 6 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Improving Reward Models with Synthetic Critiques 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.20850v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.20850v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zihuiwen Ye, Fraser Greenlee-Scott, Max Bartolo, Phil Blunsom, Jon Ander Campos, Matthias Gallé
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Reward models (RMs) play a critical role in aligning language models through
the process of reinforcement learning from human feedback. RMs are trained to
predict a score reflecting human preference, which requires significant time
and cost for human annotation. Additionally, RMs tend to quickly overfit on
superficial features in the training set, hindering their generalization
performance on unseen distributions. We propose a novel approach using
synthetic natural language critiques generated by large language models to
provide additional feedback, evaluating aspects such as instruction following,
correctness, and style. This offers richer signals and more robust features for
RMs to assess and score on. We demonstrate that high-quality critiques improve
the performance and data efficiency of RMs initialized from different
pretrained models, reducing the reliance on costly human annotations.
Furthermore, incorporating critiques improves both the interpretability and
robustness of RM training.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ With Ears to See and Eyes to Hear: Sound Symbolism Experiments with
  Multimodal Large Language Models <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.14917v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.14917v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Tyler Loakman, Yucheng Li, Chenghua Lin
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recently, Large Language Models (LLMs) and Vision Language Models (VLMs) have
demonstrated aptitude as potential substitutes for human participants in
experiments testing psycholinguistic phenomena. However, an understudied
question is to what extent models that only have access to vision and text
modalities are able to implicitly understand sound-based phenomena via abstract
reasoning from orthography and imagery alone. To investigate this, we analyse
the ability of VLMs and LLMs to demonstrate sound symbolism (i.e., to recognise
a non-arbitrary link between sounds and concepts) as well as their ability to
"hear" via the interplay of the language and vision modules of open and
closed-source multimodal models. We perform multiple experiments, including
replicating the classic Kiki-Bouba and Mil-Mal shape and magnitude symbolism
tasks, and comparing human judgements of linguistic iconicity with that of
LLMs. Our results show that VLMs demonstrate varying levels of agreement with
human labels, and more task information may be required for VLMs versus their
human counterparts for in silico experimentation. We additionally see through
higher maximum agreement levels that Magnitude Symbolism is an easier pattern
for VLMs to identify than Shape Symbolism, and that an understanding of
linguistic iconicity is highly dependent on model size.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to EMNLP 2024 (Camera Ready)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Crossroads of Continents: Automated Artifact Extraction for Cultural
  Adaptation with Large Multimodal Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.02067v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.02067v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Anjishnu Mukherjee, Ziwei Zhu, Antonios Anastasopoulos
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We present a comprehensive three-phase study to examine (1) the cultural
understanding of Large Multimodal Models (LMMs) by introducing DalleStreet, a
large-scale dataset generated by DALL-E 3 and validated by humans, containing
9,935 images of 67 countries and 10 concept classes; (2) the underlying
implicit and potentially stereotypical cultural associations with a cultural
artifact extraction task; and (3) an approach to adapt cultural representation
in an image based on extracted associations using a modular pipeline,
CultureAdapt. We find disparities in cultural understanding at geographic
sub-region levels with both open-source (LLaVA) and closed-source (GPT-4V)
models on DalleStreet and other existing benchmarks, which we try to understand
using over 18,000 artifacts that we identify in association to different
countries. Our findings reveal a nuanced picture of the cultural competence of
LMMs, highlighting the need to develop culture-aware systems. Dataset and code
are available at https://github.com/iamshnoo/crossroads
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>under review</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ What's under the hood: Investigating Automatic Metrics on Meeting
  Summarization 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2404.11124v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2404.11124v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Frederic Kirstein, Jan Philip Wahle, Terry Ruas, Bela Gipp
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Meeting summarization has become a critical task considering the increase in
online interactions. While new techniques are introduced regularly, their
evaluation uses metrics not designed to capture meeting-specific errors,
undermining effective evaluation. This paper investigates what the frequently
used automatic metrics capture and which errors they mask by correlating
automatic metric scores with human evaluations across a broad error taxonomy.
We commence with a comprehensive literature review on English meeting
summarization to define key challenges like speaker dynamics and contextual
turn-taking and error types such as missing information and linguistic
inaccuracy, concepts previously loosely defined in the field. We examine the
relationship between characteristic challenges and errors by using annotated
transcripts and summaries from Transformer-based sequence-to-sequence and
autoregressive models from the general summary QMSum dataset. Through
experimental validation, we find that different model architectures respond
variably to challenges in meeting transcripts, resulting in different
pronounced links between challenges and errors. Current default-used metrics
struggle to capture observable errors, showing weak to mid-correlations, while
a third of the correlations show trends of error masking. Only a subset reacts
accurately to specific errors, while most correlations show either
unresponsiveness or failure to reflect the error's impact on summary quality.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ On Debiasing Text Embeddings Through Context Injection 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12874v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12874v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Thomas Uriot
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Current advances in Natural Language Processing (NLP) have made it
increasingly feasible to build applications leveraging textual data. Generally,
the core of these applications rely on having a good semantic representation of
text into vectors, via embedding models. However, it has been shown that these
embeddings capture and perpetuate biases already present in text. While a few
techniques have been proposed to debias embeddings, they do not take advantage
of the recent advances in context understanding of modern embedding models. In
this paper, we fill this gap by conducting a review of 19 embedding models by
quantifying their biases and how well they respond to context injection as a
mean of debiasing. We show that higher performing models are more prone to
capturing biases, but are also better at incorporating context. Surprisingly,
we find that while models can easily embed affirmative semantics, they fail at
embedding neutral semantics. Finally, in a retrieval task, we show that biases
in embeddings can lead to non-desirable outcomes. We use our new-found insights
to design a simple algorithm for top $k$ retrieval, where $k$ is dynamically
selected. We show that our algorithm is able to retrieve all relevant gendered
and neutral chunks.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Train & Constrain: Phonologically Informed Tongue-Twister Generation
  from Topics and Paraphrases 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2403.13901v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2403.13901v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Tyler Loakman, Chen Tang, Chenghua Lin
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Previous work in phonologically and phonetically grounded language generation
has mainly focused on domains such as puns and poetry. In this article, we
present new work on the generation of English tongue twisters - a form of
language that is required to be conditioned on a phoneme level to maximize
sound overlap, while maintaining semantic consistency with an input topic or
phrase and still being grammatically correct. We present TwisterLister, a
pipeline for generating phonologically informed tongue twisters from large
language models (LLMs) that we use to generate TwistList 2.0, the largest
annotated dataset of tongue twisters to date, consisting of 17K+ examples from
a combination of human and LLM authors. Our generation pipeline involves the
use of a phonologically constrained vocabulary alongside LLM prompting to
generate novel, non-derivative tongue twister examples. We additionally present
the results of automatic and human evaluation of smaller models trained on our
generated dataset to demonstrate the extent to which phonologically motivated
language types can be generated without explicit injection of phonological
knowledge. Additionally, we introduce a phoneme-aware constrained decoding
module (PACD) that can be integrated into an autoregressive language model and
demonstrate that this method generates good quality tongue twisters both with
and without fine-tuning the underlying language model. We also design and
implement a range of automatic metrics for the task of tongue twister
generation that is phonologically motivated and captures the unique essence of
tongue twisters, primarily based on phonemic edit distance (PED)
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted Final Version to Computational Linguistics</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Error Span Annotation: A Balanced Approach for Human Evaluation of
  Machine Translation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.11580v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.11580v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Tom Kocmi, Vilém Zouhar, Eleftherios Avramidis, Roman Grundkiewicz, Marzena Karpinska, Maja Popović, Mrinmaya Sachan, Mariya Shmatova
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  High-quality Machine Translation (MT) evaluation relies heavily on human
judgments. Comprehensive error classification methods, such as Multidimensional
Quality Metrics (MQM), are expensive as they are time-consuming and can only be
done by experts, whose availability may be limited especially for low-resource
languages. On the other hand, just assigning overall scores, like Direct
Assessment (DA), is simpler and faster and can be done by translators of any
level, but is less reliable. In this paper, we introduce Error Span Annotation
(ESA), a human evaluation protocol which combines the continuous rating of DA
with the high-level error severity span marking of MQM. We validate ESA by
comparing it to MQM and DA for 12 MT systems and one human reference
translation (English to German) from WMT23. The results show that ESA offers
faster and cheaper annotations than MQM at the same quality level, without the
requirement of expensive MQM experts.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ BlackDAN: A Black-Box Multi-Objective Approach for Effective and
  Contextual Jailbreaking of Large Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.09804v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.09804v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xinyuan Wang, Victor Shea-Jay Huang, Renmiao Chen, Hao Wang, Chengwei Pan, Lei Sha, Minlie Huang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  While large language models (LLMs) exhibit remarkable capabilities across
various tasks, they encounter potential security risks such as jailbreak
attacks, which exploit vulnerabilities to bypass security measures and generate
harmful outputs. Existing jailbreak strategies mainly focus on maximizing
attack success rate (ASR), frequently neglecting other critical factors,
including the relevance of the jailbreak response to the query and the level of
stealthiness. This narrow focus on single objectives can result in ineffective
attacks that either lack contextual relevance or are easily recognizable. In
this work, we introduce BlackDAN, an innovative black-box attack framework with
multi-objective optimization, aiming to generate high-quality prompts that
effectively facilitate jailbreaking while maintaining contextual relevance and
minimizing detectability. BlackDAN leverages Multiobjective Evolutionary
Algorithms (MOEAs), specifically the NSGA-II algorithm, to optimize jailbreaks
across multiple objectives including ASR, stealthiness, and semantic relevance.
By integrating mechanisms like mutation, crossover, and Pareto-dominance,
BlackDAN provides a transparent and interpretable process for generating
jailbreaks. Furthermore, the framework allows customization based on user
preferences, enabling the selection of prompts that balance harmfulness,
relevance, and other factors. Experimental results demonstrate that BlackDAN
outperforms traditional single-objective methods, yielding higher success rates
and improved robustness across various LLMs and multimodal LLMs, while ensuring
jailbreak responses are both relevant and less detectable.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Improving Retrieval in Sponsored Search by Leveraging Query Context
  Signals <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.14346v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.14346v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Akash Kumar Mohankumar, Gururaj K, Gagan Madan, Amit Singh
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Accurately retrieving relevant bid keywords for user queries is critical in
Sponsored Search but remains challenging, particularly for short, ambiguous
queries. Existing dense and generative retrieval models often fail to capture
nuanced user intent in these cases. To address this, we propose an approach to
enhance query understanding by augmenting queries with rich contextual signals
derived from web search results and large language models, stored in an online
cache. Specifically, we use web search titles and snippets to ground queries in
real-world information and utilize GPT-4 to generate query rewrites and
explanations that clarify user intent. These signals are efficiently integrated
through a Fusion-in-Decoder based Unity architecture, enabling both dense and
generative retrieval with serving costs on par with traditional context-free
models. To address scenarios where context is unavailable in the cache, we
introduce context glancing, a curriculum learning strategy that improves model
robustness and performance even without contextual signals during inference.
Extensive offline experiments demonstrate that our context-aware approach
substantially outperforms context-free models. Furthermore, online A/B testing
on a prominent search engine across 160+ countries shows significant
improvements in user engagement and revenue.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to EMNLP 2024 Industry Track. 10 pages, 10 tables, 1 figure</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Model Internals-based Answer Attribution for Trustworthy
  Retrieval-Augmented Generation <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.13663v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.13663v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jirui Qi, Gabriele Sarti, Raquel Fernández, Arianna Bisazza
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Ensuring the verifiability of model answers is a fundamental challenge for
retrieval-augmented generation (RAG) in the question answering (QA) domain.
Recently, self-citation prompting was proposed to make large language models
(LLMs) generate citations to supporting documents along with their answers.
However, self-citing LLMs often struggle to match the required format, refer to
non-existent sources, and fail to faithfully reflect LLMs' context usage
throughout the generation. In this work, we present MIRAGE --Model
Internals-based RAG Explanations -- a plug-and-play approach using model
internals for faithful answer attribution in RAG applications. MIRAGE detects
context-sensitive answer tokens and pairs them with retrieved documents
contributing to their prediction via saliency methods. We evaluate our proposed
approach on a multilingual extractive QA dataset, finding high agreement with
human answer attribution. On open-ended QA, MIRAGE achieves citation quality
and efficiency comparable to self-citation while also allowing for a
finer-grained control of attribution parameters. Our qualitative evaluation
highlights the faithfulness of MIRAGE's attributions and underscores the
promising application of model internals for RAG answer attribution.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by EMNLP 2024 Main Conference. Code and data released at
  https://github.com/Betswish/MIRAGE</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ A Novel Cartography-Based Curriculum Learning Method Applied on RoNLI:
  The First Romanian Natural Language Inference Corpus <span class="chip">ACL 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.11877v5">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.11877v5.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Eduard Poesina, Cornelia Caragea, Radu Tudor Ionescu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Natural language inference (NLI), the task of recognizing the entailment
relationship in sentence pairs, is an actively studied topic serving as a proxy
for natural language understanding. Despite the relevance of the task in
building conversational agents and improving text classification, machine
translation and other NLP tasks, to the best of our knowledge, there is no
publicly available NLI corpus for the Romanian language. To this end, we
introduce the first Romanian NLI corpus (RoNLI) comprising 58K training
sentence pairs, which are obtained via distant supervision, and 6K validation
and test sentence pairs, which are manually annotated with the correct labels.
We conduct experiments with multiple machine learning methods based on distant
learning, ranging from shallow models based on word embeddings to
transformer-based neural networks, to establish a set of competitive baselines.
Furthermore, we improve on the best model by employing a new curriculum
learning strategy based on data cartography. Our dataset and code to reproduce
the baselines are available at https://github.com/Eduard6421/RONLI.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted at ACL 2024 (Main)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Towards Lifelong Dialogue Agents via Relation-aware Memory Construction
  and Timeline-augmented Response Generation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.10996v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.10996v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Kai Tzu-iunn Ong, Namyoung Kim, Minju Gwak, Hyungjoo Chae, Taeyoon Kwon, Yohan Jo, Seung-won Hwang, Dongha Lee, Jinyoung Yeo
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  To achieve lifelong human-agent interaction, dialogue agents need to
constantly memorize perceived information and properly retrieve it for response
generation (RG). While prior work focuses on getting rid of outdated memories
to improve retrieval quality, we argue that such memories provide rich,
important contextual cues for RG (e.g., changes in user behaviors) in long-term
conversations. We present Theanine, a framework for LLM-based lifelong dialogue
agents. Theanine discards memory removal and manages large-scale memories by
linking them based on their temporal and cause-effect relation. Enabled by this
linking structure, Theanine augments RG with memory timelines - series of
memories representing the evolution or causality of relevant past events. Along
with Theanine, we introduce TeaFarm, a counterfactual-driven evaluation scheme,
addressing the limitation of G-Eval and human efforts in measuring
memory-augmented dialogue agents. A supplementary video for Theanine and data
for TeaFarm are at https://huggingface.co/spaces/ResearcherScholar/Theanine.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Work in Progress</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Large Language Models, scientific knowledge and factuality: A framework
  to streamline human expert evaluation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2305.17819v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2305.17819v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Magdalena Wysocka, Oskar Wysocki, Maxime Delmas, Vincent Mutel, Andre Freitas
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The paper introduces a framework for the evaluation of the encoding of
factual scientific knowledge, designed to streamline the manual evaluation
process typically conducted by domain experts. Inferring over and extracting
information from Large Language Models (LLMs) trained on a large corpus of
scientific literature can potentially define a step change in biomedical
discovery, reducing the barriers for accessing and integrating existing medical
evidence. This work explores the potential of LLMs for dialoguing with
biomedical background knowledge, using the context of antibiotic discovery. The
framework involves of three evaluation steps, each assessing different aspects
sequentially: fluency, prompt alignment, semantic coherence, factual knowledge,
and specificity of the generated responses. By splitting these tasks between
non-experts and experts, the framework reduces the effort required from the
latter. The work provides a systematic assessment on the ability of eleven
state-of-the-art models LLMs, including ChatGPT, GPT-4 and Llama 2, in two
prompting-based tasks: chemical compound definition generation and chemical
compound-fungus relation determination. Although recent models have improved in
fluency, factual accuracy is still low and models are biased towards
over-represented entities. The ability of LLMs to serve as biomedical knowledge
bases is questioned, and the need for additional systematic evaluation
frameworks is highlighted. While LLMs are currently not fit for purpose to be
used as biomedical factual knowledge bases in a zero-shot setting, there is a
promising emerging property in the direction of factuality as the models become
domain specialised, scale-up in size and level of human feedback.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted at the Journal of Biomedical Informatics, Volume 158,
  October 2024, 104724</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Multi-LLM QA with Embodied Exploration 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.10918v5">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.10918v5.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Bhrij Patel, Vishnu Sashank Dorbala, Amrit Singh Bedi, Dinesh Manocha
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large language models (LLMs) have grown in popularity due to their natural
language interface and pre trained knowledge, leading to rapidly increasing
success in question-answering (QA) tasks. More recently, multi-agent systems
with LLM-based agents (Multi-LLM) have been utilized increasingly more for QA.
In these scenarios, the models may each answer the question and reach a
consensus or each model is specialized to answer different domain questions.
However, most prior work dealing with Multi-LLM QA has focused on scenarios
where the models are asked in a zero-shot manner or are given information
sources to extract the answer. For question answering of an unknown
environment, embodied exploration of the environment is first needed to answer
the question. This skill is necessary for personalizing embodied AI to
environments such as households. There is a lack of insight into whether a
Multi-LLM system can handle question-answering based on observations from
embodied exploration. In this work, we address this gap by investigating the
use of Multi-Embodied LLM Explorers (MELE) for QA in an unknown environment.
Multiple LLM-based agents independently explore and then answer queries about a
household environment. We analyze different aggregation methods to generate a
single, final answer for each query: debating, majority voting, and training a
central answer module (CAM). Using CAM, we observe a $46\%$ higher accuracy
compared against the other non-learning-based aggregation methods. We provide
code and the query dataset for further research.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>16 pages, 9 Figures, 5 Tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Molecular<span class="highlight-title">GPT</span>: Open Large Language Model (LLM) for Few-Shot Molecular
  Property Prediction 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.12950v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.12950v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yuyan Liu, Sirui Ding, Sheng Zhou, Wenqi Fan, Qiaoyu Tan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Molecular property prediction (MPP) is a fundamental and crucial task in drug
discovery. However, prior methods are limited by the requirement for a large
number of labeled molecules and their restricted ability to generalize for
unseen and new tasks, both of which are essential for real-world applications.
To address these challenges, we present MolecularGPT for few-shot MPP. From a
perspective on instruction tuning, we fine-tune large language models (LLMs)
based on curated molecular instructions spanning over 1000 property prediction
tasks. This enables building a versatile and specialized LLM that can be
adapted to novel MPP tasks without any fine-tuning through zero- and few-shot
in-context learning (ICL). MolecularGPT exhibits competitive in-context
reasoning capabilities across 10 downstream evaluation datasets, setting new
benchmarks for few-shot molecular prediction tasks. More importantly, with just
two-shot examples, MolecularGPT can outperform standard supervised graph neural
network methods on 4 out of 7 datasets. It also excels state-of-the-art LLM
baselines by up to 15.7% increase on classification accuracy and decrease of
17.9 on regression metrics (e.g., RMSE) under zero-shot. This study
demonstrates the potential of LLMs as effective few-shot molecular property
predictors. The code is available at https://github.com/NYUSHCS/MolecularGPT.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ A Fundamental Trade-off in Aligned Language Models and its Relation to
  Sampling Adaptors <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.10203v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.10203v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Naaman Tan, Josef Valvoda, Tianyu Liu, Anej Svete, Yanxia Qin, Kan Min-Yen, Ryan Cotterell
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The relationship between the quality of a string, as judged by a human
reader, and its probability, $p(\boldsymbol{y})$ under a language model
undergirds the development of better language models. For example, many popular
algorithms for sampling from a language model have been conceived with the goal
of manipulating $p(\boldsymbol{y})$ to place higher probability on strings that
humans deem of high quality. In this article, we examine the
probability--quality relationship in language models explicitly aligned to
human preferences, e.g., through reinforcement learning through human feedback.
We show that, when sampling corpora from an aligned language model, there
exists a trade-off between the strings' average reward and average
log-likelihood under the prior language model, i.e., the same model before
alignment with human preferences. We provide a formal treatment of this
phenomenon and demonstrate how a choice of sampling adaptor allows for a
selection of how much likelihood we exchange for the reward.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>EMNLP 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Entity Matching using Large Language Models <span class="chip">EDBT</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2310.11244v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2310.11244v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ralph Peeters, Aaron Steiner, Christian Bizer
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Entity matching is the task of deciding whether two entity descriptions refer
to the same real-world entity. Entity matching is a central step in most data
integration pipelines. Many state-of-the-art entity matching methods rely on
pre-trained language models (PLMs) such as BERT or RoBERTa. Two major drawbacks
of these models for entity matching are that (i) the models require significant
amounts of task-specific training data and (ii) the fine-tuned models are not
robust concerning out-of-distribution entities. This paper investigates using
generative large language models (LLMs) as a less task-specific training
data-dependent and more robust alternative to PLM-based matchers. The study
covers hosted and open-source LLMs which can be run locally. We evaluate these
models in a zero-shot scenario and a scenario where task-specific training data
is available. We compare different prompt designs and the prompt sensitivity of
the models. We show that there is no single best prompt but that the prompt
needs to be tuned for each model/dataset combination. We further investigate
(i) the selection of in-context demonstrations, (ii) the generation of matching
rules, as well as (iii) fine-tuning LLMs using the same pool of training data.
Our experiments show that the best LLMs require no or only a few training
examples to perform comparably to PLMs that were fine-tuned using thousands of
examples. LLM-based matchers further exhibit higher robustness to unseen
entities. We show that GPT4 can generate structured explanations for matching
decisions and can automatically identify potential causes of matching errors by
analyzing explanations of wrong decisions. We demonstrate that the model can
generate meaningful textual descriptions of the identified error classes, which
can help data engineers to improve entity matching pipelines.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Published in Proceedings of the 28th International Conference on
  Extending Database Technology (EDBT), 25th March-28th March, 2025, ISBN
  978-3-89318-098-1 on OpenProceedings.org</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ 2D-TPE: Two-Dimensional Positional Encoding Enhances Table Understanding
  for Large Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.19700v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.19700v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jia-Nan Li, Jian Guan, Wei Wu, Zhengtao Yu, Rui Yan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Tables are ubiquitous across various domains for concisely representing
structured information. Empowering large language models (LLMs) to reason over
tabular data represents an actively explored direction. However, since typical
LLMs only support one-dimensional~(1D) inputs, existing methods often flatten
the two-dimensional~(2D) table structure into a sequence of tokens, which can
severely disrupt the spatial relationships and result in an inevitable loss of
vital contextual information. In this paper, we first empirically demonstrate
the detrimental impact of such flattening operations on the performance of LLMs
in capturing the spatial information of tables through two elaborate proxy
tasks. Subsequently, we introduce a simple yet effective positional encoding
method, termed ``2D-TPE'' (Two-Dimensional Table Positional Encoding), to
address this challenge. 2D-TPE enables each attention head to dynamically
select a permutation order of tokens within the context for attending to them,
where each permutation represents a distinct traversal mode for the table, such
as column-wise or row-wise traversal. 2D-TPE effectively mitigates the risk of
losing essential spatial information while preserving computational efficiency,
thus better preserving the table structure. Extensive experiments across five
benchmarks demonstrate that 2D-TPE outperforms strong baselines, underscoring
the importance of preserving the table structure for accurate table
comprehension. Comprehensive analysis further reveals the substantially better
scalability of 2D-TPE to large tables than baselines.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ FAME: Towards Factual Multi-Task Model Editing <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.10859v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.10859v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Li Zeng, Yingyu Shan, Zeming Liu, Jiashu Yao, Yuhang Guo
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large language models (LLMs) embed extensive knowledge and utilize it to
perform exceptionally well across various tasks. Nevertheless, outdated
knowledge or factual errors within LLMs can lead to misleading or incorrect
responses, causing significant issues in practical applications. To rectify the
fatal flaw without the necessity for costly model retraining, various model
editing approaches have been proposed to correct inaccurate knowledge within
LLMs in a cost-efficient way. To evaluate these model editing methods, previous
work introduced a series of datasets. However, most of the previous datasets
only contain fabricated data in a single format, which diverges from real-world
model editing scenarios, raising doubts about their usability in practice. To
facilitate the application of model editing in real-world scenarios, we propose
the challenge of practicality. To resolve such challenges and effectively
enhance the capabilities of LLMs, we present FAME, an factual, comprehensive,
and multi-task dataset, which is designed to enhance the practicality of model
editing. We then propose SKEME, a model editing method that uses a novel
caching mechanism to ensure synchronization with the real world. The
experiments demonstrate that SKEME performs excellently across various tasks
and scenarios, confirming its practicality.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>9 pages, 3 figures. This paper has been accepted by EMNLP 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ <span class="highlight-title">Prompt</span> Tuning of Deep Neural Networks for Speaker-adaptive Visual Speech
  Recognition 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2302.08102v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2302.08102v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Minsu Kim, Hyung-Il Kim, Yong Man Ro
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Visual Speech Recognition (VSR) aims to infer speech into text depending on
lip movements alone. As it focuses on visual information to model the speech,
its performance is inherently sensitive to personal lip appearances and
movements, and this makes the VSR models show degraded performance when they
are applied to unseen speakers. In this paper, to remedy the performance
degradation of the VSR model on unseen speakers, we propose prompt tuning
methods of Deep Neural Networks (DNNs) for speaker-adaptive VSR. Specifically,
motivated by recent advances in Natural Language Processing (NLP), we finetune
prompts on adaptation data of target speakers instead of modifying the
pre-trained model parameters. Different from the previous prompt tuning methods
mainly limited to Transformer variant architecture, we explore different types
of prompts, the addition, the padding, and the concatenation form prompts that
can be applied to the VSR model which is composed of CNN and Transformer in
general. With the proposed prompt tuning, we show that the performance of the
pre-trained VSR model on unseen speakers can be largely improved by using a
small amount of adaptation data (e.g., less than 5 minutes), even if the
pre-trained model is already developed with large speaker variations. Moreover,
by analyzing the performance and parameters of different types of prompts, we
investigate when the prompt tuning is preferred over the finetuning methods.
The effectiveness of the proposed method is evaluated on both word- and
sentence-level VSR databases, LRW-ID and GRID.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>IEEE TPAMI</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ BANTH: A Multi-label Hate Speech Detection <span class="highlight-title">Dataset</span> for Transliterated
  Bangla 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.13281v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.13281v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Fabiha Haider, Fariha Tanjim Shifat, Md Farhan Ishmam, Deeparghya Dutta Barua, Md Sakib Ul Rahman Sourove, Md Fahim, Md Farhad Alam
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The proliferation of transliterated texts in digital spaces has emphasized
the need for detecting and classifying hate speech in languages beyond English,
particularly in low-resource languages. As online discourse can perpetuate
discrimination based on target groups, e.g. gender, religion, and origin,
multi-label classification of hateful content can help in comprehending hate
motivation and enhance content moderation. While previous efforts have focused
on monolingual or binary hate classification tasks, no work has yet addressed
the challenge of multi-label hate speech classification in transliterated
Bangla. We introduce BanTH, the first multi-label transliterated Bangla hate
speech dataset comprising 37.3k samples. The samples are sourced from YouTube
comments, where each instance is labeled with one or more target groups,
reflecting the regional demographic. We establish novel transformer
encoder-based baselines by further pre-training on transliterated Bangla
corpus. We also propose a novel translation-based LLM prompting strategy for
transliterated text. Experiments reveal that our further pre-trained encoders
are achieving state-of-the-art performance on the BanTH dataset, while our
translation-based prompting outperforms other strategies in the zero-shot
setting. The introduction of BanTH not only fills a critical gap in hate speech
research for Bangla but also sets the stage for future exploration into
code-mixed and multi-label classification challenges in underrepresented
languages.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Understanding Likelihood Over-optimisation in Direct Alignment
  Algorithms 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.11677v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.11677v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zhengyan Shi, Sander Land, Acyr Locatelli, Matthieu Geist, Max Bartolo
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Direct Alignment Algorithms (DAAs), such as Direct Preference Optimisation
(DPO) and Identity Preference Optimisation (IPO), have emerged as alternatives
to online Reinforcement Learning from Human Feedback (RLHF) algorithms such as
Proximal Policy Optimisation (PPO) for aligning language models to human
preferences, without the need for explicit reward modelling. These methods
generally aim to increase the likelihood of generating better (preferred)
completions while discouraging worse (non-preferred) ones, while staying close
to the original model's behaviour. In this work, we explore the relationship
between completion likelihood and model performance in state-of-the-art DAAs,
and identify a critical issue of likelihood over-optimisation. Contrary to
expectations, we find that higher likelihood of better completions and larger
margins between better and worse completion likelihoods do not necessarily lead
to better performance, and may even degrade it. Our analysis reveals that while
higher likelihood correlates with better memorisation of factual knowledge
patterns, a slightly lower completion likelihood tends to improve output
diversity, thus leading to better generalisation to unseen scenarios. Moreover,
we identify two key indicators that signal when over-optimised output diversity
begins to harm performance: Decreasing Entropy over Top-k Tokens and
Diminishing Top-k Probability Mass. Our experimental results validate that
these indicators are reliable signs of declining performance under different
regularisations, helping prevent over-optimisation and improve alignment with
human preferences.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Preprint Version</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ MaiBaam Annotation Guidelines 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2403.05902v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2403.05902v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Verena Blaschke, Barbara Kovačić, Siyao Peng, Barbara Plank
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This document provides the annotation guidelines for MaiBaam, a Bavarian
corpus manually annotated with part-of-speech (POS) tags, syntactic
dependencies, and German lemmas. MaiBaam belongs to the Universal Dependencies
(UD) project, and our annotations elaborate on the general and German UD
version 2 guidelines. In this document, we detail how to preprocess and
tokenize Bavarian data, provide an overview of the POS tags and dependencies we
use, explain annotation decisions that would also apply to closely related
languages like German, and lastly we introduce and motivate decisions that are
specific to Bavarian grammar.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Updated for UD v2.15 (German lemmas added)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Evaluating Semantic Variation in Text-to-Image Synthesis: A Causal
  Perspective 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.10291v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.10291v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xiangru Zhu, Penglei Sun, Yaoxian Song, Yanghua Xiao, Zhixu Li, Chengyu Wang, Jun Huang, Bei Yang, Xiaoxiao Xu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Accurate interpretation and visualization of human instructions are crucial
for text-to-image (T2I) synthesis. However, current models struggle to capture
semantic variations from word order changes, and existing evaluations, relying
on indirect metrics like text-image similarity, fail to reliably assess these
challenges. This often obscures poor performance on complex or uncommon
linguistic patterns by the focus on frequent word combinations. To address
these deficiencies, we propose a novel metric called SemVarEffect and a
benchmark named SemVarBench, designed to evaluate the causality between
semantic variations in inputs and outputs in T2I synthesis. Semantic variations
are achieved through two types of linguistic permutations, while avoiding
easily predictable literal variations. Experiments reveal that the
CogView-3-Plus and Ideogram 2 performed the best, achieving a score of 0.2/1.
Semantic variations in object relations are less understood than attributes,
scoring 0.07/1 compared to 0.17-0.19/1. We found that cross-modal alignment in
UNet or Transformers plays a crucial role in handling semantic variations, a
factor previously overlooked by a focus on textual encoders. Our work
establishes an effective evaluation framework that advances the T2I synthesis
community's exploration of human instruction understanding. Our benchmark and
code are available at https://github.com/zhuxiangru/SemVarBench .
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>The only change in the current version update is the replacement of
  the template with a more precise one</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ I run as fast as a rabbit, can you? A Multilingual Simile Dialogue
  <span class="highlight-title">Dataset</span> <span class="chip">ACL 2023</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2306.05672v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2306.05672v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Longxuan Ma, Weinan Zhang, Shuhan Zhou, Churui Sun, Changxin Ke, Ting Liu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  A simile is a figure of speech that compares two different things (called the
tenor and the vehicle) via shared properties. The tenor and the vehicle are
usually connected with comparator words such as "like" or "as". The simile
phenomena are unique and complex in a real-life dialogue scene where the tenor
and the vehicle can be verbal phrases or sentences, mentioned by different
speakers, exist in different sentences, or occur in reversed order. However,
the current simile research usually focuses on similes in a triplet tuple
(tenor, property, vehicle) or a single sentence where the tenor and vehicle are
usually entities or noun phrases, which could not reflect complex simile
phenomena in real scenarios. In this paper, we propose a novel and high-quality
multilingual simile dialogue (MSD) dataset to facilitate the study of complex
simile phenomena. The MSD is the largest manually annotated simile data
($\sim$20K) and it contains both English and Chinese data. Meanwhile, the MSD
data can also be used on dialogue tasks to test the ability of dialogue systems
when using similes. We design 3 simile tasks (recognition, interpretation, and
generation) and 2 dialogue tasks (retrieval and generation) with MSD. For each
task, we provide experimental results from strong pre-trained or
state-of-the-art models. The experiments demonstrate the challenge of MSD and
we have released the data/code on GitHub.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>13 Pages, 1 Figure, 12 Tables, ACL 2023 findings</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Can Few-shot Work in Long-Context? Recycling the Context to Generate
  Demonstrations 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.13632v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.13632v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Arie Cattan, Alon Jacovi, Alex Fabrikant, Jonathan Herzig, Roee Aharoni, Hannah Rashkin, Dror Marcus, Avinatan Hassidim, Yossi Matias, Idan Szpektor, Avi Caciularu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Despite recent advancements in Large Language Models (LLMs), their
performance on tasks involving long contexts remains sub-optimal. In-Context
Learning (ICL) with few-shot examples may be an appealing solution to enhance
LLM performance in this scenario; However, na\"ively adding ICL examples with
long context introduces challenges, including substantial token overhead added
for each few-shot example and context mismatch between the demonstrations and
the target query. In this work, we propose to automatically generate few-shot
examples for long context QA tasks by recycling contexts. Specifically, given a
long input context (1-3k tokens) and a query, we generate additional
query-output pairs from the given context as few-shot examples, while
introducing the context only once. This ensures that the demonstrations are
leveraging the same context as the target query while only adding a small
number of tokens to the prompt. We further enhance each demonstration by
instructing the model to explicitly identify the relevant paragraphs before the
answer, which improves performance while providing fine-grained attribution to
the answer source. We apply our method on multiple LLMs and obtain substantial
improvements (+16 absolute points on average across models) on various QA
datasets with long context, especially when the answer lies within the middle
of the context. Surprisingly, despite introducing only single-hop ICL examples,
LLMs also successfully generalize to multi-hop long-context QA using our
approach.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Towards Verifiable Text Generation with Evolving Memory and
  Self-Reflection <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2312.09075v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2312.09075v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hao Sun, Hengyi Cai, Bo Wang, Yingyan Hou, Xiaochi Wei, Shuaiqiang Wang, Yan Zhang, Dawei Yin
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Despite the remarkable ability of large language models (LLMs) in language
comprehension and generation, they often suffer from producing factually
incorrect information, also known as hallucination. A promising solution to
this issue is verifiable text generation, which prompts LLMs to generate
content with citations for accuracy verification. However, verifiable text
generation is non-trivial due to the focus-shifting phenomenon, the intricate
reasoning needed to align the claim with correct citations, and the dilemma
between the precision and breadth of retrieved documents. In this paper, we
present VTG, an innovative framework for Verifiable Text Generation with
evolving memory and self-reflection. VTG introduces evolving long short-term
memory to retain both valuable documents and recent documents. A two-tier
verifier equipped with an evidence finder is proposed to rethink and reflect on
the relationship between the claim and citations. Furthermore, active retrieval
and diverse query generation are utilized to enhance both the precision and
breadth of the retrieved documents. We conduct extensive experiments on five
datasets across three knowledge-intensive tasks and the results reveal that VTG
significantly outperforms baselines.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>EMNLP 2024 Main Conference</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Harnessing Webpage UIs for Text-Rich Visual Understanding 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.13824v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.13824v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Junpeng Liu, Tianyue Ou, Yifan Song, Yuxiao Qu, Wai Lam, Chenyan Xiong, Wenhu Chen, Graham Neubig, Xiang Yue
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Text-rich visual understanding-the ability to process environments where
dense textual content is integrated with visuals-is crucial for multimodal
large language models (MLLMs) to interact effectively with structured
environments. To enhance this capability, we propose synthesizing general
multimodal instructions from webpage UIs using text-based large language models
(LLMs). Despite lacking direct visual input, text-based LLMs are able to
process structured text representations from webpage accessibility trees. These
instructions are then paired with UI screenshots to train multimodal models. We
introduce MultiUI, a dataset containing 7.3 million samples from 1 million
websites, covering diverse multimodal tasks and UI layouts. Models trained on
MultiUI not only excel in web UI tasks-achieving up to a 48% improvement on
VisualWebBench and a 19.1% boost in element accuracy on a web agent dataset
Mind2Web-but also generalize surprisingly well to non-web UI tasks and even to
non-UI domains, such as document understanding, OCR, and chart interpretation.
These results highlight the broad applicability of web UI data for advancing
text-rich visual understanding across various scenarios.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Dating ancient manuscripts using radiocarbon and AI-based writing style
  analysis 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.12013v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.12013v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mladen Popović, Maruf A. Dhali, Lambert Schomaker, Johannes van der Plicht, Kaare Lund Rasmussen, Jacopo La Nasa, Ilaria Degano, Maria Perla Colombini, Eibert Tigchelaar
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Determining the chronology of ancient handwritten manuscripts is essential
for reconstructing the evolution of ideas. For the Dead Sea Scrolls, this is
particularly important. However, there is an almost complete lack of
date-bearing manuscripts evenly distributed across the timeline and written in
similar scripts available for palaeographic comparison. Here, we present Enoch,
a state-of-the-art AI-based date-prediction model, trained on the basis of new
radiocarbon-dated samples of the scrolls. Enoch uses established
handwriting-style descriptors and applies Bayesian ridge regression. The
challenge of this study is that the number of radiocarbon-dated manuscripts is
small, while current machine learning requires an abundance of training data.
We show that by using combined angular and allographic writing style feature
vectors and applying Bayesian ridge regression, Enoch could predict the
radiocarbon-based dates from style, supported by leave-one-out validation, with
varied MAEs of 27.9 to 30.7 years relative to the radiocarbon dating. Enoch was
then used to estimate the dates of 135 unseen manuscripts, revealing that 79
per cent of the samples were considered 'realistic' upon palaeographic post-hoc
evaluation. We present a new chronology of the scrolls. The radiocarbon ranges
and Enoch's style-based predictions are often older than the traditionally
assumed palaeographic estimates. In the range of 300-50 BCE, Enoch's date
prediction provides an improved granularity. The study is in line with current
developments in multimodal machine-learning techniques, and the methods can be
used for date prediction in other partially-dated manuscript collections. This
research shows how Enoch's quantitative, probability-based approach can be a
tool for palaeographers and historians, re-dating ancient Jewish key texts and
contributing to current debates on Jewish and Christian origins.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>16 pages of main article, 103 pages of supplementary materials; the
  first version of this article is originally prepared in July 2023 after the
  completion of all the experiments</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Conversational Recommender System and Large Language Model Are Made for
  Each Other in E-commerce Pre-sales Dialogue <span class="chip">EMNLP 2023</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2310.14626v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2310.14626v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yuanxing Liu, Wei-Nan Zhang, Yifan Chen, Yuchi Zhang, Haopeng Bai, Fan Feng, Hengbin Cui, Yongbin Li, Wanxiang Che
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  E-commerce pre-sales dialogue aims to understand and elicit user needs and
preferences for the items they are seeking so as to provide appropriate
recommendations. Conversational recommender systems (CRSs) learn user
representation and provide accurate recommendations based on dialogue context,
but rely on external knowledge. Large language models (LLMs) generate responses
that mimic pre-sales dialogues after fine-tuning, but lack domain-specific
knowledge for accurate recommendations. Intuitively, the strengths of LLM and
CRS in E-commerce pre-sales dialogues are complementary, yet no previous work
has explored this. This paper investigates the effectiveness of combining LLM
and CRS in E-commerce pre-sales dialogues, proposing two collaboration methods:
CRS assisting LLM and LLM assisting CRS. We conduct extensive experiments on a
real-world dataset of Ecommerce pre-sales dialogues. We analyze the impact of
two collaborative approaches with two CRSs and two LLMs on four tasks of
Ecommerce pre-sales dialogue. We find that collaborations between CRS and LLM
can be very effective in some cases.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>EMNLP 2023 Findings</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Unraveling and Mitigating Retriever Inconsistencies in
  Retrieval-Augmented Large Language Models <span class="chip">ACL 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.20680v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.20680v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mingda Li, Xinyu Li, Yifan Chen, Wenfeng Xuan, Weinan Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Although Retrieval-Augmented Large Language Models (RALMs) demonstrate their
superiority in terms of factuality, they do not consistently outperform the
original retrieval-free Language Models (LMs). Our experiments reveal that this
example-level performance inconsistency exists not only between
retrieval-augmented and retrieval-free LM but also among different retrievers.
To understand this phenomenon, we investigate the degeneration behavior of
RALMs and theoretically decompose it into four categories. Further analysis
based on our decomposition reveals that the innate difference in knowledge
sources and the unpredictable degeneration of the reader model contribute most
to the inconsistency. Drawing from our analysis, we introduce Ensemble of
Retrievers (EoR), a trainable framework that can adaptively retrieve from
different knowledge sources and effectively decrease unpredictable reader
errors. Our experiments on Open Domain Question Answering show that EoR
substantially improves performance over the RALM with a single retriever by
considerably reducing inconsistent behaviors.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>ACL 2024 (findings)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ PARIKSHA: A Large-Scale Investigation of Human-LLM Evaluator Agreement
  on Multilingual and Multi-Cultural Data <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.15053v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.15053v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ishaan Watts, Varun Gumma, Aditya Yadavalli, Vivek Seshadri, Manohar Swaminathan, Sunayana Sitaram
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Evaluation of multilingual Large Language Models (LLMs) is challenging due to
a variety of factors -- the lack of benchmarks with sufficient linguistic
diversity, contamination of popular benchmarks into LLM pre-training data and
the lack of local, cultural nuances in translated benchmarks. In this work, we
study human and LLM-based evaluation in a multilingual, multi-cultural setting.
We evaluate 30 models across 10 Indic languages by conducting 90K human
evaluations and 30K LLM-based evaluations and find that models such as GPT-4o
and Llama-3 70B consistently perform best for most Indic languages. We build
leaderboards for two evaluation settings - pairwise comparison and direct
assessment and analyze the agreement between humans and LLMs. We find that
humans and LLMs agree fairly well in the pairwise setting but the agreement
drops for direct assessment evaluation especially for languages such as Bengali
and Odia. We also check for various biases in human and LLM-based evaluation
and find evidence of self-bias in the GPT-based evaluator. Our work presents a
significant step towards scaling up multilingual evaluation of LLMs.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to EMNLP 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Graph Neural Network Enhanced Retrieval for Question Answering of LLMs 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.06572v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.06572v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zijian Li, Qingyan Guo, Jiawei Shao, Lei Song, Jiang Bian, Jun Zhang, Rui Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Retrieval augmented generation has revolutionized large language model (LLM)
outputs by providing factual supports. Nevertheless, it struggles to capture
all the necessary knowledge for complex reasoning questions. Existing retrieval
methods typically divide reference documents into passages, treating them in
isolation. These passages, however, are often interrelated, such as passages
that are contiguous or share the same keywords. Therefore, it is crucial to
recognize such relatedness for enhancing the retrieval process. In this paper,
we propose a novel retrieval method, called GNN-Ret, which leverages graph
neural networks (GNNs) to enhance retrieval by exploiting the relatedness
between passages. Specifically, we first construct a graph of passages by
connecting passages that are structure-related or keyword-related. A graph
neural network (GNN) is then leveraged to exploit the relationships between
passages and improve the retrieval of supporting passages. Furthermore, we
extend our method to handle multi-hop reasoning questions using a recurrent
graph neural network (RGNN), named RGNN-Ret. At each step, RGNN-Ret integrates
the graphs of passages from previous steps, thereby enhancing the retrieval of
supporting passages. Extensive experiments on benchmark datasets demonstrate
that GNN-Ret achieves higher accuracy for question answering with a single
query of LLMs than strong baselines that require multiple queries, and RGNN-Ret
further improves accuracy and achieves state-of-the-art performance, with up to
10.4% accuracy improvement on the 2WikiMQA dataset.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Under review</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ On the Use of Large Language Models to Generate Capability Ontologies 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2404.17524v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2404.17524v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Luis Miguel Vieira da Silva, Aljosha Köcher, Felix Gehlhoff, Alexander Fay
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Capability ontologies are increasingly used to model functionalities of
systems or machines. The creation of such ontological models with all
properties and constraints of capabilities is very complex and can only be done
by ontology experts. However, Large Language Models (LLMs) have shown that they
can generate machine-interpretable models from natural language text input and
thus support engineers / ontology experts. Therefore, this paper investigates
how LLMs can be used to create capability ontologies. We present a study with a
series of experiments in which capabilities with varying complexities are
generated using different prompting techniques and with different LLMs. Errors
in the generated ontologies are recorded and compared. To analyze the quality
of the generated ontologies, a semi-automated approach based on RDF syntax
checking, OWL reasoning, and SHACL constraints is used. The results of this
study are very promising because even for complex capabilities, the generated
ontologies are almost free of errors.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>\c{opyright} 2024 IEEE. Personal use of this material is permitted.
  Permission from IEEE must be obtained for all other uses, in any current or
  future media, including reprinting/republishing this material for advertising
  or promotional purposes, creating new collective works, for resale or
  redistribution to servers or lists, or reuse of any copyrighted component of
  this work in other works</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Toward a Method to Generate Capability Ontologies from Natural Language
  Descriptions 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.07962v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.07962v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Luis Miguel Vieira da Silva, Aljosha Köcher, Felix Gehlhoff, Alexander Fay
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  To achieve a flexible and adaptable system, capability ontologies are
increasingly leveraged to describe functions in a machine-interpretable way.
However, modeling such complex ontological descriptions is still a manual and
error-prone task that requires a significant amount of effort and ontology
expertise. This contribution presents an innovative method to automate
capability ontology modeling using Large Language Models (LLMs), which have
proven to be well suited for such tasks. Our approach requires only a natural
language description of a capability, which is then automatically inserted into
a predefined prompt using a few-shot prompting technique. After prompting an
LLM, the resulting capability ontology is automatically verified through
various steps in a loop with the LLM to check the overall correctness of the
capability ontology. First, a syntax check is performed, then a check for
contradictions, and finally a check for hallucinations and missing ontology
elements. Our method greatly reduces manual effort, as only the initial natural
language description and a final human review and possible correction are
necessary, thereby streamlining the capability ontology generation process.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>\c{opyright} 2024 IEEE. Personal use of this material is permitted.
  Permission from IEEE must be obtained for all other uses, in any current or
  future media, including reprinting/republishing this material for advertising
  or promotional purposes, creating new collective works, for resale or
  redistribution to servers or lists, or reuse of any copyrighted component of
  this work in other works</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Large Language Model Based Generative Error Correction: A Challenge and
  Baselines for Speech Recognition, Speaker Tagging, and Emotion Recognition 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.09785v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.09785v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Chao-Han Huck Yang, Taejin Park, Yuan Gong, Yuanchao Li, Zhehuai Chen, Yen-Ting Lin, Chen Chen, Yuchen Hu, Kunal Dhawan, Piotr Żelasko, Chao Zhang, Yun-Nung Chen, Yu Tsao, Jagadeesh Balam, Boris Ginsburg, Sabato Marco Siniscalchi, Eng Siong Chng, Peter Bell, Catherine Lai, Shinji Watanabe, Andreas Stolcke
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Given recent advances in generative AI technology, a key question is how
large language models (LLMs) can enhance acoustic modeling tasks using text
decoding results from a frozen, pretrained automatic speech recognition (ASR)
model. To explore new capabilities in language modeling for speech processing,
we introduce the generative speech transcription error correction (GenSEC)
challenge. This challenge comprises three post-ASR language modeling tasks: (i)
post-ASR transcription correction, (ii) speaker tagging, and (iii) emotion
recognition. These tasks aim to emulate future LLM-based agents handling
voice-based interfaces while remaining accessible to a broad audience by
utilizing open pretrained language models or agent-based APIs. We also discuss
insights from baseline evaluations, as well as lessons learned for designing
future evaluations.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>IEEE SLT 2024. The initial draft version has been done in December
  2023. Post-ASR Text Processing and Understanding Community and LlaMA-7B
  pre-training correction model:
  https://huggingface.co/GenSEC-LLM/SLT-Task1-Llama2-7b-HyPo-baseline</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ VLFeedback: A Large-Scale AI Feedback <span class="highlight-title">Dataset</span> for Large Vision-Language
  Models Alignment <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.09421v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.09421v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Lei Li, Zhihui Xie, Mukai Li, Shunian Chen, Peiyi Wang, Liang Chen, Yazheng Yang, Benyou Wang, Lingpeng Kong, Qi Liu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  As large vision-language models (LVLMs) evolve rapidly, the demand for
high-quality and diverse data to align these models becomes increasingly
crucial. However, the creation of such data with human supervision proves
costly and time-intensive. In this paper, we investigate the efficacy of AI
feedback to scale supervision for aligning LVLMs. We introduce VLFeedback, the
first large-scale vision-language feedback dataset, comprising over 82K
multi-modal instructions and comprehensive rationales generated by
off-the-shelf models without human annotations. To evaluate the effectiveness
of AI feedback for vision-language alignment, we train Silkie, an LVLM
fine-tuned via direct preference optimization on VLFeedback. Silkie showcases
exceptional performance regarding helpfulness, visual faithfulness, and safety
metrics. It outperforms its base model by 6.9\% and 9.5\% in perception and
cognition tasks, reduces hallucination issues on MMHal-Bench, and exhibits
enhanced resilience against red-teaming attacks. Furthermore, our analysis
underscores the advantage of AI feedback, particularly in fostering preference
diversity to deliver more comprehensive improvements. Our dataset, training
code and models are available at https://vlf-silkie.github.io.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>EMNLP 2024 Main Conference camera-ready version (fixed small typos).
  This article supersedes arXiv:2312.10665</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ WaterMax: breaking the LLM watermark detectability-robustness-quality
  trade-off 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2403.04808v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2403.04808v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Eva Giboulot, Teddy Furon
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Watermarking is a technical means to dissuade malfeasant usage of Large
Language Models. This paper proposes a novel watermarking scheme, so-called
WaterMax, that enjoys high detectability while sustaining the quality of the
generated text of the original LLM. Its new design leaves the LLM untouched (no
modification of the weights, logits, temperature, or sampling technique).
WaterMax balances robustness and complexity contrary to the watermarking
techniques of the literature inherently provoking a trade-off between quality
and robustness. Its performance is both theoretically proven and experimentally
validated. It outperforms all the SotA techniques under the most complete
benchmark suite. Code available at https://github.com/eva-giboulot/WaterMax.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ LLM Critics Help Catch Bugs in Mathematics: Towards a Better
  Mathematical Verifier with Natural Language Feedback 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.14024v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.14024v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Bofei Gao, Zefan Cai, Runxin Xu, Peiyi Wang, Ce Zheng, Runji Lin, Keming Lu, Dayiheng Liu, Chang Zhou, Wen Xiao, Junjie Hu, Tianyu Liu, Baobao Chang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In recent progress, mathematical verifiers have achieved success in
mathematical reasoning tasks by validating the correctness of solutions
generated by policy models. However, existing verifiers are trained with binary
classification labels, which are not informative enough for the model to
accurately assess the solutions. To mitigate the aforementioned insufficiency
of binary labels, we introduce step-wise natural language feedback as rationale
labels, that is, the correctness of each step and the detailed explanations. In
this paper, we propose Math-Minos, a natural language feedback-enhanced
verifier by constructing automatically generated training data and a two-stage
training paradigm for effective training and efficient inference. Our
experiments reveal that a small set of natural language feedback can
significantly boost the performance of the verifier in both verification and
reinforcement learning. We have released the code and data for further
exploration.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>15 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ PertEval: Unveiling Real Knowledge Capacity of LLMs with
  Knowledge-Invariant Perturbations <span class="chip">NeurIPS '24</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.19740v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.19740v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jiatong Li, Renjun Hu, Kunzhe Huang, Yan Zhuang, Qi Liu, Mengxiao Zhu, Xing Shi, Wei Lin
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Expert-designed close-ended benchmarks are indispensable in assessing the
knowledge capacity of large language models (LLMs). Despite their widespread
use, concerns have mounted regarding their reliability due to limited test
scenarios and an unavoidable risk of data contamination. To rectify this, we
present PertEval, a toolkit devised for in-depth probing of LLMs' knowledge
capacity through \textbf{knowledge-invariant perturbations}. These
perturbations employ human-like restatement techniques to generate on-the-fly
test samples from static benchmarks, meticulously retaining knowledge-critical
content while altering irrelevant details. Our toolkit further includes a suite
of \textbf{response consistency analyses} that compare performance on raw vs.
perturbed test sets to precisely assess LLMs' genuine knowledge capacity. Six
representative LLMs are re-evaluated using PertEval. Results reveal
significantly inflated performance of the LLMs on raw benchmarks, including an
absolute 25.8% overestimation for GPT-4. Additionally, through a nuanced
response pattern analysis, we discover that PertEval retains LLMs' uncertainty
to specious knowledge, and reveals their potential rote memorization to correct
options which leads to overestimated performance. We also find that the
detailed response consistency analyses by PertEval could illuminate various
weaknesses in existing LLMs' knowledge mastery and guide the development of
refinement. Our findings provide insights for advancing more robust and
genuinely knowledgeable LLMs. Our code is available at
\url{https://github.com/aigc-apps/PertEval}.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by NeurIPS '24 D&B Spotlight; 28 pages, 15 figures, 14
  tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ SciAssess: Benchmarking LLM Proficiency in Scientific Literature
  Analysis 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2403.01976v5">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2403.01976v5.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hengxing Cai, Xiaochen Cai, Junhan Chang, Sihang Li, Lin Yao, Changxin Wang, Zhifeng Gao, Hongshuai Wang, Yongge Li, Mujie Lin, Shuwen Yang, Jiankun Wang, Mingjun Xu, Jin Huang, Xi Fang, Jiaxi Zhuang, Yuqi Yin, Yaqi Li, Changhong Chen, Zheng Cheng, Zifeng Zhao, Linfeng Zhang, Guolin Ke
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent breakthroughs in Large Language Models (LLMs) have revolutionized
scientific literature analysis. However, existing benchmarks fail to adequately
evaluate the proficiency of LLMs in this domain, particularly in scenarios
requiring higher-level abilities beyond mere memorization and the handling of
multimodal data. In response to this gap, we introduce SciAssess, a benchmark
specifically designed for the comprehensive evaluation of LLMs in scientific
literature analysis. It aims to thoroughly assess the efficacy of LLMs by
evaluating their capabilities in Memorization (L1), Comprehension (L2), and
Analysis \& Reasoning (L3). It encompasses a variety of tasks drawn from
diverse scientific fields, including biology, chemistry, material, and
medicine. To ensure the reliability of SciAssess, rigorous quality control
measures have been implemented, ensuring accuracy, anonymization, and
compliance with copyright standards. SciAssess evaluates 11 LLMs, highlighting
their strengths and areas for improvement. We hope this evaluation supports the
ongoing development of LLM applications in scientific literature analysis.
SciAssess and its resources are available at
\url{https://github.com/sci-assess/SciAssess}.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Does Mapo Tofu Contain Coffee? Probing LLMs for Food-related Cultural
  Knowledge 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2404.06833v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2404.06833v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Li Zhou, Taelin Karidi, Wanlong Liu, Nicolas Garneau, Yong Cao, Wenyu Chen, Haizhou Li, Daniel Hershcovich
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent studies have highlighted the presence of cultural biases in Large
Language Models (LLMs), yet often lack a robust methodology to dissect these
phenomena comprehensively. Our work aims to bridge this gap by delving into the
Food domain, a universally relevant yet culturally diverse aspect of human
life. We introduce FmLAMA, a multilingual dataset centered on food-related
cultural facts and variations in food practices. We analyze LLMs across various
architectures and configurations, evaluating their performance in both
monolingual and multilingual settings. By leveraging templates in six different
languages, we investigate how LLMs interact with language-specific and cultural
knowledge. Our findings reveal that (1) LLMs demonstrate a pronounced bias
towards food knowledge prevalent in the United States; (2) Incorporating
relevant cultural context significantly improves LLMs' ability to access
cultural knowledge; (3) The efficacy of LLMs in capturing cultural nuances is
highly dependent on the interplay between the probing language, the specific
model architecture, and the cultural context in question. This research
underscores the complexity of integrating cultural understanding into LLMs and
emphasizes the importance of culturally diverse datasets to mitigate biases and
enhance model performance across different cultural domains.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>cultural bias analysis, cultural knowledge probing, large language
  models, cultural NLP</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Synergizing In-context Learning with Hints for End-to-end Task-oriented
  Dialog Systems <span class="chip">EMNLP2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.15585v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.15585v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Vishal Vivek Saley, Rocktim Jyoti Das, Dinesh Raghu,  Mausam
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  End-to-end Task-Oriented Dialog (TOD) systems typically require extensive
training datasets to perform well. In contrast, large language model (LLM)
based TOD systems can excel even with limited data due to their ability to
learn tasks through in-context exemplars. However, these models lack alignment
with the style of responses in training data and often generate comprehensive
responses, making it difficult for users to grasp the information quickly. In
response, we propose SyncTOD that synergizes LLMs with task-specific hints to
improve alignment in low-data settings. SyncTOD employs small auxiliary models
to provide hints and select exemplars for in-context prompts. With ChatGPT,
SyncTOD achieves superior performance compared to LLM-based baselines and SoTA
models in low-data settings, while retaining competitive performance in
full-data settings.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>EMNLP2024 Camera-Ready Version</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Hyper-multi-step: The Truth Behind Difficult Long-context Tasks 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.04422v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.04422v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yijiong Yu, Ma Xiufa, Fang Jianwei, Zhi Xu, Su Guangyao, Wang Jiancheng, Yongfeng Huang, Zhixiao Qi, Wei Wang, Weifeng Liu, Ran Chen, Ji Pei
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Long-context language models (LCLM), characterized by their extensive context
window, is becoming increasingly popular. Meanwhile, many long-context
benchmarks present challenging tasks that even the most advanced LCLMs struggle
to complete. However, the underlying sources of various challenging
long-context tasks have seldom been studied. To bridge this gap, we conduct
experiments to indicate their difficulty stems primarily from two basic issues:
"multi-matching retrieval," which requires the simultaneous retrieval of
multiple items, and "logic-based retrieval," which necessitates logical
judgment within retrieval criteria. These two problems, while seemingly
straightforward, actually exceed the capabilities of LCLMs because they are
proven to be hyper-multi-step (demanding numerous steps to solve) in nature.
This finding could explain why LLMs struggle with more advanced long-context
tasks, providing a more accurate perspective for rethinking solutions for them.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Our code is publicly available at
  https://github.com/yuyijiong/hard_retrieval_for_llm and the datasets is at
  https://huggingface.co/datasets/yuyijiong/difficult_retrieval</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Fisher Information-based Efficient Curriculum Federated Learning with
  Large Language Models <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.00131v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.00131v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ji Liu, Jiaxiang Ren, Ruoming Jin, Zijie Zhang, Yang Zhou, Patrick Valduriez, Dejing Dou
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  As a promising paradigm to collaboratively train models with decentralized
data, Federated Learning (FL) can be exploited to fine-tune Large Language
Models (LLMs). While LLMs correspond to huge size, the scale of the training
data significantly increases, which leads to tremendous amounts of computation
and communication costs. The training data is generally non-Independent and
Identically Distributed (non-IID), which requires adaptive data processing
within each device. Although Low Rank Adaptation (LoRA) can significantly
reduce the scale of parameters to update in the fine-tuning process, it still
takes unaffordable time to transfer the low-rank parameters of all the layers
in LLMs. In this paper, we propose a Fisher Information-based Efficient
Curriculum Federated Learning framework (FibecFed) with two novel methods,
i.e., adaptive federated curriculum learning and efficient sparse parameter
update. First, we propose a fisher information-based method to adaptively
sample data within each device to improve the effectiveness of the FL
fine-tuning process. Second, we dynamically select the proper layers for global
aggregation and sparse parameters for local update with LoRA so as to improve
the efficiency of the FL fine-tuning process. Extensive experimental results
based on 10 datasets demonstrate that FibecFed yields excellent performance (up
to 45.35% in terms of accuracy) and superb fine-tuning speed (up to 98.61%
faster) compared with 17 baseline approaches).
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>27 pages, 8 figures, 14 tables, to appear in EMNLP 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ QUIS: Question-guided Insights Generation for Automated Exploratory Data
  Analysis 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.10270v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.10270v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Abhijit Manatkar, Ashlesha Akella, Parthivi Gupta, Krishnasuri Narayanam
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Discovering meaningful insights from a large dataset, known as Exploratory
Data Analysis (EDA), is a challenging task that requires thorough exploration
and analysis of the data. Automated Data Exploration (ADE) systems use
goal-oriented methods with Large Language Models and Reinforcement Learning
towards full automation. However, these methods require human involvement to
anticipate goals that may limit insight extraction, while fully automated
systems demand significant computational resources and retraining for new
datasets. We introduce QUIS, a fully automated EDA system that operates in two
stages: insight generation (ISGen) driven by question generation (QUGen). The
QUGen module generates questions in iterations, refining them from previous
iterations to enhance coverage without human intervention or manually curated
examples. The ISGen module analyzes data to produce multiple relevant insights
in response to each question, requiring no prior training and enabling QUIS to
adapt to new datasets.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted for ENLP 2024 Industry Track</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ SciLitLLM: How to Adapt LLMs for Scientific Literature Understanding 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2408.15545v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2408.15545v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Sihang Li, Jin Huang, Jiaxi Zhuang, Yaorui Shi, Xiaochen Cai, Mingjun Xu, Xiang Wang, Linfeng Zhang, Guolin Ke, Hengxing Cai
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Scientific literature understanding is crucial for extracting targeted
information and garnering insights, thereby significantly advancing scientific
discovery. Despite the remarkable success of Large Language Models (LLMs), they
face challenges in scientific literature understanding, primarily due to (1) a
lack of scientific knowledge and (2) unfamiliarity with specialized scientific
tasks.
  To develop an LLM specialized in scientific literature understanding, we
propose a hybrid strategy that integrates continual pre-training (CPT) and
supervised fine-tuning (SFT), to simultaneously infuse scientific domain
knowledge and enhance instruction-following capabilities for domain-specific
tasks.cIn this process, we identify two key challenges: (1) constructing
high-quality CPT corpora, and (2) generating diverse SFT instructions. We
address these challenges through a meticulous pipeline, including PDF text
extraction, parsing content error correction, quality filtering, and synthetic
instruction creation. Applying this strategy, we present a suite of LLMs:
SciLitLLM, specialized in scientific literature understanding. These models
demonstrate promising performance on scientific literature understanding
benchmarks.
  Our contributions are threefold: (1) We present an effective framework that
integrates CPT and SFT to adapt LLMs to scientific literature understanding,
which can also be easily adapted to other domains. (2) We propose an LLM-based
synthesis method to generate diverse and high-quality scientific instructions,
resulting in a new instruction set -- SciLitIns -- for supervised fine-tuning
in less-represented scientific domains. (3) SciLitLLM achieves promising
performance improvements on scientific literature understanding benchmarks.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ SeerAttention: Learning Intrinsic Sparse Attention in Your LLMs 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.13276v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.13276v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yizhao Gao, Zhichen Zeng, Dayou Du, Shijie Cao, Hayden Kwok-Hay So, Ting Cao, Fan Yang, Mao Yang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Attention is the cornerstone of modern Large Language Models (LLMs). Yet its
quadratic complexity limits the efficiency and scalability of LLMs, especially
for those with a long-context window. A promising approach addressing this
limitation is to leverage the sparsity in attention. However, existing
sparsity-based solutions predominantly rely on predefined patterns or
heuristics to approximate sparsity. This practice falls short to fully capture
the dynamic nature of attention sparsity in language-based tasks. This paper
argues that attention sparsity should be learned rather than predefined. To
this end, we design SeerAttention, a new Attention mechanism that augments the
conventional attention with a learnable gate that adaptively selects
significant blocks in an attention map and deems the rest blocks sparse. Such
block-level sparsity effectively balances accuracy and speedup. To enable
efficient learning of the gating network, we develop a customized
FlashAttention implementation that extracts the block-level ground truth of
attention map with minimum overhead. SeerAttention not only applies to
post-training, but also excels in long-context fine-tuning. Our results show
that at post-training stages, SeerAttention significantly outperforms
state-of-the-art static or heuristic-based sparse attention methods, while also
being more versatile and flexible to adapt to varying context lengths and
sparsity ratios. When applied to long-context fine-tuning with YaRN,
SeerAttention can achieve a remarkable 90% sparsity ratio at a 32k context
length with minimal perplexity loss, offering a 5.67x speedup over
FlashAttention-2.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ P3: A Policy-Driven, Pace-Adaptive, and Diversity-Promoted Framework for
  data pruning in LLM Training 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2408.05541v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2408.05541v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yingxuan Yang, Huayi Wang, Muning Wen, Xiaoyun Mo, Qiuying Peng, Jun Wang, Weinan Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In the rapidly advancing field of Large Language Models (LLMs), effectively
leveraging existing datasets during fine-tuning to maximize the model's
potential is of paramount importance. This paper introduces P3, an adaptive
framework aimed at optimizing the task-specific fine-tuning process through
iterative data pruning. P3 consists of three key components: (1) Policy-driven
Difficulty Measurement, which dynamically assesses data difficulty based on the
model's real-time performance, replacing static metrics with adaptable
evaluations; (2) Pace-Adaptive Selection, leveraging self-paced learning to
progressively introduce more challenging data, thereby enhancing model
capability; (3) Diversity Promotion, incorporating Determinantal Point Process
(DPP) to ensure data diversity across epochs, enriching the learning process.
We validate P3 on the reasoning scenarios, APPS and MATH, demonstrating
significant improvements over traditional data pruning methods. By advancing
dynamic data selection and utilization strategies, P3 contributes both a
theoretical framework and concrete approach to fully exploit existing data for
LLMs' performance improvement, offering utility across diverse tasks.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ LatentExplainer: Explaining Latent Representations in Deep Generative
  Models with Multi-modal Foundation Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.14862v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.14862v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mengdan Zhu, Raasikh Kanjiani, Jiahui Lu, Andrew Choi, Qirui Ye, Liang Zhao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Deep generative models like VAEs and diffusion models have advanced various
generation tasks by leveraging latent variables to learn data distributions and
generate high-quality samples. Despite the field of explainable AI making
strides in interpreting machine learning models, understanding latent variables
in generative models remains challenging. This paper introduces
\textit{LatentExplainer}, a framework for automatically generating semantically
meaningful explanations of latent variables in deep generative models.
\textit{LatentExplainer} tackles three main challenges: inferring the meaning
of latent variables, aligning explanations with inductive biases, and handling
varying degrees of explainability. Our approach perturbs latent variables,
interpreting changes in generated data, and uses multi-modal large language
models (MLLMs) to produce human-understandable explanations. We evaluate our
proposed method on several real-world and synthetic datasets, and the results
demonstrate superior performance in generating high-quality explanations for
latent variables. The results highlight the effectiveness of incorporating
inductive biases and uncertainty quantification, significantly enhancing model
interpretability.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Supervised Fine-Tuning Achieve Rapid Task Adaption Via Alternating
  Attention Head Activation Patterns 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.15820v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.15820v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yang Zhao, Li Du, Xiao Ding, Kai Xiong, Ting Liu, Bing Qin
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  LLMs' performance on complex tasks is still unsatisfactory. A key issue is
that presently LLMs learn in a data-driven schema, while the instructions about
these complex tasks are both scarce and hard to collect or construct. On the
contrary, a prominent phenomenon is that LLMs can learn rather fast on simpler
tasks with adequate prior knowledge captured during pretraining stage. Thus, if
the prerequisite and mechanism of such rapid generalization could be
elucidated, it could enhance the efficiency and effectiveness of the LLM's
ability to learn complex tasks. Thus, in this paper, we employ a gradient-based
method, to dissect the process that the SFT process adapts LLMs to downstream
tasks via the perspective of attention patterns. We find that: (1) LLMs
selectively activate task-specific attention heads during SFT; (2) activation
patterns for complex tasks are combinations of basic task patterns; and (3)
changes in a few parameters can significantly impact activation patterns after
SFT on a small number of samples.Based on these insights, experiments are
conducted to actually enhance the efficiency and effectiveness of SFT.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>in review</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ From Introspection to Best Practices: Principled Analysis of
  Demonstrations in Multimodal In-Context Learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.00902v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.00902v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Nan Xu, Fei Wang, Sheng Zhang, Hoifung Poon, Muhao Chen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Motivated by in-context learning (ICL) capabilities of Large Language models
(LLMs), multimodal LLMs with additional visual modality are also exhibited with
similar ICL abilities when multiple image-text pairs are provided as
demonstrations. However, relatively less work has been done to investigate the
principles behind how and why multimodal ICL works. We conduct a systematic and
principled evaluation of multimodal ICL for models of different scales on a
broad spectrum of new yet critical tasks. Through perturbations over different
modality information, we show that modalities matter differently across tasks
in multimodal ICL. Guided by task-specific modality impact, we recommend
modality-driven demonstration strategies to boost ICL performance. We also find
that models may follow inductive biases from multimodal ICL even if they are
rarely seen in or contradict semantic priors from pretraining data. Our
principled analysis provides a comprehensive way of understanding the role of
demonstrations in multimodal in-context learning, and sheds light on
effectively improving multimodal ICL on a wide range of tasks.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Everything is Editable: Extend Knowledge Editing to Unstructured Data in
  Large Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.15349v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.15349v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jingcheng Deng, Zihao Wei, Liang Pang, Hanxing Ding, Huawei Shen, Xueqi Cheng
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent knowledge editing methods have primarily focused on modifying
structured knowledge in large language models. However, this task setting
overlooks the fact that a significant portion of real-world knowledge is stored
in an unstructured format, characterized by long-form content, noise, and a
complex yet comprehensive nature. Techniques like local layer key-value storage
and term-driven optimization, as used in previous methods like MEMIT, are not
effective for handling unstructured knowledge. To address these challenges, we
propose a novel Unstructured Knowledge Editing method, namely UnKE, which
extends previous assumptions in the layer dimension and token dimension.
Firstly, in the layer dimension, we propose non-local block key-value storage
to replace local layer key-value storage, increasing the representation ability
of key-value pairs and incorporating attention layer knowledge. Secondly, in
the token dimension, we replace term-driven optimization with cause-driven
optimization, which edits the last token directly while preserving context,
avoiding the need to locate terms and preventing the loss of context
information. Results on newly proposed unstructured knowledge editing dataset
(UnKEBench) and traditional structured datasets demonstrate that UnKE achieves
remarkable performance, surpassing strong baselines. In addition, UnKE has
robust batch editing and sequential editing capabilities.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Amphista: Bi-directional Multi-head Decoding for Accelerating LLM
  Inference 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.13170v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.13170v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zeping Li, Xinlong Yang, Ziheng Gao, Ji Liu, Guanchen Li, Zhuang Liu, Dong Li, Jinzhang Peng, Lu Tian, Emad Barsoum
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large Language Models (LLMs) inherently use autoregressive decoding, which
lacks parallelism in inference and results in significantly slow inference
speed. While methods such as Medusa constructs parallelized heads, they lack
adequate information interaction across different prediction positions. To
overcome this limitation, we introduce Amphista, an enhanced speculative
decoding framework that builds upon Medusa. Specifically, Amphista models an
Auto-embedding Block capable of parallel inference, incorporating
bi-directional attention to enable interaction between different drafting
heads. Additionally, Amphista integrates Staged Adaptation Layers, which ensure
a seamless transition of semantic information from the target model's
autoregressive inference to the drafting heads' non-autoregressive inference,
effectively achieving paradigm shift and feature fusion. Experimental results
on Vicuna models using MT-Bench and Spec-Bench demonstrate that Amphista
achieves substantial acceleration while maintaining generation quality. On
MT-Bench, Amphista delivers up to 2.75$\times$ speedup over vanilla
autoregressive decoding and 1.40$\times$ over Medusa on Vicuna 33B in
wall-clock time.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ LayerSkip: Enabling Early Exit Inference and Self-Speculative Decoding <span class="chip">ACL 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2404.16710v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2404.16710v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mostafa Elhoushi, Akshat Shrivastava, Diana Liskovich, Basil Hosmer, Bram Wasti, Liangzhen Lai, Anas Mahmoud, Bilge Acun, Saurabh Agarwal, Ahmed Roman, Ahmed A Aly, Beidi Chen, Carole-Jean Wu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We present LayerSkip, an end-to-end solution to speed-up inference of large
language models (LLMs). First, during training we apply layer dropout, with low
dropout rates for earlier layers and higher dropout rates for later layers, and
an early exit loss where all transformer layers share the same exit. Second,
during inference, we show that this training recipe increases the accuracy of
early exit at earlier layers, without adding any auxiliary layers or modules to
the model. Third, we present a novel self-speculative decoding solution where
we exit at early layers and verify and correct with remaining layers of the
model. Our proposed self-speculative decoding approach has less memory
footprint than other speculative decoding approaches and benefits from shared
compute and activations of the draft and verification stages. We run
experiments on different Llama model sizes on different types of training:
pretraining from scratch, continual pretraining, finetuning on specific data
domain, and finetuning on specific task. We implement our inference solution
and show speedups of up to 2.16x on summarization for CNN/DM documents, 1.82x
on coding, and 2.0x on TOPv2 semantic parsing task. We open source our code and
checkpoints at https://github.com/facebookresearch/LayerSkip.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>ACL 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ A Tighter Complexity Analysis of Sparse<span class="highlight-title">GPT</span> 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2408.12151v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2408.12151v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xiaoyu Li, Yingyu Liang, Zhenmei Shi, Zhao Song
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this work, we improved the analysis of the running time of SparseGPT
[Frantar, Alistarh ICML 2023] from $O(d^{3})$ to $O(d^{\omega} + d^{2+a+o(1)} +
d^{1+\omega(1,1,a)-a})$ for any $a \in [0, 1]$, where $\omega$ is the exponent
of matrix multiplication. In particular, for the current $\omega \approx 2.371$
[Alman, Duan, Williams, Xu, Xu, Zhou 2024], our running time boils down to
$O(d^{2.53})$. This running time is due to the analysis of the lazy update
behavior in iterative maintenance problems such as [Deng, Song, Weinstein 2022;
Brand, Song, Zhou ICML 2024].
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ A Comprehensive Study of Multilingual Confidence Estimation on Large
  Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2402.13606v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2402.13606v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Boyang Xue, Hongru Wang, Rui Wang, Sheng Wang, Zezhong Wang, Yiming Du, Bin Liang, Kam-Fai Wong
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The tendency of Large Language Models (LLMs) to generate hallucinations
raises concerns regarding their reliability. Therefore, confidence estimations
indicating the extent of trustworthiness of the generations become essential.
However, current LLM confidence estimations in languages other than English
remain underexplored. This paper addresses this gap by introducing a
comprehensive investigation of Multilingual Confidence estimation (MlingConf)
on LLMs, focusing on both language-agnostic (LA) and language-specific (LS)
tasks to explore the performance and language dominance effects of multilingual
confidence estimations on different tasks. The benchmark comprises four
meticulously checked and human-evaluate high-quality multilingual datasets for
LA tasks and one for the LS task tailored to specific social, cultural, and
geographical contexts of a language. Our experiments reveal that on LA tasks
English exhibits notable linguistic dominance in confidence estimations than
other languages, while on LS tasks, using question-related language to prompt
LLMs demonstrates better linguistic dominance in multilingual confidence
estimations. The phenomena inspire a simple yet effective native-tone prompting
strategy by employing language-specific prompts for LS tasks, effectively
improving LLMs' reliability and accuracy on LS tasks.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Comments: n pages; Previously this version appeared as
  arXiv:2410.12478 which was submitted as a new work by accident</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ ExACT: Teaching AI Agents to Explore with Reflective-MCTS and
  Exploratory Learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.02052v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.02052v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xiao Yu, Baolin Peng, Vineeth Vajipey, Hao Cheng, Michel Galley, Jianfeng Gao, Zhou Yu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Autonomous agents have demonstrated significant potential in automating
complex multistep decision-making tasks. However, even state-of-the-art
vision-language models (VLMs), such as GPT-4o, still fall short of human-level
performance, particularly in intricate web environments and long-horizon tasks.
To address these limitations, we present ExACT, an approach to combine
test-time search and self-learning to build o1-like models for agentic
applications. We first introduce Reflective Monte Carlo Tree Search (R-MCTS), a
novel test time algorithm designed to enhance AI agents' ability to explore
decision space on the fly. R-MCTS extends traditional MCTS by 1) incorporating
contrastive reflection, allowing agents to learn from past interactions and
dynamically improve their search efficiency; and 2) using multi-agent debate
for reliable state evaluation. Next, we introduce Exploratory Learning, a novel
learning strategy to teach agents to search at inference time without relying
on any external search algorithms. On the challenging VisualWebArena benchmark,
our GPT-4o based R-MCTS agent achieves a 6% to 30% relative improvement across
various tasks compared to the previous state-of-the-art. Additionally, we show
that the knowledge and experience gained from test-time search can be
effectively transferred back to GPT-4o via fine-tuning. After Exploratory
Learning, GPT-4o 1) demonstrates the ability to explore the environment,
evaluate a state, and backtrack to viable ones when it detects that the current
state cannot lead to success, and 2) matches 87% of R-MCTS's performance while
using significantly less compute. Notably, our work demonstrates the compute
scaling properties in both training - data collection with R-MCTS - and testing
time. These results suggest a promising research direction to enhance VLMs'
capabilities for agentic applications via test-time search and self-learning.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ MlingConf: A Comprehensive Study of Multilingual Confidence Estimation
  on Large Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12478v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12478v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Boyang Xue, Hongru Wang, Rui Wang, Sheng Wang, Zezhong Wang, Yiming Du, Bin Liang, Kam-Fai Wong
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The tendency of Large Language Models (LLMs) to generate hallucinations
raises concerns regarding their reliability. Therefore, confidence estimations
indicating the extent of trustworthiness of the generations become essential.
However, current LLM confidence estimations in languages other than English
remain underexplored. This paper addresses this gap by introducing a
comprehensive investigation of Multilingual Confidence estimation (MlingConf)
on LLMs, focusing on both language-agnostic (LA) and language-specific (LS)
tasks to explore the performance and language dominance effects of multilingual
confidence estimations on different tasks. The benchmark comprises four
meticulously checked and human-evaluate high-quality multilingual datasets for
LA tasks and one for the LS task tailored to specific social, cultural, and
geographical contexts of a language. Our experiments reveal that on LA tasks
English exhibits notable linguistic dominance in confidence estimations than
other languages, while on LS tasks, using question-related language to prompt
LLMs demonstrates better linguistic dominance in multilingual confidence
estimations. The phenomena inspire a simple yet effective native-tone prompting
strategy by employing language-specific prompts for LS tasks, effectively
improving LLMs' reliability and accuracy on LS tasks.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Comments: This work was intended as a replacement of arXiv:2402.13606
  and any subsequent updates will appear there</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ $\textbf{Only-IF}$:Revealing the Decisive Effect of Instruction
  Diversity on Generalization 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.04717v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.04717v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Dylan Zhang, Justin Wang, Francois Charton
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Understanding and accurately following instructions is critical for large
language models (LLMs) to be effective across diverse tasks. In this work, we
rigorously examine the key factors that enable models to generalize to unseen
instructions, providing insights to guide the collection of data for
instruction-tuning. Through controlled experiments, inspired by the
Turing-complete Markov algorithm, we demonstrate that such generalization
$\textbf{only emerges}$ when training data is diversified enough across
semantic domains. Our findings also reveal that merely diversifying within
limited domains fails to ensure robust generalization. In contrast,
cross-domain data diversification, even under constrained data budgets,
significantly enhances a model's adaptability. We further extend our analysis
to real-world scenarios, including fine-tuning of
$\textit{$\textbf{specialist}$}$ and $\textit{$\textbf{generalist}$}$ models.
In both cases, we demonstrate that 1) better performance can be achieved by
increasing the diversity of an established dataset while keeping the data size
constant, and 2) when scaling up the data, diversifying the semantics of
instructions is more effective than simply increasing the quantity of similar
data. Our research provides important insights for dataset collation,
particularly when optimizing model performance by expanding training data for
both specialist and generalist scenarios. We show that careful consideration of
data diversification is key: training specialist models with data extending
beyond their core domain leads to significant performance improvements, while
generalist models benefit from diverse data mixtures that enhance their overall
instruction-following capabilities across a wide range of applications. Our
results highlight the critical role of strategic diversification and offer
clear guidelines for improving data quality.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Fix formatting issues</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ BenTo: Benchmark Task Reduction with In-Context Transferability 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.13804v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.13804v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hongyu Zhao, Ming Li, Lichao Sun, Tianyi Zhou
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Evaluating large language models (LLMs) is costly: it requires the generation
and examination of LLM outputs on a large-scale benchmark of various tasks.
This paper investigates how to efficiently reduce the tasks used to benchmark
LLMs without affecting the evaluation quality. Our study reveals that task
transferability and relevance provide critical information to identify the most
representative subset of tasks via optimizing a facility location function. We
propose a practically efficient metric for estimating the transferability
between two tasks via in-context learning (ICL). By analyzing the pairwise
transferability, we can reduce tasks in a modern LLM benchmark (e.g., MMLU or
FLAN) to 5% while inducing only a <4% difference to the evaluation on the
original benchmark. Compared to prior works, our method is training-free,
gradient-free, and highly efficient requiring ICL only.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>https://github.com/tianyi-lab/bento</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ GraphInsight: Unlocking Insights in Large Language Models for Graph
  Structure Understanding 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.03258v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.03258v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yukun Cao, Shuo Han, Zengyi Gao, Zezhong Ding, Xike Xie, S. Kevin Zhou
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Although Large Language Models (LLMs) have demonstrated potential in
processing graphs, they struggle with comprehending graphical structure
information through prompts of graph description sequences, especially as the
graph size increases. We attribute this challenge to the uneven memory
performance of LLMs across different positions in graph description sequences,
known as ''positional biases''. To address this, we propose GraphInsight, a
novel framework aimed at improving LLMs' comprehension of both macro- and
micro-level graphical information. GraphInsight is grounded in two key
strategies: 1) placing critical graphical information in positions where LLMs
exhibit stronger memory performance, and 2) investigating a lightweight
external knowledge base for regions with weaker memory performance, inspired by
retrieval-augmented generation (RAG). Moreover, GraphInsight explores
integrating these two strategies into LLM agent processes for composite graph
tasks that require multi-step reasoning. Extensive empirical studies on
benchmarks with a wide range of evaluation tasks show that GraphInsight
significantly outperforms all other graph description methods (e.g., prompting
techniques and reordering strategies) in understanding graph structures of
varying sizes.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ AutoPal: Autonomous Adaptation to Users for Personal AI Companionship 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.13960v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.13960v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yi Cheng, Wenge Liu, Kaishuai Xu, Wenjun Hou, Yi Ouyang, Chak Tou Leong, Xian Wu, Yefeng Zheng
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Previous research has demonstrated the potential of AI agents to act as
companions that can provide constant emotional support for humans. In this
paper, we emphasize the necessity of autonomous adaptation in personal AI
companionship, an underexplored yet promising direction. Such adaptability is
crucial as it can facilitate more tailored interactions with users and allow
the agent to evolve in response to users' changing needs. However, imbuing
agents with autonomous adaptability presents unique challenges, including
identifying optimal adaptations to meet users' expectations and ensuring a
smooth transition during the adaptation process. To address them, we devise a
hierarchical framework, AutoPal, that enables controllable and authentic
adjustments to the agent's persona based on user interactions. A
personamatching dataset is constructed to facilitate the learning of optimal
persona adaptations. Extensive experiments demonstrate the effectiveness of
AutoPal and highlight the importance of autonomous adaptability in AI
companionship.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Efficiently Quantifying and Mitigating Ripple Effects in Model Editing 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2403.07825v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2403.07825v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jianchen Wang, Zhouhong Gu, Xiaoxuan Zhu, Lin Zhang, Haoning Ye, Zhuozhi Xiong, Hongwei Feng, Yanghua Xiao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large Language Models have revolutionized numerous tasks with their
remarkable efficacy. However, editing these models, crucial for rectifying
outdated or erroneous information, often leads to a complex issue known as the
ripple effect in the hidden space. While difficult to detect, this effect can
significantly impede the efficacy of model editing tasks and deteriorate model
performance. This paper addresses this scientific challenge by proposing a
novel evaluation methodology, Graphical Impact Evaluation(GIE), which
quantitatively evaluates the adaptations of the model and the subsequent impact
of editing. Furthermore, we introduce the Selective Impact Revision(SIR), a
model editing method designed to mitigate this ripple effect. Our comprehensive
evaluations reveal that the ripple effect in the hidden space is a significant
issue in all current model editing methods. However, our proposed methods, GIE
and SIR, effectively identify and alleviate this issue, contributing to the
advancement of LLM editing techniques.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ MoR: Mixture of Ranks for Low-Rank Adaptation Tuning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.13408v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.13408v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Chuanyu Tang, Yilong Chen, Zhenyu Zhang, Junyuan Shang, Wenyuan Zhang, Yong Huang, Tingwen Liu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Low-Rank Adaptation (LoRA) drives research to align its performance with full
fine-tuning. However, significant challenges remain: (1) Simply increasing the
rank size of LoRA does not effectively capture high-rank information, which
leads to a performance bottleneck.(2) MoE-style LoRA methods substantially
increase parameters and inference latency, contradicting the goals of efficient
fine-tuning and ease of application. To address these challenges, we introduce
Mixture of Ranks (MoR), which learns rank-specific information for different
tasks based on input and efficiently integrates multi-rank information. We
firstly propose a new framework that equates the integration of multiple LoRAs
to expanding the rank of LoRA. Moreover, we hypothesize that low-rank LoRA
already captures sufficient intrinsic information, and MoR can derive high-rank
information through mathematical transformations of the low-rank components.
Thus, MoR can reduces the learning difficulty of LoRA and enhances its
multi-task capabilities. MoR achieves impressive results, with MoR delivering a
1.31\% performance improvement while using only 93.93\% of the parameters
compared to baseline methods.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>11 pages, 7 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ UniAutoML: A Human-Centered Framework for Unified Discriminative and
  Generative AutoML with Large Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12841v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12841v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jiayi Guo, Zan Chen, Yingrui Ji, Liyun Zhang, Daqin Luo, Zhigang Li, Yiqin Shen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Automated Machine Learning (AutoML) has simplified complex ML processes such
as data pre-processing, model selection, and hyper-parameter searching.
However, traditional AutoML frameworks focus solely on discriminative tasks,
often falling short in tackling AutoML for generative models. Additionally,
these frameworks lack interpretability and user engagement during the training
process, primarily due to the absence of human-centered design. It leads to a
lack of transparency in final decision-making and limited user control,
potentially reducing trust and adoption of AutoML methods. To address these
limitations, we introduce UniAutoML, a human-centered AutoML framework that
leverages Large Language Models (LLMs) to unify AutoML for both discriminative
(e.g., Transformers and CNNs for classification or regression tasks) and
generative tasks (e.g., fine-tuning diffusion models or LLMs). The
human-centered design of UniAutoML innovatively features a conversational user
interface (CUI) that facilitates natural language interactions, providing users
with real-time guidance, feedback, and progress updates for better
interpretability. This design enhances transparency and user control throughout
the AutoML training process, allowing users to seamlessly break down or modify
the model being trained. To mitigate potential risks associated with LLM
generated content, UniAutoML incorporates a safety guardline that filters
inputs and censors outputs. We evaluated UniAutoML's performance and usability
through experiments on eight diverse datasets and user studies involving 25
participants, demonstrating that UniAutoML not only enhances performance but
also improves user control and trust. Our human-centered design bridges the gap
between AutoML capabilities and user understanding, making ML more accessible
to a broader audience.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ ACCEPT: Adaptive Codebook for Composite and Efficient <span class="highlight-title">Prompt</span> Tuning <span class="chip">EMNLP</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12847v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12847v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yu-Chen Lin, Wei-Hua Li, Jun-Cheng Chen, Chu-Song Chen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Prompt Tuning has been a popular Parameter-Efficient Fine-Tuning method
attributed to its remarkable performance with few updated parameters on various
large-scale pretrained Language Models (PLMs). Traditionally, each prompt has
been considered indivisible and updated independently, leading the parameters
increase proportionally as prompt length grows. To address this issue, we
propose Adaptive Codebook for Composite and Efficient Prompt Tuning (ACCEPT).
In our method, we refer to the concept of product quantization (PQ), allowing
all soft prompts to share a set of learnable codebook vectors in each subspace,
with each prompt differentiated by a set of adaptive weights. We achieve the
superior performance on 17 diverse natural language tasks including natural
language understanding (NLU) and question answering (QA) tasks by tuning only
0.3% of parameters of the PLMs. Our approach also excels in few-shot and large
model settings, highlighting its significant potential.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>EMNLP Findings 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ On Subjective Uncertainty Quantification and Calibration in Natural
  Language Generation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.05213v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.05213v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ziyu Wang, Chris Holmes
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Applications of large language models often involve the generation of
free-form responses, in which case uncertainty quantification becomes
challenging. This is due to the need to identify task-specific uncertainties
(e.g., about the semantics) which appears difficult to define in general cases.
This work addresses these challenges from a perspective of Bayesian decision
theory, starting from the assumption that our utility is characterized by a
similarity measure that compares a generated response with a hypothetical true
response. We discuss how this assumption enables principled quantification of
the model's subjective uncertainty and its calibration. We further derive a
measure for epistemic uncertainty, based on a missing data perspective and its
characterization as an excess risk. The proposed methods can be applied to
black-box language models. We illustrate the methods on question answering and
machine translation tasks. Our experiments provide a principled evaluation of
task-specific calibration, and demonstrate that epistemic uncertainty offers a
promising deferral strategy for efficient data acquisition in in-context
learning.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ An Evolved Universal <span class="highlight-title">Transformer</span> Memory 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.13166v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.13166v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Edoardo Cetin, Qi Sun, Tianyu Zhao, Yujin Tang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Prior methods propose to offset the escalating costs of modern foundation
models by dropping specific parts of their contexts with hand-designed rules,
while attempting to preserve their original performance. We overcome this
trade-off with Neural Attention Memory Models (NAMMs), introducing a learned
network for memory management that improves both the performance and efficiency
of transformers. We evolve NAMMs atop pre-trained transformers to provide
different latent contexts focusing on the most relevant information for
individual layers and attention heads. NAMMs are universally applicable to any
model using self-attention as they condition exclusively on the values in the
produced attention matrices. Learning NAMMs on a small set of problems, we
achieve substantial performance improvements across multiple long-context
benchmarks while cutting the model's input contexts up to a fraction of the
original sizes. We show the generality of our conditioning enables zero-shot
transfer of NAMMs trained only on language to entirely new transformer
architectures even across input modalities, with their benefits carrying over
to vision and reinforcement learning.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>29 pages, 14 figures. Preprint, under submission. Source code is
  available at https://github.com/SakanaAI/evo-memory</span>
                                        </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
            <article>
                <details>
                    <Summary>
                        Computer Vision and Pattern Recognition <span class="chip" style="font-size: 60%">108</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ BiGR: Harnessing Binary Latent Codes for Image Generation and Improved
  Visual Representation Capabilities 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14672v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14672v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Shaozhe Hao, Xuantong Liu, Xianbiao Qi, Shihao Zhao, Bojia Zi, Rong Xiao, Kai Han, Kwan-Yee K. Wong
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We introduce BiGR, a novel conditional image generation model using compact
binary latent codes for generative training, focusing on enhancing both
generation and representation capabilities. BiGR is the first conditional
generative model that unifies generation and discrimination within the same
framework. BiGR features a binary tokenizer, a masked modeling mechanism, and a
binary transcoder for binary code prediction. Additionally, we introduce a
novel entropy-ordered sampling method to enable efficient image generation.
Extensive experiments validate BiGR's superior performance in generation
quality, as measured by FID-50k, and representation capabilities, as evidenced
by linear-probe accuracy. Moreover, BiGR showcases zero-shot generalization
across various vision tasks, enabling applications such as image inpainting,
outpainting, editing, interpolation, and enrichment, without the need for
structural modifications. Our findings suggest that BiGR unifies generative and
discriminative tasks effectively, paving the way for further advancements in
the field.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Project page: https://haoosz.github.io/BiGR</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ NaturalBench: Evaluating Vision-Language Models on Natural Adversarial
  Samples <span class="chip">NeurIPS 24</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14669v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14669v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Baiqi Li, Zhiqiu Lin, Wenxuan Peng, Jean de Dieu Nyandwi, Daniel Jiang, Zixian Ma, Simran Khanuja, Ranjay Krishna, Graham Neubig, Deva Ramanan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Vision-language models (VLMs) have made significant progress in recent
visual-question-answering (VQA) benchmarks that evaluate complex
visio-linguistic reasoning. However, are these models truly effective? In this
work, we show that VLMs still struggle with natural images and questions that
humans can easily answer, which we term natural adversarial samples. We also
find it surprisingly easy to generate these VQA samples from natural image-text
corpora using off-the-shelf models like CLIP and ChatGPT. We propose a
semi-automated approach to collect a new benchmark, NaturalBench, for reliably
evaluating VLMs with 10,000 human-verified VQA samples. Crucially, we adopt a
$\textbf{vision-centric}$ design by pairing each question with two images that
yield different answers, preventing blind solutions from answering without
using the images. This makes NaturalBench more challenging than previous
benchmarks that can be solved with commonsense priors. We evaluate 53
state-of-the-art VLMs on NaturalBench, showing that models like
LLaVA-OneVision, Cambrian-1, Llama3.2-Vision, Molmo, Qwen2-VL, and even GPT-4o
lag 50%-70% behind human performance (over 90%). We analyze why NaturalBench is
hard from two angles: (1) Compositionality: Solving NaturalBench requires
diverse visio-linguistic skills, including understanding attribute bindings,
object relationships, and advanced reasoning like logic and counting. To this
end, unlike prior work that uses a single tag per sample, we tag each
NaturalBench sample with 1 to 8 skill tags for fine-grained evaluation. (2)
Biases: NaturalBench exposes severe biases in VLMs, as models often choose the
same answer regardless of the image. Lastly, we apply our benchmark curation
method to diverse data sources, including long captions (over 100 words) and
non-English languages like Chinese and Hindi, highlighting its potential for
dynamic evaluations of VLMs.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to NeurIPS 24; We open-source our dataset at:
  https://huggingface.co/datasets/BaiqiL/NaturalBench; Project page at:
  https://linzhiqiu.github.io/papers/naturalbench/</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Parallel Backpropagation for Inverse of a Convolution with Application
  to Normalizing Flows 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14634v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14634v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Sandeep Nagar, Girish Varma
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Inverse of an invertible convolution is an important operation that comes up
in Normalizing Flows, Image Deblurring, etc. The naive algorithm for
backpropagation of this operation using Gaussian elimination has running time
$O(n^3)$ where $n$ is the number of pixels in the image. We give a fast
parallel backpropagation algorithm with running time $O(\sqrt{n})$ for a square
image and provide a GPU implementation of the same. Inverse Convolutions are
usually used in Normalizing Flows in the sampling pass, making them slow. We
propose to use Inverse Convolutions in the forward (image to latent vector)
pass of the Normalizing flow. Since the sampling pass is the inverse of the
forward pass, it will use convolutions only, resulting in efficient sampling
times. We use our parallel backpropagation algorithm for optimizing the inverse
convolution layer resulting in fast training times also. We implement this
approach in various Normalizing Flow backbones, resulting in our Inverse-Flow
models. We benchmark Inverse-Flow on standard datasets and show significantly
improved sampling times with similar bits per dimension compared to previous
models.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Preprint</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Swiss Army Knife: Synergizing Biases in Knowledge from Vision Foundation
  Models for Multi-Task Learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14633v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14633v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yuxiang Lu, Shengcao Cao, Yu-Xiong Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Vision Foundation Models (VFMs) have demonstrated outstanding performance on
numerous downstream tasks. However, due to their inherent representation biases
originating from different training paradigms, VFMs exhibit advantages and
disadvantages across distinct vision tasks. Although amalgamating the strengths
of multiple VFMs for downstream tasks is an intuitive strategy, effectively
exploiting these biases remains a significant challenge. In this paper, we
propose a novel and versatile "Swiss Army Knife" (SAK) solution, which
adaptively distills knowledge from a committee of VFMs to enhance multi-task
learning. Unlike existing methods that use a single backbone for knowledge
transfer, our approach preserves the unique representation bias of each teacher
by collaborating the lightweight Teacher-Specific Adapter Path modules with the
Teacher-Agnostic Stem. Through dynamic selection and combination of
representations with Mixture-of-Representations Routers, our SAK is capable of
synergizing the complementary strengths of multiple VFMs. Extensive experiments
show that our SAK remarkably outperforms prior state of the arts in multi-task
learning by 10% on the NYUD-v2 benchmark, while also providing a flexible and
robust framework that can readily accommodate more advanced model designs.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ MultiOrg: A Multi-rater Organoid-detection <span class="highlight-title">Dataset</span> 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14612v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14612v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Christina Bukas, Harshavardhan Subramanian, Fenja See, Carina Steinchen, Ivan Ezhov, Gowtham Boosarpu, Sara Asgharpour, Gerald Burgstaller, Mareike Lehmann, Florian Kofler, Marie Piraud
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  High-throughput image analysis in the biomedical domain has gained
significant attention in recent years, driving advancements in drug discovery,
disease prediction, and personalized medicine. Organoids, specifically, are an
active area of research, providing excellent models for human organs and their
functions. Automating the quantification of organoids in microscopy images
would provide an effective solution to overcome substantial manual
quantification bottlenecks, particularly in high-throughput image analysis.
However, there is a notable lack of open biomedical datasets, in contrast to
other domains, such as autonomous driving, and, notably, only few of them have
attempted to quantify annotation uncertainty. In this work, we present MultiOrg
a comprehensive organoid dataset tailored for object detection tasks with
uncertainty quantification. This dataset comprises over 400 high-resolution 2d
microscopy images and curated annotations of more than 60,000 organoids. Most
importantly, it includes three label sets for the test data, independently
annotated by two experts at distinct time points. We additionally provide a
benchmark for organoid detection, and make the best model available through an
easily installable, interactive plugin for the popular image visualization tool
Napari, to perform organoid quantification.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ DRACO-DehazeNet: An Efficient Image Dehazing Network Combining Detail
  Recovery and a Novel Contrastive Learning Paradigm 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14595v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14595v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Gao Yu Lee, Tanmoy Dam, Md Meftahul Ferdaus, Daniel Puiu Poenar, Vu Duong
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Image dehazing is crucial for clarifying images obscured by haze or fog, but
current learning-based approaches is dependent on large volumes of training
data and hence consumed significant computational power. Additionally, their
performance is often inadequate under non-uniform or heavy haze. To address
these challenges, we developed the Detail Recovery And Contrastive DehazeNet,
which facilitates efficient and effective dehazing via a dense dilated inverted
residual block and an attention-based detail recovery network that tailors
enhancements to specific dehazed scene contexts. A major innovation is its
ability to train effectively with limited data, achieved through a novel
quadruplet loss-based contrastive dehazing paradigm. This approach distinctly
separates hazy and clear image features while also distinguish lower-quality
and higher-quality dehazed images obtained from each sub-modules of our
network, thereby refining the dehazing process to a larger extent. Extensive
tests on a variety of benchmarked haze datasets demonstrated the superiority of
our approach. The code repository for this work will be available soon.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Submitted to a journal and currently under review. Once the paper is
  accepted and published, the copyright will be transferred to the
  corresponding journal</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ MomentumSMoE: Integrating Momentum into Sparse Mixture of Experts <span class="chip">NeurIPS 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14574v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14574v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Rachel S. Y. Teo, Tan M. Nguyen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Sparse Mixture of Experts (SMoE) has become the key to unlocking unparalleled
scalability in deep learning. SMoE has the potential to exponentially increase
parameter count while maintaining the efficiency of the model by only
activating a small subset of these parameters for a given sample. However, it
has been observed that SMoE suffers from unstable training and has difficulty
adapting to new distributions, leading to the model's lack of robustness to
data contamination. To overcome these limitations, we first establish a
connection between the dynamics of the expert representations in SMoEs and
gradient descent on a multi-objective optimization problem. Leveraging our
framework, we then integrate momentum into SMoE and propose a new family of
SMoEs named MomentumSMoE. We theoretically prove and numerically demonstrate
that MomentumSMoE is more stable and robust than SMoE. In particular, we verify
the advantages of MomentumSMoE over SMoE on a variety of practical tasks
including ImageNet-1K object recognition and WikiText-103 language modeling. We
demonstrate the applicability of MomentumSMoE to many types of SMoE models,
including those in the Sparse MoE model for vision (V-MoE) and the Generalist
Language Model (GLaM). We also show that other advanced momentum-based
optimization methods, such as Adam, can be easily incorporated into the
MomentumSMoE framework for designing new SMoE models with even better
performance, almost negligible additional computation cost, and simple
implementations.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>10 pages in the main text. Published at NeurIPS 2024. The code is
  available at https://github.com/rachtsy/MomentumSMoE</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Multi-modal Pose Diffuser: A Multimodal Generative Conditional Pose
  Prior 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14540v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14540v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Calvin-Khang Ta, Arindam Dutta, Rohit Kundu, Rohit Lal, Hannah Dela Cruz, Dripta S. Raychaudhuri, Amit Roy-Chowdhury
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The Skinned Multi-Person Linear (SMPL) model plays a crucial role in 3D human
pose estimation, providing a streamlined yet effective representation of the
human body. However, ensuring the validity of SMPL configurations during tasks
such as human mesh regression remains a significant challenge , highlighting
the necessity for a robust human pose prior capable of discerning realistic
human poses. To address this, we introduce MOPED:
\underline{M}ulti-m\underline{O}dal \underline{P}os\underline{E}
\underline{D}iffuser. MOPED is the first method to leverage a novel multi-modal
conditional diffusion model as a prior for SMPL pose parameters. Our method
offers powerful unconditional pose generation with the ability to condition on
multi-modal inputs such as images and text. This capability enhances the
applicability of our approach by incorporating additional context often
overlooked in traditional pose priors. Extensive experiments across three
distinct tasks-pose estimation, pose denoising, and pose completion-demonstrate
that our multi-modal diffusion model-based prior significantly outperforms
existing methods. These results indicate that our model captures a broader
spectrum of plausible human poses.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ A Hybrid Feature Fusion Deep Learning Framework for Leukemia Cancer
  Detection in Microscopic Blood Sample Using Gated Recurrent Unit and
  Uncertainty Quantification 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14536v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14536v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Maksuda Akter, Rabea Khatun, Md Manowarul Islam
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Acute lymphoblastic leukemia (ALL) is the most malignant form of leukemia and
the most common cancer in adults and children. Traditionally, leukemia is
diagnosed by analyzing blood and bone marrow smears under a microscope, with
additional cytochemical tests for confirmation. However, these methods are
expensive, time consuming, and highly dependent on expert knowledge. In recent
years, deep learning, particularly Convolutional Neural Networks (CNNs), has
provided advanced methods for classifying microscopic smear images, aiding in
the detection of leukemic cells. These approaches are quick, cost effective,
and not subject to human bias. However, most methods lack the ability to
quantify uncertainty, which could lead to critical misdiagnoses. In this
research, hybrid deep learning models (InceptionV3-GRU, EfficientNetB3-GRU,
MobileNetV2-GRU) were implemented to classify ALL. Bayesian optimization was
used to fine tune the model's hyperparameters and improve its performance.
Additionally, Deep Ensemble uncertainty quantification was applied to address
uncertainty during leukemia image classification. The proposed models were
trained on the publicly available datasets ALL-IDB1 and ALL-IDB2. Their results
were then aggregated at the score level using the sum rule. The parallel
architecture used in these models offers a high level of confidence in
differentiating between ALL and non-ALL cases. The proposed method achieved a
remarkable detection accuracy rate of 100% on the ALL-IDB1 dataset, 98.07% on
the ALL-IDB2 dataset, and 98.64% on the combined dataset, demonstrating its
potential for accurate and reliable leukemia diagnosis.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Less is More: Selective Reduction of CT Data for <span class="highlight-title">Self-Supervised</span>
  <span class="highlight-title">Pre-Train</span>ing of Deep Learning Models with Contrastive Learning Improves
  Downstream Classification Performance 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14524v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14524v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Daniel Wolf, Tristan Payer, Catharina Silvia Lisson, Christoph Gerhard Lisson, Meinrad Beer, Michael Götz, Timo Ropinski
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Self-supervised pre-training of deep learning models with contrastive
learning is a widely used technique in image analysis. Current findings
indicate a strong potential for contrastive pre-training on medical images.
However, further research is necessary to incorporate the particular
characteristics of these images. We hypothesize that the similarity of medical
images hinders the success of contrastive learning in the medical imaging
domain. To this end, we investigate different strategies based on deep
embedding, information theory, and hashing in order to identify and reduce
redundancy in medical pre-training datasets. The effect of these different
reduction strategies on contrastive learning is evaluated on two pre-training
datasets and several downstream classification tasks. In all of our
experiments, dataset reduction leads to a considerable performance gain in
downstream tasks, e.g., an AUC score improvement from 0.78 to 0.83 for the
COVID CT Classification Grand Challenge, 0.97 to 0.98 for the OrganSMNIST
Classification Challenge and 0.73 to 0.83 for a brain hemorrhage classification
task. Furthermore, pre-training is up to nine times faster due to the dataset
reduction. In conclusion, the proposed approach highlights the importance of
dataset quality and provides a transferable approach to improve contrastive
pre-training for classification downstream tasks on medical images.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Published in Computers in Biology and Medicine</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ CLIP-VAD: Exploiting Vision-Language Models for Voice Activity Detection 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14509v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14509v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Andrea Appiani, Cigdem Beyan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Voice Activity Detection (VAD) is the process of automatically determining
whether a person is speaking and identifying the timing of their speech in an
audiovisual data. Traditionally, this task has been tackled by processing
either audio signals or visual data, or by combining both modalities through
fusion or joint learning. In our study, drawing inspiration from recent
advancements in visual-language models, we introduce a novel approach
leveraging Contrastive Language-Image Pretraining (CLIP) models. The CLIP
visual encoder analyzes video segments composed of the upper body of an
individual, while the text encoder handles textual descriptions automatically
generated through prompt engineering. Subsequently, embeddings from these
encoders are fused through a deep neural network to perform VAD. Our
experimental analysis across three VAD benchmarks showcases the superior
performance of our method compared to existing visual VAD approaches. Notably,
our approach outperforms several audio-visual methods despite its simplicity,
and without requiring pre-training on extensive audio-visual datasets.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ LEAD: Latent Realignment for Human Motion Diffusion 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14508v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14508v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Nefeli Andreou, Xi Wang, Victoria Fernández Abrevaya, Marie-Paule Cani, Yiorgos Chrysanthou, Vicky Kalogeiton
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Our goal is to generate realistic human motion from natural language. Modern
methods often face a trade-off between model expressiveness and text-to-motion
alignment. Some align text and motion latent spaces but sacrifice
expressiveness; others rely on diffusion models producing impressive motions,
but lacking semantic meaning in their latent space. This may compromise
realism, diversity, and applicability. Here, we address this by combining
latent diffusion with a realignment mechanism, producing a novel, semantically
structured space that encodes the semantics of language. Leveraging this
capability, we introduce the task of textual motion inversion to capture novel
motion concepts from a few examples. For motion synthesis, we evaluate LEAD on
HumanML3D and KIT-ML and show comparable performance to the state-of-the-art in
terms of realism, diversity, and text-motion consistency. Our qualitative
analysis and user study reveal that our synthesized motions are sharper, more
human-like and comply better with the text compared to modern methods. For
motion textual inversion, our method demonstrates improved capacity in
capturing out-of-distribution characteristics in comparison to traditional
VAEs.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Neural Real-Time Recalibration for Infrared Multi-Camera Systems 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14505v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14505v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Benyamin Mehmandar, Reza Talakoob, Charalambos Poullis
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Currently, there are no learning-free or neural techniques for real-time
recalibration of infrared multi-camera systems. In this paper, we address the
challenge of real-time, highly-accurate calibration of multi-camera infrared
systems, a critical task for time-sensitive applications. Unlike traditional
calibration techniques that lack adaptability and struggle with on-the-fly
recalibrations, we propose a neural network-based method capable of dynamic
real-time calibration. The proposed method integrates a differentiable
projection model that directly correlates 3D geometries with their 2D image
projections and facilitates the direct optimization of both intrinsic and
extrinsic camera parameters. Key to our approach is the dynamic camera pose
synthesis with perturbations in camera parameters, emulating realistic
operational challenges to enhance model robustness. We introduce two model
variants: one designed for multi-camera systems with onboard processing of 2D
points, utilizing the direct 2D projections of 3D fiducials, and another for
image-based systems, employing color-coded projected points for implicitly
establishing correspondence. Through rigorous experimentation, we demonstrate
our method is more accurate than traditional calibration techniques with or
without perturbations while also being real-time, marking a significant leap in
the field of real-time multi-camera system calibration. The source code can be
found at https://github.com/theICTlab/neural-recalibration
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>real-time camera calibration, infrared camera, neural calibration</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ An Integrated Deep Learning Model for Skin Cancer Detection Using Hybrid
  Feature Fusion Technique 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14489v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14489v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Maksuda Akter, Rabea Khatun, Md. Alamin Talukder, Md. Manowarul Islam, Md. Ashraf Uddin
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Skin cancer is a serious and potentially fatal disease caused by DNA damage.
Early detection significantly increases survival rates, making accurate
diagnosis crucial. In this groundbreaking study, we present a hybrid framework
based on Deep Learning (DL) that achieves precise classification of benign and
malignant skin lesions. Our approach begins with dataset preprocessing to
enhance classification accuracy, followed by training two separate pre-trained
DL models, InceptionV3 and DenseNet121. By fusing the results of each model
using the weighted sum rule, our system achieves exceptional accuracy rates.
Specifically, we achieve a 92.27% detection accuracy rate, 92.33% sensitivity,
92.22% specificity, 90.81% precision, and 91.57% F1-score, outperforming
existing models and demonstrating the robustness and trustworthiness of our
hybrid approach. Our study represents a significant advance in skin cancer
diagnosis and provides a promising foundation for further research in the
field. With the potential to save countless lives through earlier detection,
our hybrid deep-learning approach is a game-changer in the fight against skin
cancer.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ How Do Training Methods Influence the Utilization of Vision Models? <span class="chip">NeurIPS 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14470v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14470v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Paul Gavrikov, Shashank Agnihotri, Margret Keuper, Janis Keuper
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Not all learnable parameters (e.g., weights) contribute equally to a neural
network's decision function. In fact, entire layers' parameters can sometimes
be reset to random values with little to no impact on the model's decisions. We
revisit earlier studies that examined how architecture and task complexity
influence this phenomenon and ask: is this phenomenon also affected by how we
train the model? We conducted experimental evaluations on a diverse set of
ImageNet-1k classification models to explore this, keeping the architecture and
training data constant but varying the training pipeline. Our findings reveal
that the training method strongly influences which layers become critical to
the decision function for a given task. For example, improved training regimes
and self-supervised training increase the importance of early layers while
significantly under-utilizing deeper layers. In contrast, methods such as
adversarial training display an opposite trend. Our preliminary results extend
previous findings, offering a more nuanced understanding of the inner mechanics
of neural networks.
  Code: https://github.com/paulgavrikov/layer_criticality
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted at the Interpretable AI: Past, Present and Future Workshop
  at NeurIPS 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ LUDVIG: Learning-free Uplifting of 2D Visual features to Gaussian
  Splatting scenes 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14462v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14462v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Juliette Marrie, Romain Ménégaux, Michael Arbel, Diane Larlus, Julien Mairal
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We address the task of uplifting visual features or semantic masks from 2D
vision models to 3D scenes represented by Gaussian Splatting. Whereas common
approaches rely on iterative optimization-based procedures, we show that a
simple yet effective aggregation technique yields excellent results. Applied to
semantic masks from Segment Anything (SAM), our uplifting approach leads to
segmentation quality comparable to the state of the art. We then extend this
method to generic DINOv2 features, integrating 3D scene geometry through graph
diffusion, and achieve competitive segmentation results despite DINOv2 not
being trained on millions of annotated masks like SAM.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Toward Generalizing Visual Brain Decoding to Unseen Subjects 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14445v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14445v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xiangtao Kong, Kexin Huang, Ping Li, Lei Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Visual brain decoding aims to decode visual information from human brain
activities. Despite the great progress, one critical limitation of current
brain decoding research lies in the lack of generalization capability to unseen
subjects. Prior works typically focus on decoding brain activity of individuals
based on the observation that different subjects exhibit different brain
activities, while it remains unclear whether brain decoding can be generalized
to unseen subjects. This study aims to answer this question. We first
consolidate an image-fMRI dataset consisting of stimulus-image and
fMRI-response pairs, involving 177 subjects in the movie-viewing task of the
Human Connectome Project (HCP). This dataset allows us to investigate the brain
decoding performance with the increase of participants. We then present a
learning paradigm that applies uniform processing across all subjects, instead
of employing different network heads or tokenizers for individuals as in
previous methods, which can accommodate a large number of subjects to explore
the generalization capability across different subjects. A series of
experiments are conducted and we have the following findings. First, the
network exhibits clear generalization capabilities with the increase of
training subjects. Second, the generalization capability is common to popular
network architectures (MLP, CNN and Transformer). Third, the generalization
performance is affected by the similarity between subjects. Our findings reveal
the inherent similarities in brain activities across individuals. With the
emerging of larger and more comprehensive datasets, it is possible to train a
brain decoding foundation model in the future.Codes and models can be found at
https://github.com/Xiangtaokong/TGBD.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ FashionR2R: Texture-preserving Rendered-to-Real Image Translation with
  Diffusion Models <span class="chip">NeurIPS 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14429v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14429v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Rui Hu, Qian He, Gaofeng He, Jiedong Zhuang, Huang Chen, Huafeng Liu, Huamin Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Modeling and producing lifelike clothed human images has attracted
researchers' attention from different areas for decades, with the complexity
from highly articulated and structured content. Rendering algorithms decompose
and simulate the imaging process of a camera, while are limited by the accuracy
of modeled variables and the efficiency of computation. Generative models can
produce impressively vivid human images, however still lacking in
controllability and editability. This paper studies photorealism enhancement of
rendered images, leveraging generative power from diffusion models on the
controlled basis of rendering. We introduce a novel framework to translate
rendered images into their realistic counterparts, which consists of two
stages: Domain Knowledge Injection (DKI) and Realistic Image Generation (RIG).
In DKI, we adopt positive (real) domain finetuning and negative (rendered)
domain embedding to inject knowledge into a pretrained Text-to-image (T2I)
diffusion model. In RIG, we generate the realistic image corresponding to the
input rendered image, with a Texture-preserving Attention Control (TAC) to
preserve fine-grained clothing textures, exploiting the decoupled features
encoded in the UNet structure. Additionally, we introduce SynFashion dataset,
featuring high-quality digital clothing images with diverse textures. Extensive
experimental results demonstrate the superiority and effectiveness of our
method in rendered-to-real image translation.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by NeurIPS 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Integrating Deep Learning with Fundus and Optical Coherence Tomography
  for Cardiovascular Disease Prediction 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14423v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14423v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Cynthia Maldonado-Garcia, Arezoo Zakeri, Alejandro F Frangi, Nishant Ravikumar
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Early identification of patients at risk of cardiovascular diseases (CVD) is
crucial for effective preventive care, reducing healthcare burden, and
improving patients' quality of life. This study demonstrates the potential of
retinal optical coherence tomography (OCT) imaging combined with fundus
photographs for identifying future adverse cardiac events. We used data from
977 patients who experienced CVD within a 5-year interval post-image
acquisition, alongside 1,877 control participants without CVD, totaling 2,854
subjects. We propose a novel binary classification network based on a
Multi-channel Variational Autoencoder (MCVAE), which learns a latent embedding
of patients' fundus and OCT images to classify individuals into two groups:
those likely to develop CVD in the future and those who are not. Our model,
trained on both imaging modalities, achieved promising results (AUROC 0.78 +/-
0.02, accuracy 0.68 +/- 0.002, precision 0.74 +/- 0.02, sensitivity 0.73 +/-
0.02, and specificity 0.68 +/- 0.01), demonstrating its efficacy in identifying
patients at risk of future CVD events based on their retinal images. This study
highlights the potential of retinal OCT imaging and fundus photographs as
cost-effective, non-invasive alternatives for predicting cardiovascular disease
risk. The widespread availability of these imaging techniques in optometry
practices and hospitals further enhances their potential for large-scale CVD
risk screening. Our findings contribute to the development of standardized,
accessible methods for early CVD risk identification, potentially improving
preventive care strategies and patient outcomes.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Part of the book series: Lecture Notes in Computer Science
  ((LNCS,volume 15155))</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Variable Aperture Bokeh Rendering via Customized Focal Plane Guidance 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14400v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14400v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Kang Chen, Shijun Yan, Aiwen Jiang, Han Li, Zhifeng Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Bokeh rendering is one of the most popular techniques in photography. It can
make photographs visually appealing, forcing users to focus their attentions on
particular area of image. However, achieving satisfactory bokeh effect usually
presents significant challenge, since mobile cameras with restricted optical
systems are constrained, while expensive high-end DSLR lens with large aperture
should be needed. Therefore, many deep learning-based computational photography
methods have been developed to mimic the bokeh effect in recent years.
Nevertheless, most of these methods were limited to rendering bokeh effect in
certain single aperture. There lacks user-friendly bokeh rendering method that
can provide precise focal plane control and customised bokeh generation. There
as well lacks authentic realistic bokeh dataset that can potentially promote
bokeh learning on variable apertures. To address these two issues, in this
paper, we have proposed an effective controllable bokeh rendering method, and
contributed a Variable Aperture Bokeh Dataset (VABD). In the proposed method,
user can customize focal plane to accurately locate concerned subjects and
select target aperture information for bokeh rendering. Experimental results on
public EBB! benchmark dataset and our constructed dataset VABD have
demonstrated that the customized focal plane together aperture prompt can
bootstrap model to simulate realistic bokeh effect. The proposed method has
achieved competitive state-of-the-art performance with only 4.4M parameters,
which is much lighter than mainstream computational bokeh models. The
contributed dataset and source codes will be released on github
https://github.com/MoTong-AI-studio/VABM.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Dynamic Negative Guidance of Diffusion Models <span class="chip">ICLR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14398v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14398v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Felix Koulischer, Johannes Deleu, Gabriel Raya, Thomas Demeester, Luca Ambrogioni
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Negative Prompting (NP) is widely utilized in diffusion models, particularly
in text-to-image applications, to prevent the generation of undesired features.
In this paper, we show that conventional NP is limited by the assumption of a
constant guidance scale, which may lead to highly suboptimal results, or even
complete failure, due to the non-stationarity and state-dependence of the
reverse process. Based on this analysis, we derive a principled technique
called Dynamic Negative Guidance, which relies on a near-optimal time and state
dependent modulation of the guidance without requiring additional training.
Unlike NP, negative guidance requires estimating the posterior class
probability during the denoising process, which is achieved with limited
additional computational overhead by tracking the discrete Markov Chain during
the generative process. We evaluate the performance of DNG class-removal on
MNIST and CIFAR10, where we show that DNG leads to higher safety, preservation
of class balance and image quality when compared with baseline methods.
Furthermore, we show that it is possible to use DNG with Stable Diffusion to
obtain more accurate and less invasive guidance than NP.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Paper currently under review. Submitted to ICLR 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ SurgeryV2: Bridging the Gap Between Model Merging and Multi-Task
  Learning with Deep Representation Surgery <span class="chip">ICML 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14389v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14389v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Enneng Yang, Li Shen, Zhenyi Wang, Guibing Guo, Xingwei Wang, Xiaocun Cao, Jie Zhang, Dacheng Tao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Model merging-based multitask learning (MTL) offers a promising approach for
performing MTL by merging multiple expert models without requiring access to
raw training data. However, in this paper, we examine the merged model's
representation distribution and uncover a critical issue of "representation
bias". This bias arises from a significant distribution gap between the
representations of the merged and expert models, leading to the suboptimal
performance of the merged MTL model. To address this challenge, we first
propose a representation surgery solution called Surgery. Surgery is a
lightweight, task-specific module that aligns the final layer representations
of the merged model with those of the expert models, effectively alleviating
bias and improving the merged model's performance. Despite these improvements,
a performance gap remains compared to the traditional MTL method. Further
analysis reveals that representation bias phenomena exist at each layer of the
merged model, and aligning representations only in the last layer is
insufficient for fully reducing systemic bias because biases introduced at each
layer can accumulate and interact in complex ways. To tackle this, we then
propose a more comprehensive solution, deep representation surgery (also called
SurgeryV2), which mitigates representation bias across all layers, and thus
bridges the performance gap between model merging-based MTL and traditional
MTL. Finally, we design an unsupervised optimization objective to optimize both
the Surgery and SurgeryV2 modules. Our experimental results show that
incorporating these modules into state-of-the-art (SOTA) model merging schemes
leads to significant performance gains. Notably, our SurgeryV2 scheme reaches
almost the same level as individual expert models or the traditional MTL model.
The code is available at \url{https://github.com/EnnengYang/SurgeryV2}.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>This paper is an extended version of our previous work
  [arXiv:2402.02705] presented at ICML 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ AnomalyNCD: Towards Novel Anomaly Class Discovery in Industrial
  Scenarios 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14379v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14379v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ziming Huang, Xurui Li, Haotian Liu, Feng Xue, Yuzhe Wang, Yu Zhou
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In the industrial scenario, anomaly detection could locate but cannot
classify anomalies. To complete their capability, we study to automatically
discover and recognize visual classes of industrial anomalies. In terms of
multi-class anomaly classification, previous methods cluster anomalies
represented by frozen pre-trained models but often fail due to poor
discrimination. Novel class discovery (NCD) has the potential to tackle this.
However, it struggles with non-prominent and semantically weak anomalies that
challenge network learning focus. To address these, we introduce AnomalyNCD, a
multi-class anomaly classification framework compatible with existing anomaly
detection methods. This framework learns anomaly-specific features and
classifies anomalies in a self-supervised manner. Initially, a technique called
Main Element Binarization (MEBin) is first designed, which segments primary
anomaly regions into masks to alleviate the impact of incorrect detections on
learning. Subsequently, we employ mask-guided contrastive representation
learning to improve feature discrimination, which focuses network attention on
isolated anomalous regions and reduces the confusion of erroneous inputs
through re-corrected pseudo labels. Finally, to enable flexible classification
at both region and image levels during inference, we develop a region merging
strategy that determines the overall image category based on the classified
anomaly regions. Our method outperforms the state-of-the-art works on the MVTec
AD and MTD datasets. Compared with the current methods, AnomalyNCD combined
with zero-shot anomaly detection method achieves a 10.8% $F_1$ gain, 8.8% NMI
gain, and 9.5% ARI gain on MVTec AD, 12.8% $F_1$ gain, 5.7% NMI gain, and 10.8%
ARI gain on MTD. The source code is available at
https://github.com/HUST-SLOW/AnomalyNCD.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Impact of imperfect annotations on CNN training and performance for
  instance segmentation and classification in digital pathology 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14365v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14365v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Laura Gálvez Jiménez, Christine Decaestecker
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Segmentation and classification of large numbers of instances, such as cell
nuclei, are crucial tasks in digital pathology for accurate diagnosis. However,
the availability of high-quality datasets for deep learning methods is often
limited due to the complexity of the annotation process. In this work, we
investigate the impact of noisy annotations on the training and performance of
a state-of-the-art CNN model for the combined task of detecting, segmenting and
classifying nuclei in histopathology images. In this context, we investigate
the conditions for determining an appropriate number of training epochs to
prevent overfitting to annotation noise during training. Our results indicate
that the utilisation of a small, correctly annotated validation set is
instrumental in avoiding overfitting and maintaining model performance to a
large extent. Additionally, our findings underscore the beneficial role of
pre-training.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ 2D-3D Deformable Image Registration of Histology Slide and Micro-CT with
  ML-based Initialization 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14343v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14343v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Junan Chen, Matteo Ronchetti, Verena Stehl, Van Nguyen, Muhannad Al Kallaa, Mahesh Thalwaththe Gedara, Claudia Lölkes, Stefan Moser, Maximilian Seidl, Matthias Wieczorek
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent developments in the registration of histology and micro-computed
tomography ({\mu}CT) have broadened the perspective of pathological
applications such as virtual histology based on {\mu}CT. This topic remains
challenging because of the low image quality of soft tissue CT. Additionally,
soft tissue samples usually deform during the histology slide preparation,
making it difficult to correlate the structures between histology slide and
{\mu}CT. In this work, we propose a novel 2D-3D multi-modal deformable image
registration method. The method uses a machine learning (ML) based
initialization followed by the registration. The registration is finalized by
an analytical out-of-plane deformation refinement. The method is evaluated on
datasets acquired from tonsil and tumor tissues. {\mu}CTs of both
phase-contrast and conventional absorption modalities are investigated. The
registration results from the proposed method are compared with those from
intensity- and keypoint-based methods. The comparison is conducted using both
visual and fiducial-based evaluations. The proposed method demonstrates
superior performance compared to the other two methods.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>12 pages, 4 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Zero-shot Action Localization via the Confidence of Large
  Vision-Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14340v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14340v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Josiah Aklilu, Xiaohan Wang, Serena Yeung-Levy
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Precise action localization in untrimmed video is vital for fields such as
professional sports and minimally invasive surgery, where the delineation of
particular motions in recordings can dramatically enhance analysis. But in many
cases, large scale datasets with video-label pairs for localization are
unavailable, limiting the opportunity to fine-tune video-understanding models.
Recent developments in large vision-language models (LVLM) address this need
with impressive zero-shot capabilities in a variety of video understanding
tasks. However, the adaptation of image-based LVLMs, with their powerful visual
question answering capabilities, to action localization in long-form video is
still relatively unexplored. To this end, we introduce a true ZEro-shot Action
Localization method (ZEAL). Specifically, we leverage the built-in action
knowledge of a large language model (LLM) to inflate actions into
highly-detailed descriptions of the archetypal start and end of the action.
These descriptions serve as queries to LVLM for generating frame-level
confidence scores which can be aggregated to produce localization outputs. The
simplicity and flexibility of our method lends it amenable to more capable
LVLMs as they are developed, and we demonstrate remarkable results in zero-shot
action localization on a challenging benchmark, without any training.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Evaluating the evaluators: Towards human-aligned metrics for missing
  markers reconstruction 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14334v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14334v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Taras Kucherenko, Derek Peristy, Judith Bütepage
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Animation data is often obtained through optical motion capture systems,
which utilize a multitude of cameras to establish the position of optical
markers. However, system errors or occlusions can result in missing markers,
the manual cleaning of which can be time-consuming. This has sparked interest
in machine learning-based solutions for missing marker reconstruction in the
academic community. Most academic papers utilize a simplistic mean square error
as the main metric. In this paper, we show that this metric does not correlate
with subjective perception of the fill quality. We introduce and evaluate a set
of better-correlated metrics that can drive progress in the field.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Croc: <span class="highlight-title">Pretrain</span>ing Large Multimodal Models with Cross-Modal Comprehension 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14332v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14332v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yin Xie, Kaicheng Yang, Ninghua Yang, Weimo Deng, Xiangzi Dai, Tiancheng Gu, Yumeng Wang, Xiang An, Yongle Zhao, Ziyong Feng, Jiankang Deng
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent advances in Large Language Models (LLMs) have catalyzed the
development of Large Multimodal Models (LMMs). However, existing research
primarily focuses on tuning language and image instructions, ignoring the
critical pretraining phase where models learn to process textual and visual
modalities jointly. In this paper, we propose a new pretraining paradigm for
LMMs to enhance the visual comprehension capabilities of LLMs by introducing a
novel cross-modal comprehension stage. Specifically, we design a dynamically
learnable prompt token pool and employ the Hungarian algorithm to replace part
of the original visual tokens with the most relevant prompt tokens. Then, we
conceptualize visual tokens as analogous to a "foreign language" for the LLMs
and propose a mixed attention mechanism with bidirectional visual attention and
unidirectional textual attention to comprehensively enhance the understanding
of visual tokens. Meanwhile, we integrate a detailed caption generation task,
leveraging rich descriptions to further facilitate LLMs in understanding visual
semantic information. After pretraining on 1.5 million publicly accessible
data, we present a new foundation model called Croc. Experimental results
demonstrate that Croc achieves new state-of-the-art performance on massive
vision-language benchmarks. To support reproducibility and facilitate further
research, we release the training code and pre-trained model weights at
https://github.com/deepglint/Croc.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>18 pages, 11 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Fast proxy centers for Jeffreys centroids: The Jeffreys-Fisher-Rao and
  the inductive Gauss-Bregman centers 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14326v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14326v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Frank Nielsen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The symmetric Kullback-Leibler centroid also called the Jeffreys centroid of
a set of mutually absolutely continuous probability distributions on a measure
space provides a notion of centrality which has proven useful in many tasks
including information retrieval, information fusion, and clustering in image,
video and sound processing. However, the Jeffreys centroid is not available in
closed-form for sets of categorical or normal distributions, two widely used
statistical models, and thus need to be approximated numerically in practice.
In this paper, we first propose the new Jeffreys-Fisher-Rao center defined as
the Fisher-Rao midpoint of the sided Kullback-Leibler centroids as a plug-in
replacement of the Jeffreys centroid. This Jeffreys-Fisher-Rao center admits a
generic formula for uni-parameter exponential family distributions, and
closed-form formula for categorical and normal distributions, matches exactly
the Jeffreys centroid for same-mean normal distributions, and is experimentally
observed in practice to be close to the Jeffreys centroid. Second, we define a
new type of inductive centers generalizing the principle of Gauss
arithmetic-geometric double sequence mean for pairs of densities of any given
exponential family. This center is shown experimentally to approximate very
well the Jeffreys centroid and is suggested to use when the Jeffreys-Fisher-Rao
center is not available in closed form. Moreover, this Gauss-Bregman inductive
center always converges and matches the Jeffreys centroid for sets of same-mean
normal distributions. We report on our experiments demonstrating the use of the
Jeffreys-Fisher-Rao and Gauss-Bregman centers instead of the Jeffreys centroid.
Finally, we conclude this work by reinterpreting these fast proxy centers of
Jeffreys centroids under the lens of dually flat spaces in information
geometry.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>35 pages, 10 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ HiCo: Hierarchical Controllable Diffusion Model for Layout-to-image
  Generation <span class="chip">NeurIPS2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14324v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14324v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Bo Cheng, Yuhang Ma, Liebucha Wu, Shanyuan Liu, Ao Ma, Xiaoyu Wu, Dawei Leng, Yuhui Yin
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The task of layout-to-image generation involves synthesizing images based on
the captions of objects and their spatial positions. Existing methods still
struggle in complex layout generation, where common bad cases include object
missing, inconsistent lighting, conflicting view angles, etc. To effectively
address these issues, we propose a \textbf{Hi}erarchical \textbf{Co}ntrollable
(HiCo) diffusion model for layout-to-image generation, featuring object
seperable conditioning branch structure. Our key insight is to achieve spatial
disentanglement through hierarchical modeling of layouts. We use a multi branch
structure to represent hierarchy and aggregate them in fusion module. To
evaluate the performance of multi-objective controllable layout generation in
natural scenes, we introduce the HiCo-7K benchmark, derived from the GRIT-20M
dataset and manually cleaned. https://github.com/360CVGroup/HiCo_T2I.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>NeurIPS2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Advanced Underwater Image Quality Enhancement via Hybrid
  Super-Resolution Convolutional Neural Networks and Multi-Scale Retinex-Based
  Defogging Techniques 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14285v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14285v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yugandhar Reddy Gogireddy, Jithendra Reddy Gogireddy
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The difficulties of underwater image degradation due to light scattering,
absorption, and fog-like particles which lead to low resolution and poor
visibility are discussed in this study report. We suggest a sophisticated
hybrid strategy that combines Multi-Scale Retinex (MSR) defogging methods with
Super-Resolution Convolutional Neural Networks (SRCNN) to address these
problems. The Retinex algorithm mimics human visual perception to reduce uneven
lighting and fogging, while the SRCNN component improves the spatial resolution
of underwater photos.Through the combination of these methods, we are able to
enhance the clarity, contrast, and colour restoration of underwater images,
offering a reliable way to improve image quality in difficult underwater
conditions. The research conducts extensive experiments on real-world
underwater datasets to further illustrate the efficacy of the suggested
approach. In terms of sharpness, visibility, and feature retention,
quantitative evaluation which use metrics like the Structural Similarity Index
Measure (SSIM) and Peak Signal-to-Noise Ratio (PSNR) demonstrates notable
advances over conventional techniques.In real-time underwater applications like
marine exploration, underwater robotics, and autonomous underwater vehicles,
where clear and high-resolution imaging is crucial for operational success, the
combination of deep learning and conventional image processing techniques
offers a computationally efficient framework with superior results.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Takin-ADA: Emotion Controllable Audio-Driven Animation with Canonical
  and Landmark Loss Optimization 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14283v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14283v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Bin Lin, Yanzhen Yu, Jianhao Ye, Ruitao Lv, Yuguang Yang, Ruoye Xie, Pan Yu, Hongbin Zhou
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Existing audio-driven facial animation methods face critical challenges,
including expression leakage, ineffective subtle expression transfer, and
imprecise audio-driven synchronization. We discovered that these issues stem
from limitations in motion representation and the lack of fine-grained control
over facial expressions. To address these problems, we present Takin-ADA, a
novel two-stage approach for real-time audio-driven portrait animation. In the
first stage, we introduce a specialized loss function that enhances subtle
expression transfer while reducing unwanted expression leakage. The second
stage utilizes an advanced audio processing technique to improve lip-sync
accuracy. Our method not only generates precise lip movements but also allows
flexible control over facial expressions and head motions. Takin-ADA achieves
high-resolution (512x512) facial animations at up to 42 FPS on an RTX 4090 GPU,
outperforming existing commercial solutions. Extensive experiments demonstrate
that our model significantly surpasses previous methods in video quality,
facial dynamics realism, and natural head movements, setting a new benchmark in
the field of audio-driven facial animation.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>under review</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ You Only Look Twice! for Failure Causes Identification of Drill Bits 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14282v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14282v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Asma Yamani, Nehal Al-Otaiby, Haifa Al-Shemmeri, Imane Boudellioua
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Efficient identification of the root causes of drill bit failure is crucial
due to potential impacts such as operational losses, safety threats, and
delays. Early recognition of these failures enables proactive maintenance,
reducing risks and financial losses associated with unforeseen breakdowns and
prolonged downtime. Thus, our study investigates various causes of drill bit
failure using images of different blades. The process involves annotating
cutters with their respective locations and damage types, followed by the
development of two YOLO Location and Damage Cutter Detection models, as well as
multi-class multi-label Decision Tree and Random Forests models to identify the
causes of failure by assessing the cutters' location and damage type.
Additionally, RRFCI is proposed for the classification of failure causes.
Notably, the cutter location detection model achieved a high score of 0.97 mPA,
and the cutter damage detection model yielded a 0.49 mPA. The rule-based
approach over-performed both DT and RF in failure cause identification,
achieving a macro-average F1-score of 0.94 across all damage causes. The
integration of the complete automated pipeline successfully identified 100\% of
the 24 failure causes when tested on independent sets of ten drill bits,
showcasing its potential to efficiently assist experts in identifying the root
causes of drill bit damages.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ ClearSR: Latent Low-Resolution Image Embeddings Help Diffusion-Based
  Real-World Super Resolution Models See Clearer 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14279v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14279v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yuhao Wan, Peng-Tao Jiang, Qibin Hou, Hao Zhang, Jinwei Chen, Ming-Ming Cheng, Bo Li
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We present ClearSR, a new method that can better take advantage of latent
low-resolution image (LR) embeddings for diffusion-based real-world image
super-resolution (Real-ISR). Previous Real-ISR models mostly focus on how to
activate more generative priors of text-to-image diffusion models to make the
output high-resolution (HR) images look better. However, since these methods
rely too much on the generative priors, the content of the output images is
often inconsistent with the input LR ones. To mitigate the above issue, in this
work, we explore using latent LR embeddings to constrain the control signals
from ControlNet, and extract LR information at both detail and structure
levels. We show that the proper use of latent LR embeddings can produce
higher-quality control signals, which enables the super-resolution results to
be more consistent with the LR image and leads to clearer visual results. In
addition, we also show that latent LR embeddings can be used to control the
inference stage, allowing for the improvement of fidelity and generation
ability simultaneously. Experiments demonstrate that our model can achieve
better performance across multiple metrics on several test sets and generate
more consistent SR results with LR images than existing methods. Our code will
be made publicly available.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ HYPNOS : Highly Precise Foreground-focused Diffusion Finetuning for
  Inanimate Objects <span class="chip">ACCV</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14265v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14265v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Oliverio Theophilus Nathanael, Jonathan Samuel Lumentut, Nicholas Hans Muliawan, Edbert Valencio Angky, Felix Indra Kurniadi, Alfi Yusrotis Zakiyyah, Jeklin Harefa
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In recent years, personalized diffusion-based text-to-image generative tasks
have been a hot topic in computer vision studies. A robust diffusion model is
determined by its ability to perform near-perfect reconstruction of certain
product outcomes given few related input samples. Unfortunately, the current
prominent diffusion-based finetuning technique falls short in maintaining the
foreground object consistency while being constrained to produce diverse
backgrounds in the image outcome. In the worst scenario, the overfitting issue
may occur, meaning that the foreground object is less controllable due to the
condition above, for example, the input prompt information is transferred
ambiguously to both foreground and background regions, instead of the supposed
background region only. To tackle the issues above, we proposed Hypnos, a
highly precise foreground-focused diffusion finetuning technique. On the image
level, this strategy works best for inanimate object generation tasks, and to
do so, Hypnos implements two main approaches, namely: (i) a content-centric
prompting strategy and (ii) the utilization of our additional
foreground-focused discriminative module. The utilized module is connected with
the diffusion model and finetuned with our proposed set of supervision
mechanism. Combining the strategies above yielded to the foreground-background
disentanglement capability of the diffusion model. Our experimental results
showed that the proposed strategy gave a more robust performance and visually
pleasing results compared to the former technique. For better elaborations, we
also provided extensive studies to assess the fruitful outcomes above, which
reveal how personalization behaves in regard to several training conditions.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>26 pages, 12 figures, to appear on the Rich Media with Generative AI
  workshop in conjunction with Asian Conference on Computer Vision (ACCV) 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Vision-Language Navigation with Energy-Based Policy 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14250v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14250v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Rui Liu, Wenguan Wang, Yi Yang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Vision-language navigation (VLN) requires an agent to execute actions
following human instructions. Existing VLN models are optimized through expert
demonstrations by supervised behavioural cloning or incorporating manual reward
engineering. While straightforward, these efforts overlook the accumulation of
errors in the Markov decision process, and struggle to match the distribution
of the expert policy. Going beyond this, we propose an Energy-based Navigation
Policy (ENP) to model the joint state-action distribution using an energy-based
model. At each step, low energy values correspond to the state-action pairs
that the expert is most likely to perform, and vice versa. Theoretically, the
optimization objective is equivalent to minimizing the forward divergence
between the occupancy measure of the expert and ours. Consequently, ENP learns
to globally align with the expert policy by maximizing the likelihood of the
actions and modeling the dynamics of the navigation states in a collaborative
manner. With a variety of VLN architectures, ENP achieves promising
performances on R2R, REVERIE, RxR, and R2R-CE, unleashing the power of existing
VLN models.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ ERDDCI: Exact Reversible Diffusion via Dual-Chain Inversion for
  High-Quality Image Editing 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14247v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14247v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jimin Dai, Yingzhen Zhang, Shuo Chen, Jian Yang, Lei Luo
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Diffusion models (DMs) have been successfully applied to real image editing.
These models typically invert images into latent noise vectors used to
reconstruct the original images (known as inversion), and then edit them during
the inference process. However, recent popular DMs often rely on the assumption
of local linearization, where the noise injected during the inversion process
is expected to approximate the noise removed during the inference process.
While DM efficiently generates images under this assumption, it can also
accumulate errors during the diffusion process due to the assumption,
ultimately negatively impacting the quality of real image reconstruction and
editing. To address this issue, we propose a novel method, referred to as
ERDDCI (Exact Reversible Diffusion via Dual-Chain Inversion). ERDDCI uses the
new Dual-Chain Inversion (DCI) for joint inference to derive an exact
reversible diffusion process. By using DCI, our method effectively avoids the
cumbersome optimization process in existing inversion approaches and achieves
high-quality image editing. Additionally, to accommodate image operations under
high guidance scales, we introduce a dynamic control strategy that enables more
refined image reconstruction and editing. Our experiments demonstrate that
ERDDCI significantly outperforms state-of-the-art methods in a 50-step
diffusion process. It achieves rapid and precise image reconstruction with an
SSIM of 0.999 and an LPIPS of 0.001, and also delivers competitive results in
image editing.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ PReP: Efficient context-based shape retrieval for missing parts 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14245v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14245v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Vlassis Fotis, Ioannis Romanelis, Georgios Mylonas, Athanasios Kalogeras, Konstantinos Moustakas
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this paper we study the problem of shape part retrieval in the point cloud
domain. Shape retrieval methods in the literature rely on the presence of an
existing query object, but what if the part we are looking for is not
available? We present Part Retrieval Pipeline (PReP), a pipeline that
creatively utilizes metric learning techniques along with a trained
classification model to measure the suitability of potential replacement parts
from a database, as part of an application scenario targeting circular economy.
Through an innovative training procedure with increasing difficulty, it is able
to learn to recognize suitable parts relying only on shape context. Thanks to
its low parameter size and computational requirements, it can be used to sort
through a warehouse of potentially tens of thousand of spare parts in just a
few seconds. We also establish an alternative baseline approach to compare
against, and extensively document the unique challenges associated with this
task, as well as identify the design choices to solve them.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Pseudo-label Refinement for Improving <span class="highlight-title">Self-Supervised</span> Learning Systems 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14242v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14242v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                         Zia-ur-Rehman, Arif Mahmood, Wenxiong Kang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Self-supervised learning systems have gained significant attention in recent
years by leveraging clustering-based pseudo-labels to provide supervision
without the need for human annotations. However, the noise in these
pseudo-labels caused by the clustering methods poses a challenge to the
learning process leading to degraded performance. In this work, we propose a
pseudo-label refinement (SLR) algorithm to address this issue. The cluster
labels from the previous epoch are projected to the current epoch
cluster-labels space and a linear combination of the new label and the
projected label is computed as a soft refined label containing the information
from the previous epoch clusters as well as from the current epoch. In contrast
to the common practice of using the maximum value as a cluster/class indicator,
we employ hierarchical clustering on these soft pseudo-labels to generate
refined hard-labels. This approach better utilizes the information embedded in
the soft labels, outperforming the simple maximum value approach for hard label
generation. The effectiveness of the proposed SLR algorithm is evaluated in the
context of person re-identification (Re-ID) using unsupervised domain
adaptation (UDA). Experimental results demonstrate that the modified Re-ID
baseline, incorporating the SLR algorithm, achieves significantly improved mean
Average Precision (mAP) performance in various UDA tasks, including
real-to-synthetic, synthetic-to-real, and different real-to-real scenarios.
These findings highlight the efficacy of the SLR algorithm in enhancing the
performance of self-supervised learning systems.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Storyboard guided Alignment for Fine-grained Video Action Recognition 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14238v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14238v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Enqi Liu, Liyuan Pan, Yan Yang, Yiran Zhong, Zhijing Wu, Xinxiao Wu, Liu Liu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Fine-grained video action recognition can be conceptualized as a video-text
matching problem. Previous approaches often rely on global video semantics to
consolidate video embeddings, which can lead to misalignment in video-text
pairs due to a lack of understanding of action semantics at an atomic
granularity level. To tackle this challenge, we propose a multi-granularity
framework based on two observations: (i) videos with different global semantics
may share similar atomic actions or appearances, and (ii) atomic actions within
a video can be momentary, slow, or even non-directly related to the global
video semantics. Inspired by the concept of storyboarding, which disassembles a
script into individual shots, we enhance global video semantics by generating
fine-grained descriptions using a pre-trained large language model. These
detailed descriptions capture common atomic actions depicted in videos. A
filtering metric is proposed to select the descriptions that correspond to the
atomic actions present in both the videos and the descriptions. By employing
global semantics and fine-grained descriptions, we can identify key frames in
videos and utilize them to aggregate embeddings, thereby making the embedding
more accurate. Extensive experiments on various video action recognition
datasets demonstrate superior performance of our proposed method in supervised,
few-shot, and zero-shot settings.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ MambaSCI: Efficient Mamba-UNet for Quad-Bayer Patterned Video Snapshot
  Compressive Imaging <span class="chip">NeurIPS 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14214v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14214v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zhenghao Pan, Haijin Zeng, Jiezhang Cao, Yongyong Chen, Kai Zhang, Yong Xu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Color video snapshot compressive imaging (SCI) employs computational imaging
techniques to capture multiple sequential video frames in a single
Bayer-patterned measurement. With the increasing popularity of quad-Bayer
pattern in mainstream smartphone cameras for capturing high-resolution videos,
mobile photography has become more accessible to a wider audience. However,
existing color video SCI reconstruction algorithms are designed based on the
traditional Bayer pattern. When applied to videos captured by quad-Bayer
cameras, these algorithms often result in color distortion and ineffective
demosaicing, rendering them impractical for primary equipment. To address this
challenge, we propose the MambaSCI method, which leverages the Mamba and UNet
architectures for efficient reconstruction of quad-Bayer patterned color video
SCI. To the best of our knowledge, our work presents the first algorithm for
quad-Bayer patterned SCI reconstruction, and also the initial application of
the Mamba model to this task. Specifically, we customize Residual-Mamba-Blocks,
which residually connect the Spatial-Temporal Mamba (STMamba),
Edge-Detail-Reconstruction (EDR) module, and Channel Attention (CA) module.
Respectively, STMamba is used to model long-range spatial-temporal dependencies
with linear complexity, EDR is for better edge-detail reconstruction, and CA is
used to compensate for the missing channel information interaction in Mamba
model. Experiments demonstrate that MambaSCI surpasses state-of-the-art methods
with lower computational and memory costs. PyTorch style pseudo-code for the
core modules is provided in the supplementary materials.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>NeurIPS 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Shape Transformation Driven by Active Contour for Class-Imbalanced
  Semi-Supervised Medical Image Segmentation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14210v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14210v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yuliang Gu, Yepeng Liu, Zhichao Sun, Jinchi Zhu, Yongchao Xu, Laurent Najman
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Annotating 3D medical images demands expert knowledge and is time-consuming.
As a result, semi-supervised learning (SSL) approaches have gained significant
interest in 3D medical image segmentation. The significant size differences
among various organs in the human body lead to imbalanced class distribution,
which is a major challenge in the real-world application of these SSL
approaches. To address this issue, we develop a novel Shape Transformation
driven by Active Contour (STAC), that enlarges smaller organs to alleviate
imbalanced class distribution across different organs. Inspired by curve
evolution theory in active contour methods, STAC employs a signed distance
function (SDF) as the level set function, to implicitly represent the shape of
organs, and deforms voxels in the direction of the steepest descent of SDF
(i.e., the normal vector). To ensure that the voxels far from expansion organs
remain unchanged, we design an SDF-based weight function to control the degree
of deformation for each voxel. We then use STAC as a data-augmentation process
during the training stage. Experimental results on two benchmark datasets
demonstrate that the proposed method significantly outperforms some
state-of-the-art methods. Source code is publicly available at
https://github.com/GuGuLL123/STAC.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Text-to-Image Representativity Fairness Evaluation Framework 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14201v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14201v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Asma Yamani, Malak Baslyman
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Text-to-Image generative systems are progressing rapidly to be a source of
advertisement and media and could soon serve as image searches or artists.
However, there is a significant concern about the representativity bias these
models embody and how these biases can propagate in the social fabric after
fine-tuning them. Therefore, continuously monitoring and evaluating these
models for fairness is important. To address this issue, we propose
Text-to-Image (TTI) Representativity Fairness Evaluation Framework. In this
framework, we evaluate three aspects of a TTI system; diversity, inclusion, and
quality. For each aspect, human-based and model-based approaches are proposed
and evaluated for their ability to capture the bias and whether they can
substitute each other. The framework starts by suggesting the prompts for
generating the images for the evaluation based on the context and the sensitive
attributes under study. Then the three aspects are evaluated using the proposed
approaches. Based on the evaluation, a decision is made regarding the
representativity bias within the TTI system. The evaluation of our framework on
Stable Diffusion shows that the framework can effectively capture the bias in
TTI systems. The results also confirm that our proposed model based-approaches
can substitute human-based approaches in three out of four components with high
correlation, which could potentially reduce costs and automate the process. The
study suggests that continual learning of the model on more inclusive data
across disadvantaged minorities such as Indians and Middle Easterners is
essential to mitigate current stereotyping and lack of inclusiveness.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ E3D-<span class="highlight-title">GPT</span>: Enhanced 3D Visual Foundation for Medical Vision-Language Model 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14200v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14200v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Haoran Lai, Zihang Jiang, Qingsong Yao, Rongsheng Wang, Zhiyang He, Xiaodong Tao, Wei Wei, Weifu Lv, S. Kevin Zhou
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The development of 3D medical vision-language models holds significant
potential for disease diagnosis and patient treatment. However, compared to 2D
medical images, 3D medical images, such as CT scans, face challenges related to
limited training data and high dimension, which severely restrict the progress
of 3D medical vision-language models. To address these issues, we collect a
large amount of unlabeled 3D CT data and utilize self-supervised learning to
construct a 3D visual foundation model for extracting 3D visual features. Then,
we apply 3D spatial convolutions to aggregate and project high-level image
features, reducing computational complexity while preserving spatial
information. We also construct two instruction-tuning datasets based on BIMCV-R
and CT-RATE to fine-tune the 3D vision-language model. Our model demonstrates
superior performance compared to existing methods in report generation, visual
question answering, and disease diagnosis. Code and data will be made publicly
available soon.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Rethinking <span class="highlight-title">Transformer</span> for Long Contextual Histopathology Whole Slide
  Image Analysis <span class="chip">NeurIPS-2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14195v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14195v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Honglin Li, Yunlong Zhang, Pingyi Chen, Zhongyi Shui, Chenglu Zhu, Lin Yang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Histopathology Whole Slide Image (WSI) analysis serves as the gold standard
for clinical cancer diagnosis in the daily routines of doctors. To develop
computer-aided diagnosis model for WSIs, previous methods typically employ
Multi-Instance Learning to enable slide-level prediction given only slide-level
labels. Among these models, vanilla attention mechanisms without pairwise
interactions have traditionally been employed but are unable to model
contextual information. More recently, self-attention models have been utilized
to address this issue. To alleviate the computational complexity of long
sequences in large WSIs, methods like HIPT use region-slicing, and TransMIL
employs approximation of full self-attention. Both approaches suffer from
suboptimal performance due to the loss of key information. Moreover, their use
of absolute positional embedding struggles to effectively handle long
contextual dependencies in shape-varying WSIs. In this paper, we first analyze
how the low-rank nature of the long-sequence attention matrix constrains the
representation ability of WSI modelling. Then, we demonstrate that the rank of
attention matrix can be improved by focusing on local interactions via a local
attention mask. Our analysis shows that the local mask aligns with the
attention patterns in the lower layers of the Transformer. Furthermore, the
local attention mask can be implemented during chunked attention calculation,
reducing the quadratic computational complexity to linear with a small local
bandwidth. Building on this, we propose a local-global hybrid Transformer for
both computational acceleration and local-global information interactions
modelling. Our method, Long-contextual MIL (LongMIL), is evaluated through
extensive experiments on various WSI tasks to validate its superiority. Our
code will be available at github.com/invoker-LL/Long-MIL.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>NeurIPS-2024. arXiv admin note: text overlap with arXiv:2311.12885</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Neural Signed Distance Function Inference through Splatting 3D Gaussians
  Pulled on Zero-Level Set <span class="chip">NeurIPS 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14189v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14189v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Wenyuan Zhang, Yu-Shen Liu, Zhizhong Han
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  It is vital to infer a signed distance function (SDF) in multi-view based
surface reconstruction. 3D Gaussian splatting (3DGS) provides a novel
perspective for volume rendering, and shows advantages in rendering efficiency
and quality. Although 3DGS provides a promising neural rendering option, it is
still hard to infer SDFs for surface reconstruction with 3DGS due to the
discreteness, the sparseness, and the off-surface drift of 3D Gaussians. To
resolve these issues, we propose a method that seamlessly merge 3DGS with the
learning of neural SDFs. Our key idea is to more effectively constrain the SDF
inference with the multi-view consistency. To this end, we dynamically align 3D
Gaussians on the zero-level set of the neural SDF using neural pulling, and
then render the aligned 3D Gaussians through the differentiable rasterization.
Meanwhile, we update the neural SDF by pulling neighboring space to the pulled
3D Gaussians, which progressively refine the signed distance field near the
surface. With both differentiable pulling and splatting, we jointly optimize 3D
Gaussians and the neural SDF with both RGB and geometry constraints, which
recovers more accurate, smooth, and complete surfaces with more geometry
details. Our numerical and visual comparisons show our superiority over the
state-of-the-art results on the widely used benchmarks.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by NeurIPS 2024. Project page:
  https://wen-yuan-zhang.github.io/GS-Pull/</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ MultiChartQA: Benchmarking Vision-Language Models on Multi-Chart
  Problems 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14179v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14179v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zifeng Zhu, Mengzhao Jia, Zhihan Zhang, Lang Li, Meng Jiang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Multimodal Large Language Models (MLLMs) have demonstrated impressive
abilities across various tasks, including visual question answering and chart
comprehension, yet existing benchmarks for chart-related tasks fall short in
capturing the complexity of real-world multi-chart scenarios. Current
benchmarks primarily focus on single-chart tasks, neglecting the multi-hop
reasoning required to extract and integrate information from multiple charts,
which is essential in practical applications. To fill this gap, we introduce
MultiChartQA, a benchmark that evaluates MLLMs' capabilities in four key areas:
direct question answering, parallel question answering, comparative reasoning,
and sequential reasoning. Our evaluation of a wide range of MLLMs reveals
significant performance gaps compared to humans. These results highlight the
challenges in multi-chart comprehension and the potential of MultiChartQA to
drive advancements in this field. Our code and data are available at
https://github.com/Zivenzhu/Multi-chart-QA
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>18 pages, 9 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Feature Augmentation based Test-Time Adaptation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14178v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14178v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Younggeol Cho, Youngrae Kim, Junho Yoon, Seunghoon Hong, Dongman Lee
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Test-time adaptation (TTA) allows a model to be adapted to an unseen domain
without accessing the source data. Due to the nature of practical environments,
TTA has a limited amount of data for adaptation. Recent TTA methods further
restrict this by filtering input data for reliability, making the effective
data size even smaller and limiting adaptation potential. To address this
issue, We propose Feature Augmentation based Test-time Adaptation (FATA), a
simple method that fully utilizes the limited amount of input data through
feature augmentation. FATA employs Normalization Perturbation to augment
features and adapts the model using the FATA loss, which makes the outputs of
the augmented and original features similar. FATA is model-agnostic and can be
seamlessly integrated into existing models without altering the model
architecture. We demonstrate the effectiveness of FATA on various models and
scenarios on ImageNet-C and Office-Home, validating its superiority in diverse
real-world conditions.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>10 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Learning autonomous driving from aerial imagery <span class="chip">IROS 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14177v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14177v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Varun Murali, Guy Rosman, Sertac Karaman, Daniela Rus
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this work, we consider the problem of learning end to end perception to
control for ground vehicles solely from aerial imagery. Photogrammetric
simulators allow the synthesis of novel views through the transformation of
pre-generated assets into novel views.However, they have a large setup cost,
require careful collection of data and often human effort to create usable
simulators. We use a Neural Radiance Field (NeRF) as an intermediate
representation to synthesize novel views from the point of view of a ground
vehicle. These novel viewpoints can then be used for several downstream
autonomous navigation applications. In this work, we demonstrate the utility of
novel view synthesis though the application of training a policy for end to end
learning from images and depth data. In a traditional real to sim to real
framework, the collected data would be transformed into a visual simulator
which could then be used to generate novel views. In contrast, using a NeRF
allows a compact representation and the ability to optimize over the parameters
of the visual simulator as more data is gathered in the environment. We
demonstrate the efficacy of our method in a custom built mini-city environment
through the deployment of imitation policies on robotic cars. We additionally
consider the task of place localization and demonstrate that our method is able
to relocalize the car in the real world.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Presented at IROS 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ DaRePlane: Direction-aware Representations for Dynamic Scene
  Reconstruction 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14169v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14169v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ange Lou, Benjamin Planche, Zhongpai Gao, Yamin Li, Tianyu Luan, Hao Ding, Meng Zheng, Terrence Chen, Ziyan Wu, Jack Noble
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Numerous recent approaches to modeling and re-rendering dynamic scenes
leverage plane-based explicit representations, addressing slow training times
associated with models like neural radiance fields (NeRF) and Gaussian
splatting (GS). However, merely decomposing 4D dynamic scenes into multiple 2D
plane-based representations is insufficient for high-fidelity re-rendering of
scenes with complex motions. In response, we present DaRePlane, a novel
direction-aware representation approach that captures scene dynamics from six
different directions. This learned representation undergoes an inverse
dual-tree complex wavelet transformation (DTCWT) to recover plane-based
information. Within NeRF pipelines, DaRePlane computes features for each
space-time point by fusing vectors from these recovered planes, then passed to
a tiny MLP for color regression. When applied to Gaussian splatting, DaRePlane
computes the features of Gaussian points, followed by a tiny multi-head MLP for
spatial-time deformation prediction. Notably, to address redundancy introduced
by the six real and six imaginary direction-aware wavelet coefficients, we
introduce a trainable masking approach, mitigating storage issues without
significant performance decline. To demonstrate the generality and efficiency
of DaRePlane, we test it on both regular and surgical dynamic scenes, for both
NeRF and GS systems. Extensive experiments show that DaRePlane yields
state-of-the-art performance in novel view synthesis for various complex
dynamic scenes.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>arXiv admin note: substantial text overlap with arXiv:2403.02265</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Optimal DLT-based Solutions for the Perspective-n-Point 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14164v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14164v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Sébastien Henry, John A. Christian
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We propose a modified normalized direct linear transform (DLT) algorithm for
solving the perspective-n-point (PnP) problem with much better behavior than
the conventional DLT. The modification consists of analytically weighting the
different measurements in the linear system with a negligible increase in
computational load. Our approach exhibits clear improvements -- in both
performance and runtime -- when compared to popular methods such as EPnP, CPnP,
RPnP, and OPnP. Our new non-iterative solution approaches that of the true
optimal found via Gauss-Newton optimization, but at a fraction of the
computational cost. Our optimal DLT (oDLT) implementation, as well as the
experiments, are released in open source.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>8 pages, 6 figures, 2 tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Unlabeled Action Quality Assessment Based on Multi-dimensional Adaptive
  Constrained Dynamic Time Warping 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14161v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14161v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Renguang Chen, Guolong Zheng, Xu Yang, Zhide Chen, Jiwu Shu, Wencheng Yang, Kexin Zhu, Chen Feng
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The growing popularity of online sports and exercise necessitates effective
methods for evaluating the quality of online exercise executions. Previous
action quality assessment methods, which relied on labeled scores from motion
videos, exhibited slightly lower accuracy and discriminability. This limitation
hindered their rapid application to newly added exercises. To address this
problem, this paper presents an unlabeled Multi-Dimensional Exercise Distance
Adaptive Constrained Dynamic Time Warping (MED-ACDTW) method for action quality
assessment. Our approach uses an athletic version of DTW to compare features
from template and test videos, eliminating the need for score labels during
training. The result shows that utilizing both 2D and 3D spatial dimensions,
along with multiple human body features, improves the accuracy by 2-3% compared
to using either 2D or 3D pose estimation alone. Additionally, employing MED for
score calculation enhances the precision of frame distance matching, which
significantly boosts overall discriminability. The adaptive constraint scheme
enhances the discriminability of action quality assessment by approximately
30%. Furthermore, to address the absence of a standardized perspective in
sports class evaluations, we introduce a new dataset called BGym.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Assessing Open-world Forgetting in Generative Image Model Customization 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14159v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14159v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Héctor Laria, Alex Gomez-Villa, Imad Eddine Marouf, Kai Wang, Bogdan Raducanu, Joost van de Weijer
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent advances in diffusion models have significantly enhanced image
generation capabilities. However, customizing these models with new classes
often leads to unintended consequences that compromise their reliability. We
introduce the concept of open-world forgetting to emphasize the vast scope of
these unintended alterations, contrasting it with the well-studied closed-world
forgetting, which is measurable by evaluating performance on a limited set of
classes or skills. Our research presents the first comprehensive investigation
into open-world forgetting in diffusion models, focusing on semantic and
appearance drift of representations. We utilize zero-shot classification to
analyze semantic drift, revealing that even minor model adaptations lead to
unpredictable shifts affecting areas far beyond newly introduced concepts, with
dramatic drops in zero-shot classification of up to 60%. Additionally, we
observe significant changes in texture and color of generated content when
analyzing appearance drift. To address these issues, we propose a mitigation
strategy based on functional regularization, designed to preserve original
capabilities while accommodating new concepts. Our study aims to raise
awareness of unintended changes due to model customization and advocates for
the analysis of open-world forgetting in future research on model customization
and finetuning methods. Furthermore, we provide insights for developing more
robust adaptation methodologies.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Project page: https://hecoding.github.io/open-world-forgetting/</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Fine-Grained Verifiers: Preference Modeling as Next-token Prediction in
  Vision-Language Alignment 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14148v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14148v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Chenhang Cui, An Zhang, Yiyang Zhou, Zhaorun Chen, Gelei Deng, Huaxiu Yao, Tat-Seng Chua
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The recent advancements in large language models (LLMs) and pre-trained
vision models have accelerated the development of vision-language large models
(VLLMs), enhancing the interaction between visual and linguistic modalities.
Despite their notable success across various domains, VLLMs face challenges in
modality alignment, which can lead to issues like hallucinations and unsafe
content generation. Current alignment techniques often rely on coarse feedback
and external datasets, limiting scalability and performance. In this paper, we
propose FiSAO (Fine-Grained Self-Alignment Optimization), a novel
self-alignment method that utilizes the model's own visual encoder as a
fine-grained verifier to improve vision-language alignment without the need for
additional data. By leveraging token-level feedback from the vision encoder,
FiSAO significantly improves vision-language alignment, even surpassing
traditional preference tuning methods that require additional data. Through
both theoretical analysis and experimental validation, we demonstrate that
FiSAO effectively addresses the misalignment problem in VLLMs, marking the
first instance of token-level rewards being applied to such models.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>23 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ P<span class="highlight-title">review</span>-based Category Contrastive Learning for Knowledge Distillation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14143v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14143v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Muhe Ding, Jianlong Wu, Xue Dong, Xiaojie Li, Pengda Qin, Tian Gan, Liqiang Nie
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Knowledge distillation is a mainstream algorithm in model compression by
transferring knowledge from the larger model (teacher) to the smaller model
(student) to improve the performance of student. Despite many efforts, existing
methods mainly investigate the consistency between instance-level feature
representation or prediction, which neglects the category-level information and
the difficulty of each sample, leading to undesirable performance. To address
these issues, we propose a novel preview-based category contrastive learning
method for knowledge distillation (PCKD). It first distills the structural
knowledge of both instance-level feature correspondence and the relation
between instance features and category centers in a contrastive learning
fashion, which can explicitly optimize the category representation and explore
the distinct correlation between representations of instances and categories,
contributing to discriminative category centers and better classification
results. Besides, we introduce a novel preview strategy to dynamically
determine how much the student should learn from each sample according to their
difficulty. Different from existing methods that treat all samples equally and
curriculum learning that simply filters out hard samples, our method assigns a
small weight for hard instances as a preview to better guide the student
training. Extensive experiments on several challenging datasets, including
CIFAR-100 and ImageNet, demonstrate the superiority over state-of-the-art
methods.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>14 pages, 8 figures, Journal</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ ProReason: Multi-Modal Proactive Reasoning with Decoupled Eyesight and
  Wisdom 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14138v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14138v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jingqi Zhou, Sheng Wang, Jingwei Dong, Lei Li, Jiahui Gao, Lingpeng Kong, Chuan Wu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large vision-language models (LVLMs) have witnessed significant progress on
visual understanding tasks. However, they often prioritize language knowledge
over image information on visual reasoning tasks, incurring performance
degradation. To tackle this issue, we first identify the drawbacks of existing
solutions (i.e., insufficient and irrelevant visual descriptions, and limited
multi-modal capacities). We then decompose visual reasoning process into two
stages: visual perception (i.e., eyesight) and textual reasoning (i.e.,
wisdom), and introduce a novel visual reasoning framework named ProReason. This
framework features multi-run proactive perception and decoupled
vision-reasoning capabilities. Briefly, given a multi-modal question, ProReason
iterates proactive information collection and reasoning until the answer can be
concluded with necessary and sufficient visual descriptions. Notably, the
disassociation of capabilities allows seamless integration of existing large
language models (LLMs) to compensate for the reasoning deficits of LVLMs. Our
extensive experiments demonstrate that ProReason outperforms both existing
multi-step reasoning frameworks and passive peer methods on a wide range of
benchmarks for both open-source and closed-source models. In addition, with the
assistance of LLMs, ProReason achieves a performance improvement of up to 15%
on MMMU benchmark. Our insights into existing solutions and the decoupled
perspective for feasible integration of LLMs illuminate future research on
visual reasoning techniques, especially LLM-assisted ones.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ ViConsFormer: Constituting Meaningful Phrases of Scene Texts using
  <span class="highlight-title">Transformer</span>-based Method in Vietnamese Text-based Visual Question Answering 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14132v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14132v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Nghia Hieu Nguyen, Tho Thanh Quan, Ngan Luu-Thuy Nguyen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Text-based VQA is a challenging task that requires machines to use scene
texts in given images to yield the most appropriate answer for the given
question. The main challenge of text-based VQA is exploiting the meaning and
information from scene texts. Recent studies tackled this challenge by
considering the spatial information of scene texts in images via embedding 2D
coordinates of their bounding boxes. In this study, we follow the definition of
meaning from linguistics to introduce a novel method that effectively exploits
the information from scene texts written in Vietnamese. Experimental results
show that our proposed method obtains state-of-the-art results on two
large-scale Vietnamese Text-based VQA datasets. The implementation can be found
at this link.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Deep Learning Applications in Medical Image Analysis: Advancements,
  Challenges, and Future Directions 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14131v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14131v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Aimina Ali Eli, Abida Ali
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Medical image analysis has emerged as an essential element of contemporary
healthcare, facilitating physicians in achieving expedited and precise
diagnosis. Recent breakthroughs in deep learning, a subset of artificial
intelligence, have markedly revolutionized the analysis of medical pictures,
improving the accuracy and efficiency of clinical procedures. Deep learning
algorithms, especially convolutional neural networks (CNNs), have demonstrated
remarkable proficiency in autonomously learning features from multidimensional
medical pictures, including MRI, CT, and X-ray scans, without the necessity for
manual feature extraction. These models have been utilized across multiple
medical disciplines, including pathology, radiology, ophthalmology, and
cardiology, where they aid in illness detection, classification, and
segmentation tasks......
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Extreme Precipitation Nowcasting using Multi-Task Latent Diffusion
  Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14103v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14103v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Li Chaorong, Ling Xudong, Yang Qiang, Qin Fengqing, Huang Yuanyuan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Deep learning models have made remarkable strides in precipitation
prediction, yet they continue to struggle with capturing the spatial details of
the features of radar images, particularly over high precipitation intensity
areas. This shortcoming is evident in the form of low forecast accuracy in the
spatial positioning of radar echo images across varying precipitation intensity
regions. To address this challenge, we introduce the multi-task latent
diffusion model(MTLDM), a novel approach for precipitation prediction. The
basic concept of the MTLDM is based on the understanding that the radar image
representing precipitation is the result of multiple factors. Therefore, we
adopt a divide-and-conquer approach, that is, we decompose the radar image
using decomposition technology and then predict the decomposed sub-images
separately. We conceptualize the precipitation image as a composition of
various components corresponding to different precipitation intensities. The
MTLDM decomposes the precipitation image into these distinct components and
employs a dedicated task to predict each one. This method enables
spatiotemporally consistent prediction of real-world precipitation areas up to
5-80 min in advance, outperforming existing state-of-the-art techniques across
multiple evaluation metrics.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>12 pages, 6figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Enhancing In-vehicle Multiple Object Tracking Systems with Embeddable
  Ising Machines 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14093v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14093v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Kosuke Tatsumura, Yohei Hamakawa, Masaya Yamasaki, Koji Oya, Hiroshi Fujimoto
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  A cognitive function of tracking multiple objects, needed in autonomous
mobile vehicles, comprises object detection and their temporal association.
While great progress owing to machine learning has been recently seen for
elaborating the similarity matrix between the objects that have been recognized
and the objects detected in a current video frame, less for the assignment
problem that finally determines the temporal association, which is a
combinatorial optimization problem. Here we show an in-vehicle multiple object
tracking system with a flexible assignment function for tracking through
multiple long-term occlusion events. To solve the flexible assignment problem
formulated as a nondeterministic polynomial time-hard problem, the system
relies on an embeddable Ising machine based on a quantum-inspired algorithm
called simulated bifurcation. Using a vehicle-mountable computing platform, we
demonstrate a realtime system-wide throughput (23 frames per second on average)
with the enhanced functionality.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>18 pages, 7 figures, 2 tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Learning Generative Interactive Environments By Trained Agent
  Exploration 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06445v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06445v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Naser Kazemi, Nedko Savov, Danda Paudel, Luc Van Gool
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  World models are increasingly pivotal in interpreting and simulating the
rules and actions of complex environments. Genie, a recent model, excels at
learning from visually diverse environments but relies on costly
human-collected data. We observe that their alternative method of using random
agents is too limited to explore the environment. We propose to improve the
model by employing reinforcement learning based agents for data generation.
This approach produces diverse datasets that enhance the model's ability to
adapt and perform well across various scenarios and realistic actions within
the environment. In this paper, we first release the model GenieRedux - an
implementation based on Genie. Additionally, we introduce GenieRedux-G, a
variant that uses the agent's readily available actions to factor out action
prediction uncertainty during validation. Our evaluation, including a
replication of the Coinrun case study, shows that GenieRedux-G achieves
superior visual fidelity and controllability using the trained agent
exploration. The proposed approach is reproducable, scalable and adaptable to
new types of environments. Our codebase is available at
https://github.com/insait-institute/GenieRedux .
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ EVER: Exact Volumetric Ellipsoid Rendering for Real-time View Synthesis 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01804v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01804v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Alexander Mai, Peter Hedman, George Kopanas, Dor Verbin, David Futschik, Qiangeng Xu, Falko Kuester, Jonathan T. Barron, Yinda Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We present Exact Volumetric Ellipsoid Rendering (EVER), a method for
real-time differentiable emission-only volume rendering. Unlike recent
rasterization based approach by 3D Gaussian Splatting (3DGS), our primitive
based representation allows for exact volume rendering, rather than alpha
compositing 3D Gaussian billboards. As such, unlike 3DGS our formulation does
not suffer from popping artifacts and view dependent density, but still
achieves frame rates of $\sim\!30$ FPS at 720p on an NVIDIA RTX4090. Since our
approach is built upon ray tracing it enables effects such as defocus blur and
camera distortion (e.g. such as from fisheye cameras), which are difficult to
achieve by rasterization. We show that our method is more accurate with fewer
blending issues than 3DGS and follow-up work on view-consistent rendering,
especially on the challenging large-scale scenes from the Zip-NeRF dataset
where it achieves sharpest results among real-time techniques.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Project page: https://half-potato.gitlab.io/posts/ever</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Movie101v2: Improved Movie Narration Benchmark 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2404.13370v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2404.13370v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zihao Yue, Yepeng Zhang, Ziheng Wang, Qin Jin
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Automatic movie narration aims to generate video-aligned plot descriptions to
assist visually impaired audiences. Unlike standard video captioning, it
involves not only describing key visual details but also inferring plots that
unfold across multiple movie shots, presenting distinct and complex challenges.
To advance this field, we introduce Movie101v2, a large-scale, bilingual
dataset with enhanced data quality specifically designed for movie narration.
Revisiting the task, we propose breaking down the ultimate goal of automatic
movie narration into three progressive stages, offering a clear roadmap with
corresponding evaluation metrics. Based on our new benchmark, we baseline a
range of large vision-language models, including GPT-4V, and conduct an
in-depth analysis of the challenges in narration generation. Our findings
highlight that achieving applicable movie narration generation is a fascinating
goal that requires significant research.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Harnessing Shared Relations via Multimodal Mixup Contrastive Learning
  for Multimodal Classification <span class="chip">NeurIPS 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.17777v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.17777v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Raja Kumar, Raghav Singhal, Pranamya Kulkarni, Deval Mehta, Kshitij Jadhav
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Deep multimodal learning has shown remarkable success by leveraging
contrastive learning to capture explicit one-to-one relations across
modalities. However, real-world data often exhibits shared relations beyond
simple pairwise associations. We propose M3CoL, a Multimodal Mixup Contrastive
Learning approach to capture nuanced shared relations inherent in multimodal
data. Our key contribution is a Mixup-based contrastive loss that learns robust
representations by aligning mixed samples from one modality with their
corresponding samples from other modalities thereby capturing shared relations
between them. For multimodal classification tasks, we introduce a framework
that integrates a fusion module with unimodal prediction modules for auxiliary
supervision during training, complemented by our proposed Mixup-based
contrastive loss. Through extensive experiments on diverse datasets (N24News,
ROSMAP, BRCA, and Food-101), we demonstrate that M3CoL effectively captures
shared multimodal relations and generalizes across domains. It outperforms
state-of-the-art methods on N24News, ROSMAP, and BRCA, while achieving
comparable performance on Food-101. Our work highlights the significance of
learning shared relations for robust multimodal learning, opening up promising
avenues for future research.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>RK and RS contributed equally to this work, 20 Pages, 8 Figures, 9
  Tables. Another version of the paper accepted at NeurIPS 2024 Workshop on
  Unifying Representations in Neural Models (UniReps)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ IncEventGS: Pose-Free Gaussian Splatting from a Single Event Camera 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.08107v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.08107v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jian Huang, Chengrui Dong, Peidong Liu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Implicit neural representation and explicit 3D Gaussian Splatting (3D-GS) for
novel view synthesis have achieved remarkable progress with frame-based camera
(e.g. RGB and RGB-D cameras) recently. Compared to frame-based camera, a novel
type of bio-inspired visual sensor, i.e. event camera, has demonstrated
advantages in high temporal resolution, high dynamic range, low power
consumption and low latency. Due to its unique asynchronous and irregular data
capturing process, limited work has been proposed to apply neural
representation or 3D Gaussian splatting for an event camera. In this work, we
present IncEventGS, an incremental 3D Gaussian Splatting reconstruction
algorithm with a single event camera. To recover the 3D scene representation
incrementally, we exploit the tracking and mapping paradigm of conventional
SLAM pipelines for IncEventGS. Given the incoming event stream, the tracker
firstly estimates an initial camera motion based on prior reconstructed 3D-GS
scene representation. The mapper then jointly refines both the 3D scene
representation and camera motion based on the previously estimated motion
trajectory from the tracker. The experimental results demonstrate that
IncEventGS delivers superior performance compared to prior NeRF-based methods
and other related baselines, even we do not have the ground-truth camera poses.
Furthermore, our method can also deliver better performance compared to
state-of-the-art event visual odometry methods in terms of camera motion
estimation. Code is publicly available at:
https://github.com/wu-cvgl/IncEventGS.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Code Page: https://github.com/wu-cvgl/IncEventGS</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Scalable Drift Monitoring in Medical Imaging AI 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.13174v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.13174v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jameson Merkow, Felix J. Dorfner, Xiyu Yang, Alexander Ersoy, Giridhar Dasegowda, Mannudeep Kalra, Matthew P. Lungren, Christopher P. Bridge, Ivan Tarapov
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The integration of artificial intelligence (AI) into medical imaging has
advanced clinical diagnostics but poses challenges in managing model drift and
ensuring long-term reliability. To address these challenges, we develop MMC+,
an enhanced framework for scalable drift monitoring, building upon the
CheXstray framework that introduced real-time drift detection for medical
imaging AI models using multi-modal data concordance. This work extends the
original framework's methodologies, providing a more scalable and adaptable
solution for real-world healthcare settings and offers a reliable and
cost-effective alternative to continuous performance monitoring addressing
limitations of both continuous and periodic monitoring methods. MMC+ introduces
critical improvements to the original framework, including more robust handling
of diverse data streams, improved scalability with the integration of
foundation models like MedImageInsight for high-dimensional image embeddings
without site-specific training, and the introduction of uncertainty bounds to
better capture drift in dynamic clinical environments. Validated with
real-world data from Massachusetts General Hospital during the COVID-19
pandemic, MMC+ effectively detects significant data shifts and correlates them
with model performance changes. While not directly predicting performance
degradation, MMC+ serves as an early warning system, indicating when AI systems
may deviate from acceptable performance bounds and enabling timely
interventions. By emphasizing the importance of monitoring diverse data streams
and evaluating data shifts alongside model performance, this work contributes
to the broader adoption and integration of AI solutions in clinical settings.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Fundus to Fluorescein Angiography Video Generation as a Retinal
  Generative Foundation Model 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.13242v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.13242v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Weiyi Zhang, Jiancheng Yang, Ruoyu Chen, Siyu Huang, Pusheng Xu, Xiaolan Chen, Shanfu Lu, Hongyu Cao, Mingguang He, Danli Shi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Fundus fluorescein angiography (FFA) is crucial for diagnosing and monitoring
retinal vascular issues but is limited by its invasive nature and restricted
accessibility compared to color fundus (CF) imaging. Existing methods that
convert CF images to FFA are confined to static image generation, missing the
dynamic lesional changes. We introduce Fundus2Video, an autoregressive
generative adversarial network (GAN) model that generates dynamic FFA videos
from single CF images. Fundus2Video excels in video generation, achieving an
FVD of 1497.12 and a PSNR of 11.77. Clinical experts have validated the
fidelity of the generated videos. Additionally, the model's generator
demonstrates remarkable downstream transferability across ten external public
datasets, including blood vessel segmentation, retinal disease diagnosis,
systemic disease prediction, and multimodal retrieval, showcasing impressive
zero-shot and few-shot capabilities. These findings position Fundus2Video as a
powerful, non-invasive alternative to FFA exams and a versatile retinal
generative foundation model that captures both static and temporal retinal
features, enabling the representation of complex inter-modality relationships.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Video-XL: Extra-Long Vision Language Model for Hour-Scale Video
  Understanding 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.14485v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.14485v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yan Shu, Peitian Zhang, Zheng Liu, Minghao Qin, Junjie Zhou, Tiejun Huang, Bo Zhao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Although current Multi-modal Large Language Models (MLLMs) demonstrate
promising results in video understanding, processing extremely long videos
remains an ongoing challenge. Typically, MLLMs struggle with handling thousands
of visual tokens that exceed the maximum context length, and they suffer from
the information decay due to token aggregation. Another challenge is the high
computational cost stemming from the large number of video tokens. To tackle
these issues, we propose Video-XL, an extra-long vision language model designed
for efficient hour-scale video understanding. Specifically, we argue that LLMs
can be adapted as effective visual condensers and propose Visual Context Latent
Summarization which condenses visual contexts into highly compact forms.
Extensive experiments demonstrate that our model achieves promising results on
popular long video understanding benchmarks. For example, Video-XL outperforms
the current state-of-the-art method on VNBench by nearly 10\% in accuracy.
Moreover, Video-XL presents an impressive balance between efficiency and
effectiveness, processing 2048 frames on a single 80GB GPU while achieving
nearly 95% accuracy in the Needle-in-a-Haystack evaluation.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ On Efficient Variants of Segment Anything Model: A <span class="highlight-title">Survey</span> 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.04960v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.04960v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xiaorui Sun, Jun Liu, Heng Tao Shen, Xiaofeng Zhu, Ping Hu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The Segment Anything Model (SAM) is a foundational model for image
segmentation tasks, known for its strong generalization across diverse
applications. However, its impressive performance comes with significant
computational and resource demands, making it challenging to deploy in
resource-limited environments such as edge devices. To address this, a variety
of SAM variants have been proposed to enhance efficiency while keeping
accuracy. This survey provides the first comprehensive review of these
efficient SAM variants. We begin by exploring the motivations driving this
research. We then present core techniques used in SAM and model acceleration.
This is followed by a detailed exploration of SAM acceleration strategies,
categorized by approach, and a discussion of several future research
directions. Finally, we offer a unified and extensive evaluation of these
methods across various hardware, assessing their efficiency and accuracy on
representative benchmarks, and providing a clear comparison of their overall
performance.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Deep Implicit Optimization for Robust and Flexible Image Registration 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.07361v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.07361v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Rohit Jena, Pratik Chaudhari, James C. Gee
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Deep Learning in Image Registration (DLIR) methods have been tremendously
successful in image registration due to their speed and ability to incorporate
weak label supervision at training time. However, DLIR methods forego many of
the benefits of classical optimization-based methods. The functional nature of
deep networks do not guarantee that the predicted transformation is a local
minima of the registration objective, the representation of the transformation
(displacement/velocity field/affine) is fixed, and the networks are not robust
to domain shift. Our method aims to bridge this gap between classical and
learning methods by incorporating optimization as a layer in a deep network. A
deep network is trained to predict multi-scale dense feature images that are
registered using a black box iterative optimization solver. This optimal warp
is then used to minimize image and label alignment errors. By implicitly
differentiating end-to-end through an iterative optimization solver, our
learned features are registration and label-aware, and the warp functions are
guaranteed to be local minima of the registration objective in the feature
space. Our framework shows excellent performance on in-domain datasets, and is
agnostic to domain shift such as anisotropy and varying intensity profiles. For
the first time, our method allows switching between arbitrary transformation
representations (free-form to diffeomorphic) at test time with zero retraining.
End-to-end feature learning also facilitates interpretability of features, and
out-of-the-box promptability using additional label-fidelity terms at
inference.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Quantization Effects on Neural Networks Perception: How would
  quantization change the perceptual field of vision models? 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2403.09939v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2403.09939v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mohamed Amine Kerkouri, Marouane Tliba, Aladine Chetouani, Alessandro Bruno
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Neural network quantization is a critical technique for deploying models on
resource-limited devices. Despite its widespread use, the impact of
quantization on model perceptual fields, particularly in relation to class
activation maps (CAMs), remains underexplored. This study investigates how
quantization influences the spatial recognition abilities of vision models by
examining the alignment between CAMs and visual salient objects maps across
various architectures. Utilizing a dataset of 10,000 images from ImageNet, we
conduct a comprehensive evaluation of six diverse CNN architectures: VGG16,
ResNet50, EfficientNet, MobileNet, SqueezeNet, and DenseNet. Through the
systematic application of quantization techniques, we identify subtle changes
in CAMs and their alignment with Salient object maps. Our results demonstrate
the differing sensitivities of these architectures to quantization and
highlight its implications for model performance and interpretability in
real-world applications. This work primarily contributes to a deeper
understanding of neural network quantization, offering insights essential for
deploying efficient and interpretable models in practical settings.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted & presented at IPTA 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ MicroDreamer: Efficient 3D Generation in $\sim$20 Seconds by Score-based
  Iterative Reconstruction 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2404.19525v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2404.19525v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Luxi Chen, Zhengyi Wang, Zihan Zhou, Tingting Gao, Hang Su, Jun Zhu, Chongxuan Li
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Optimization-based approaches, such as score distillation sampling (SDS),
show promise in zero-shot 3D generation but suffer from low efficiency,
primarily due to the high number of function evaluations (NFEs) required for
each sample and the limitation of optimization confined to latent space. This
paper introduces score-based iterative reconstruction (SIR), an efficient and
general algorithm mimicking a differentiable 3D reconstruction process to
reduce the NFEs and enable optimization in pixel space. Given a single set of
images sampled from a multi-view score-based diffusion model, SIR repeatedly
optimizes 3D parameters, unlike the single-step optimization in SDS. With other
improvements in training, we present an efficient approach called MicroDreamer
that generally applies to various 3D representations and 3D generation tasks.
In particular, MicroDreamer is 5-20 times faster than SDS in generating neural
radiance field while retaining a comparable performance and takes about 20
seconds to create meshes from 3D Gaussian splatting on a single A100 GPU,
halving the time of the fastest optimization-based baseline DreamGaussian with
significantly superior performance compared to the measurement standard
deviation. Our code is available at https://github.com/ML-GSAI/MicroDreamer.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Similarity and Quality Metrics for MR Image-To-Image Translation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.08431v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.08431v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Melanie Dohmen, Mark Klemens, Ivo Baltruschat, Tuan Truong, Matthias Lenga
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Image-to-image translation can create large impact in medical imaging, as
images can be synthetically transformed to other modalities, sequence types,
higher resolutions or lower noise levels. To ensure patient safety, these
methods should be validated by human readers, which requires a considerable
amount of time and costs. Quantitative metrics can effectively complement such
studies and provide reproducible and objective assessment of synthetic images.
If a reference is available, the similarity of MR images is frequently
evaluated by SSIM and PSNR metrics, even though these metrics are not or too
sensitive regarding specific distortions. When reference images to compare with
are not available, non-reference quality metrics can reliably detect specific
distortions, such as blurriness. To provide an overview on distortion
sensitivity, we quantitatively analyze 11 similarity (reference) and 12 quality
(non-reference) metrics for assessing synthetic images. We additionally include
a metric on a downstream segmentation task. We investigate the sensitivity
regarding 11 kinds of distortions and typical MR artifacts, and analyze the
influence of different normalization methods on each metric and distortion.
Finally, we derive recommendations for effective usage of the analyzed
similarity and quality metrics for evaluation of image-to-image translation
models.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>21 pages, 8 figures, supplement with 16 pages, 10 figures, submitted
  to Nature Scientific Reports</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ LED: Light Enhanced Depth Estimation at Night 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.08031v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.08031v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Simon de Moreau, Yasser Almehio, Andrei Bursuc, Hafid El-Idrissi, Bogdan Stanciulescu, Fabien Moutarde
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Nighttime camera-based depth estimation is a highly challenging task,
especially for autonomous driving applications, where accurate depth perception
is essential for ensuring safe navigation. We aim to improve the reliability of
perception systems at night time, where models trained on daytime data often
fail in the absence of precise but costly LiDAR sensors. In this work, we
introduce Light Enhanced Depth (LED), a novel cost-effective approach that
significantly improves depth estimation in low-light environments by harnessing
a pattern projected by high definition headlights available in modern vehicles.
LED leads to significant performance boosts across multiple depth-estimation
architectures (encoder-decoder, Adabins, DepthFormer) both on synthetic and
real datasets. Furthermore, increased performances beyond illuminated areas
reveal a holistic enhancement in scene understanding. Finally, we release the
Nighttime Synthetic Drive Dataset, a new synthetic and photo-realistic
nighttime dataset, which comprises 49,990 comprehensively annotated images.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Preprint. Code and dataset available on the project page :
  https://simondemoreau.github.io/LED/</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ DiTFastAttn: Attention Compression for Diffusion <span class="highlight-title">Transformer</span> Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.08552v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.08552v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zhihang Yuan, Hanling Zhang, Pu Lu, Xuefei Ning, Linfeng Zhang, Tianchen Zhao, Shengen Yan, Guohao Dai, Yu Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Diffusion Transformers (DiT) excel at image and video generation but face
computational challenges due to the quadratic complexity of self-attention
operators. We propose DiTFastAttn, a post-training compression method to
alleviate the computational bottleneck of DiT. We identify three key
redundancies in the attention computation during DiT inference: (1) spatial
redundancy, where many attention heads focus on local information; (2) temporal
redundancy, with high similarity between the attention outputs of neighboring
steps; (3) conditional redundancy, where conditional and unconditional
inferences exhibit significant similarity. We propose three techniques to
reduce these redundancies: (1) Window Attention with Residual Sharing to reduce
spatial redundancy; (2) Attention Sharing across Timesteps to exploit the
similarity between steps; (3) Attention Sharing across CFG to skip redundant
computations during conditional generation. We apply DiTFastAttn to DiT,
PixArt-Sigma for image generation tasks, and OpenSora for video generation
tasks. Our results show that for image generation, our method reduces up to 76%
of the attention FLOPs and achieves up to 1.8x end-to-end speedup at
high-resolution (2k x 2k) generation.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ <span class="highlight-title">Prompt</span> Tuning of Deep Neural Networks for Speaker-adaptive Visual Speech
  Recognition 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2302.08102v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2302.08102v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Minsu Kim, Hyung-Il Kim, Yong Man Ro
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Visual Speech Recognition (VSR) aims to infer speech into text depending on
lip movements alone. As it focuses on visual information to model the speech,
its performance is inherently sensitive to personal lip appearances and
movements, and this makes the VSR models show degraded performance when they
are applied to unseen speakers. In this paper, to remedy the performance
degradation of the VSR model on unseen speakers, we propose prompt tuning
methods of Deep Neural Networks (DNNs) for speaker-adaptive VSR. Specifically,
motivated by recent advances in Natural Language Processing (NLP), we finetune
prompts on adaptation data of target speakers instead of modifying the
pre-trained model parameters. Different from the previous prompt tuning methods
mainly limited to Transformer variant architecture, we explore different types
of prompts, the addition, the padding, and the concatenation form prompts that
can be applied to the VSR model which is composed of CNN and Transformer in
general. With the proposed prompt tuning, we show that the performance of the
pre-trained VSR model on unseen speakers can be largely improved by using a
small amount of adaptation data (e.g., less than 5 minutes), even if the
pre-trained model is already developed with large speaker variations. Moreover,
by analyzing the performance and parameters of different types of prompts, we
investigate when the prompt tuning is preferred over the finetuning methods.
The effectiveness of the proposed method is evaluated on both word- and
sentence-level VSR databases, LRW-ID and GRID.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>IEEE TPAMI</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Harnessing Webpage UIs for Text-Rich Visual Understanding 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.13824v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.13824v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Junpeng Liu, Tianyue Ou, Yifan Song, Yuxiao Qu, Wai Lam, Chenyan Xiong, Wenhu Chen, Graham Neubig, Xiang Yue
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Text-rich visual understanding-the ability to process environments where
dense textual content is integrated with visuals-is crucial for multimodal
large language models (MLLMs) to interact effectively with structured
environments. To enhance this capability, we propose synthesizing general
multimodal instructions from webpage UIs using text-based large language models
(LLMs). Despite lacking direct visual input, text-based LLMs are able to
process structured text representations from webpage accessibility trees. These
instructions are then paired with UI screenshots to train multimodal models. We
introduce MultiUI, a dataset containing 7.3 million samples from 1 million
websites, covering diverse multimodal tasks and UI layouts. Models trained on
MultiUI not only excel in web UI tasks-achieving up to a 48% improvement on
VisualWebBench and a 19.1% boost in element accuracy on a web agent dataset
Mind2Web-but also generalize surprisingly well to non-web UI tasks and even to
non-UI domains, such as document understanding, OCR, and chart interpretation.
These results highlight the broad applicability of web UI data for advancing
text-rich visual understanding across various scenarios.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Dating ancient manuscripts using radiocarbon and AI-based writing style
  analysis 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.12013v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.12013v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mladen Popović, Maruf A. Dhali, Lambert Schomaker, Johannes van der Plicht, Kaare Lund Rasmussen, Jacopo La Nasa, Ilaria Degano, Maria Perla Colombini, Eibert Tigchelaar
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Determining the chronology of ancient handwritten manuscripts is essential
for reconstructing the evolution of ideas. For the Dead Sea Scrolls, this is
particularly important. However, there is an almost complete lack of
date-bearing manuscripts evenly distributed across the timeline and written in
similar scripts available for palaeographic comparison. Here, we present Enoch,
a state-of-the-art AI-based date-prediction model, trained on the basis of new
radiocarbon-dated samples of the scrolls. Enoch uses established
handwriting-style descriptors and applies Bayesian ridge regression. The
challenge of this study is that the number of radiocarbon-dated manuscripts is
small, while current machine learning requires an abundance of training data.
We show that by using combined angular and allographic writing style feature
vectors and applying Bayesian ridge regression, Enoch could predict the
radiocarbon-based dates from style, supported by leave-one-out validation, with
varied MAEs of 27.9 to 30.7 years relative to the radiocarbon dating. Enoch was
then used to estimate the dates of 135 unseen manuscripts, revealing that 79
per cent of the samples were considered 'realistic' upon palaeographic post-hoc
evaluation. We present a new chronology of the scrolls. The radiocarbon ranges
and Enoch's style-based predictions are often older than the traditionally
assumed palaeographic estimates. In the range of 300-50 BCE, Enoch's date
prediction provides an improved granularity. The study is in line with current
developments in multimodal machine-learning techniques, and the methods can be
used for date prediction in other partially-dated manuscript collections. This
research shows how Enoch's quantitative, probability-based approach can be a
tool for palaeographers and historians, re-dating ancient Jewish key texts and
contributing to current debates on Jewish and Christian origins.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>16 pages of main article, 103 pages of supplementary materials; the
  first version of this article is originally prepared in July 2023 after the
  completion of all the experiments</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Distribution Guidance Network for Weakly Supervised Point Cloud Semantic
  Segmentation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.08091v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.08091v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zhiyi Pan, Wei Gao, Shan Liu, Ge Li
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Despite alleviating the dependence on dense annotations inherent to fully
supervised methods, weakly supervised point cloud semantic segmentation suffers
from inadequate supervision signals. In response to this challenge, we
introduce a novel perspective that imparts auxiliary constraints by regulating
the feature space under weak supervision. Our initial investigation identifies
which distributions accurately characterize the feature space, subsequently
leveraging this priori to guide the alignment of the weakly supervised
embeddings. Specifically, we analyze the superiority of the mixture of von
Mises-Fisher distributions (moVMF) among several common distribution
candidates. Accordingly, we develop a Distribution Guidance Network (DGNet),
which comprises a weakly supervised learning branch and a distribution
alignment branch. Leveraging reliable clustering initialization derived from
the weakly supervised learning branch, the distribution alignment branch
alternately updates the parameters of the moVMF and the network, ensuring
alignment with the moVMF-defined latent space. Extensive experiments validate
the rationality and effectiveness of our distribution choice and network
design. Consequently, DGNet achieves state-of-the-art performance under
multiple datasets and various weakly supervised settings.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ SatSwinMAE: Efficient Autoencoding for Multiscale Time-series Satellite
  Imagery 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.02512v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.02512v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yohei Nakayama, Jiawei Su, Luis M. Pazos-Outón
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent advancements in foundation models have significantly impacted various
fields, including natural language processing, computer vision, and multi-modal
tasks. One area that stands to benefit greatly is Earth observation, where
these models can efficiently process large-scale, unlabeled geospatial data. In
this work we extend the SwinMAE model to integrate temporal information for
satellite time-series data. The architecture employs a hierarchical 3D Masked
Autoencoder (MAE) with Video Swin Transformer blocks to effectively capture
multi-scale spatio-temporal dependencies in satellite imagery. To enhance
transfer learning, we incorporate both encoder and decoder pretrained weights,
along with skip connections to preserve scale-specific information. This forms
an architecture similar to SwinUNet with an additional temporal component. Our
approach shows significant performance improvements over existing
state-of-the-art foundation models for all the evaluated downstream tasks: land
cover segmentation, building density prediction, flood mapping, wildfire scar
mapping and multi-temporal crop segmentation. Particularly, in the land cover
segmentation task of the PhilEO Bench dataset, it outperforms other geospatial
foundation models with a 10.4% higher accuracy.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ TotalVibeSegmentator: Full Body MRI Segmentation for the NAKO and UK
  Biobank 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.00125v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.00125v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Robert Graf, Paul-Sören Platzek, Evamaria Olga Riedel, Constanze Ramschütz, Sophie Starck, Hendrik Kristian Möller, Matan Atad, Henry Völzke, Robin Bülow, Carsten Oliver Schmidt, Julia Rüdebusch, Matthias Jung, Marco Reisert, Jakob Weiss, Maximilian Löffler, Fabian Bamberg, Bene Wiestler, Johannes C. Paetzold, Daniel Rueckert, Jan Stefan Kirschke
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Objectives: To present a publicly available torso segmentation network for
large epidemiology datasets on volumetric interpolated breath-hold examination
(VIBE) images. Materials & Methods: We extracted preliminary segmentations from
TotalSegmentator, spine, and body composition networks for VIBE images, then
improved them iteratively and retrained a nnUNet network. Using subsets of NAKO
(85 subjects) and UK Biobank (16 subjects), we evaluated with Dice-score on a
holdout set (12 subjects) and existing organ segmentation approach (1000
subjects), generating 71 semantic segmentation types for VIBE images. We
provide an additional network for the vertebra segments 22 individual vertebra
types. Results: We achieved an average Dice score of 0.89 +- 0.07 overall 71
segmentation labels. We scored > 0.90 Dice-score on the abdominal organs except
for the pancreas with a Dice of 0.70. Conclusion: Our work offers a detailed
and refined publicly available full torso segmentation on VIBE images.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>https://github.com/robert-graf/TotalVibeSegmentator</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Enhanced <span class="highlight-title">Prompt</span>-leveraged Weakly Supervised Cancer Segmentation based on
  Segment Anything 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.13621v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.13621v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Joonhyeon Song, Seohwan Yun, Seongho Yoon, Joohyeok Kim, Sangmin Lee
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This work proposes a novel approach beyond supervised learning for effective
pathological image analysis, addressing the challenge of limited robust labeled
data. Pathological diagnosis of diseases like cancer has conventionally relied
on the evaluation of morphological features by physicians and pathologists.
However, recent advancements in compute-aided diagnosis (CAD) systems are
gaining significant attention as diagnostic support tools. Although the
advancement of deep learning has improved CAD significantly, segmentation
models typically require large pixel-level annotated dataset, and such labeling
is expensive. Existing studies not based on supervised approaches still
struggle with limited generalization, and no practical approach has emerged
yet. To address this issue, we present a weakly supervised semantic
segmentation (WSSS) model by combining class activation map and Segment
Anything Model (SAM)-based pseudo-labeling. For effective pretraining, we adopt
the SAM-a foundation model that is pretrained on large datasets and operates in
zero-shot configurations using only coarse prompts. The proposed approach
transfer enhanced Attention Dropout Layer's knowledge to SAM, thereby
generating pseudo-labels. To demonstrate the superiority of the proposed
method, experimental studies are conducted on histopathological breast cancer
datasets. The proposed method outperformed other WSSS methods across three
datasets, demonstrating its efficiency by achieving this with only 12GB of GPU
memory during training. Our code is available at :
https://github.com/QI-NemoSong/EPLC-SAM
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>10 pages, 7 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Encode-Store-Retrieve: Augmenting Human Memory through Language-Encoded
  Egocentric Perception 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2308.05822v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2308.05822v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Junxiao Shen, John Dudley, Per Ola Kristensson
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We depend on our own memory to encode, store, and retrieve our experiences.
However, memory lapses can occur. One promising avenue for achieving memory
augmentation is through the use of augmented reality head-mounted displays to
capture and preserve egocentric videos, a practice commonly referred to as
lifelogging. However, a significant challenge arises from the sheer volume of
video data generated through lifelogging, as the current technology lacks the
capability to encode and store such large amounts of data efficiently. Further,
retrieving specific information from extensive video archives requires
substantial computational power, further complicating the task of quickly
accessing desired content. To address these challenges, we propose a memory
augmentation agent that involves leveraging natural language encoding for video
data and storing them in a vector database. This approach harnesses the power
of large vision language models to perform the language encoding process.
Additionally, we propose using large language models to facilitate natural
language querying. Our agent underwent extensive evaluation using the QA-Ego4D
dataset and achieved state-of-the-art results with a BLEU score of 8.3,
outperforming conventional machine learning models that scored between 3.4 and
5.8. Additionally, we conducted a user study in which participants interacted
with the human memory augmentation agent through episodic memory and open-ended
questions. The results of this study show that the agent results in
significantly better recall performance on episodic memory tasks compared to
human participants. The results also highlight the agent's practical
applicability and user acceptance.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Object Pose Estimation via the Aggregation of Diffusion Features <span class="chip">CVPR2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2403.18791v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2403.18791v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Tianfu Wang, Guosheng Hu, Hongguang Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Estimating the pose of objects from images is a crucial task of 3D scene
understanding, and recent approaches have shown promising results on very large
benchmarks. However, these methods experience a significant performance drop
when dealing with unseen objects. We believe that it results from the limited
generalizability of image features. To address this problem, we have an
in-depth analysis on the features of diffusion models, e.g. Stable Diffusion,
which hold substantial potential for modeling unseen objects. Based on this
analysis, we then innovatively introduce these diffusion features for object
pose estimation. To achieve this, we propose three distinct architectures that
can effectively capture and aggregate diffusion features of different
granularity, greatly improving the generalizability of object pose estimation.
Our approach outperforms the state-of-the-art methods by a considerable margin
on three popular benchmark datasets, LM, O-LM, and T-LESS. In particular, our
method achieves higher accuracy than the previous best arts on unseen objects:
97.9% vs. 93.5% on Unseen LM, 85.9% vs. 76.3% on Unseen O-LM, showing the
strong generalizability of our method. Our code is released at
https://github.com/Tianfu18/diff-feats-pose.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to CVPR2024, fix typo</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ VLFeedback: A Large-Scale AI Feedback <span class="highlight-title">Dataset</span> for Large Vision-Language
  Models Alignment <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.09421v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.09421v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Lei Li, Zhihui Xie, Mukai Li, Shunian Chen, Peiyi Wang, Liang Chen, Yazheng Yang, Benyou Wang, Lingpeng Kong, Qi Liu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  As large vision-language models (LVLMs) evolve rapidly, the demand for
high-quality and diverse data to align these models becomes increasingly
crucial. However, the creation of such data with human supervision proves
costly and time-intensive. In this paper, we investigate the efficacy of AI
feedback to scale supervision for aligning LVLMs. We introduce VLFeedback, the
first large-scale vision-language feedback dataset, comprising over 82K
multi-modal instructions and comprehensive rationales generated by
off-the-shelf models without human annotations. To evaluate the effectiveness
of AI feedback for vision-language alignment, we train Silkie, an LVLM
fine-tuned via direct preference optimization on VLFeedback. Silkie showcases
exceptional performance regarding helpfulness, visual faithfulness, and safety
metrics. It outperforms its base model by 6.9\% and 9.5\% in perception and
cognition tasks, reduces hallucination issues on MMHal-Bench, and exhibits
enhanced resilience against red-teaming attacks. Furthermore, our analysis
underscores the advantage of AI feedback, particularly in fostering preference
diversity to deliver more comprehensive improvements. Our dataset, training
code and models are available at https://vlf-silkie.github.io.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>EMNLP 2024 Main Conference camera-ready version (fixed small typos).
  This article supersedes arXiv:2312.10665</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ X-Fi: A Modality-Invariant Foundation Model for Multimodal Human Sensing 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.10167v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.10167v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xinyan Chen, Jianfei Yang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Human sensing, which employs various sensors and advanced deep learning
technologies to accurately capture and interpret human body information, has
significantly impacted fields like public security and robotics. However,
current human sensing primarily depends on modalities such as cameras and
LiDAR, each of which has its own strengths and limitations. Furthermore,
existing multi-modal fusion solutions are typically designed for fixed modality
combinations, requiring extensive retraining when modalities are added or
removed for diverse scenarios. In this paper, we propose a modality-invariant
foundation model for all modalities, X-Fi, to address this issue. X-Fi enables
the independent or combinatory use of sensor modalities without additional
training by utilizing a transformer structure to accommodate variable input
sizes and incorporating a novel "X-fusion" mechanism to preserve
modality-specific features during multimodal integration. This approach not
only enhances adaptability but also facilitates the learning of complementary
features across modalities. Extensive experiments conducted on the MM-Fi and
XRF55 datasets, employing six distinct modalities, demonstrate that X-Fi
achieves state-of-the-art performance in human pose estimation (HPE) and human
activity recognition (HAR) tasks. The findings indicate that our proposed model
can efficiently support a wide range of human sensing applications, ultimately
contributing to the evolution of scalable, multimodal sensing technologies.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Suppress Content Shift: Better Diffusion Features via Off-the-Shelf
  Generation Techniques 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.06719v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.06719v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Benyuan Meng, Qianqian Xu, Zitai Wang, Zhiyong Yang, Xiaochun Cao, Qingming Huang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Diffusion models are powerful generative models, and this capability can also
be applied to discrimination. The inner activations of a pre-trained diffusion
model can serve as features for discriminative tasks, namely, diffusion
feature. We discover that diffusion feature has been hindered by a hidden yet
universal phenomenon that we call content shift. To be specific, there are
content differences between features and the input image, such as the exact
shape of a certain object. We locate the cause of content shift as one inherent
characteristic of diffusion models, which suggests the broad existence of this
phenomenon in diffusion feature. Further empirical study also indicates that
its negative impact is not negligible even when content shift is not visually
perceivable. Hence, we propose to suppress content shift to enhance the overall
quality of diffusion features. Specifically, content shift is related to the
information drift during the process of recovering an image from the noisy
input, pointing out the possibility of turning off-the-shelf generation
techniques into tools for content shift suppression. We further propose a
practical guideline named GATE to efficiently evaluate the potential benefit of
a technique and provide an implementation of our methodology. Despite the
simplicity, the proposed approach has achieved superior results on various
tasks and datasets, validating its potential as a generic booster for diffusion
features. Our code is available at
https://github.com/Darkbblue/diffusion-content-shift.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>arXiv admin note: substantial text overlap with arXiv:2410.03558</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Not All Diffusion Model Activations Have Been Evaluated as
  Discriminative Features 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.03558v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.03558v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Benyuan Meng, Qianqian Xu, Zitai Wang, Xiaochun Cao, Qingming Huang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Diffusion models are initially designed for image generation. Recent research
shows that the internal signals within their backbones, named activations, can
also serve as dense features for various discriminative tasks such as semantic
segmentation. Given numerous activations, selecting a small yet effective
subset poses a fundamental problem. To this end, the early study of this field
performs a large-scale quantitative comparison of the discriminative ability of
the activations. However, we find that many potential activations have not been
evaluated, such as the queries and keys used to compute attention scores.
Moreover, recent advancements in diffusion architectures bring many new
activations, such as those within embedded ViT modules. Both combined,
activation selection remains unresolved but overlooked. To tackle this issue,
this paper takes a further step with a much broader range of activations
evaluated. Considering the significant increase in activations, a full-scale
quantitative comparison is no longer operational. Instead, we seek to
understand the properties of these activations, such that the activations that
are clearly inferior can be filtered out in advance via simple qualitative
evaluation. After careful analysis, we discover three properties universal
among diffusion models, enabling this study to go beyond specific models. On
top of this, we present effective feature selection solutions for several
popular diffusion models. Finally, the experiments across multiple
discriminative tasks validate the superiority of our method over the SOTA
competitors. Our code is available at
https://github.com/Darkbblue/generic-diffusion-feature.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ UniG: Modelling Unitary 3D Gaussians for View-consistent 3D
  Reconstruction 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.13195v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.13195v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jiamin Wu, Kenkun Liu, Yukai Shi, Xiaoke Jiang, Yuan Yao, Lei Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this work, we present UniG, a view-consistent 3D reconstruction and novel
view synthesis model that generates a high-fidelity representation of 3D
Gaussians from sparse images. Existing 3D Gaussians-based methods usually
regress Gaussians per-pixel of each view, create 3D Gaussians per view
separately, and merge them through point concatenation. Such a view-independent
reconstruction approach often results in a view inconsistency issue, where the
predicted positions of the same 3D point from different views may have
discrepancies. To address this problem, we develop a DETR (DEtection
TRansformer)-like framework, which treats 3D Gaussians as decoder queries and
updates their parameters layer by layer by performing multi-view
cross-attention (MVDFA) over multiple input images. In this way, multiple views
naturally contribute to modeling a unitary representation of 3D Gaussians,
thereby making 3D reconstruction more view-consistent. Moreover, as the number
of 3D Gaussians used as decoder queries is irrespective of the number of input
views, allow an arbitrary number of input images without causing memory
explosion. Extensive experiments validate the advantages of our approach,
showcasing superior performance over existing methods quantitatively (improving
PSNR by 4.2 dB when trained on Objaverse and tested on the GSO benchmark) and
qualitatively. The code will be released at https://github.com/jwubz123/UNIG.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ ViLCo-Bench: VIdeo Language COntinual learning Benchmark <span class="chip">NeurIPS</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.13123v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.13123v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Tianqi Tang, Shohreh Deldari, Hao Xue, Celso De Melo, Flora D. Salim
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Video language continual learning involves continuously adapting to
information from video and text inputs, enhancing a model's ability to handle
new tasks while retaining prior knowledge. This field is a relatively
under-explored area, and establishing appropriate datasets is crucial for
facilitating communication and research in this field. In this study, we
present the first dedicated benchmark, ViLCo-Bench, designed to evaluate
continual learning models across a range of video-text tasks. The dataset
comprises ten-minute-long videos and corresponding language queries collected
from publicly available datasets. Additionally, we introduce a novel
memory-efficient framework that incorporates self-supervised learning and
mimics long-term and short-term memory effects. This framework addresses
challenges including memory complexity from long video clips, natural language
complexity from open queries, and text-video misalignment. We posit that
ViLCo-Bench, with greater complexity compared to existing continual learning
benchmarks, would serve as a critical tool for exploring the video-language
domain, extending beyond conventional class-incremental tasks, and addressing
complex and limited annotation issues. The curated data, evaluations, and our
novel method are available at https://github.com/cruiseresearchgroup/ViLCo.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>14 pages, 4 figures, 8 tables, Accepted at NeurIPS Dataset and
  Benchmark Track 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ MK-SGN: A Spiking Graph Convolutional Network with Multimodal Fusion and
  Knowledge Distillation for Skeleton-based Action Recognition 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2404.10210v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2404.10210v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Naichuan Zheng, Hailun Xia, Zeyu Liang, Yuanyuan Chai
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In recent years, skeleton-based action recognition, leveraging multimodal
Graph Convolutional Networks (GCN), has achieved remarkable results. However,
due to their deep structure and reliance on continuous floating-point
operations, GCN-based methods are energy-intensive. We propose an innovative
Spiking Graph Convolutional Network with Multimodal Fusion and Knowledge
Distillation (MK-SGN) to address this issue. By merging the energy efficiency
of Spiking Neural Network (SNN) with the graph representation capability of
GCN, the proposed MK-SGN reduces energy consumption while maintaining
recognition accuracy. Firstly, we convert Graph Convolutional Networks (GCN)
into Spiking Graph Convolutional Networks (SGN) establishing a new benchmark
and paving the way for future research exploration. During this process, we
introduce a spiking attention mechanism and design a Spiking-Spatio Graph
Convolution module with a Spatial Global Spiking Attention mechanism (SA-SGC),
enhancing feature learning capability. Secondly, we propose a Spiking
Multimodal Fusion module (SMF), leveraging mutual information to process
multimodal data more efficiently. Lastly, we delve into knowledge distillation
methods from multimodal GCN to SGN and propose a novel, integrated method that
simultaneously focuses on both intermediate layer distillation and soft label
distillation to improve the performance of SGN. MK-SGN outperforms the
state-of-the-art GCN-like frameworks on three challenging datasets for
skeleton-based action recognition in reducing energy consumption. It also
outperforms the state-of-the-art SNN frameworks in accuracy. Specifically, our
method reduces energy consumption by more than 98% compared to typical
GCN-based methods, while maintaining competitive accuracy on the NTU-RGB+D 60
cross-subject split using 4-time steps.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Hard Region Aware Network for Remote Sensing Change Detection 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2305.19513v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2305.19513v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zhenglai Li, Chang Tang, Xinwang Liu, Xingchen Hu, Xianju Li, Ning Li, Changdong Li
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Change detection (CD) is essential for various real-world applications, such
as urban management and disaster assessment. Numerous CD methods have been
proposed, and considerable results have been achieved recently. However,
detecting changes in hard regions, i.e., the change boundary and irrelevant
pseudo changes caused by background clutters, remains difficult for these
methods, since they pose equal attention for all regions in bi-temporal images.
This paper proposes a novel change detection network, termed as HRANet, which
provides accurate change maps via hard region mining. Specifically, an online
hard region estimation branch is constructed to model the pixel-wise hard
samples, supervised by the error between predicted change maps and
corresponding ground truth during the training process. A cross-layer knowledge
review module is introduced to distill temporal change information from
low-level to high-level features, thereby enhancing the feature representation
capabilities. Finally, the hard region aware features extracted from the online
hard region estimation branch and multi-level temporal difference features are
aggregated into a unified feature representation to improve the accuracy of CD.
Experimental results on two benchmark datasets demonstrate the superior
performance of HRANet in the CD task.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Signal-SGN: A Spiking Graph Convolutional Network for Skeletal Action
  Recognition via Learning Temporal-Frequency Dynamics 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2408.01701v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2408.01701v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Naichuan Zheng, Hailun Xia, Dapeng Liu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In skeletal-based action recognition, Graph Convolutional Networks (GCNs)
based methods face limitations due to their complexity and high energy
consumption. Spiking Neural Networks (SNNs) have gained attention in recent
years for their low energy consumption, but existing methods combining GCNs and
SNNs fail to fully utilize the temporal characteristics of skeletal sequences,
leading to increased storage and computational costs. To address this issue, we
propose a Signal-SGN(Spiking Graph Convolutional Network), which leverages the
temporal dimension of skeletal sequences as the spiking timestep and treats
features as discrete stochastic signals. The core of the network consists of a
1D Spiking Graph Convolutional Network (1D-SGN) and a Frequency Spiking
Convolutional Network (FSN). The SGN performs graph convolution on single
frames and incorporates spiking network characteristics to capture inter-frame
temporal relationships, while the FSN uses Fast Fourier Transform (FFT) and
complex convolution to extract temporal-frequency features. We also introduce a
multi-scale wavelet transform feature fusion module(MWTF) to capture spectral
features of temporal signals, enhancing the model's classification capability.
We propose a pluggable temporal-frequency spatial semantic feature extraction
module(TFSM) to enhance the model's ability to distinguish features without
increasing inference-phase consumption. Our numerous experiments on the NTU
RGB+D, NTU RGB+D 120, and NW-UCLA datasets demonstrate that the proposed models
not only surpass existing SNN-based methods in accuracy but also reduce
computational and storage costs during training. Furthermore, they achieve
competitive accuracy compared to corresponding GCN-based methods, which is
quite remarkable.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Scene Prior Filtering for Depth Super-Resolution 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2402.13876v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2402.13876v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zhengxue Wang, Zhiqiang Yan, Ming-Hsuan Yang, Jinshan Pan, Guangwei Gao, Ying Tai, Jian Yang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Multi-modal fusion is vital to the success of super-resolution of depth maps.
However, commonly used fusion strategies, such as addition and concatenation,
fall short of effectively bridging the modal gap. As a result, guided image
filtering methods have been introduced to mitigate this issue. Nevertheless, it
is observed that their filter kernels usually encounter significant texture
interference and edge inaccuracy. To tackle these two challenges, we introduce
a Scene Prior Filtering network, SPFNet, which utilizes the priors surface
normal and semantic map from large-scale models. Specifically, we design an
All-in-one Prior Propagation that computes the similarity between multi-modal
scene priors, i.e., RGB, normal, semantic, and depth, to reduce the texture
interference. In addition, we present a One-to-one Prior Embedding that
continuously embeds each single-modal prior into depth using Mutual Guided
Filtering, further alleviating the texture interference while enhancing edges.
Our SPFNet has been extensively evaluated on both real and synthetic datasets,
achieving state-of-the-art performance.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>13 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ LatentExplainer: Explaining Latent Representations in Deep Generative
  Models with Multi-modal Foundation Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.14862v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.14862v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mengdan Zhu, Raasikh Kanjiani, Jiahui Lu, Andrew Choi, Qirui Ye, Liang Zhao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Deep generative models like VAEs and diffusion models have advanced various
generation tasks by leveraging latent variables to learn data distributions and
generate high-quality samples. Despite the field of explainable AI making
strides in interpreting machine learning models, understanding latent variables
in generative models remains challenging. This paper introduces
\textit{LatentExplainer}, a framework for automatically generating semantically
meaningful explanations of latent variables in deep generative models.
\textit{LatentExplainer} tackles three main challenges: inferring the meaning
of latent variables, aligning explanations with inductive biases, and handling
varying degrees of explainability. Our approach perturbs latent variables,
interpreting changes in generated data, and uses multi-modal large language
models (MLLMs) to produce human-understandable explanations. We evaluate our
proposed method on several real-world and synthetic datasets, and the results
demonstrate superior performance in generating high-quality explanations for
latent variables. The results highlight the effectiveness of incorporating
inductive biases and uncertainty quantification, significantly enhancing model
interpretability.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ From Introspection to Best Practices: Principled Analysis of
  Demonstrations in Multimodal In-Context Learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.00902v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.00902v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Nan Xu, Fei Wang, Sheng Zhang, Hoifung Poon, Muhao Chen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Motivated by in-context learning (ICL) capabilities of Large Language models
(LLMs), multimodal LLMs with additional visual modality are also exhibited with
similar ICL abilities when multiple image-text pairs are provided as
demonstrations. However, relatively less work has been done to investigate the
principles behind how and why multimodal ICL works. We conduct a systematic and
principled evaluation of multimodal ICL for models of different scales on a
broad spectrum of new yet critical tasks. Through perturbations over different
modality information, we show that modalities matter differently across tasks
in multimodal ICL. Guided by task-specific modality impact, we recommend
modality-driven demonstration strategies to boost ICL performance. We also find
that models may follow inductive biases from multimodal ICL even if they are
rarely seen in or contradict semantic priors from pretraining data. Our
principled analysis provides a comprehensive way of understanding the role of
demonstrations in multimodal in-context learning, and sheds light on
effectively improving multimodal ICL on a wide range of tasks.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ PAPL-SLAM: Principal Axis-Anchored Monocular Point-Line SLAM 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12324v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12324v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Guanghao Li, Yu Cao, Qi Chen, Yifan Yang, Jian Pu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In point-line SLAM systems, the utilization of line structural information
and the optimization of lines are two significant problems. The former is
usually addressed through structural regularities, while the latter typically
involves using minimal parameter representations of lines in optimization.
However, separating these two steps leads to the loss of constraint information
to each other. We anchor lines with similar directions to a principal axis and
optimize them with $n+2$ parameters for $n$ lines, solving both problems
together. Our method considers scene structural information, which can be
easily extended to different world hypotheses while significantly reducing the
number of line parameters to be optimized, enabling rapid and accurate mapping
and tracking. To further enhance the system's robustness and avoid mismatch, we
have modeled the line-axis probabilistic data association and provided the
algorithm for axis creation, updating, and optimization. Additionally,
considering that most real-world scenes conform to the Atlanta World
hypothesis, we provide a structural line detection strategy based on vertical
priors and vanishing points. Experimental results and ablation studies on
various indoor and outdoor datasets demonstrate the effectiveness of our
system.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>8 pages, 4 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ PredFormer: <span class="highlight-title">Transformer</span>s Are Effective Spatial-Temporal Predictive
  Learners 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.04733v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.04733v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yujin Tang, Lu Qi, Fei Xie, Xiangtai Li, Chao Ma, Ming-Hsuan Yang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Spatiotemporal predictive learning methods generally fall into two
categories: recurrent-based approaches, which face challenges in
parallelization and performance, and recurrent-free methods, which employ
convolutional neural networks (CNNs) as encoder-decoder architectures. These
methods benefit from strong inductive biases but often at the expense of
scalability and generalization. This paper proposes PredFormer, a pure
transformer-based framework for spatiotemporal predictive learning. Motivated
by the Vision Transformers (ViT) design, PredFormer leverages carefully
designed Gated Transformer blocks, following a comprehensive analysis of 3D
attention mechanisms, including full-, factorized-, and
interleaved-spatial-temporal attention. With its recurrent-free,
transformer-based design, PredFormer is both simple and efficient,
significantly outperforming previous methods by large margins. Extensive
experiments on synthetic and real-world datasets demonstrate that PredFormer
achieves state-of-the-art performance. On Moving MNIST, PredFormer achieves a
51.3% reduction in MSE relative to SimVP. For TaxiBJ, the model decreases MSE
by 33.1% and boosts FPS from 533 to 2364. Additionally, on WeatherBench, it
reduces MSE by 11.1% while enhancing FPS from 196 to 404. These performance
gains in both accuracy and efficiency demonstrate PredFormer's potential for
real-world applications. The source code will be released at
https://github.com/yyyujintang/PredFormer .
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>15 pages, 7 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Biometric Authentication Based on Enhanced Remote Photoplethysmography
  Signal Morphology 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.04127v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.04127v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zhaodong Sun, Xiaobai Li, Jukka Komulainen, Guoying Zhao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Remote photoplethysmography (rPPG) is a non-contact method for measuring
cardiac signals from facial videos, offering a convenient alternative to
contact photoplethysmography (cPPG) obtained from contact sensors. Recent
studies have shown that each individual possesses a unique cPPG signal
morphology that can be utilized as a biometric identifier, which has inspired
us to utilize the morphology of rPPG signals extracted from facial videos for
person authentication. Since the facial appearance and rPPG are mixed in the
facial videos, we first de-identify facial videos to remove facial appearance
while preserving the rPPG information, which protects facial privacy and
guarantees that only rPPG is used for authentication. The de-identified videos
are fed into an rPPG model to get the rPPG signal morphology for
authentication. In the first training stage, unsupervised rPPG training is
performed to get coarse rPPG signals. In the second training stage, an
rPPG-cPPG hybrid training is performed by incorporating external cPPG datasets
to achieve rPPG biometric authentication and enhance rPPG signal morphology.
Our approach needs only de-identified facial videos with subject IDs to train
rPPG authentication models. The experimental results demonstrate that rPPG
signal morphology hidden in facial videos can be used for biometric
authentication. The code is available at
https://github.com/zhaodongsun/rppg_biometrics.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>accepted by IJCB 2024, Best Paper Runner-Up Award</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ DAWN: Dynamic Frame Avatar with Non-autoregressive Diffusion Framework
  for Talking Head Video Generation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.13726v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.13726v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hanbo Cheng, Limin Lin, Chenyu Liu, Pengcheng Xia, Pengfei Hu, Jiefeng Ma, Jun Du, Jia Pan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Talking head generation intends to produce vivid and realistic talking head
videos from a single portrait and speech audio clip. Although significant
progress has been made in diffusion-based talking head generation, almost all
methods rely on autoregressive strategies, which suffer from limited context
utilization beyond the current generation step, error accumulation, and slower
generation speed. To address these challenges, we present DAWN (Dynamic frame
Avatar With Non-autoregressive diffusion), a framework that enables all-at-once
generation of dynamic-length video sequences. Specifically, it consists of two
main components: (1) audio-driven holistic facial dynamics generation in the
latent motion space, and (2) audio-driven head pose and blink generation.
Extensive experiments demonstrate that our method generates authentic and vivid
videos with precise lip motions, and natural pose/blink movements.
Additionally, with a high generation speed, DAWN possesses strong extrapolation
capabilities, ensuring the stable production of high-quality long videos. These
results highlight the considerable promise and potential impact of DAWN in the
field of talking head video generation. Furthermore, we hope that DAWN sparks
further exploration of non-autoregressive approaches in diffusion models. Our
code will be publicly available at https://github.com/Hanbo-Cheng/DAWN-pytorch.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Diffusion Curriculum: Synthetic-to-Real Generative Curriculum Learning
  via Image-Guided Diffusion 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.13674v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.13674v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yijun Liang, Shweta Bhardwaj, Tianyi Zhou
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Low-quality or scarce data has posed significant challenges for training deep
neural networks in practice. While classical data augmentation cannot
contribute very different new data, diffusion models opens up a new door to
build self-evolving AI by generating high-quality and diverse synthetic data
through text-guided prompts. However, text-only guidance cannot control
synthetic images' proximity to the original images, resulting in
out-of-distribution data detrimental to the model performance. To overcome the
limitation, we study image guidance to achieve a spectrum of interpolations
between synthetic and real images. With stronger image guidance, the generated
images are similar to the training data but hard to learn. While with weaker
image guidance, the synthetic images will be easier for model but contribute to
a larger distribution gap with the original data. The generated full spectrum
of data enables us to build a novel "Diffusion Curriculum (DisCL)". DisCL
adjusts the image guidance level of image synthesis for each training stage: It
identifies and focuses on hard samples for the model and assesses the most
effective guidance level of synthetic images to improve hard data learning. We
apply DisCL to two challenging tasks: long-tail (LT) classification and
learning from low-quality data. It focuses on lower-guidance images of
high-quality to learn prototypical features as a warm-up of learning
higher-guidance images that might be weak on diversity or quality. Extensive
experiments showcase a gain of 2.7% and 2.1% in OOD and ID macro-accuracy when
applying DisCL to iWildCam dataset. On ImageNet-LT, DisCL improves the base
model's tail-class accuracy from 4.4% to 23.64% and leads to a 4.02%
improvement in all-class accuracy.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>23 pages, including references and appendix. Code is available at
  http://github.com/tianyi-lab/DisCL</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ ExACT: Teaching AI Agents to Explore with Reflective-MCTS and
  Exploratory Learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.02052v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.02052v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xiao Yu, Baolin Peng, Vineeth Vajipey, Hao Cheng, Michel Galley, Jianfeng Gao, Zhou Yu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Autonomous agents have demonstrated significant potential in automating
complex multistep decision-making tasks. However, even state-of-the-art
vision-language models (VLMs), such as GPT-4o, still fall short of human-level
performance, particularly in intricate web environments and long-horizon tasks.
To address these limitations, we present ExACT, an approach to combine
test-time search and self-learning to build o1-like models for agentic
applications. We first introduce Reflective Monte Carlo Tree Search (R-MCTS), a
novel test time algorithm designed to enhance AI agents' ability to explore
decision space on the fly. R-MCTS extends traditional MCTS by 1) incorporating
contrastive reflection, allowing agents to learn from past interactions and
dynamically improve their search efficiency; and 2) using multi-agent debate
for reliable state evaluation. Next, we introduce Exploratory Learning, a novel
learning strategy to teach agents to search at inference time without relying
on any external search algorithms. On the challenging VisualWebArena benchmark,
our GPT-4o based R-MCTS agent achieves a 6% to 30% relative improvement across
various tasks compared to the previous state-of-the-art. Additionally, we show
that the knowledge and experience gained from test-time search can be
effectively transferred back to GPT-4o via fine-tuning. After Exploratory
Learning, GPT-4o 1) demonstrates the ability to explore the environment,
evaluate a state, and backtrack to viable ones when it detects that the current
state cannot lead to success, and 2) matches 87% of R-MCTS's performance while
using significantly less compute. Notably, our work demonstrates the compute
scaling properties in both training - data collection with R-MCTS - and testing
time. These results suggest a promising research direction to enhance VLMs'
capabilities for agentic applications via test-time search and self-learning.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Double-Condensing Attention Condenser: Leveraging Attention in Deep
  Learning to Detect Skin Cancer from Skin Lesion Images 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2311.11656v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2311.11656v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Chi-en Amy Tai, Elizabeth Janes, Chris Czarnecki, Alexander Wong
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Skin cancer is the most common type of cancer in the United States and is
estimated to affect one in five Americans. Recent advances have demonstrated
strong performance on skin cancer detection, as exemplified by state of the art
performance in the SIIM-ISIC Melanoma Classification Challenge; however these
solutions leverage ensembles of complex deep neural architectures requiring
immense storage and compute costs, and therefore may not be tractable. A recent
movement for TinyML applications is integrating Double-Condensing Attention
Condensers (DC-AC) into a self-attention neural network backbone architecture
to allow for faster and more efficient computation. This paper explores
leveraging an efficient self-attention structure to detect skin cancer in skin
lesion images and introduces a deep neural network design with DC-AC customized
for skin cancer detection from skin lesion images. The final model is publicly
available as a part of a global open-source initiative dedicated to
accelerating advancement in machine learning to aid clinicians in the fight
against cancer. Future work of this research includes iterating on the design
of the selected network architecture and refining the approach to generalize to
other forms of cancer.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Residual-INR: Communication Efficient On-Device Learning Using Implicit
  Neural Representation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2408.05617v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2408.05617v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hanqiu Chen, Xuebin Yao, Pradeep Subedi, Cong Hao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Edge computing is a distributed computing paradigm that collects and
processes data at or near the source of data generation. The on-device learning
at edge relies on device-to-device wireless communication to facilitate
real-time data sharing and collaborative decision-making among multiple
devices. This significantly improves the adaptability of the edge computing
system to the changing environments. However, as the scale of the edge
computing system is getting larger, communication among devices is becoming the
bottleneck because of the limited bandwidth of wireless communication leads to
large data transfer latency. To reduce the amount of device-to-device data
transmission and accelerate on-device learning, in this paper, we propose
Residual-INR, a fog computing-based communication-efficient on-device learning
framework by utilizing implicit neural representation (INR) to compress
images/videos into neural network weights. Residual-INR enhances data transfer
efficiency by collecting JPEG images from edge devices, compressing them into
INR format at the fog node, and redistributing them for on-device learning. By
using a smaller INR for full image encoding and a separate object INR for
high-quality object region reconstruction through residual encoding, our
technique can reduce the encoding redundancy while maintaining the object
quality. Residual-INR is a promising solution for edge on-device learning
because it reduces data transmission by up to 5.16 x across a network of 10
edge devices. It also facilitates CPU-free accelerated on-device learning,
achieving up to 2.9 x speedup without sacrificing accuracy. Our code is
available at: https://github.com/sharclab/Residual-INR.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>This paper has been accepted by ICCAD 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Embedded <span class="highlight-title">Prompt</span> Tuning: Towards Enhanced Calibration of <span class="highlight-title">Pretrain</span>ed
  Models for Medical Images 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.01003v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.01003v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Wenqiang Zu, Shenghao Xie, Qing Zhao, Guoqi Li, Lei Ma
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Foundation models pre-trained on large-scale data have been widely witnessed
to achieve success in various natural imaging downstream tasks.
Parameter-efficient fine-tuning (PEFT) methods aim to adapt foundation models
to new domains by updating only a small portion of parameters in order to
reduce computational overhead. However, the effectiveness of these PEFT
methods, especially in cross-domain few-shot scenarios, e.g., medical image
analysis, has not been fully explored. In this work, we facilitate the study of
the performance of PEFT when adapting foundation models to medical image
classification tasks. Furthermore, to alleviate the limitations of prompt
introducing ways and approximation capabilities on Transformer architectures of
mainstream prompt tuning methods, we propose the Embedded Prompt Tuning (EPT)
method by embedding prompt tokens into the expanded channels. We also find that
there are anomalies in the feature space distribution of foundation models
during pre-training process, and prompt tuning can help mitigate this negative
impact. To explain this phenomenon, we also introduce a novel perspective to
understand prompt tuning: Prompt tuning is a distribution calibrator. And we
support it by analyzing patch-wise scaling and feature separation operations
contained in EPT. Our experiments show that EPT outperforms several
state-of-the-art fine-tuning methods by a significant margin on few-shot
medical image classification tasks, and completes the fine-tuning process
within highly competitive time, indicating EPT is an effective PEFT method. The
source code is available at github.com/zuwenqiang/EPT.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>16 pages, 7 figures. arXiv admin note: text overlap with
  arXiv:2306.09579, arXiv:2203.12119 by other authors</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Polyhedral Complex Derivation from Piecewise Trilinear Networks <span class="chip">NeurIPS 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2402.10403v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2402.10403v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jin-Hwa Kim
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent advancements in visualizing deep neural networks provide insights into
their structures and mesh extraction from Continuous Piecewise Affine (CPWA)
functions. Meanwhile, developments in neural surface representation learning
incorporate non-linear positional encoding, addressing issues like spectral
bias; however, this poses challenges in applying mesh extraction techniques
based on CPWA functions. Focusing on trilinear interpolating methods as
positional encoding, we present theoretical insights and an analytical mesh
extraction, showing the transformation of hypersurfaces to flat planes within
the trilinear region under the eikonal constraint. Moreover, we introduce a
method for approximating intersecting points among three hypersurfaces
contributing to broader applications. We empirically validate correctness and
parsimony through chamfer distance and efficiency, and angular distance, while
examining the correlation between the eikonal loss and the planarity of the
hypersurfaces.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted at NeurIPS 2024. Updated with the camera-ready version</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ MOS: Model Synergy for Test-Time Adaptation on LiDAR-Based 3D Object
  Detection 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.14878v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.14878v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zhuoxiao Chen, Junjie Meng, Mahsa Baktashmotlagh, Yonggang Zhang, Zi Huang, Yadan Luo
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  LiDAR-based 3D object detection is crucial for various applications but often
experiences performance degradation in real-world deployments due to domain
shifts. While most studies focus on cross-dataset shifts, such as changes in
environments and object geometries, practical corruptions from sensor
variations and weather conditions remain underexplored. In this work, we
propose a novel online test-time adaptation framework for 3D detectors that
effectively tackles these shifts, including a challenging cross-corruption
scenario where cross-dataset shifts and corruptions co-occur. By leveraging
long-term knowledge from previous test batches, our approach mitigates
catastrophic forgetting and adapts effectively to diverse shifts. Specifically,
we propose a Model Synergy (MOS) strategy that dynamically selects historical
checkpoints with diverse knowledge and assembles them to best accommodate the
current test batch. This assembly is directed by our proposed Synergy Weights
(SW), which perform a weighted averaging of the selected checkpoints,
minimizing redundancy in the composite model. The SWs are computed by
evaluating the similarity of predicted bounding boxes on the test data and the
independence of features between checkpoint pairs in the model bank. To
maintain an efficient and informative model bank, we discard checkpoints with
the lowest average SW scores, replacing them with newly updated models. Our
method was rigorously tested against existing test-time adaptation strategies
across three datasets and eight types of corruptions, demonstrating superior
adaptability to dynamic scenes and conditions. Notably, it achieved a 67.3%
improvement in a challenging cross-corruption scenario, offering a more
comprehensive benchmark for adaptation. The source code will be made publicly
available.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Action Selection Learning for Multi-label Multi-view Action Recognition 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.03302v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.03302v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Trung Thanh Nguyen, Yasutomo Kawanishi, Takahiro Komamizu, Ichiro Ide
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Multi-label multi-view action recognition aims to recognize multiple
concurrent or sequential actions from untrimmed videos captured by multiple
cameras. Existing work has focused on multi-view action recognition in a narrow
area with strong labels available, where the onset and offset of each action
are labeled at the frame-level. This study focuses on real-world scenarios
where cameras are distributed to capture a wide-range area with only weak
labels available at the video-level. We propose the method named Multi-view
Action Selection Learning (MultiASL), which leverages action selection learning
to enhance view fusion by selecting the most useful information from different
viewpoints. The proposed method includes a Multi-view Spatial-Temporal
Transformer video encoder to extract spatial and temporal features from
multi-viewpoint videos. Action Selection Learning is employed at the
frame-level, using pseudo ground-truth obtained from weak labels at the
video-level, to identify the most relevant frames for action recognition.
Experiments in a real-world office environment using the MM-Office dataset
demonstrate the superior performance of the proposed method compared to
existing methods. The source code is available at
https://github.com/thanhhff/MultiASL/.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>ACM Multimedia Asia 2024</span>
                                        </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
            <article>
                <details>
                    <Summary>
                        Information Retrieval <span class="chip" style="font-size: 60%">18</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ SIMformer: Single-Layer Vanilla <span class="highlight-title">Transformer</span> Can Learn Free-Space
  Trajectory Similarity 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14629v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14629v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Chuang Yang, Renhe Jiang, Xiaohang Xu, Chuan Xiao, Kaoru Sezaki
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Free-space trajectory similarity calculation, e.g., DTW, Hausdorff, and
Frechet, often incur quadratic time complexity, thus learning-based methods
have been proposed to accelerate the computation. The core idea is to train an
encoder to transform trajectories into representation vectors and then compute
vector similarity to approximate the ground truth. However, existing methods
face dual challenges of effectiveness and efficiency: 1) they all utilize
Euclidean distance to compute representation similarity, which leads to the
severe curse of dimensionality issue -- reducing the distinguishability among
representations and significantly affecting the accuracy of subsequent
similarity search tasks; 2) most of them are trained in triplets manner and
often necessitate additional information which downgrades the efficiency; 3)
previous studies, while emphasizing the scalability in terms of efficiency,
overlooked the deterioration of effectiveness when the dataset size grows. To
cope with these issues, we propose a simple, yet accurate, fast, scalable model
that only uses a single-layer vanilla transformer encoder as the feature
extractor and employs tailored representation similarity functions to
approximate various ground truth similarity measures. Extensive experiments
demonstrate our model significantly mitigates the curse of dimensionality issue
and outperforms the state-of-the-arts in effectiveness, efficiency, and
scalability.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Enhancing AI Accessibility in Veterinary Medicine: Linking Classifiers
  and Electronic Health Records 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14625v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14625v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Chun Yin Kong, Picasso Vasquez, Makan Farhoodimoghadam, Chris Brandt, Titus C. Brown, Krystle L. Reagan, Allison Zwingenberger, Stefan M. Keller
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In the rapidly evolving landscape of veterinary healthcare, integrating
machine learning (ML) clinical decision-making tools with electronic health
records (EHRs) promises to improve diagnostic accuracy and patient care.
However, the seamless integration of ML classifiers into existing EHRs in
veterinary medicine is frequently hindered by the rigidity of EHR systems or
the limited availability of IT resources. To address this shortcoming, we
present Anna, a freely-available software solution that provides ML classifier
results for EHR laboratory data in real-time.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ DiSCo Meets LLMs: A Unified Approach for Sparse Retrieval and Contextual
  Distillation in Conversational Search 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14609v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14609v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Simon Lupart, Mohammad Aliannejadi, Evangelos Kanoulas
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Conversational Search (CS) is the task of retrieving relevant documents from
a corpus within a conversational context, combining retrieval with
conversational context modeling. With the explosion of Large Language Models
(LLMs), the CS field has seen major improvements with LLMs rewriting user
queries, accounting for conversational context. However, engaging LLMs at
inference time harms efficiency. Current methods address this by distilling
embeddings from human-rewritten queries to learn the context modeling task.
Yet, these approaches predominantly focus on context modeling, and only treat
the contrastive component of the retrieval task within a
distillation-independent loss term. To address these limitations, we propose a
new distillation method, as a relaxation of the previous objective, unifying
retrieval and context modeling. We relax the existing training objectives by
distilling similarity scores between conversations and documents, rather than
relying solely on representation learning. Our proposed distillation objective
allows for more freedom in the representation space and leverages the
contrastive nature of document relevance. Through experiments on Learned Sparse
Retrieval (LSR) across 5 CS datasets, our approach demonstrates substantial
improvements in both in-domain and out-of-domain retrieval performance,
outperforming state-of-the-art with gains of up to 6 points in recall for
out-of-domain datasets. Additionally, through the relaxation of the objective,
we propose a multi-teacher distillation, using multiple LLMs as teachers,
yielding additional gains, and outperforming the teachers themselves in
in-domain experiments. Finally, analysis of the sparsity of the models reveals
that our distillation allows for better control over the sparsity of the
trained models.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ RAG-ConfusionQA: A Benchmark for Evaluating LLMs on Confusing Questions 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14567v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14567v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zhiyuan Peng, Jinming Nian, Alexandre Evfimievski, Yi Fang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Conversational AI agents use Retrieval Augmented Generation (RAG) to provide
verifiable document-grounded responses to user inquiries. However, many natural
questions do not have good answers: about 25\% contain false
assumptions~\cite{Yu2023:CREPE}, and over 50\% are
ambiguous~\cite{Min2020:AmbigQA}. RAG agents need high-quality data to improve
their responses to confusing questions. This paper presents a novel synthetic
data generation method to efficiently create a diverse set of context-grounded
confusing questions from a given document corpus. We conduct an empirical
comparative evaluation of several large language models as RAG agents to
measure the accuracy of confusion detection and appropriate response
generation. We contribute a benchmark dataset to the public domain.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>under review</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ SPFresh: Incremental In-Place Update for Billion-Scale Vector Search <span class="chip">SOSP 23</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14452v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14452v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yuming Xu, Hengyu Liang, Jin Li, Shuotao Xu, Qi Chen, Qianxi Zhang, Cheng Li, Ziyue Yang, Fan Yang, Yuqing Yang, Peng Cheng, Mao Yang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Approximate Nearest Neighbor Search (ANNS) is now widely used in various
applications, ranging from information retrieval, question answering, and
recommendation, to search for similar high-dimensional vectors. As the amount
of vector data grows continuously, it becomes important to support updates to
vector index, the enabling technique that allows for efficient and accurate
ANNS on vectors. Because of the curse of high dimensionality, it is often
costly to identify the right neighbors of a single new vector, a necessary
process for index update. To amortize update costs, existing systems maintain a
secondary index to accumulate updates, which are merged by the main index by
global rebuilding the entire index periodically. However, this approach has
high fluctuations of search latency and accuracy, not even to mention that it
requires substantial resources and is extremely time-consuming for rebuilds. We
introduce SPFresh, a system that supports in-place vector updates. At the heart
of SPFresh is LIRE, a lightweight incremental rebalancing protocol to split
vector partitions and reassign vectors in the nearby partitions to adapt to
data distribution shift. LIRE achieves low-overhead vector updates by only
reassigning vectors at the boundary between partitions, where in a high-quality
vector index the amount of such vectors are deemed small. With LIRE, SPFresh
provides superior query latency and accuracy to solutions based on global
rebuild, with only 1% of DRAM and less than 10% cores needed at the peak
compared to the state-of-the-art, in a billion scale vector index with 1% of
daily vector update rate.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>SOSP 23</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ ChartifyText: Automated Chart Generation from Data-Involved Texts via
  LLM 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14331v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14331v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Songheng Zhang, Lei Wang, Toby Jia-Jun Li, Qiaomu Shen, Yixin Cao, Yong Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Text documents with numerical values involved are widely used in various
applications such as scientific research, economy, public health and
journalism. However, it is difficult for readers to quickly interpret such
data-involved texts and gain deep insights. To fill this research gap, this
work aims to automatically generate charts to accurately convey the underlying
data and ideas to readers, which is essentially a challenging task. The
challenges originate from text ambiguities, intrinsic sparsity and uncertainty
of data in text documents, and subjective sentiment differences. Specifically,
we propose ChartifyText, a novel fully-automated approach that leverages Large
Language Models (LLMs) to convert complex data-involved texts to expressive
charts. It consists of two major modules: tabular data inference and expressive
chart generation. The tabular data inference module employs systematic prompt
engineering to guide the LLM (e.g., GPT-4) to infer table data, where data
ranges, uncertainties, missing data values and corresponding subjective
sentiments are explicitly considered. The expressive chart generation module
augments standard charts with intuitive visual encodings and concise texts to
accurately convey the underlying data and insights. We extensively evaluate the
effectiveness of ChartifyText on real-world data-involved text documents
through case studies, in-depth interviews with three visualization experts, and
a carefully-designed user study with 15 participants. The results demonstrate
the usefulness and effectiveness of ChartifyText in helping readers efficiently
and effectively make sense of data-involved texts.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Graph Neural Patching for Cold-Start Recommendations 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14241v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14241v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hao Chen, Yu Yang, Yuanchen Bei, Zefan Wang, Yue Xu, Feiran Huang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The cold start problem in recommender systems remains a critical challenge.
Current solutions often train hybrid models on auxiliary data for both cold and
warm users/items, potentially degrading the experience for the latter. This
drawback limits their viability in practical scenarios where the satisfaction
of existing warm users/items is paramount. Although graph neural networks
(GNNs) excel at warm recommendations by effective collaborative signal
modeling, they haven't been effectively leveraged for the cold-start issue
within a user-item graph, which is largely due to the lack of initial
connections for cold user/item entities. Addressing this requires a GNN adept
at cold-start recommendations without sacrificing performance for existing
ones. To this end, we introduce Graph Neural Patching for Cold-Start
Recommendations (GNP), a customized GNN framework with dual functionalities:
GWarmer for modeling collaborative signal on existing warm users/items and
Patching Networks for simulating and enhancing GWarmer's performance on
cold-start recommendations. Extensive experiments on three benchmark datasets
confirm GNP's superiority in recommending both warm and cold users/items.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>13 pages, accepted by Australasian Database Conference 2024. arXiv
  admin note: substantial text overlap with arXiv:2209.12215</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Personalized Image Generation with Large Multimodal Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14170v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14170v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yiyan Xu, Wenjie Wang, Yang Zhang, Tang Biao, Peng Yan, Fuli Feng, Xiangnan He
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Personalized content filtering, such as recommender systems, has become a
critical infrastructure to alleviate information overload. However, these
systems merely filter existing content and are constrained by its limited
diversity, making it difficult to meet users' varied content needs. To address
this limitation, personalized content generation has emerged as a promising
direction with broad applications. Nevertheless, most existing research focuses
on personalized text generation, with relatively little attention given to
personalized image generation. The limited work in personalized image
generation faces challenges in accurately capturing users' visual preferences
and needs from noisy user-interacted images and complex multimodal
instructions. Worse still, there is a lack of supervised data for training
personalized image generation models.
  To overcome the challenges, we propose a Personalized Image Generation
Framework named Pigeon, which adopts exceptional large multimodal models with
three dedicated modules to capture users' visual preferences and needs from
noisy user history and multimodal instructions. To alleviate the data scarcity,
we introduce a two-stage preference alignment scheme, comprising masked
preference reconstruction and pairwise preference alignment, to align Pigeon
with the personalized image generation task. We apply Pigeon to personalized
sticker and movie poster generation, where extensive quantitative results and
human evaluation highlight its superiority over various generative baselines.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Optimizing Retrieval-Augmented Generation with Elasticsearch for
  Enhanced Question-Answering Systems 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14167v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14167v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jiajing Chen, Runyuan Bao, Hongye Zheng, Zhen Qi, Jianjun Wei, Jiacheng Hu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This study aims to improve the accuracy and quality of large-scale language
models (LLMs) in answering questions by integrating Elasticsearch into the
Retrieval Augmented Generation (RAG) framework. The experiment uses the
Stanford Question Answering Dataset (SQuAD) version 2.0 as the test dataset and
compares the performance of different retrieval methods, including traditional
methods based on keyword matching or semantic similarity calculation, BM25-RAG
and TF-IDF- RAG, and the newly proposed ES-RAG scheme. The results show that
ES-RAG not only has obvious advantages in retrieval efficiency but also
performs well in key indicators such as accuracy, which is 0.51 percentage
points higher than TF-IDF-RAG. In addition, Elasticsearch's powerful search
capabilities and rich configuration options enable the entire
question-answering system to better handle complex queries and provide more
flexible and efficient responses based on the diverse needs of users. Future
research directions can further explore how to optimize the interaction
mechanism between Elasticsearch and LLM, such as introducing higher-level
semantic understanding and context-awareness capabilities, to achieve a more
intelligent and humanized question-answering experience.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Towards Robust Transcription: Exploring Noise Injection Strategies for
  Training Data Augmentation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14122v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14122v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yonghyun Kim, Alexander Lerch
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent advancements in Automatic Piano Transcription (APT) have significantly
improved system performance, but the impact of noisy environments on the system
performance remains largely unexplored. This study investigates the impact of
white noise at various Signal-to-Noise Ratio (SNR) levels on state-of-the-art
APT models and evaluates the performance of the Onsets and Frames model when
trained on noise-augmented data. We hope this research provides valuable
insights as preliminary work toward developing transcription models that
maintain consistent performance across a range of acoustic conditions.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to the Late-Breaking Demo Session of the 25th International
  Society for Music Information Retrieval (ISMIR) Conference, 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ EasyRec: Simple yet Effective Language Models for Recommendation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2408.08821v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2408.08821v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xubin Ren, Chao Huang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Deep neural networks have become a powerful technique for learning
representations from user-item interaction data in collaborative filtering (CF)
for recommender systems. However, many existing methods heavily rely on unique
user and item IDs, which limits their ability to perform well in practical
zero-shot learning scenarios where sufficient training data may be unavailable.
Inspired by the success of language models (LMs) and their strong
generalization capabilities, a crucial question arises: How can we harness the
potential of language models to empower recommender systems and elevate its
generalization capabilities to new heights? In this study, we propose EasyRec -
an effective and easy-to-use approach that seamlessly integrates text-based
semantic understanding with collaborative signals. EasyRec employs a
text-behavior alignment framework, which combines contrastive learning with
collaborative language model tuning, to ensure a strong alignment between the
text-enhanced semantic space and the collaborative behavior information.
Extensive empirical evaluations across diverse real-world datasets demonstrate
the superior performance of EasyRec compared to state-of-the-art alternative
models, particularly in the challenging text-based zero-shot recommendation
scenarios. Furthermore, the study highlights the potential of seamlessly
integrating EasyRec as a plug-and-play component into text-enhanced
collaborative filtering frameworks, thereby empowering existing recommender
systems to elevate their recommendation performance and adapt to the evolving
user preferences in dynamic environments. For better result reproducibility of
our EasyRec framework, the model implementation details, source code, and
datasets are available at the link: https://github.com/HKUDS/EasyRec.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Improving Retrieval in Sponsored Search by Leveraging Query Context
  Signals <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.14346v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.14346v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Akash Kumar Mohankumar, Gururaj K, Gagan Madan, Amit Singh
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Accurately retrieving relevant bid keywords for user queries is critical in
Sponsored Search but remains challenging, particularly for short, ambiguous
queries. Existing dense and generative retrieval models often fail to capture
nuanced user intent in these cases. To address this, we propose an approach to
enhance query understanding by augmenting queries with rich contextual signals
derived from web search results and large language models, stored in an online
cache. Specifically, we use web search titles and snippets to ground queries in
real-world information and utilize GPT-4 to generate query rewrites and
explanations that clarify user intent. These signals are efficiently integrated
through a Fusion-in-Decoder based Unity architecture, enabling both dense and
generative retrieval with serving costs on par with traditional context-free
models. To address scenarios where context is unavailable in the cache, we
introduce context glancing, a curriculum learning strategy that improves model
robustness and performance even without contextual signals during inference.
Extensive offline experiments demonstrate that our context-aware approach
substantially outperforms context-free models. Furthermore, online A/B testing
on a prominent search engine across 160+ countries shows significant
improvements in user engagement and revenue.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to EMNLP 2024 Industry Track. 10 pages, 10 tables, 1 figure</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Revisiting BPR: A Replicability Study of a Common Recommender System
  Baseline <span class="chip">RecSys
  '24</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.14217v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.14217v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Aleksandr Milogradskii, Oleg Lashinin, Alexander P, Marina Ananyeva, Sergey Kolesnikov
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Bayesian Personalized Ranking (BPR), a collaborative filtering approach based
on matrix factorization, frequently serves as a benchmark for recommender
systems research. However, numerous studies often overlook the nuances of BPR
implementation, claiming that it performs worse than newly proposed methods
across various tasks. In this paper, we thoroughly examine the features of the
BPR model, indicating their impact on its performance, and investigate
open-source BPR implementations. Our analysis reveals inconsistencies between
these implementations and the original BPR paper, leading to a significant
decrease in performance of up to 50% for specific implementations. Furthermore,
through extensive experiments on real-world datasets under modern evaluation
settings, we demonstrate that with proper tuning of its hyperparameters, the
BPR model can achieve performance levels close to state-of-the-art methods on
the top-n recommendation tasks and even outperform them on specific datasets.
Specifically, on the Million Song Dataset, the BPR model with hyperparameters
tuning statistically significantly outperforms Mult-VAE by 10% in NDCG@100 with
binary relevance function.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>This paper is accepted at the Reproducibility track of the ACM RecSys
  '24 conference</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Generate and Instantiate What You Prefer: Text-Guided Diffusion for
  Sequential Recommendation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.13428v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.13428v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Guoqing Hu, Zhangyi Yang, Zhibo Cai, An Zhang, Xiang Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent advancements in generative recommendation systems, particularly in the
realm of sequential recommendation tasks, have shown promise in enhancing
generalization to new items. Among these approaches, diffusion-based generative
recommendation has emerged as an effective tool, leveraging its ability to
capture data distributions and generate high-quality samples. Despite
effectiveness, two primary challenges have been identified: 1) the lack of
consistent modeling of data distribution for oracle items; and 2) the
difficulty in scaling to more informative control signals beyond historical
interactions. These issues stem from the uninformative nature of ID embeddings,
which necessitate random initialization and limit the incorporation of
additional control signals. To address these limitations, we propose iDreamRec
to involve more concrete prior knowledge to establish item embeddings,
particularly through detailed item text descriptions and advanced Text
Embedding Models (TEM). More importantly, by converting item descriptions into
embeddings aligned with TEM, we enable the integration of intention
instructions as control signals to guide the generation of oracle items.
Experimental results on four datasets demonstrate that iDreamRec not only
outperforms existing diffusion-based generative recommenders but also
facilitates the incorporation of intention instructions for more precise and
effective recommendation generation.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Conversational Recommender System and Large Language Model Are Made for
  Each Other in E-commerce Pre-sales Dialogue <span class="chip">EMNLP 2023</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2310.14626v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2310.14626v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yuanxing Liu, Wei-Nan Zhang, Yifan Chen, Yuchi Zhang, Haopeng Bai, Fan Feng, Hengbin Cui, Yongbin Li, Wanxiang Che
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  E-commerce pre-sales dialogue aims to understand and elicit user needs and
preferences for the items they are seeking so as to provide appropriate
recommendations. Conversational recommender systems (CRSs) learn user
representation and provide accurate recommendations based on dialogue context,
but rely on external knowledge. Large language models (LLMs) generate responses
that mimic pre-sales dialogues after fine-tuning, but lack domain-specific
knowledge for accurate recommendations. Intuitively, the strengths of LLM and
CRS in E-commerce pre-sales dialogues are complementary, yet no previous work
has explored this. This paper investigates the effectiveness of combining LLM
and CRS in E-commerce pre-sales dialogues, proposing two collaboration methods:
CRS assisting LLM and LLM assisting CRS. We conduct extensive experiments on a
real-world dataset of Ecommerce pre-sales dialogues. We analyze the impact of
two collaborative approaches with two CRSs and two LLMs on four tasks of
Ecommerce pre-sales dialogue. We find that collaborations between CRS and LLM
can be very effective in some cases.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>EMNLP 2023 Findings</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Starbucks: Improved Training for 2D Matryoshka Embeddings 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.13230v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.13230v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Shengyao Zhuang, Shuai Wang, Bevan Koopman, Guido Zuccon
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Effective approaches that can scale embedding model depth (i.e. layers) and
embedding size allow for the creation of models that are highly scalable across
different computational resources and task requirements. While the recently
proposed 2D Matryoshka training approach can efficiently produce a single
embedding model such that its sub-layers and sub-dimensions can measure text
similarity, its effectiveness is significantly worse than if smaller models
were trained separately. To address this issue, we propose Starbucks, a new
training strategy for Matryoshka-like embedding models, which encompasses both
the fine-tuning and pre-training phases. For the fine-tuning phase, we discover
that, rather than sampling a random sub-layer and sub-dimensions for each
training steps, providing a fixed list of layer-dimension pairs, from small
size to large sizes, and computing the loss across all pairs significantly
improves the effectiveness of 2D Matryoshka embedding models, bringing them on
par with their separately trained counterparts. To further enhance performance,
we introduce a new pre-training strategy, which applies masked autoencoder
language modelling to sub-layers and sub-dimensions during pre-training,
resulting in a stronger backbone for subsequent fine-tuning of the embedding
model. Experimental results on both semantic text similarity and retrieval
benchmarks demonstrate that the proposed pre-training and fine-tuning
strategies significantly improved the effectiveness over 2D Matryoshka models,
enabling Starbucks models to perform more efficiently and effectively than
separately trained models.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Graph Neural Network Enhanced Retrieval for Question Answering of LLMs 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.06572v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.06572v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zijian Li, Qingyan Guo, Jiawei Shao, Lei Song, Jiang Bian, Jun Zhang, Rui Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Retrieval augmented generation has revolutionized large language model (LLM)
outputs by providing factual supports. Nevertheless, it struggles to capture
all the necessary knowledge for complex reasoning questions. Existing retrieval
methods typically divide reference documents into passages, treating them in
isolation. These passages, however, are often interrelated, such as passages
that are contiguous or share the same keywords. Therefore, it is crucial to
recognize such relatedness for enhancing the retrieval process. In this paper,
we propose a novel retrieval method, called GNN-Ret, which leverages graph
neural networks (GNNs) to enhance retrieval by exploiting the relatedness
between passages. Specifically, we first construct a graph of passages by
connecting passages that are structure-related or keyword-related. A graph
neural network (GNN) is then leveraged to exploit the relationships between
passages and improve the retrieval of supporting passages. Furthermore, we
extend our method to handle multi-hop reasoning questions using a recurrent
graph neural network (RGNN), named RGNN-Ret. At each step, RGNN-Ret integrates
the graphs of passages from previous steps, thereby enhancing the retrieval of
supporting passages. Extensive experiments on benchmark datasets demonstrate
that GNN-Ret achieves higher accuracy for question answering with a single
query of LLMs than strong baselines that require multiple queries, and RGNN-Ret
further improves accuracy and achieves state-of-the-art performance, with up to
10.4% accuracy improvement on the 2WikiMQA dataset.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Under review</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ FINED: Feed Instance-Wise Information Need with Essential and
  Disentangled Parametric Knowledge from the Past 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.00012v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.00012v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Kounianhua Du, Jizheng Chen, Jianghao Lin, Menghui Zhu, Bo Chen, Shuai Li, Yong Yu, Weinan Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recommender models play a vital role in various industrial scenarios, while
often faced with the catastrophic forgetting problem caused by the fast
shifting data distribution. To alleviate this problem, a common approach is to
reuse knowledge from the historical data. However, preserving the vast and
fast-accumulating data is hard, which causes dramatic storage overhead.
Memorizing old data through a parametric knowledge base is then proposed, which
compresses the vast amount of raw data into model parameters. Despite the
flexibility, how to improve the memorization and generalization capabilities of
the parametric knowledge base and suit the flexible information need of each
instance are challenging. In this paper, we propose FINED to Feed INstance-wise
information need with Essential and Disentangled parametric knowledge from past
data for recommendation enhancement. Concretely, we train a knowledge extractor
that extracts knowledge patterns of arbitrary order from past data and a
knowledge encoder that memorizes the arbitrary order patterns, which serves as
the retrieval key generator and memory network respectively in the following
knowledge reusing phase. The whole process is regularized by the proposed two
constraints, which improve the capabilities of the parametric knowledge base
without increasing the size of it. The essential principle helps to compress
the input into representative vectors that capture the task-relevant
information and filter out the noisy information. The disentanglement principle
reduces the redundancy of stored information and pushes the knowledge base to
focus on capturing the disentangled invariant patterns. These two rules
together promote rational compression of information for robust and generalized
knowledge representations. Extensive experiments on two datasets justify the
effectiveness of the proposed method.
</span>
                                    </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
            <article>
                <details>
                    <Summary>
                        Machine Learning <span class="chip" style="font-size: 60%">150</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ <span class="highlight-title">Self-supervised</span> contrastive learning performs non-linear system
  identification 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14673v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14673v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Rodrigo González Laiz, Tobias Schmidt, Steffen Schneider
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Self-supervised learning (SSL) approaches have brought tremendous success
across many tasks and domains. It has been argued that these successes can be
attributed to a link between SSL and identifiable representation learning:
Temporal structure and auxiliary variables ensure that latent representations
are related to the true underlying generative factors of the data. Here, we
deepen this connection and show that SSL can perform system identification in
latent space. We propose DynCL, a framework to uncover linear, switching linear
and non-linear dynamics under a non-linear observation model, give theoretical
guarantees and validate them empirically.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Decomposing The Dark Matter of Sparse Autoencoders 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14670v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14670v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Joshua Engels, Logan Riggs, Max Tegmark
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Sparse autoencoders (SAEs) are a promising technique for decomposing language
model activations into interpretable linear features. However, current SAEs
fall short of completely explaining model performance, resulting in "dark
matter": unexplained variance in activations. This work investigates dark
matter as an object of study in its own right. Surprisingly, we find that much
of SAE dark matter--about half of the error vector itself and >90% of its
norm--can be linearly predicted from the initial activation vector.
Additionally, we find that the scaling behavior of SAE error norms at a per
token level is remarkably predictable: larger SAEs mostly struggle to
reconstruct the same contexts as smaller SAEs. We build on the linear
representation hypothesis to propose models of activations that might lead to
these observations, including postulating a new type of "introduced error";
these insights imply that the part of the SAE error vector that cannot be
linearly predicted ("nonlinear" error) might be fundamentally different from
the linearly predictable component. To validate this hypothesis, we empirically
analyze nonlinear SAE error and show that 1) it contains fewer not yet learned
features, 2) SAEs trained on it are quantitatively worse, 3) it helps predict
SAE per-token scaling behavior, and 4) it is responsible for a proportional
amount of the downstream increase in cross entropy loss when SAE activations
are inserted into the model. Finally, we examine two methods to reduce
nonlinear SAE error at a fixed sparsity: inference time gradient pursuit, which
leads to a very slight decrease in nonlinear error, and linear transformations
from earlier layer SAE outputs, which leads to a larger reduction.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Code at https://github.com/JoshEngels/SAE-Dark-Matter</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Stochastic Gradient Descent Jittering for Inverse Problems: Alleviating
  the Accuracy-Robustness Tradeoff 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14667v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14667v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Peimeng Guan, Mark A. Davenport
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Inverse problems aim to reconstruct unseen data from corrupted or perturbed
measurements. While most work focuses on improving reconstruction quality,
generalization accuracy and robustness are equally important, especially for
safety-critical applications. Model-based architectures (MBAs), such as loop
unrolling methods, are considered more interpretable and achieve better
reconstructions. Empirical evidence suggests that MBAs are more robust to
perturbations than black-box solvers, but the accuracy-robustness tradeoff in
MBAs remains underexplored. In this work, we propose a simple yet effective
training scheme for MBAs, called SGD jittering, which injects noise
iteration-wise during reconstruction. We theoretically demonstrate that SGD
jittering not only generalizes better than the standard mean squared error
training but is also more robust to average-case attacks. We validate SGD
jittering using denoising toy examples, seismic deconvolution, and single-coil
MRI reconstruction. The proposed method achieves cleaner reconstructions for
out-of-distribution data and demonstrates enhanced robustness to adversarial
attacks.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ DiscoGraMS: Enhancing Movie Screen-Play Summarization using Movie
  Character-Aware Discourse Graph 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14666v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14666v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Maitreya Prafulla Chitale, Uday Bindal, Rajakrishnan Rajkumar, Rahul Mishra
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Summarizing movie screenplays presents a unique set of challenges compared to
standard document summarization. Screenplays are not only lengthy, but also
feature a complex interplay of characters, dialogues, and scenes, with numerous
direct and subtle relationships and contextual nuances that are difficult for
machine learning models to accurately capture and comprehend. Recent attempts
at screenplay summarization focus on fine-tuning transformer-based pre-trained
models, but these models often fall short in capturing long-term dependencies
and latent relationships, and frequently encounter the "lost in the middle"
issue. To address these challenges, we introduce DiscoGraMS, a novel resource
that represents movie scripts as a movie character-aware discourse graph (CaD
Graph). This approach is well-suited for various downstream tasks, such as
summarization, question-answering, and salience detection. The model aims to
preserve all salient information, offering a more comprehensive and faithful
representation of the screenplay's content. We further explore a baseline
method that combines the CaD Graph with the corresponding movie script through
a late fusion of graph and text modalities, and we present very initial
promising results.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Online Reinforcement Learning with Passive Memory 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14665v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14665v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Anay Pattanaik, Lav R. Varshney
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper considers an online reinforcement learning algorithm that
leverages pre-collected data (passive memory) from the environment for online
interaction. We show that using passive memory improves performance and further
provide theoretical guarantees for regret that turns out to be near-minimax
optimal. Results show that the quality of passive memory determines
sub-optimality of the incurred regret. The proposed approach and results hold
in both continuous and discrete state-action spaces.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ A Large Language Model-Driven Reward Design Framework via Dynamic
  Feedback for Reinforcement Learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14660v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14660v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Shengjie Sun, Runze Liu, Jiafei Lyu, Jing-Wen Yang, Liangpeng Zhang, Xiu Li
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large Language Models (LLMs) have shown significant potential in designing
reward functions for Reinforcement Learning (RL) tasks. However, obtaining
high-quality reward code often involves human intervention, numerous LLM
queries, or repetitive RL training. To address these issues, we propose CARD, a
LLM-driven Reward Design framework that iteratively generates and improves
reward function code. Specifically, CARD includes a Coder that generates and
verifies the code, while a Evaluator provides dynamic feedback to guide the
Coder in improving the code, eliminating the need for human feedback. In
addition to process feedback and trajectory feedback, we introduce Trajectory
Preference Evaluation (TPE), which evaluates the current reward function based
on trajectory preferences. If the code fails the TPE, the Evaluator provides
preference feedback, avoiding RL training at every iteration and making the
reward function better aligned with the task objective. Empirical results on
Meta-World and ManiSkill2 demonstrate that our method achieves an effective
balance between task performance and token efficiency, outperforming or
matching the baselines across all tasks. On 10 out of 12 tasks, CARD shows
better or comparable performance to policies trained with expert-designed
rewards, and our method even surpasses the oracle on 3 tasks.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Harnessing Causality in Reinforcement Learning With Bagged Decision
  Times 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14659v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14659v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Daiqi Gao, Hsin-Yu Lai, Predrag Klasnja, Susan A. Murphy
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We consider reinforcement learning (RL) for a class of problems with bagged
decision times. A bag contains a finite sequence of consecutive decision times.
The transition dynamics are non-Markovian and non-stationary within a bag.
Further, all actions within a bag jointly impact a single reward, observed at
the end of the bag. Our goal is to construct an online RL algorithm to maximize
the discounted sum of the bag-specific rewards. To handle non-Markovian
transitions within a bag, we utilize an expert-provided causal directed acyclic
graph (DAG). Based on the DAG, we construct the states as a dynamical Bayesian
sufficient statistic of the observed history, which results in Markovian state
transitions within and across bags. We then frame this problem as a periodic
Markov decision process (MDP) that allows non-stationarity within a period. An
online RL algorithm based on Bellman-equations for stationary MDPs is
generalized to handle periodic MDPs. To justify the proposed RL algorithm, we
show that our constructed state achieves the maximal optimal value function
among all state constructions for a periodic MDP. Further we prove the Bellman
optimality equations for periodic MDPs. We evaluate the proposed method on
testbed variants, constructed with real data from a mobile health clinical
trial.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Bridging the Training-Inference Gap in LLMs by Leveraging Self-Generated
  Tokens 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14655v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14655v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zhepeng Cen, Yao Liu, Siliang Zeng, Pratik Chaudhar, Huzefa Rangwala, George Karypis, Rasool Fakoor
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Language models are often trained to maximize the likelihood of the next
token given past tokens in the training dataset. However, during inference
time, they are utilized differently, generating text sequentially and
auto-regressively by using previously generated tokens as input to predict the
next one. Marginal differences in predictions at each step can cascade over
successive steps, resulting in different distributions from what the models
were trained for and potentially leading to unpredictable behavior. This paper
proposes two simple approaches based on model own generation to address this
discrepancy between the training and inference time. Our first approach is
Batch-Scheduled Sampling, where, during training, we stochastically choose
between the ground-truth token from the dataset and the model's own generated
token as input to predict the next token. This is done in an offline manner,
modifying the context window by interleaving ground-truth tokens with those
generated by the model. Our second approach is Reference-Answer-based
Correction, where we explicitly incorporate a self-correction capability into
the model during training. This enables the model to effectively self-correct
the gaps between the generated sequences and the ground truth data without
relying on an external oracle model. By incorporating our proposed strategies
during training, we have observed an overall improvement in performance
compared to baseline methods, as demonstrated by our extensive experiments
using summarization, general question-answering, and math question-answering
tasks.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ EvoPress: Towards Optimal Dynamic Model Compression via Evolutionary
  Search 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14649v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14649v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Oliver Sieberling, Denis Kuznedelev, Eldar Kurtic, Dan Alistarh
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The high computational costs of large language models (LLMs) have led to a
flurry of research on LLM compression, via methods such as quantization,
sparsification, or structured pruning. A new frontier in this area is given by
\emph{dynamic, non-uniform} compression methods, which adjust the compression
levels (e.g., sparsity) per-block or even per-layer in order to minimize
accuracy loss, while guaranteeing a global compression threshold. Yet, current
methods rely on heuristics for identifying the "importance" of a given layer
towards the loss, based on assumptions such as \emph{error monotonicity}, i.e.
that the end-to-end model compression error is proportional to the sum of
layer-wise errors. In this paper, we revisit this area, and propose a new and
general approach for dynamic compression that is provably optimal in a given
input range. We begin from the motivating observation that, in general,
\emph{error monotonicity does not hold for LLMs}: compressed models with lower
sum of per-layer errors can perform \emph{worse} than models with higher error
sums. To address this, we propose a new general evolutionary framework for
dynamic LLM compression called EvoPress, which has provable convergence, and
low sample and evaluation complexity. We show that these theoretical guarantees
lead to highly competitive practical performance for dynamic compression of
Llama, Mistral and Phi models. Via EvoPress, we set new state-of-the-art
results across all compression approaches: structural pruning (block/layer
dropping), unstructured sparsity, as well as quantization with dynamic
bitwidths. Our code is available at https://github.com/IST-DASLab/EvoPress.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ HR-Bandit: Human-AI Collaborated Linear Recourse Bandit 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14640v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14640v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Junyu Cao, Ruijiang Gao, Esmaeil Keyvanshokooh
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Human doctors frequently recommend actionable recourses that allow patients
to modify their conditions to access more effective treatments. Inspired by
such healthcare scenarios, we propose the Recourse Linear UCB
($\textsf{RLinUCB}$) algorithm, which optimizes both action selection and
feature modifications by balancing exploration and exploitation. We further
extend this to the Human-AI Linear Recourse Bandit ($\textsf{HR-Bandit}$),
which integrates human expertise to enhance performance. $\textsf{HR-Bandit}$
offers three key guarantees: (i) a warm-start guarantee for improved initial
performance, (ii) a human-effort guarantee to minimize required human
interactions, and (iii) a robustness guarantee that ensures sublinear regret
even when human decisions are suboptimal. Empirical results, including a
healthcare case study, validate its superior performance against existing
benchmarks.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>18 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Convergence of Manifold Filter-Combine Networks <span class="chip">NeurIPS</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14639v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14639v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        David R. Johnson, Joyce Chew, Siddharth Viswanath, Edward De Brouwer, Deanna Needell, Smita Krishnaswamy, Michael Perlmutter
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In order to better understand manifold neural networks (MNNs), we introduce
Manifold Filter-Combine Networks (MFCNs). The filter-combine framework
parallels the popular aggregate-combine paradigm for graph neural networks
(GNNs) and naturally suggests many interesting families of MNNs which can be
interpreted as the manifold analog of various popular GNNs. We then propose a
method for implementing MFCNs on high-dimensional point clouds that relies on
approximating the manifold by a sparse graph. We prove that our method is
consistent in the sense that it converges to a continuum limit as the number of
data points tends to infinity.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to NeurIPS Workshop on Symmetry and Geometry in Neural
  Representations (Extended Abstract Track)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Parallel Backpropagation for Inverse of a Convolution with Application
  to Normalizing Flows 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14634v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14634v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Sandeep Nagar, Girish Varma
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Inverse of an invertible convolution is an important operation that comes up
in Normalizing Flows, Image Deblurring, etc. The naive algorithm for
backpropagation of this operation using Gaussian elimination has running time
$O(n^3)$ where $n$ is the number of pixels in the image. We give a fast
parallel backpropagation algorithm with running time $O(\sqrt{n})$ for a square
image and provide a GPU implementation of the same. Inverse Convolutions are
usually used in Normalizing Flows in the sampling pass, making them slow. We
propose to use Inverse Convolutions in the forward (image to latent vector)
pass of the Normalizing flow. Since the sampling pass is the inverse of the
forward pass, it will use convolutions only, resulting in efficient sampling
times. We use our parallel backpropagation algorithm for optimizing the inverse
convolution layer resulting in fast training times also. We implement this
approach in various Normalizing Flow backbones, resulting in our Inverse-Flow
models. We benchmark Inverse-Flow on standard datasets and show significantly
improved sampling times with similar bits per dimension compared to previous
models.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Preprint</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ On the Regularization of Learnable Embeddings for Time Series Processing 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14630v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14630v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Luca Butera, Giovanni De Felice, Andrea Cini, Cesare Alippi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In processing multiple time series, accounting for the individual features of
each sequence can be challenging. To address this, modern deep learning methods
for time series analysis combine a shared (global) model with local layers,
specific to each time series, often implemented as learnable embeddings.
Ideally, these local embeddings should encode meaningful representations of the
unique dynamics of each sequence. However, when these are learned end-to-end as
parameters of a forecasting model, they may end up acting as mere sequence
identifiers. Shared processing blocks may then become reliant on such
identifiers, limiting their transferability to new contexts. In this paper, we
address this issue by investigating methods to regularize the learning of local
learnable embeddings for time series processing. Specifically, we perform the
first extensive empirical study on the subject and show how such
regularizations consistently improve performance in widely adopted
architectures. Furthermore, we show that methods preventing the co-adaptation
of local and global parameters are particularly effective in this context. This
hypothesis is validated by comparing several methods preventing the downstream
models from relying on sequence identifiers, going as far as completely
resetting the embeddings during training. The obtained results provide an
important contribution to understanding the interplay between learnable local
parameters and shared processing layers: a key challenge in modern time series
processing models and a step toward developing effective foundation models for
time series.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ SIMformer: Single-Layer Vanilla <span class="highlight-title">Transformer</span> Can Learn Free-Space
  Trajectory Similarity 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14629v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14629v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Chuang Yang, Renhe Jiang, Xiaohang Xu, Chuan Xiao, Kaoru Sezaki
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Free-space trajectory similarity calculation, e.g., DTW, Hausdorff, and
Frechet, often incur quadratic time complexity, thus learning-based methods
have been proposed to accelerate the computation. The core idea is to train an
encoder to transform trajectories into representation vectors and then compute
vector similarity to approximate the ground truth. However, existing methods
face dual challenges of effectiveness and efficiency: 1) they all utilize
Euclidean distance to compute representation similarity, which leads to the
severe curse of dimensionality issue -- reducing the distinguishability among
representations and significantly affecting the accuracy of subsequent
similarity search tasks; 2) most of them are trained in triplets manner and
often necessitate additional information which downgrades the efficiency; 3)
previous studies, while emphasizing the scalability in terms of efficiency,
overlooked the deterioration of effectiveness when the dataset size grows. To
cope with these issues, we propose a simple, yet accurate, fast, scalable model
that only uses a single-layer vanilla transformer encoder as the feature
extractor and employs tailored representation similarity functions to
approximate various ground truth similarity measures. Extensive experiments
demonstrate our model significantly mitigates the curse of dimensionality issue
and outperforms the state-of-the-arts in effectiveness, efficiency, and
scalability.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Enhancing AI Accessibility in Veterinary Medicine: Linking Classifiers
  and Electronic Health Records 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14625v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14625v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Chun Yin Kong, Picasso Vasquez, Makan Farhoodimoghadam, Chris Brandt, Titus C. Brown, Krystle L. Reagan, Allison Zwingenberger, Stefan M. Keller
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In the rapidly evolving landscape of veterinary healthcare, integrating
machine learning (ML) clinical decision-making tools with electronic health
records (EHRs) promises to improve diagnostic accuracy and patient care.
However, the seamless integration of ML classifiers into existing EHRs in
veterinary medicine is frequently hindered by the rigidity of EHR systems or
the limited availability of IT resources. To address this shortcoming, we
present Anna, a freely-available software solution that provides ML classifier
results for EHR laboratory data in real-time.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ syren-new: Precise formulae for the linear and nonlinear matter power
  spectra with massive neutrinos and dynamical dark energy 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14623v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14623v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ce Sui, Deaglan J. Bartlett, Shivam Pandey, Harry Desmond, Pedro G. Ferreira, Benjamin D. Wandelt
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Current and future large scale structure surveys aim to constrain the
neutrino mass and the equation of state of dark energy. We aim to construct
accurate and interpretable symbolic approximations to the linear and nonlinear
matter power spectra as a function of cosmological parameters in extended
$\Lambda$CDM models which contain massive neutrinos and non-constant equations
of state for dark energy. This constitutes an extension of the syren-halofit
emulators to incorporate these two effects, which we call syren-new
(SYmbolic-Regression-ENhanced power spectrum emulator with NEutrinos and
$W_0-w_a$). We also obtain a simple approximation to the derived parameter
$\sigma_8$ as a function of the cosmological parameters for these models. Our
results for the linear power spectrum are designed to emulate CLASS, whereas
for the nonlinear case we aim to match the results of EuclidEmulator2. We
compare our results to existing emulators and $N$-body simulations. Our
analytic emulators for $\sigma_8$, the linear and nonlinear power spectra
achieve root mean squared errors of 0.1%, 0.3% and 1.3%, respectively, across a
wide range of cosmological parameters, redshifts and wavenumbers. We verify
that emulator-related discrepancies are subdominant compared to observational
errors and other modelling uncertainties when computing shear power spectra for
LSST-like surveys. Our expressions have similar accuracy to existing
(numerical) emulators, but are at least an order of magnitude faster, both on a
CPU and GPU. Our work greatly improves the accuracy, speed and range of
applicability of current symbolic approximations to the linear and nonlinear
matter power spectra. We provide publicly available code for all symbolic
approximations found.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>18 pages, 15 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ JAMUN: Transferable Molecular Conformational Ensemble Generation with
  Walk-Jump Sampling 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14621v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14621v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ameya Daigavane, Bodhi P. Vani, Saeed Saremi, Joseph Kleinhenz, Joshua Rackers
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Conformational ensembles of protein structures are immensely important both
to understanding protein function, and for drug discovery in novel modalities
such as cryptic pockets. Current techniques for sampling ensembles are
computationally inefficient, or do not transfer to systems outside their
training data. We present walk-Jump Accelerated Molecular ensembles with
Universal Noise (JAMUN), a step towards the goal of efficiently sampling the
Boltzmann distribution of arbitrary proteins. By extending Walk-Jump Sampling
to point clouds, JAMUN enables ensemble generation at orders of magnitude
faster rates than traditional molecular dynamics or state-of-the-art ML
methods. Further, JAMUN is able to predict the stable basins of small peptides
that were not seen during training.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Benchmarking Deep Reinforcement Learning for Navigation in Denied Sensor
  Environments 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14616v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14616v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mariusz Wisniewski, Paraskevas Chatzithanos, Weisi Guo, Antonios Tsourdos
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Deep Reinforcement learning (DRL) is used to enable autonomous navigation in
unknown environments. Most research assume perfect sensor data, but real-world
environments may contain natural and artificial sensor noise and denial. Here,
we present a benchmark of both well-used and emerging DRL algorithms in a
navigation task with configurable sensor denial effects. In particular, we are
interested in comparing how different DRL methods (e.g. model-free PPO vs.
model-based DreamerV3) are affected by sensor denial. We show that DreamerV3
outperforms other methods in the visual end-to-end navigation task with a
dynamic goal - and other methods are not able to learn this. Furthermore,
DreamerV3 generally outperforms other methods in sensor-denied environments. In
order to improve robustness, we use adversarial training and demonstrate an
improved performance in denied environments, although this generally comes with
a performance cost on the vanilla environments. We anticipate this benchmark of
different DRL methods and the usage of adversarial training to be a starting
point for the development of more elaborate navigation strategies that are
capable of dealing with uncertain and denied sensor readings.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>31 pages, 19 figures. For associated code, see
  https://github.com/mazqtpopx/cranfield-navigation-gym</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Asymptotically Optimal Change Detection for Unnormalized Pre- and
  Post-Change Distributions 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14615v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14615v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Arman Adibi, Sanjeev Kulkarni, H. Vincent Poor, Taposh Banerjee, Vahid Tarokh
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper addresses the problem of detecting changes when only unnormalized
pre- and post-change distributions are accessible. This situation happens in
many scenarios in physics such as in ferromagnetism, crystallography,
magneto-hydrodynamics, and thermodynamics, where the energy models are
difficult to normalize.
  Our approach is based on the estimation of the Cumulative Sum (CUSUM)
statistics, which is known to produce optimal performance. We first present an
intuitively appealing approximation method. Unfortunately, this produces a
biased estimator of the CUSUM statistics and may cause performance degradation.
We then propose the Log-Partition Approximation Cumulative Sum (LPA-CUSUM)
algorithm based on thermodynamic integration (TI) in order to estimate the
log-ratio of normalizing constants of pre- and post-change distributions. It is
proved that this approach gives an unbiased estimate of the log-partition
function and the CUSUM statistics, and leads to an asymptotically optimal
performance. Moreover, we derive a relationship between the required sample
size for thermodynamic integration and the desired detection delay performance,
offering guidelines for practical parameter selection. Numerical studies are
provided demonstrating the efficacy of our approach.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Streaming Deep Reinforcement Learning Finally Works 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14606v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14606v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mohamed Elsayed, Gautham Vasan, A. Rupam Mahmood
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Natural intelligence processes experience as a continuous stream, sensing,
acting, and learning moment-by-moment in real time. Streaming learning, the
modus operandi of classic reinforcement learning (RL) algorithms like
Q-learning and TD, mimics natural learning by using the most recent sample
without storing it. This approach is also ideal for resource-constrained,
communication-limited, and privacy-sensitive applications. However, in deep RL,
learners almost always use batch updates and replay buffers, making them
computationally expensive and incompatible with streaming learning. Although
the prevalence of batch deep RL is often attributed to its sample efficiency, a
more critical reason for the absence of streaming deep RL is its frequent
instability and failure to learn, which we refer to as stream barrier. This
paper introduces the stream-x algorithms, the first class of deep RL algorithms
to overcome stream barrier for both prediction and control and match sample
efficiency of batch RL. Through experiments in Mujoco Gym, DM Control Suite,
and Atari Games, we demonstrate stream barrier in existing algorithms and
successful stable learning with our stream-x algorithms: stream Q, stream AC,
and stream TD, achieving the best model-free performance in DM Control Dog
environments. A set of common techniques underlies the stream-x algorithms,
enabling their success with a single set of hyperparameters and allowing for
easy extension to other algorithms, thereby reviving streaming RL.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Learning to Control the Smoothness of Graph Convolutional Network
  Features 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14604v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14604v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Shih-Hsin Wang, Justin Baker, Cory Hauck, Bao Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The pioneering work of Oono and Suzuki [ICLR, 2020] and Cai and Wang
[arXiv:2006.13318] initializes the analysis of the smoothness of graph
convolutional network (GCN) features. Their results reveal an intricate
empirical correlation between node classification accuracy and the ratio of
smooth to non-smooth feature components. However, the optimal ratio that favors
node classification is unknown, and the non-smooth features of deep GCN with
ReLU or leaky ReLU activation function diminish. In this paper, we propose a
new strategy to let GCN learn node features with a desired smoothness --
adapting to data and tasks -- to enhance node classification. Our approach has
three key steps: (1) We establish a geometric relationship between the input
and output of ReLU or leaky ReLU. (2) Building on our geometric insights, we
augment the message-passing process of graph convolutional layers (GCLs) with a
learnable term to modulate the smoothness of node features with computational
efficiency. (3) We investigate the achievable ratio between smooth and
non-smooth feature components for GCNs with the augmented message-passing
scheme. Our extensive numerical results show that the augmented message-passing
schemes significantly improve node classification for GCN and some related
models.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>48 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ How Does Data Diversity Shape the Weight Landscape of Neural Networks? 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14602v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14602v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yang Ba, Michelle V. Mancenido, Rong Pan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  To enhance the generalization of machine learning models to unseen data,
techniques such as dropout, weight decay ($L_2$ regularization), and noise
augmentation are commonly employed. While regularization methods (i.e., dropout
and weight decay) are geared toward adjusting model parameters to prevent
overfitting, data augmentation increases the diversity of the input training
set, a method purported to improve accuracy and calibration error. In this
paper, we investigate the impact of each of these techniques on the parameter
space of neural networks, with the goal of understanding how they alter the
weight landscape in transfer learning scenarios. To accomplish this, we employ
Random Matrix Theory to analyze the eigenvalue distributions of pre-trained
models, fine-tuned using these techniques but using different levels of data
diversity, for the same downstream tasks. We observe that diverse data
influences the weight landscape in a similar fashion as dropout. Additionally,
we compare commonly used data augmentation methods with synthetic data created
by generative models. We conclude that synthetic data can bring more diversity
into real input data, resulting in a better performance on out-of-distribution
test instances.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Contractivity and linear convergence in bilinear saddle-point problems:
  An operator-theoretic approach 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14592v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14592v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Colin Dirren, Mattia Bianchi, Panagiotis D. Grontas, John Lygeros, Florian Dörfler
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We study the convex-concave bilinear saddle-point problem $\min_x \max_y f(x)
+ y^\top Ax - g(y)$, where both, only one, or none of the functions $f$ and $g$
are strongly convex, and suitable rank conditions on the matrix $A$ hold. The
solution of this problem is at the core of many machine learning tasks. By
employing tools from operator theory, we systematically prove the contractivity
(in turn, the linear convergence) of several first-order primal-dual
algorithms, including the Chambolle-Pock method. Our approach results in
concise and elegant proofs, and it yields new convergence guarantees and
tighter bounds compared to known results.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ A Lipschitz spaces view of infinitely wide shallow neural networks 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14591v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14591v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Francesca Bartolucci, Marcello Carioni, José A. Iglesias, Yury Korolev, Emanuele Naldi, Stefano Vigogna
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We revisit the mean field parametrization of shallow neural networks, using
signed measures on unbounded parameter spaces and duality pairings that take
into account the regularity and growth of activation functions. This setting
directly leads to the use of unbalanced Kantorovich-Rubinstein norms defined by
duality with Lipschitz functions, and of spaces of measures dual to those of
continuous functions with controlled growth. These allow to make transparent
the need for total variation and moment bounds or penalization to obtain
existence of minimizers of variational formulations, under which we prove a
compactness result in strong Kantorovich-Rubinstein norm, and in the absence of
which we show several examples demonstrating undesirable behavior. Further, the
Kantorovich-Rubinstein setting enables us to combine the advantages of a
completely linear parametrization and ensuing reproducing kernel Banach space
framework with optimal transport insights. We showcase this synergy with
representer theorems and uniform large data limits for empirical risk
minimization, and in proposed formulations for distillation and fusion
applications.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>39 pages, 1 table</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Learning With Multi-Group Guarantees For Clusterable Subpopulations 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14588v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14588v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jessica Dai, Nika Haghtalab, Eric Zhao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  A canonical desideratum for prediction problems is that performance
guarantees should hold not just on average over the population, but also for
meaningful subpopulations within the overall population. But what constitutes a
meaningful subpopulation? In this work, we take the perspective that relevant
subpopulations should be defined with respect to the clusters that naturally
emerge from the distribution of individuals for which predictions are being
made. In this view, a population refers to a mixture model whose components
constitute the relevant subpopulations. We suggest two formalisms for capturing
per-subgroup guarantees: first, by attributing each individual to the component
from which they were most likely drawn, given their features; and second, by
attributing each individual to all components in proportion to their relative
likelihood of having been drawn from each component. Using online calibration
as a case study, we study a \variational algorithm that provides guarantees for
each of these formalisms by handling all plausible underlying subpopulation
structures simultaneously, and achieve an $O(T^{1/2})$ rate even when the
subpopulations are not well-separated. In comparison, the more natural
cluster-then-predict approach that first recovers the structure of the
subpopulations and then makes predictions suffers from a $O(T^{2/3})$ rate and
requires the subpopulations to be separable. Along the way, we prove that
providing per-subgroup calibration guarantees for underlying clusters can be
easier than learning the clusters: separation between median subgroup features
is required for the latter but not the former.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Neuro-Symbolic Traders: Assessing the Wisdom of AI Crowds in Markets 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14587v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14587v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Namid R. Stillman, Rory Baggott
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Deep generative models are becoming increasingly used as tools for financial
analysis. However, it is unclear how these models will influence financial
markets, especially when they infer financial value in a semi-autonomous way.
In this work, we explore the interplay between deep generative models and
market dynamics. We develop a form of virtual traders that use deep generative
models to make buy/sell decisions, which we term neuro-symbolic traders, and
expose them to a virtual market. Under our framework, neuro-symbolic traders
are agents that use vision-language models to discover a model of the
fundamental value of an asset. Agents develop this model as a stochastic
differential equation, calibrated to market data using gradient descent. We
test our neuro-symbolic traders on both synthetic data and real financial time
series, including an equity stock, commodity, and a foreign exchange pair. We
then expose several groups of neuro-symbolic traders to a virtual market
environment. This market environment allows for feedback between the traders
belief of the underlying value to the observed price dynamics. We find that
this leads to price suppression compared to the historical data, highlighting a
future risk to market stability. Our work is a first step towards quantifying
the effect of deep generative agents on markets dynamics and sets out some of
the potential risks and benefits of this approach in the future.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>8 pages, 4 figures, ACM format</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Neural Combinatorial Clustered Bandits for Recommendation Systems 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14586v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14586v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Baran Atalar, Carlee Joe-Wong
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We consider the contextual combinatorial bandit setting where in each round,
the learning agent, e.g., a recommender system, selects a subset of "arms,"
e.g., products, and observes rewards for both the individual base arms, which
are a function of known features (called "context"), and the super arm (the
subset of arms), which is a function of the base arm rewards. The agent's goal
is to simultaneously learn the unknown reward functions and choose the
highest-reward arms. For example, the "reward" may represent a user's
probability of clicking on one of the recommended products. Conventional bandit
models, however, employ restrictive reward function models in order to obtain
performance guarantees. We make use of deep neural networks to estimate and
learn the unknown reward functions and propose Neural UCB Clustering
(NeUClust), which adopts a clustering approach to select the super arm in every
round by exploiting underlying structure in the context space. Unlike prior
neural bandit works, NeUClust uses a neural network to estimate the super arm
reward and select the super arm, thus eliminating the need for a known
optimization oracle. We non-trivially extend prior neural combinatorial bandit
works to prove that NeUClust achieves
$\widetilde{O}\left(\widetilde{d}\sqrt{T}\right)$ regret, where $\widetilde{d}$
is the effective dimension of a neural tangent kernel matrix, $T$ the number of
rounds. Experiments on real world recommendation datasets show that NeUClust
achieves better regret and reward than other contextual combinatorial and
neural bandit algorithms.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Optimizing Attention with Mirror Descent: Generalized Max-Margin Token
  Selection 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14581v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14581v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Aaron Alvarado Kristanto Julistiono, Davoud Ataee Tarzanagh, Navid Azizan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Attention mechanisms have revolutionized several domains of artificial
intelligence, such as natural language processing and computer vision, by
enabling models to selectively focus on relevant parts of the input data. While
recent work has characterized the optimization dynamics of gradient descent
(GD) in attention-based models and the structural properties of its preferred
solutions, less is known about more general optimization algorithms such as
mirror descent (MD). In this paper, we investigate the convergence properties
and implicit biases of a family of MD algorithms tailored for softmax attention
mechanisms, with the potential function chosen as the $p$-th power of the
$\ell_p$-norm. Specifically, we show that these algorithms converge in
direction to a generalized hard-margin SVM with an $\ell_p$-norm objective when
applied to a classification problem using a softmax attention model. Notably,
our theoretical results reveal that the convergence rate is comparable to that
of traditional GD in simpler models, despite the highly nonlinear and nonconvex
nature of the present problem. Additionally, we delve into the joint
optimization dynamics of the key-query matrix and the decoder, establishing
conditions under which this complex joint optimization converges to their
respective hard-margin SVM solutions. Lastly, our numerical experiments on real
data demonstrate that MD algorithms improve generalization over standard GD and
excel in optimal token selection.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Towards Unsupervised Validation of Anomaly-Detection Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14579v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14579v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Lihi Idan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Unsupervised validation of anomaly-detection models is a highly challenging
task. While the common practices for model validation involve a labeled
validation set, such validation sets cannot be constructed when the underlying
datasets are unlabeled. The lack of robust and efficient unsupervised
model-validation techniques presents an acute challenge in the implementation
of automated anomaly-detection pipelines, especially when there exists no prior
knowledge of the model's performance on similar datasets. This work presents a
new paradigm to automated validation of anomaly-detection models, inspired by
real-world, collaborative decision-making mechanisms. We focus on two
commonly-used, unsupervised model-validation tasks -- model selection and model
evaluation -- and provide extensive experimental results that demonstrate the
accuracy and robustness of our approach on both tasks.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Large Language Models Are Overparameterized Text Encoders 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14578v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14578v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Thennal D K, Tim Fischer, Chris Biemann
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large language models (LLMs) demonstrate strong performance as text embedding
models when finetuned with supervised contrastive training. However, their
large size balloons inference time and memory requirements. In this paper, we
show that by pruning the last $p\%$ layers of an LLM before supervised training
for only 1000 steps, we can achieve a proportional reduction in memory and
inference time. We evaluate four different state-of-the-art LLMs on text
embedding tasks and find that our method can prune up to 30\% of layers with
negligible impact on performance and up to 80\% with only a modest drop. With
only three lines of code, our method is easily implemented in any pipeline for
transforming LLMs to text encoders. We also propose $\text{L}^3 \text{Prune}$,
a novel layer-pruning strategy based on the model's initial loss that provides
two optimal pruning configurations: a large variant with negligible performance
loss and a small variant for resource-constrained settings. On average, the
large variant prunes 21\% of the parameters with a $-0.3$ performance drop, and
the small variant only suffers from a $-5.1$ decrease while pruning 74\% of the
model. We consider these results strong evidence that LLMs are
overparameterized for text embedding tasks, and can be easily pruned.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>8 pages of content + 1 for limitations and ethical considerations, 14
  pages in total including references and appendix, 5+1 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ MomentumSMoE: Integrating Momentum into Sparse Mixture of Experts <span class="chip">NeurIPS 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14574v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14574v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Rachel S. Y. Teo, Tan M. Nguyen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Sparse Mixture of Experts (SMoE) has become the key to unlocking unparalleled
scalability in deep learning. SMoE has the potential to exponentially increase
parameter count while maintaining the efficiency of the model by only
activating a small subset of these parameters for a given sample. However, it
has been observed that SMoE suffers from unstable training and has difficulty
adapting to new distributions, leading to the model's lack of robustness to
data contamination. To overcome these limitations, we first establish a
connection between the dynamics of the expert representations in SMoEs and
gradient descent on a multi-objective optimization problem. Leveraging our
framework, we then integrate momentum into SMoE and propose a new family of
SMoEs named MomentumSMoE. We theoretically prove and numerically demonstrate
that MomentumSMoE is more stable and robust than SMoE. In particular, we verify
the advantages of MomentumSMoE over SMoE on a variety of practical tasks
including ImageNet-1K object recognition and WikiText-103 language modeling. We
demonstrate the applicability of MomentumSMoE to many types of SMoE models,
including those in the Sparse MoE model for vision (V-MoE) and the Generalist
Language Model (GLaM). We also show that other advanced momentum-based
optimization methods, such as Adam, can be easily incorporated into the
MomentumSMoE framework for designing new SMoE models with even better
performance, almost negligible additional computation cost, and simple
implementations.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>10 pages in the main text. Published at NeurIPS 2024. The code is
  available at https://github.com/rachtsy/MomentumSMoE</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Building Trust in Black-box Optimization: A Comprehensive Framework for
  Explainability 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14573v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14573v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Nazanin Nezami, Hadis Anahideh
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Optimizing costly black-box functions within a constrained evaluation budget
presents significant challenges in many real-world applications. Surrogate
Optimization (SO) is a common resolution, yet its proprietary nature introduced
by the complexity of surrogate models and the sampling core (e.g., acquisition
functions) often leads to a lack of explainability and transparency. While
existing literature has primarily concentrated on enhancing convergence to
global optima, the practical interpretation of newly proposed strategies
remains underexplored, especially in batch evaluation settings. In this paper,
we propose \emph{Inclusive} Explainability Metrics for Surrogate Optimization
(IEMSO), a comprehensive set of model-agnostic metrics designed to enhance the
transparency, trustworthiness, and explainability of the SO approaches. Through
these metrics, we provide both intermediate and post-hoc explanations to
practitioners before and after performing expensive evaluations to gain trust.
We consider four primary categories of metrics, each targeting a specific
aspect of the SO process: Sampling Core Metrics, Batch Properties Metrics,
Optimization Process Metrics, and Feature Importance. Our experimental
evaluations demonstrate the significant potential of the proposed metrics
across different benchmarks.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Understanding the difficulty of low-precision post-training quantization
  of large language models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14570v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14570v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zifei Xu, Sayeh Sharify, Wanzin Yazar, Tristan Webb, Xin Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large language models of high parameter counts are computationally expensive,
yet can be made much more efficient by compressing their weights to very low
numerical precision. This can be achieved either through post-training
quantization by minimizing local, layer-wise quantization errors, or through
quantization-aware fine-tuning by minimizing the global loss function. In this
study, we discovered that, under the same data constraint, the former approach
nearly always fared worse than the latter, a phenomenon particularly prominent
when the numerical precision is very low. We further showed that this
difficulty of post-training quantization arose from stark misalignment between
optimization of the local and global objective functions. Our findings explains
limited utility in minimization of local quantization error and the importance
of direct quantization-aware fine-tuning, in the regime of large models at very
low precision.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Measuring Diversity: Axioms and Challenges 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14556v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14556v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mikhail Mironov, Liudmila Prokhorenkova
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The concept of diversity is widely used in various applications: from image
or molecule generation to recommender systems. Thus, being able to properly
measure diversity is important. This paper addresses the problem of quantifying
diversity for a set of objects. First, we make a systematic review of existing
diversity measures and explore their undesirable behavior in some cases. Based
on this review, we formulate three desirable properties (axioms) of a reliable
diversity measure: monotonicity, uniqueness, and continuity. We show that none
of the existing measures has all three properties and thus these measures are
not suitable for quantifying diversity. Then, we construct two examples of
measures that have all the desirable properties, thus proving that the list of
axioms is not self-contradicting. Unfortunately, the constructed examples are
too computationally complex for practical use, thus we pose an open problem of
constructing a diversity measure that has all the listed properties and can be
computed in practice.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>17 pages, 7 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Boosting K-means for Big Data by Fusing Data Streaming with Global
  Optimization 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14548v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14548v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ravil Mussabayev, Rustam Mussabayev
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  K-means clustering is a cornerstone of data mining, but its efficiency
deteriorates when confronted with massive datasets. To address this limitation,
we propose a novel heuristic algorithm that leverages the Variable Neighborhood
Search (VNS) metaheuristic to optimize K-means clustering for big data. Our
approach is based on the sequential optimization of the partial objective
function landscapes obtained by restricting the Minimum Sum-of-Squares
Clustering (MSSC) formulation to random samples from the original big dataset.
Within each landscape, systematically expanding neighborhoods of the currently
best (incumbent) solution are explored by reinitializing all degenerate and a
varying number of additional centroids. Extensive and rigorous experimentation
on a large number of real-world datasets reveals that by transforming the
traditional local search into a global one, our algorithm significantly
enhances the accuracy and efficiency of K-means clustering in big data
environments, becoming the new state of the art in the field.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Diffusion-based Semi-supervised Spectral Algorithm for Regression on
  Manifolds 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14539v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14539v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Weichun Xia, Jiaxin Jiang, Lei Shi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We introduce a novel diffusion-based spectral algorithm to tackle regression
analysis on high-dimensional data, particularly data embedded within
lower-dimensional manifolds. Traditional spectral algorithms often fall short
in such contexts, primarily due to the reliance on predetermined kernel
functions, which inadequately address the complex structures inherent in
manifold-based data. By employing graph Laplacian approximation, our method
uses the local estimation property of heat kernel, offering an adaptive,
data-driven approach to overcome this obstacle. Another distinct advantage of
our algorithm lies in its semi-supervised learning framework, enabling it to
fully use the additional unlabeled data. This ability enhances the performance
by allowing the algorithm to dig the spectrum and curvature of the data
manifold, providing a more comprehensive understanding of the dataset.
Moreover, our algorithm performs in an entirely data-driven manner, operating
directly within the intrinsic manifold structure of the data, without requiring
any predefined manifold information. We provide a convergence analysis of our
algorithm. Our findings reveal that the algorithm achieves a convergence rate
that depends solely on the intrinsic dimension of the underlying manifold,
thereby avoiding the curse of dimensionality associated with the higher ambient
dimension.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Comparing Differentiable and Dynamic Ray Tracing: Introducing the
  Multipath Lifetime Map 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14535v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14535v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jérome Eertmans, Enrico Maria Vittuci, Vittorio Degli Esposti, Laurent Jacques, Claude Oestges
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  With the increasing presence of dynamic scenarios, such as Vehicle-to-Vehicle
communications, radio propagation modeling tools must adapt to the rapidly
changing nature of the radio channel. Recently, both Differentiable and Dynamic
Ray Tracing frameworks have emerged to address these challenges. However, there
is often confusion about how these approaches differ and which one should be
used in specific contexts. In this paper, we provide an overview of these two
techniques and a comparative analysis against two state-of-the-art tools:
3DSCAT from UniBo and Sionna from NVIDIA. To provide a more precise
characterization of the scope of these methods, we introduce a novel
simulation-based metric, the Multipath Lifetime Map, which enables the
evaluation of spatial and temporal coherence in radio channels only based on
the geometrical description of the environment. Finally, our metrics are
evaluated on a classic urban street canyon scenario, yielding similar results
to those obtained from measurement campaigns.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>5 pages, 5 figures, 1 table, submitted to EuCAP 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ The Traveling Bandit: A Framework for Bayesian Optimization with
  Movement Costs 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14533v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14533v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Qiyuan Chen, Raed Al Kontar
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper introduces a framework for Bayesian Optimization (BO) with metric
movement costs, addressing a critical challenge in practical applications where
input alterations incur varying costs. Our approach is a convenient plug-in
that seamlessly integrates with the existing literature on batched algorithms,
where designs within batches are observed following the solution of a Traveling
Salesman Problem. The proposed method provides a theoretical guarantee of
convergence in terms of movement costs for BO. Empirically, our method
effectively reduces average movement costs over time while maintaining
comparable regret performance to conventional BO methods. This framework also
shows promise for broader applications in various bandit settings with movement
costs.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Using Sentiment and Technical Analysis to Predict Bitcoin with Machine
  Learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14532v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14532v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Arthur Emanuel de Oliveira Carosia
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Cryptocurrencies have gained significant attention in recent years due to
their decentralized nature and potential for financial innovation. Thus, the
ability to accurately predict its price has become a subject of great interest
for investors, traders, and researchers. Some works in the literature show how
Bitcoin's market sentiment correlates with its price fluctuations in the
market. However, papers that consider the sentiment of the market associated
with financial Technical Analysis indicators in order to predict Bitcoin's
price are still scarce. In this paper, we present a novel approach for
predicting Bitcoin price movements by combining the Fear & Greedy Index, a
measure of market sentiment, Technical Analysis indicators, and the potential
of Machine Learning algorithms. This work represents a preliminary study on the
importance of sentiment metrics in cryptocurrency forecasting. Our initial
experiments demonstrate promising results considering investment returns,
surpassing the Buy & Hold baseline, and offering valuable insights about the
combination of indicators of sentiment and market in a cryptocurrency
prediction model.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Domain Adaptive Safety Filters via Deep Operator Learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14528v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14528v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Lakshmideepakreddy Manda, Shaoru Chen, Mahyar Fazlyab
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Learning-based approaches for constructing Control Barrier Functions (CBFs)
are increasingly being explored for safety-critical control systems. However,
these methods typically require complete retraining when applied to unseen
environments, limiting their adaptability. To address this, we propose a
self-supervised deep operator learning framework that learns the mapping from
environmental parameters to the corresponding CBF, rather than learning the CBF
directly. Our approach leverages the residual of a parametric Partial
Differential Equation (PDE), where the solution defines a parametric CBF
approximating the maximal control invariant set. This framework accommodates
complex safety constraints, higher relative degrees, and actuation limits. We
demonstrate the effectiveness of the method through numerical experiments on
navigation tasks involving dynamic obstacles.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>63rd IEEE Conference on Decision and Control (CDC)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Rethinking Distance Metrics for Counterfactual Explainability 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14522v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14522v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Joshua Nathaniel Williams, Anurag Katakkar, Hoda Heidari, J. Zico Kolter
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Counterfactual explanations have been a popular method of post-hoc
explainability for a variety of settings in Machine Learning. Such methods
focus on explaining classifiers by generating new data points that are similar
to a given reference, while receiving a more desirable prediction. In this
work, we investigate a framing for counterfactual generation methods that
considers counterfactuals not as independent draws from a region around the
reference, but as jointly sampled with the reference from the underlying data
distribution. Through this framing, we derive a distance metric, tailored for
counterfactual similarity that can be applied to a broad range of settings.
Through both quantitative and qualitative analyses of counterfactual generation
methods, we show that this framing allows us to express more nuanced
dependencies among the covariates.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>13 pages, 3 figures, 1 table</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Efficient Annotator Reliability Assessment and Sample Weighting for
  Knowledge-Based Misinformation Detection on Social Media 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14515v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14515v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Owen Cook, Charlie Grimshaw, Ben Wu, Sophie Dillon, Jack Hicks, Luke Jones, Thomas Smith, Matyas Szert, Xingyi Song
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Misinformation spreads rapidly on social media, confusing the truth and
targetting potentially vulnerable people. To effectively mitigate the negative
impact of misinformation, it must first be accurately detected before applying
a mitigation strategy, such as X's community notes, which is currently a manual
process. This study takes a knowledge-based approach to misinformation
detection, modelling the problem similarly to one of natural language
inference. The EffiARA annotation framework is introduced, aiming to utilise
inter- and intra-annotator agreement to understand the reliability of each
annotator and influence the training of large language models for
classification based on annotator reliability. In assessing the EffiARA
annotation framework, the Russo-Ukrainian Conflict Knowledge-Based
Misinformation Classification Dataset (RUC-MCD) was developed and made publicly
available. This study finds that sample weighting using annotator reliability
performs the best, utilising both inter- and intra-annotator agreement and
soft-label training. The highest classification performance achieved using
Llama-3.2-1B was a macro-F1 of 0.757 and 0.740 using TwHIN-BERT-large.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>8 pages, 3 figures, 3 tables. Code available here:
  https://github.com/MiniEggz/ruc-misinfo</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ An Integrated Deep Learning Model for Skin Cancer Detection Using Hybrid
  Feature Fusion Technique 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14489v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14489v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Maksuda Akter, Rabea Khatun, Md. Alamin Talukder, Md. Manowarul Islam, Md. Ashraf Uddin
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Skin cancer is a serious and potentially fatal disease caused by DNA damage.
Early detection significantly increases survival rates, making accurate
diagnosis crucial. In this groundbreaking study, we present a hybrid framework
based on Deep Learning (DL) that achieves precise classification of benign and
malignant skin lesions. Our approach begins with dataset preprocessing to
enhance classification accuracy, followed by training two separate pre-trained
DL models, InceptionV3 and DenseNet121. By fusing the results of each model
using the weighted sum rule, our system achieves exceptional accuracy rates.
Specifically, we achieve a 92.27% detection accuracy rate, 92.33% sensitivity,
92.22% specificity, 90.81% precision, and 91.57% F1-score, outperforming
existing models and demonstrating the robustness and trustworthiness of our
hybrid approach. Our study represents a significant advance in skin cancer
diagnosis and provides a promising foundation for further research in the
field. With the potential to save countless lives through earlier detection,
our hybrid deep-learning approach is a game-changer in the fight against skin
cancer.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ ANT: Adaptive Noise Schedule for Time Series Diffusion Models <span class="chip">NeurIPS 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14488v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14488v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Seunghan Lee, Kibok Lee, Taeyoung Park
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Advances in diffusion models for generative artificial intelligence have
recently propagated to the time series (TS) domain, demonstrating
state-of-the-art performance on various tasks. However, prior works on TS
diffusion models often borrow the framework of existing works proposed in other
domains without considering the characteristics of TS data, leading to
suboptimal performance. In this work, we propose Adaptive Noise schedule for
Time series diffusion models (ANT), which automatically predetermines proper
noise schedules for given TS datasets based on their statistics representing
non-stationarity. Our intuition is that an optimal noise schedule should
satisfy the following desiderata: 1) It linearly reduces the non-stationarity
of TS data so that all diffusion steps are equally meaningful, 2) the data is
corrupted to the random noise at the final step, and 3) the number of steps is
sufficiently large. The proposed method is practical for use in that it
eliminates the necessity of finding the optimal noise schedule with a small
additional cost to compute the statistics for given datasets, which can be done
offline before training. We validate the effectiveness of our method across
various tasks, including TS forecasting, refinement, and generation, on
datasets from diverse domains. Code is available at this repository:
https://github.com/seunghan96/ANT.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>NeurIPS 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ CaTs and DAGs: Integrating Directed Acyclic Graphs with <span class="highlight-title">Transformer</span>s and
  Fully-Connected Neural Networks for Causally Constrained Predictions 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14485v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14485v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Matthew J. Vowels, Mathieu Rochat, Sina Akbari
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Artificial Neural Networks (ANNs), including fully-connected networks and
transformers, are highly flexible and powerful function approximators, widely
applied in fields like computer vision and natural language processing.
However, their inability to inherently respect causal structures can limit
their robustness, making them vulnerable to covariate shift and difficult to
interpret/explain. This poses significant challenges for their reliability in
real-world applications. In this paper, we introduce Causal Fully-Connected
Neural Networks (CFCNs) and Causal Transformers (CaTs), two general model
families designed to operate under predefined causal constraints, as specified
by a Directed Acyclic Graph (DAG). These models retain the powerful function
approximation abilities of traditional neural networks while adhering to the
underlying structural constraints, improving robustness, reliability, and
interpretability at inference time. This approach opens new avenues for
deploying neural networks in more demanding, real-world scenarios where
robustness and explainability is critical.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Transfer Reinforcement Learning in Heterogeneous Action Spaces using
  Subgoal Mapping 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14484v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14484v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Kavinayan P. Sivakumar, Yan Zhang, Zachary Bell, Scott Nivison, Michael M. Zavlanos
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this paper, we consider a transfer reinforcement learning problem
involving agents with different action spaces. Specifically, for any new unseen
task, the goal is to use a successful demonstration of this task by an expert
agent in its action space to enable a learner agent learn an optimal policy in
its own different action space with fewer samples than those required if the
learner was learning on its own. Existing transfer learning methods across
different action spaces either require handcrafted mappings between those
action spaces provided by human experts, which can induce bias in the learning
procedure, or require the expert agent to share its policy parameters with the
learner agent, which does not generalize well to unseen tasks. In this work, we
propose a method that learns a subgoal mapping between the expert agent policy
and the learner agent policy. Since the expert agent and the learner agent have
different action spaces, their optimal policies can have different subgoal
trajectories. We learn this subgoal mapping by training a Long Short Term
Memory (LSTM) network for a distribution of tasks and then use this mapping to
predict the learner subgoal sequence for unseen tasks, thereby improving the
speed of learning by biasing the agent's policy towards the predicted learner
subgoal sequence. Through numerical experiments, we demonstrate that the
proposed learning scheme can effectively find the subgoal mapping underlying
the given distribution of tasks. Moreover, letting the learner agent imitate
the expert agent's policy with the learnt subgoal mapping can significantly
improve the sample efficiency and training time of the learner agent in unseen
new tasks.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Spectral Representations for Accurate Causal Uncertainty Quantification
  with Gaussian Processes 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14483v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14483v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hugh Dance, Peter Orbanz, Arthur Gretton
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Accurate uncertainty quantification for causal effects is essential for
robust decision making in complex systems, but remains challenging in
non-parametric settings. One promising framework represents conditional
distributions in a reproducing kernel Hilbert space and places Gaussian process
priors on them to infer posteriors on causal effects, but requires restrictive
nuclear dominant kernels and approximations that lead to unreliable uncertainty
estimates. In this work, we introduce a method, IMPspec, that addresses these
limitations via a spectral representation of the Hilbert space. We show that
posteriors in this model can be obtained explicitly, by extending a result in
Hilbert space regression theory. We also learn the spectral representation to
optimise posterior calibration. Our method achieves state-of-the-art
performance in uncertainty quantification and causal Bayesian optimisation
across simulations and a healthcare application.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Backdoored Retrievers for <span class="highlight-title">Prompt</span> Injection Attacks on Retrieval
  Augmented Generation of Large Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14479v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14479v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Cody Clop, Yannick Teglia
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large Language Models (LLMs) have demonstrated remarkable capabilities in
generating coherent text but remain limited by the static nature of their
training data. Retrieval Augmented Generation (RAG) addresses this issue by
combining LLMs with up-to-date information retrieval, but also expand the
attack surface of the system. This paper investigates prompt injection attacks
on RAG, focusing on malicious objectives beyond misinformation, such as
inserting harmful links, promoting unauthorized services, and initiating
denial-of-service behaviors. We build upon existing corpus poisoning techniques
and propose a novel backdoor attack aimed at the fine-tuning process of the
dense retriever component. Our experiments reveal that corpus poisoning can
achieve significant attack success rates through the injection of a small
number of compromised documents into the retriever corpus. In contrast,
backdoor attacks demonstrate even higher success rates but necessitate a more
complex setup, as the victim must fine-tune the retriever using the attacker
poisoned dataset.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>12 pages, 5 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Laplace Transform Based Low-Complexity Learning of Continuous Markov
  Semigroups 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14477v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14477v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Vladimir R. Kostic, Karim Lounici, Hélène Halconruy, Timothée Devergne, Pietro Novelli, Massimiliano Pontil
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Markov processes serve as a universal model for many real-world random
processes. This paper presents a data-driven approach for learning these models
through the spectral decomposition of the infinitesimal generator (IG) of the
Markov semigroup. The unbounded nature of IGs complicates traditional methods
such as vector-valued regression and Hilbert-Schmidt operator analysis.
Existing techniques, including physics-informed kernel regression, are
computationally expensive and limited in scope, with no recovery guarantees for
transfer operator methods when the time-lag is small. We propose a novel method
that leverages the IG's resolvent, characterized by the Laplace transform of
transfer operators. This approach is robust to time-lag variations, ensuring
accurate eigenvalue learning even for small time-lags. Our statistical analysis
applies to a broader class of Markov processes than current methods while
reducing computational complexity from quadratic to linear in the state
dimension. Finally, we illustrate the behaviour of our method in two
experiments.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>35 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Enhancing Cryptocurrency Market Forecasting: Advanced Machine Learning
  Techniques and Industrial Engineering Contributions 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14475v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14475v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jannatun Nayeem Pinky, Ramya Akula
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Cryptocurrencies, as decentralized digital assets, have experienced rapid
growth and adoption, with over 23,000 cryptocurrencies and a market
capitalization nearing \$1.1 trillion (about \$3,400 per person in the US) as
of 2023. This dynamic market presents significant opportunities and risks,
highlighting the need for accurate price prediction models to manage
volatility. This chapter comprehensively reviews machine learning (ML)
techniques applied to cryptocurrency price prediction from 2014 to 2024. We
explore various ML algorithms, including linear models, tree-based approaches,
and advanced deep learning architectures such as transformers and large
language models. Additionally, we examine the role of sentiment analysis in
capturing market sentiment from textual data like social media posts and news
articles to anticipate price fluctuations. With expertise in optimizing complex
systems and processes, industrial engineers are pivotal in enhancing these
models. They contribute by applying principles of process optimization,
efficiency, and risk mitigation to improve computational performance and data
management. This chapter highlights the evolving landscape of cryptocurrency
price prediction, the integration of emerging technologies, and the significant
role of industrial engineers in refining predictive models. By addressing
current limitations and exploring future research directions, this chapter aims
to advance the development of more accurate and robust prediction systems,
supporting better-informed investment decisions and more stable market
behavior.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>63 pages, 6 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ How Do Training Methods Influence the Utilization of Vision Models? <span class="chip">NeurIPS 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14470v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14470v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Paul Gavrikov, Shashank Agnihotri, Margret Keuper, Janis Keuper
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Not all learnable parameters (e.g., weights) contribute equally to a neural
network's decision function. In fact, entire layers' parameters can sometimes
be reset to random values with little to no impact on the model's decisions. We
revisit earlier studies that examined how architecture and task complexity
influence this phenomenon and ask: is this phenomenon also affected by how we
train the model? We conducted experimental evaluations on a diverse set of
ImageNet-1k classification models to explore this, keeping the architecture and
training data constant but varying the training pipeline. Our findings reveal
that the training method strongly influences which layers become critical to
the decision function for a given task. For example, improved training regimes
and self-supervised training increase the importance of early layers while
significantly under-utilizing deeper layers. In contrast, methods such as
adversarial training display an opposite trend. Our preliminary results extend
previous findings, offering a more nuanced understanding of the inner mechanics
of neural networks.
  Code: https://github.com/paulgavrikov/layer_criticality
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted at the Interpretable AI: Past, Present and Future Workshop
  at NeurIPS 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Flow-based Sampling for Entanglement Entropy and the Machine Learning of
  Defects 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14466v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14466v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Andrea Bulgarelli, Elia Cellini, Karl Jansen, Stefan Kühn, Alessandro Nada, Shinichi Nakajima, Kim A. Nicoli, Marco Panero
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We introduce a novel technique to numerically calculate R\'enyi entanglement
entropies in lattice quantum field theory using generative models. We describe
how flow-based approaches can be combined with the replica trick using a custom
neural-network architecture around a lattice defect connecting two replicas.
Numerical tests for the $\phi^4$ scalar field theory in two and three
dimensions demonstrate that our technique outperforms state-of-the-art Monte
Carlo calculations, and exhibit a promising scaling with the defect size.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>10 pages, 9 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Electrocardiogram-Language Model for Few-Shot Question Answering with
  Meta Learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14464v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14464v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jialu Tang, Tong Xia, Yuan Lu, Cecilia Mascolo, Aaqib Saeed
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Electrocardiogram (ECG) interpretation requires specialized expertise, often
involving synthesizing insights from ECG signals with complex clinical queries
posed in natural language. The scarcity of labeled ECG data coupled with the
diverse nature of clinical inquiries presents a significant challenge for
developing robust and adaptable ECG diagnostic systems. This work introduces a
novel multimodal meta-learning method for few-shot ECG question answering,
addressing the challenge of limited labeled data while leveraging the rich
knowledge encoded within large language models (LLMs). Our LLM-agnostic
approach integrates a pre-trained ECG encoder with a frozen LLM (e.g., LLaMA
and Gemma) via a trainable fusion module, enabling the language model to reason
about ECG data and generate clinically meaningful answers. Extensive
experiments demonstrate superior generalization to unseen diagnostic tasks
compared to supervised baselines, achieving notable performance even with
limited ECG leads. For instance, in a 5-way 5-shot setting, our method using
LLaMA-3.1-8B achieves accuracy of 84.6%, 77.3%, and 69.6% on single verify,
choose and query question types, respectively. These results highlight the
potential of our method to enhance clinical ECG interpretation by combining
signal processing with the nuanced language understanding capabilities of LLMs,
particularly in data-constrained scenarios.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ The Propensity for Density in Feed-forward Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14461v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14461v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Nandi Schoots, Alex Jackson, Ali Kholmovaia, Peter McBurney, Murray Shanahan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Does the process of training a neural network to solve a task tend to use all
of the available weights even when the task could be solved with fewer weights?
To address this question we study the effects of pruning fully connected,
convolutional and residual models while varying their widths. We find that the
proportion of weights that can be pruned without degrading performance is
largely invariant to model size. Increasing the width of a model has little
effect on the density of the pruned model relative to the increase in absolute
size of the pruned network. In particular, we find substantial prunability
across a large range of model sizes, where our biggest model is 50 times as
wide as our smallest model. We explore three hypotheses that could explain
these findings.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Learning to refine domain knowledge for biological network inference 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14436v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14436v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Peiwen Li, Menghua Wu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Perturbation experiments allow biologists to discover causal relationships
between variables of interest, but the sparsity and high dimensionality of
these data pose significant challenges for causal structure learning
algorithms. Biological knowledge graphs can bootstrap the inference of causal
structures in these situations, but since they compile vastly diverse
information, they can bias predictions towards well-studied systems.
Alternatively, amortized causal structure learning algorithms encode inductive
biases through data simulation and train supervised models to recapitulate
these synthetic graphs. However, realistically simulating biology is arguably
even harder than understanding a specific system. In this work, we take
inspiration from both strategies and propose an amortized algorithm for
refining domain knowledge, based on data observations. On real and synthetic
datasets, we show that our approach outperforms baselines in recovering ground
truth causal graphs and identifying errors in the prior knowledge with limited
interventional data.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ A Bioinformatic Approach Validated Utilizing Machine Learning Algorithms
  to Identify Relevant Biomarkers and Crucial Pathways in Gallbladder Cancer 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14433v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14433v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Rabea Khatun, Wahia Tasnim, Maksuda Akter, Md Manowarul Islam, Md. Ashraf Uddin, Md. Zulfiker Mahmud, Saurav Chandra Das
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Gallbladder cancer (GBC) is the most frequent cause of disease among biliary
tract neoplasms. Identifying the molecular mechanisms and biomarkers linked to
GBC progression has been a significant challenge in scientific research. Few
recent studies have explored the roles of biomarkers in GBC. Our study aimed to
identify biomarkers in GBC using machine learning (ML) and bioinformatics
techniques. We compared GBC tumor samples with normal samples to identify
differentially expressed genes (DEGs) from two microarray datasets (GSE100363,
GSE139682) obtained from the NCBI GEO database. A total of 146 DEGs were found,
with 39 up-regulated and 107 down-regulated genes. Functional enrichment
analysis of these DEGs was performed using Gene Ontology (GO) terms and
REACTOME pathways through DAVID. The protein-protein interaction network was
constructed using the STRING database. To identify hub genes, we applied three
ranking algorithms: Degree, MNC, and Closeness Centrality. The intersection of
hub genes from these algorithms yielded 11 hub genes. Simultaneously, two
feature selection methods (Pearson correlation and recursive feature
elimination) were used to identify significant gene subsets. We then developed
ML models using SVM and RF on the GSE100363 dataset, with validation on
GSE139682, to determine the gene subset that best distinguishes GBC samples.
The hub genes outperformed the other gene subsets. Finally, NTRK2, COL14A1,
SCN4B, ATP1A2, SLC17A7, SLIT3, COL7A1, CLDN4, CLEC3B, ADCYAP1R1, and MFAP4 were
identified as crucial genes, with SLIT3, COL7A1, and CLDN4 being strongly
linked to GBC development and prediction.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ FashionR2R: Texture-preserving Rendered-to-Real Image Translation with
  Diffusion Models <span class="chip">NeurIPS 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14429v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14429v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Rui Hu, Qian He, Gaofeng He, Jiedong Zhuang, Huang Chen, Huafeng Liu, Huamin Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Modeling and producing lifelike clothed human images has attracted
researchers' attention from different areas for decades, with the complexity
from highly articulated and structured content. Rendering algorithms decompose
and simulate the imaging process of a camera, while are limited by the accuracy
of modeled variables and the efficiency of computation. Generative models can
produce impressively vivid human images, however still lacking in
controllability and editability. This paper studies photorealism enhancement of
rendered images, leveraging generative power from diffusion models on the
controlled basis of rendering. We introduce a novel framework to translate
rendered images into their realistic counterparts, which consists of two
stages: Domain Knowledge Injection (DKI) and Realistic Image Generation (RIG).
In DKI, we adopt positive (real) domain finetuning and negative (rendered)
domain embedding to inject knowledge into a pretrained Text-to-image (T2I)
diffusion model. In RIG, we generate the realistic image corresponding to the
input rendered image, with a Texture-preserving Attention Control (TAC) to
preserve fine-grained clothing textures, exploiting the decoupled features
encoded in the UNet structure. Additionally, we introduce SynFashion dataset,
featuring high-quality digital clothing images with diverse textures. Extensive
experimental results demonstrate the superiority and effectiveness of our
method in rendered-to-real image translation.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by NeurIPS 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Predicting time-varying flux and balance in metabolic systems using
  structured neural-ODE processes 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14426v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14426v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Santanu Rathod, Pietro Lio, Xiao Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We develop a novel data-driven framework as an alternative to dynamic flux
balance analysis, bypassing the demand for deep domain knowledge and manual
efforts to formulate the optimization problem. The proposed framework is
end-to-end, which trains a structured neural ODE process (SNODEP) model to
estimate flux and balance samples using gene-expression time-series data.
SNODEP is designed to circumvent the limitations of the standard neural ODE
process model, including restricting the latent and decoder sampling
distributions to be normal and lacking structure between context points for
calculating the latent, thus more suitable for modeling the underlying dynamics
of a metabolic system. Through comprehensive experiments ($156$ in total), we
demonstrate that SNODEP not only predicts the unseen time points of real-world
gene-expression data and the flux and balance estimates well but can even
generalize to more challenging unseen knockout configurations and irregular
data sampling scenarios, all essential for metabolic pathway analysis. We hope
our work can serve as a catalyst for building more scalable and powerful models
for genome-scale metabolic analysis. Our code is available at:
\url{https://github.com/TrustMLRG/SNODEP}.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Integrating Deep Learning with Fundus and Optical Coherence Tomography
  for Cardiovascular Disease Prediction 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14423v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14423v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Cynthia Maldonado-Garcia, Arezoo Zakeri, Alejandro F Frangi, Nishant Ravikumar
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Early identification of patients at risk of cardiovascular diseases (CVD) is
crucial for effective preventive care, reducing healthcare burden, and
improving patients' quality of life. This study demonstrates the potential of
retinal optical coherence tomography (OCT) imaging combined with fundus
photographs for identifying future adverse cardiac events. We used data from
977 patients who experienced CVD within a 5-year interval post-image
acquisition, alongside 1,877 control participants without CVD, totaling 2,854
subjects. We propose a novel binary classification network based on a
Multi-channel Variational Autoencoder (MCVAE), which learns a latent embedding
of patients' fundus and OCT images to classify individuals into two groups:
those likely to develop CVD in the future and those who are not. Our model,
trained on both imaging modalities, achieved promising results (AUROC 0.78 +/-
0.02, accuracy 0.68 +/- 0.002, precision 0.74 +/- 0.02, sensitivity 0.73 +/-
0.02, and specificity 0.68 +/- 0.01), demonstrating its efficacy in identifying
patients at risk of future CVD events based on their retinal images. This study
highlights the potential of retinal OCT imaging and fundus photographs as
cost-effective, non-invasive alternatives for predicting cardiovascular disease
risk. The widespread availability of these imaging techniques in optometry
practices and hospitals further enhances their potential for large-scale CVD
risk screening. Our findings contribute to the development of standardized,
accessible methods for early CVD risk identification, potentially improving
preventive care strategies and patient outcomes.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Part of the book series: Lecture Notes in Computer Science
  ((LNCS,volume 15155))</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Asymptotic non-linear shrinkage formulas for weighted sample covariance 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14420v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14420v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Benoit Oriol
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We compute asymptotic non-linear shrinkage formulas for covariance and
precision matrix estimators for weighted sample covariances, in the spirit of
Ledoit and P\'ech\'e. We detail explicitly the formulas for
exponentially-weighted sample covariances. Those new tools pave a way for
applying non-linear shrinkage methods on weighted sample covariance. We show
experimentally the performance of the asymptotic shrinkage formulas. Finally,
we test the robustness of the theory to a heavy-tailed distributions.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ An explainable machine learning approach for energy forecasting at the
  household level 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14416v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14416v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Pauline Béraud, Margaux Rioux, Michel Babany, Philippe de La Chevasnerie, Damien Theis, Giacomo Teodori, Chloé Pinguet, Romane Rigaud, François Leclerc
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Electricity forecasting has been a recurring research topic, as it is key to
finding the right balance between production and consumption. While most papers
are focused on the national or regional scale, few are interested in the
household level. Desegregated forecast is a common topic in Machine Learning
(ML) literature but lacks explainability that household energy forecasts
require. This paper specifically targets the challenges of forecasting
electricity use at the household level. This paper confronts common Machine
Learning algorithms to electricity household forecasts, weighing the pros and
cons, including accuracy and explainability with well-known key metrics.
Furthermore, we also confront them in this paper with the business challenges
specific to this sector such as explainability or outliers resistance. We
introduce a custom decision tree, aiming at providing a fair estimate of the
energy consumption, while being explainable and consistent with human
intuition. We show that this novel method allows greater explainability without
sacrificing much accuracy. The custom tree methodology can be used in various
business use cases but is subject to limitations, such as a lack of resilience
with outliers.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ WeSpeR: Population spectrum retrieval and spectral density estimation of
  weighted sample covariance 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14413v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14413v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Benoit Oriol
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The spectrum of the weighted sample covariance shows a asymptotic non random
behavior when the dimension grows with the number of samples. In this setting,
we prove that the asymptotic spectral distribution $F$ of the weighted sample
covariance has a continuous density on $\mathbb{R}^*$. We address then the
practical problem of numerically finding this density. We propose a procedure
to compute it, to determine the support of $F$ and define an efficient grid on
it. We use this procedure to design the $\textit{WeSpeR}$ algorithm, which
estimates the spectral density and retrieves the true spectral covariance
spectrum. Empirical tests confirm the good properties of the $\textit{WeSpeR}$
algorithm.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ SNAC: Multi-Scale Neural Audio Codec 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14411v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14411v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hubert Siuzdak, Florian Grötschla, Luca A. Lanzendörfer
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Neural audio codecs have recently gained popularity because they can
represent audio signals with high fidelity at very low bitrates, making it
feasible to use language modeling approaches for audio generation and
understanding. Residual Vector Quantization (RVQ) has become the standard
technique for neural audio compression using a cascade of VQ codebooks. This
paper proposes the Multi-Scale Neural Audio Codec, a simple extension of RVQ
where the quantizers can operate at different temporal resolutions. By applying
a hierarchy of quantizers at variable frame rates, the codec adapts to the
audio structure across multiple timescales. This leads to more efficient
compression, as demonstrated by extensive objective and subjective evaluations.
The code and model weights are open-sourced at
https://github.com/hubertsiuzdak/snac.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Debug Smarter, Not Harder: AI Agents for Error Resolution in
  Computational Notebooks <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14393v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14393v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Konstantin Grotov, Artem Borzilov, Maksim Krivobok, Timofey Bryksin, Yaroslav Zharov
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Computational notebooks became indispensable tools for research-related
development, offering unprecedented interactivity and flexibility in the
development process. However, these benefits come at the cost of
reproducibility and an increased potential for bugs. With the rise of
code-fluent Large Language Models empowered with agentic techniques, smart
bug-fixing tools with a high level of autonomy have emerged. However, those
tools are tuned for classical script programming and still struggle with
non-linear computational notebooks. In this paper, we present an AI agent
designed specifically for error resolution in a computational notebook. We have
developed an agentic system capable of exploring a notebook environment by
interacting with it -- similar to how a user would -- and integrated the system
into the JetBrains service for collaborative data science called Datalore. We
evaluate our approach against the pre-existing single-action solution by
comparing costs and conducting a user study. Users rate the error resolution
capabilities of the agentic system higher but experience difficulties with UI.
We share the results of the study and consider them valuable for further
improving user-agent collaboration.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to EMNLP 2024 System Demonstrations</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Personalizing Low-Rank Bayesian Neural Networks Via Federated Learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14390v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14390v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Boning Zhang, Dongzhu Liu, Osvaldo Simeone, Guanchu Wang, Dimitrios Pezaros, Guangxu Zhu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  To support real-world decision-making, it is crucial for models to be
well-calibrated, i.e., to assign reliable confidence estimates to their
predictions. Uncertainty quantification is particularly important in
personalized federated learning (PFL), as participating clients typically have
small local datasets, making it difficult to unambiguously determine optimal
model parameters. Bayesian PFL (BPFL) methods can potentially enhance
calibration, but they often come with considerable computational and memory
requirements due to the need to track the variances of all the individual model
parameters. Furthermore, different clients may exhibit heterogeneous
uncertainty levels owing to varying local dataset sizes and distributions. To
address these challenges, we propose LR-BPFL, a novel BPFL method that learns a
global deterministic model along with personalized low-rank Bayesian
corrections. To tailor the local model to each client's inherent uncertainty
level, LR-BPFL incorporates an adaptive rank selection mechanism. We evaluate
LR-BPFL across a variety of datasets, demonstrating its advantages in terms of
calibration, accuracy, as well as computational and memory requirements.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ SurgeryV2: Bridging the Gap Between Model Merging and Multi-Task
  Learning with Deep Representation Surgery <span class="chip">ICML 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14389v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14389v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Enneng Yang, Li Shen, Zhenyi Wang, Guibing Guo, Xingwei Wang, Xiaocun Cao, Jie Zhang, Dacheng Tao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Model merging-based multitask learning (MTL) offers a promising approach for
performing MTL by merging multiple expert models without requiring access to
raw training data. However, in this paper, we examine the merged model's
representation distribution and uncover a critical issue of "representation
bias". This bias arises from a significant distribution gap between the
representations of the merged and expert models, leading to the suboptimal
performance of the merged MTL model. To address this challenge, we first
propose a representation surgery solution called Surgery. Surgery is a
lightweight, task-specific module that aligns the final layer representations
of the merged model with those of the expert models, effectively alleviating
bias and improving the merged model's performance. Despite these improvements,
a performance gap remains compared to the traditional MTL method. Further
analysis reveals that representation bias phenomena exist at each layer of the
merged model, and aligning representations only in the last layer is
insufficient for fully reducing systemic bias because biases introduced at each
layer can accumulate and interact in complex ways. To tackle this, we then
propose a more comprehensive solution, deep representation surgery (also called
SurgeryV2), which mitigates representation bias across all layers, and thus
bridges the performance gap between model merging-based MTL and traditional
MTL. Finally, we design an unsupervised optimization objective to optimize both
the Surgery and SurgeryV2 modules. Our experimental results show that
incorporating these modules into state-of-the-art (SOTA) model merging schemes
leads to significant performance gains. Notably, our SurgeryV2 scheme reaches
almost the same level as individual expert models or the traditional MTL model.
The code is available at \url{https://github.com/EnnengYang/SurgeryV2}.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>This paper is an extended version of our previous work
  [arXiv:2402.02705] presented at ICML 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Unscrambling disease progression at scale: fast inference of event
  permutations with optimal transport <span class="chip">NeurIPS 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14388v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14388v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Peter A. Wijeratne, Daniel C. Alexander
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Disease progression models infer group-level temporal trajectories of change
in patients' features as a chronic degenerative condition plays out. They
provide unique insight into disease biology and staging systems with
individual-level clinical utility. Discrete models consider disease progression
as a latent permutation of events, where each event corresponds to a feature
becoming measurably abnormal. However, permutation inference using traditional
maximum likelihood approaches becomes prohibitive due to combinatoric
explosion, severely limiting model dimensionality and utility. Here we leverage
ideas from optimal transport to model disease progression as a latent
permutation matrix of events belonging to the Birkhoff polytope, facilitating
fast inference via optimisation of the variational lower bound. This enables a
factor of 1000 times faster inference than the current state of the art and,
correspondingly, supports models with several orders of magnitude more features
than the current state of the art can consider. Experiments demonstrate the
increase in speed, accuracy and robustness to noise in simulation. Further
experiments with real-world imaging data from two separate datasets, one from
Alzheimer's disease patients, the other age-related macular degeneration,
showcase, for the first time, pixel-level disease progression events in the
brain and eye, respectively. Our method is low compute, interpretable and
applicable to any progressive condition and data modality, giving it broad
potential clinical utility.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Pre-print of version accepted to NeurIPS 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Investigating the Capabilities of Deep Learning for Processing and
  Interpreting One-Shot Multi-offset GPR Data: A Numerical Case Study for Lunar
  and Martian Environments 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14386v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14386v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Iraklis Giannakis, Craig Warren, Antonios Giannopoulos, Georgios Leontidis, Yan Su, Feng Zhou, Javier Martin-Torres, Nectaria Diamanti
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Ground-penetrating radar (GPR) is a mature geophysical method that has gained
increasing popularity in planetary science over the past decade. GPR has been
utilised both for Lunar and Martian missions providing pivotal information
regarding the near surface geology of Terrestrial planets. Within that context,
numerous processing pipelines have been suggested to address the unique
challenges present in planetary setups. These processing pipelines often
require manual tuning resulting to ambiguous outputs open to non-unique
interpretations. These pitfalls combined with the large number of planetary GPR
data (kilometers in magnitude), highlight the necessity for automatic,
objective and advanced processing and interpretation schemes. The current paper
investigates the potential of deep learning for interpreting and processing GPR
data. The one-shot multi-offset configuration is investigated via a coherent
numerical case study, showcasing the potential of deep learning for A)
reconstructing the dielectric distribution of the the near surface of
Terrestrial planets, and B) filling missing or bad-quality traces. Special care
was taken for the numerical data to be both realistic and challenging.
Moreover, the generated synthetic data are properly labelled and made publicly
available for training future data-driven pipelines and contributing towards
developing pre-trained foundation models for GPR.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Dual-Label LearningWith Irregularly Present Labels 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14380v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14380v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mingqian Li, Qiao Han, Yiteng Zhai, Ruifeng Li, Yao Yang, Hongyang Chen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In multi-task learning, we often encounter the case when the presence of
labels across samples exhibits irregular patterns: samples can be fully
labeled, partially labeled or unlabeled. Taking drug analysis as an example,
multiple toxicity properties of a drug molecule may not be concurrently
available due to experimental limitations. It triggers a demand for a new
training and inference mechanism that could accommodate irregularly present
labels and maximize the utility of any available label information. In this
work, we focus on the two-label learning task, and propose a novel training and
inference framework, Dual-Label Learning (DLL). The DLL framework formulates
the problem into a dual-function system, in which the two functions should
simultaneously satisfy standard supervision, structural duality and
probabilistic duality. DLL features a dual-tower model architecture that
explicitly captures the information exchange between labels, aimed at
maximizing the utility of partially available labels in understanding label
correlation. During training, label imputation for missing labels is conducted
as part of the forward propagation process, while during inference, labels are
regarded as unknowns of a bivariate system of equations and are solved jointly.
Theoretical analysis guarantees the feasibility of DLL, and extensive
experiments are conducted to verify that by explicitly modeling label
correlation and maximizing the utility of available labels, our method makes
consistently better predictions than baseline approaches by up to a 10% gain in
F1-score or MAPE. Remarkably, our method provided with data at a label missing
rate as high as 60% can achieve similar or even better results than baseline
approaches at a label missing rate of only 10%.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Fine-Tuning <span class="highlight-title">Pre-train</span>ed Language Models for Robust Causal Representation
  Learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14375v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14375v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jialin Yu, Yuxiang Zhou, Yulan He, Nevin L. Zhang, Ricardo Silva
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The fine-tuning of pre-trained language models (PLMs) has been shown to be
effective across various domains. By using domain-specific supervised data, the
general-purpose representation derived from PLMs can be transformed into a
domain-specific representation. However, these methods often fail to generalize
to out-of-domain (OOD) data due to their reliance on non-causal
representations, often described as spurious features. Existing methods either
make use of adjustments with strong assumptions about lack of hidden common
causes, or mitigate the effect of spurious features using multi-domain data. In
this work, we investigate how fine-tuned pre-trained language models aid
generalizability from single-domain scenarios under mild assumptions, targeting
more general and practical real-world scenarios. We show that a robust
representation can be derived through a so-called causal front-door adjustment,
based on a decomposition assumption, using fine-tuned representations as a
source of data augmentation. Comprehensive experiments in both synthetic and
real-world settings demonstrate the superior generalizability of the proposed
method compared to existing approaches. Our work thus sheds light on the domain
generalization problem by introducing links between fine-tuning and causal
mechanisms into representation learning.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ A Scientific Machine Learning Approach for Predicting and Forecasting
  Battery Degradation in Electric Vehicles 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14347v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14347v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Sharv Murgai, Hrishikesh Bhagwat, Raj Abhijit Dandekar, Rajat Dandekar, Sreedath Panat
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Carbon emissions are rising at an alarming rate, posing a significant threat
to global efforts to mitigate climate change. Electric vehicles have emerged as
a promising solution, but their reliance on lithium-ion batteries introduces
the critical challenge of battery degradation. Accurate prediction and
forecasting of battery degradation over both short and long time spans are
essential for optimizing performance, extending battery life, and ensuring
effective long-term energy management. This directly influences the
reliability, safety, and sustainability of EVs, supporting their widespread
adoption and aligning with key UN SDGs. In this paper, we present a novel
approach to the prediction and long-term forecasting of battery degradation
using Scientific Machine Learning framework which integrates domain knowledge
with neural networks, offering more interpretable and scientifically grounded
solutions for both predicting short-term battery health and forecasting
degradation over extended periods. This hybrid approach captures both known and
unknown degradation dynamics, improving predictive accuracy while reducing data
requirements. We incorporate ground-truth data to inform our models, ensuring
that both the predictions and forecasts reflect practical conditions. The model
achieved MSE of 9.90 with the UDE and 11.55 with the NeuralODE, in experimental
data, a loss of 1.6986 with the UDE, and a MSE of 2.49 in the NeuralODE,
demonstrating the enhanced precision of our approach. This integration of
data-driven insights with SciML's strengths in interpretability and scalability
allows for robust battery management. By enhancing battery longevity and
minimizing waste, our approach contributes to the sustainability of energy
systems and accelerates the global transition toward cleaner, more responsible
energy solutions, aligning with the UN's SDG agenda.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Evaluating the evaluators: Towards human-aligned metrics for missing
  markers reconstruction 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14334v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14334v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Taras Kucherenko, Derek Peristy, Judith Bütepage
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Animation data is often obtained through optical motion capture systems,
which utilize a multitude of cameras to establish the position of optical
markers. However, system errors or occlusions can result in missing markers,
the manual cleaning of which can be time-consuming. This has sparked interest
in machine learning-based solutions for missing marker reconstruction in the
academic community. Most academic papers utilize a simplistic mean square error
as the main metric. In this paper, we show that this metric does not correlate
with subjective perception of the fill quality. We introduce and evaluate a set
of better-correlated metrics that can drive progress in the field.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Fast proxy centers for Jeffreys centroids: The Jeffreys-Fisher-Rao and
  the inductive Gauss-Bregman centers 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14326v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14326v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Frank Nielsen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The symmetric Kullback-Leibler centroid also called the Jeffreys centroid of
a set of mutually absolutely continuous probability distributions on a measure
space provides a notion of centrality which has proven useful in many tasks
including information retrieval, information fusion, and clustering in image,
video and sound processing. However, the Jeffreys centroid is not available in
closed-form for sets of categorical or normal distributions, two widely used
statistical models, and thus need to be approximated numerically in practice.
In this paper, we first propose the new Jeffreys-Fisher-Rao center defined as
the Fisher-Rao midpoint of the sided Kullback-Leibler centroids as a plug-in
replacement of the Jeffreys centroid. This Jeffreys-Fisher-Rao center admits a
generic formula for uni-parameter exponential family distributions, and
closed-form formula for categorical and normal distributions, matches exactly
the Jeffreys centroid for same-mean normal distributions, and is experimentally
observed in practice to be close to the Jeffreys centroid. Second, we define a
new type of inductive centers generalizing the principle of Gauss
arithmetic-geometric double sequence mean for pairs of densities of any given
exponential family. This center is shown experimentally to approximate very
well the Jeffreys centroid and is suggested to use when the Jeffreys-Fisher-Rao
center is not available in closed form. Moreover, this Gauss-Bregman inductive
center always converges and matches the Jeffreys centroid for sets of same-mean
normal distributions. We report on our experiments demonstrating the use of the
Jeffreys-Fisher-Rao and Gauss-Bregman centers instead of the Jeffreys centroid.
Finally, we conclude this work by reinterpreting these fast proxy centers of
Jeffreys centroids under the lens of dually flat spaces in information
geometry.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>35 pages, 10 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Debiasing Mini-Batch Quadratics for Applications in Deep Learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14325v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14325v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Lukas Tatzel, Bálint Mucsányi, Osane Hackel, Philipp Hennig
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Quadratic approximations form a fundamental building block of machine
learning methods. E.g., second-order optimizers try to find the Newton step
into the minimum of a local quadratic proxy to the objective function; and the
second-order approximation of a network's loss function can be used to quantify
the uncertainty of its outputs via the Laplace approximation. When computations
on the entire training set are intractable - typical for deep learning - the
relevant quantities are computed on mini-batches. This, however, distorts and
biases the shape of the associated stochastic quadratic approximations in an
intricate way with detrimental effects on applications. In this paper, we (i)
show that this bias introduces a systematic error, (ii) provide a theoretical
explanation for it, (iii) explain its relevance for second-order optimization
and uncertainty quantification via the Laplace approximation in deep learning,
and (iv) develop and evaluate debiasing strategies.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Main text (including references): 13 pages, 6 figures; Supplements:
  25 pages, 13 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Optimizing importance weighting in the presence of sub-population shifts 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14315v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14315v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Floris Holstege, Bram Wouters, Noud van Giersbergen, Cees Diks
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  A distribution shift between the training and test data can severely harm
performance of machine learning models. Importance weighting addresses this
issue by assigning different weights to data points during training. We argue
that existing heuristics for determining the weights are suboptimal, as they
neglect the increase of the variance of the estimated model due to the finite
sample size of the training data. We interpret the optimal weights in terms of
a bias-variance trade-off, and propose a bi-level optimization procedure in
which the weights and model parameters are optimized simultaneously. We apply
this optimization to existing importance weighting techniques for last-layer
retraining of deep neural networks in the presence of sub-population shifts and
show empirically that optimizing weights significantly improves generalization
performance.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Preprint. Currently under review</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ PTR: A <span class="highlight-title">Pre-train</span>ed Language Model for Trajectory Recovery 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14281v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14281v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Tonglong Wei, Yan Lin, Youfang Lin, Shengnan Guo, Jilin Hu, Gao Cong, Huaiyu Wan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Spatiotemporal trajectory data is vital for web-of-things services and is
extensively collected and analyzed by web-based hardware and platforms.
However, issues such as service interruptions and network instability often
lead to sparsely recorded trajectories, resulting in a loss of detailed
movement data. As a result, recovering these trajectories to restore missing
information becomes essential. Despite progress, several challenges remain
unresolved. First, the lack of large-scale dense trajectory data hampers the
performance of existing deep learning methods, which rely heavily on abundant
data for supervised training. Second, current methods struggle to generalize
across sparse trajectories with varying sampling intervals, necessitating
separate re-training for each interval and increasing computational costs.
Third, external factors crucial for the recovery of missing points are not
fully incorporated.
  To address these challenges, we propose a framework called PTR. This
framework mitigates the issue of limited dense trajectory data by leveraging
the capabilities of pre-trained language models (PLMs). PTR incorporates an
explicit trajectory prompt and is trained on datasets with multiple sampling
intervals, enabling it to generalize effectively across different intervals in
sparse trajectories. To capture external factors, we introduce an implicit
trajectory prompt that models road conditions, providing richer information for
recovering missing points. Additionally, we present a trajectory embedder that
encodes trajectory points and transforms the embeddings of both observed and
missing points into a format comprehensible to PLMs. Experimental results on
two public trajectory datasets with three sampling intervals demonstrate the
efficacy and scalability of PTR.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Stochastic Quasi-Newton Optimization in Large Dimensions Including Deep
  Network Training 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14270v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14270v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Uttam Suman, Mariya Mamajiwala, Mukul Saxena, Ankit Tyagi, Debasish Roy
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Our proposal is on a new stochastic optimizer for non-convex and possibly
non-smooth objective functions typically defined over large dimensional design
spaces. Towards this, we have tried to bridge noise-assisted global search and
faster local convergence, the latter being the characteristic feature of a
Newton-like search. Our specific scheme -- acronymed FINDER (Filtering Informed
Newton-like and Derivative-free Evolutionary Recursion), exploits the nonlinear
stochastic filtering equations to arrive at a derivative-free update that has
resemblance with the Newton search employing the inverse Hessian of the
objective function. Following certain simplifications of the update to enable a
linear scaling with dimension and a few other enhancements, we apply FINDER to
a range of problems, starting with some IEEE benchmark objective functions to a
couple of archetypal data-driven problems in deep networks to certain cases of
physics-informed deep networks. The performance of the new method vis-\'a-vis
the well-known Adam and a few others bears evidence to its promise and
potentialities for large dimensional optimization problems of practical
interest.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>19 pages, 12 figures, 3 tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ On time series clustering with k-means 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14269v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14269v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Christopher Holder, Anthony Bagnall, Jason Lines
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  There is a long history of research into time series clustering using
distance-based partitional clustering. Many of the most popular algorithms
adapt k-means (also known as Lloyd's algorithm) to exploit time dependencies in
the data by specifying a time series distance function. However, these
algorithms are often presented with k-means configured in various ways,
altering key parameters such as the initialisation strategy. This variability
makes it difficult to compare studies because k-means is known to be highly
sensitive to its configuration. To address this, we propose a standard
Lloyd's-based model for TSCL that adopts an end-to-end approach, incorporating
a specialised distance function not only in the assignment step but also in the
initialisation and stopping criteria. By doing so, we create a unified
structure for comparing seven popular Lloyd's-based TSCL algorithms. This
common framework enables us to more easily attribute differences in clustering
performance to the distance function itself, rather than variations in the
k-means configuration.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ MoDification: Mixture of Depths Made Easy 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14268v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14268v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Chen Zhang, Meizhi Zhong, Qimeng Wang, Xuantao Lu, Zheyu Ye, Chengqiang Lu, Yan Gao, Yao Hu, Kehai Chen, Min Zhang, Dawei Song
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Long-context efficiency has recently become a trending topic in serving large
language models (LLMs). And mixture of depths (MoD) is proposed as a perfect
fit to bring down both latency and memory. In this paper, however, we discover
that MoD can barely transform existing LLMs without costly training over an
extensive number of tokens. To enable the transformations from any LLMs to MoD
ones, we showcase top-k operator in MoD should be promoted to threshold-p
operator, and refinement to architecture and data should also be crafted along.
All these designs form our method termed MoDification. Through a comprehensive
set of experiments covering model scales from 3B to 70B, we exhibit
MoDification strikes an excellent balance between efficiency and effectiveness.
MoDification can achieve up to ~1.2x speedup in latency and ~1.8x reduction in
memory compared to original LLMs especially in long-context applications.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>12 pages, 9 figures, 5 tables, work in progress</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Revisiting SLO and Goodput Metrics in LLM Serving 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14257v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14257v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zhibin Wang, Shipeng Li, Yuhang Zhou, Xue Li, Rong Gu, Nguyen Cam-Tu, Chen Tian, Sheng Zhong
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large language models (LLMs) have achieved remarkable performance and are
widely deployed in various applications, while the serving of LLM inference has
raised concerns about user experience and serving throughput. Accordingly,
service level objectives (SLOs) and goodput-the number of requests that meet
SLOs per second-are introduced to evaluate the performance of LLM serving.
However, existing metrics fail to capture the nature of user experience. We
observe two ridiculous phenomena in existing metrics: 1) delaying token
delivery can smooth the tail time between tokens (tail TBT) of a request and 2)
dropping the request that fails to meet the SLOs midway can improve goodput.
  In this paper, we revisit SLO and goodput metrics in LLM serving and propose
a unified metric framework smooth goodput including SLOs and goodput to reflect
the nature of user experience in LLM serving. The framework can adapt to
specific goals of different tasks by setting parameters. We re-evaluate the
performance of different LLM serving systems under multiple workloads based on
this unified framework and provide possible directions for future optimization
of existing strategies. We hope that this framework can provide a unified
standard for evaluating LLM serving and foster researches in the field of LLM
serving optimization to move in a cohesive direction.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ RAZOR: Refining Accuracy by Zeroing Out Redundancies 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14254v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14254v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Daniel Riccio, Genoveffa Tortora, Mara Sangiovanni
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In many application domains, the proliferation of sensors and devices is
generating vast volumes of data, imposing significant pressure on existing data
analysis and data mining techniques. Nevertheless, an increase in data volume
does not inherently imply an increase in informational content, as a
substantial portion may be redundant or represent noise. This challenge is
particularly evident in the deep learning domain, where the utility of
additional data is contingent on its informativeness. In the absence of such,
larger datasets merely exacerbate the computational cost and complexity of the
learning process. To address these challenges, we propose RAZOR, a novel
instance selection technique designed to extract a significantly smaller yet
sufficiently informative subset from a larger set of instances without
compromising the learning process. RAZOR has been specifically engineered to be
robust, efficient, and scalable, making it suitable for large-scale datasets.
Unlike many techniques in the literature, RAZOR is capable of operating in both
supervised and unsupervised settings. Experimental results demonstrate that
RAZOR outperforms recent state-of-the-art techniques in terms of both
effectiveness and efficiency.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>17 pages, 3 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Pseudo-label Refinement for Improving <span class="highlight-title">Self-Supervised</span> Learning Systems 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14242v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14242v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                         Zia-ur-Rehman, Arif Mahmood, Wenxiong Kang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Self-supervised learning systems have gained significant attention in recent
years by leveraging clustering-based pseudo-labels to provide supervision
without the need for human annotations. However, the noise in these
pseudo-labels caused by the clustering methods poses a challenge to the
learning process leading to degraded performance. In this work, we propose a
pseudo-label refinement (SLR) algorithm to address this issue. The cluster
labels from the previous epoch are projected to the current epoch
cluster-labels space and a linear combination of the new label and the
projected label is computed as a soft refined label containing the information
from the previous epoch clusters as well as from the current epoch. In contrast
to the common practice of using the maximum value as a cluster/class indicator,
we employ hierarchical clustering on these soft pseudo-labels to generate
refined hard-labels. This approach better utilizes the information embedded in
the soft labels, outperforming the simple maximum value approach for hard label
generation. The effectiveness of the proposed SLR algorithm is evaluated in the
context of person re-identification (Re-ID) using unsupervised domain
adaptation (UDA). Experimental results demonstrate that the modified Re-ID
baseline, incorporating the SLR algorithm, achieves significantly improved mean
Average Precision (mAP) performance in various UDA tasks, including
real-to-synthetic, synthetic-to-real, and different real-to-real scenarios.
These findings highlight the efficacy of the SLR algorithm in enhancing the
performance of self-supervised learning systems.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Almost-Linear RNNs Yield Highly Interpretable Symbolic Codes in
  Dynamical Systems Reconstruction <span class="chip">NeurIPS
  2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14240v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14240v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Manuel Brenner, Christoph Jürgen Hemmer, Zahra Monfared, Daniel Durstewitz
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Dynamical systems (DS) theory is fundamental for many areas of science and
engineering. It can provide deep insights into the behavior of systems evolving
in time, as typically described by differential or recursive equations. A
common approach to facilitate mathematical tractability and interpretability of
DS models involves decomposing nonlinear DS into multiple linear DS separated
by switching manifolds, i.e. piecewise linear (PWL) systems. PWL models are
popular in engineering and a frequent choice in mathematics for analyzing the
topological properties of DS. However, hand-crafting such models is tedious and
only possible for very low-dimensional scenarios, while inferring them from
data usually gives rise to unnecessarily complex representations with very many
linear subregions. Here we introduce Almost-Linear Recurrent Neural Networks
(AL-RNNs) which automatically and robustly produce most parsimonious PWL
representations of DS from time series data, using as few PWL nonlinearities as
possible. AL-RNNs can be efficiently trained with any SOTA algorithm for
dynamical systems reconstruction (DSR), and naturally give rise to a symbolic
encoding of the underlying DS that provably preserves important topological
properties. We show that for the Lorenz and R\"ossler systems, AL-RNNs
discover, in a purely data-driven way, the known topologically minimal PWL
representations of the corresponding chaotic attractors. We further illustrate
on two challenging empirical datasets that interpretable symbolic encodings of
the dynamics can be achieved, tremendously facilitating mathematical and
computational analysis of the underlying systems.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>38th Conference on Neural Information Processing Systems (NeurIPS
  2024)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Unified Convergence Analysis for Score-Based Diffusion Models with
  Deterministic Samplers 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14237v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14237v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Runjia Li, Qiwei Di, Quanquan Gu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Score-based diffusion models have emerged as powerful techniques for
generating samples from high-dimensional data distributions. These models
involve a two-phase process: first, injecting noise to transform the data
distribution into a known prior distribution, and second, sampling to recover
the original data distribution from noise. Among the various sampling methods,
deterministic samplers stand out for their enhanced efficiency. However,
analyzing these deterministic samplers presents unique challenges, as they
preclude the use of established techniques such as Girsanov's theorem, which
are only applicable to stochastic samplers. Furthermore, existing analysis for
deterministic samplers usually focuses on specific examples, lacking a
generalized approach for general forward processes and various deterministic
samplers. Our paper addresses these limitations by introducing a unified
convergence analysis framework. To demonstrate the power of our framework, we
analyze the variance-preserving (VP) forward process with the exponential
integrator (EI) scheme, achieving iteration complexity of $\tilde
O(d^2/\epsilon)$. Additionally, we provide a detailed analysis of Denoising
Diffusion Implicit Models (DDIM)-type samplers, which have been underexplored
in previous research, achieving polynomial iteration complexity.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>68 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ G-NeuroDAVIS: A Neural Network model for generalized embedding, data
  visualization and sample generation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14223v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14223v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Chayan Maitra, Rajat K. De
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Visualizing high-dimensional datasets through a generalized embedding has
been a challenge for a long time. Several methods have shown up for the same,
but still, they have not been able to generate a generalized embedding, which
not only can reveal the hidden patterns present in the data but also generate
realistic high-dimensional samples from it. Motivated by this aspect, in this
study, a novel generative model, called G-NeuroDAVIS, has been developed, which
is capable of visualizing high-dimensional data through a generalized
embedding, and thereby generating new samples. The model leverages advanced
generative techniques to produce high-quality embedding that captures the
underlying structure of the data more effectively than existing methods.
G-NeuroDAVIS can be trained in both supervised and unsupervised settings. We
rigorously evaluated our model through a series of experiments, demonstrating
superior performance in classification tasks, which highlights the robustness
of the learned representations. Furthermore, the conditional sample generation
capability of the model has been described through qualitative assessments,
revealing a marked improvement in generating realistic and diverse samples.
G-NeuroDAVIS has outperformed the Variational Autoencoder (VAE) significantly
in multiple key aspects, including embedding quality, classification
performance, and sample generation capability. These results underscore the
potential of our generative model to serve as a powerful tool in various
applications requiring high-quality data generation and representation
learning.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>15 pages, 8 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Formal Explanations for Neuro-Symbolic AI 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14219v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14219v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Sushmita Paul, Jinqiang Yu, Jip J. Dekker, Alexey Ignatiev, Peter J. Stuckey
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Despite the practical success of Artificial Intelligence (AI), current neural
AI algorithms face two significant issues. First, the decisions made by neural
architectures are often prone to bias and brittleness. Second, when a chain of
reasoning is required, neural systems often perform poorly. Neuro-symbolic
artificial intelligence is a promising approach that tackles these (and other)
weaknesses by combining the power of neural perception and symbolic reasoning.
Meanwhile, the success of AI has made it critical to understand its behaviour,
leading to the development of explainable artificial intelligence (XAI). While
neuro-symbolic AI systems have important advantages over purely neural AI, we
still need to explain their actions, which are obscured by the interactions of
the neural and symbolic components. To address the issue, this paper proposes a
formal approach to explaining the decisions of neuro-symbolic systems. The
approach hinges on the use of formal abductive explanations and on solving the
neuro-symbolic explainability problem hierarchically. Namely, it first computes
a formal explanation for the symbolic component of the system, which serves to
identify a subset of the individual parts of neural information that needs to
be explained. This is followed by explaining only those individual neural
inputs, independently of each other, which facilitates succinctness of
hierarchical formal explanations and helps to increase the overall performance
of the approach. Experimental results for a few complex reasoning tasks
demonstrate practical efficiency of the proposed approach, in comparison to
purely neural systems, from the perspective of explanation size, explanation
time, training time, model sizes, and the quality of explanations reported.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Comparative Evaluation of Clustered Federated Learning Method 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14212v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14212v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Michael Ben Ali, Omar El-Rifai, Imen Megdiche, André Peninou, Olivier Teste
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Over recent years, Federated Learning (FL) has proven to be one of the most
promising methods of distributed learning which preserves data privacy. As the
method evolved and was confronted to various real-world scenarios, new
challenges have emerged. One such challenge is the presence of highly
heterogeneous (often referred as non-IID) data distributions among participants
of the FL protocol. A popular solution to this hurdle is Clustered Federated
Learning (CFL), which aims to partition clients into groups where the
distribution are homogeneous. In the literature, state-of-the-art CFL
algorithms are often tested using a few cases of data heterogeneities, without
systematically justifying the choices. Further, the taxonomy used for
differentiating the different heterogeneity scenarios is not always
straightforward. In this paper, we explore the performance of two
state-of-theart CFL algorithms with respect to a proposed taxonomy of data
heterogeneities in federated learning (FL). We work with three image
classification datasets and analyze the resulting clusters against the
heterogeneity classes using extrinsic clustering metrics. Our objective is to
provide a clearer understanding of the relationship between CFL performances
and data heterogeneity scenarios.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Montessori-Instruct: Generate Influential Training Data Tailored for
  Student Learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14208v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14208v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xiaochuan Li, Zichun Yu, Chenyan Xiong
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Synthetic data has been widely used to train large language models, but their
generative nature inevitably introduces noisy, non-informative, and misleading
learning signals. In this paper, we propose Montessori-Instruct, a novel data
synthesis framework that tailors the data synthesis ability of the teacher
language model toward the student language model's learning process.
Specifically, we utilize local data influence of synthetic training data points
on students to characterize students' learning preferences. Then, we train the
teacher model with Direct Preference Optimization (DPO) to generate synthetic
data tailored toward student learning preferences. Experiments with
Llama3-8B-Instruct (teacher) and Llama3-8B (student) on Alpaca Eval and
MT-Bench demonstrate that Montessori-Instruct significantly outperforms
standard synthesis methods by 18.35\% and 46.24\% relatively. Our method also
beats data synthesized by a stronger teacher model, GPT-4o. Further analysis
confirms the benefits of teacher's learning to generate more influential
training data in the student's improved learning, the advantages of local data
influence in accurately measuring student preferences, and the robustness of
Montessori-Instruct across different student models. Our code and data are
open-sourced at https://github.com/cxcscmu/Montessori-Instruct.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Codes and data are open-sourced at
  https://github.com/cxcscmu/Montessori-Instruct</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Flexi-Fuzz least squares SVM for Alzheimer's diagnosis: Tackling noise,
  outliers, and class imbalance 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14207v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14207v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mushir Akhtar, A. Quadir, M. Tanveer, Mohd. Arshad
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Alzheimer's disease (AD) is a leading neurodegenerative condition and the
primary cause of dementia, characterized by progressive cognitive decline and
memory loss. Its progression, marked by shrinkage in the cerebral cortex, is
irreversible. Numerous machine learning algorithms have been proposed for the
early diagnosis of AD. However, they often struggle with the issues of noise,
outliers, and class imbalance. To tackle the aforementioned limitations, in
this article, we introduce a novel, robust, and flexible membership scheme
called Flexi-Fuzz. This scheme integrates a novel flexible weighting mechanism,
class probability, and imbalance ratio. The proposed flexible weighting
mechanism assigns the maximum weight to samples within a specific proximity to
the center, with a gradual decrease in weight beyond a certain threshold. This
approach ensures that samples near the class boundary still receive significant
weight, maintaining their influence in the classification process. Class
probability is used to mitigate the impact of noisy samples, while the
imbalance ratio addresses class imbalance. Leveraging this, we incorporate the
proposed Flexi-Fuzz membership scheme into the least squares support vector
machines (LSSVM) framework, resulting in a robust and flexible model termed
Flexi-Fuzz-LSSVM. We determine the class-center using two methods: the
conventional mean approach and an innovative median approach, leading to two
model variants, Flexi-Fuzz-LSSVM-I and Flexi-Fuzz-LSSVM-II. To validate the
effectiveness of the proposed Flexi-Fuzz-LSSVM models, we evaluated them on
benchmark UCI and KEEL datasets, both with and without label noise.
Additionally, we tested the models on the Alzheimer's Disease Neuroimaging
Initiative (ADNI) dataset for AD diagnosis. Experimental results demonstrate
the superiority of the Flexi-Fuzz-LSSVM models over baseline models.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ xPerT: Extended Persistence <span class="highlight-title">Transformer</span> 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14193v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14193v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Sehun Kim
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  A persistence diagram provides a compact summary of persistent homology,
which captures the topological features of a space at different scales.
However, due to its nature as a set, incorporating it as a feature into a
machine learning framework is challenging. Several methods have been proposed
to use persistence diagrams as input for machine learning models, but they
often require complex preprocessing steps and extensive hyperparameter tuning.
In this paper, we propose a novel transformer architecture called the
\textit{Extended Persistence Transformer (xPerT)}, which is highly scalable
than the compared to Persformer, an existing transformer for persistence
diagrams. xPerT reduces GPU memory usage by over 90\% and improves accuracy on
multiple datasets. Additionally, xPerT does not require complex preprocessing
steps or extensive hyperparameter tuning, making it easy to use in practice.
Our code is available at https://github.com/sehunfromdaegu/ECG_JEPA.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Locate-then-edit for Multi-hop Factual Recall under Knowledge Editing 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.06331v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.06331v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zhuoran Zhang, Yongxiang Li, Zijian Kan, Keyuan Cheng, Lijie Hu, Di Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The locate-then-edit paradigm has shown significant promise for knowledge
editing (KE) in Large Language Models (LLMs). While previous methods perform
well on single-hop fact recall tasks, they consistently struggle with multi-hop
factual recall tasks involving newly edited knowledge. In this paper,
leveraging tools in mechanistic interpretability, we first identify that in
multi-hop tasks, LLMs tend to retrieve implicit subject knowledge from deeper
MLP layers, unlike single-hop tasks, which rely on earlier layers. This
distinction explains the poor performance of current methods in multi-hop
queries, as they primarily focus on editing shallow layers, leaving deeper
layers unchanged. To address this, we propose IFMET, a novel locate-then-edit
KE approach designed to edit both shallow and deep MLP layers. IFMET employs
multi-hop editing prompts and supplementary sets to locate and modify knowledge
across different reasoning stages. Experimental results demonstrate that IFMET
significantly improves performance on multi-hop factual recall tasks,
effectively overcoming the limitations of previous locate-then-edit methods.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>21 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ A Distance-based Anomaly Detection Framework for Deep Reinforcement
  Learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2109.09889v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2109.09889v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hongming Zhang, Ke Sun, Bo Xu, Linglong Kong, Martin Müller
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In deep reinforcement learning (RL) systems, abnormal states pose significant
risks by potentially triggering unpredictable behaviors and unsafe actions,
thus impeding the deployment of RL systems in real-world scenarios. It is
crucial for reliable decision-making systems to have the capability to cast an
alert whenever they encounter unfamiliar observations that they are not
equipped to handle. In this paper, we propose a novel Mahalanobis
distance-based (MD) anomaly detection framework, called \textit{MDX}, for deep
RL algorithms. MDX simultaneously addresses random, adversarial, and
out-of-distribution (OOD) state outliers in both offline and online settings.
It utilizes Mahalanobis distance within class-conditional distributions for
each action and operates within a statistical hypothesis testing framework
under the Gaussian assumption. We further extend it to robust and
distribution-free versions by incorporating Robust MD and conformal inference
techniques. Through extensive experiments on classical control environments,
Atari games, and autonomous driving scenarios, we demonstrate the effectiveness
of our MD-based detection framework. MDX offers a simple, unified, and
practical anomaly detection tool for enhancing the safety and reliability of RL
systems in real-world applications.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>19 pages, 21 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Liger Kernel: Efficient Triton Kernels for LLM Training 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.10989v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.10989v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Pin-Lun Hsu, Yun Dai, Vignesh Kothapalli, Qingquan Song, Shao Tang, Siyu Zhu, Steven Shimizu, Shivam Sahni, Haowen Ning, Yanning Chen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Training Large Language Models (LLMs) efficiently at scale presents a
formidable challenge, driven by their ever-increasing computational demands and
the need for enhanced performance. In this work, we introduce Liger-Kernel, an
open-sourced set of Triton kernels developed specifically for LLM training.
With kernel optimization techniques like kernel operation fusing and input
chunking, our kernels achieve on average a 20% increase in training throughput
and a 60% reduction in GPU memory usage for popular LLMs compared to
HuggingFace implementations. In addition, Liger-Kernel is designed with
modularity, accessibility, and adaptability in mind, catering to both casual
and expert users. Comprehensive benchmarks and integration tests are built in
to ensure compatibility, performance, correctness, and convergence across
diverse computing environments and model architectures.
  The source code is available under a permissive license at:
github.com/linkedin/Liger-Kernel.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>17 pages, 12 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Learning Linear Attention in Polynomial Time 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.10101v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.10101v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Morris Yau, Ekin Akyürek, Jiayuan Mao, Joshua B. Tenenbaum, Stefanie Jegelka, Jacob Andreas
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Previous research has explored the computational expressivity of Transformer
models in simulating Boolean circuits or Turing machines. However, the
learnability of these simulators from observational data has remained an open
question. Our study addresses this gap by providing the first polynomial-time
learnability results (specifically strong, agnostic PAC learning) for
single-layer Transformers with linear attention. We show that linear attention
may be viewed as a linear predictor in a suitably defined RKHS. As a
consequence, the problem of learning any linear transformer may be converted
into the problem of learning an ordinary linear predictor in an expanded
feature space, and any such predictor may be converted back into a multiheaded
linear transformer. Moving to generalization, we show how to efficiently
identify training datasets for which every empirical risk minimizer is
equivalent (up to trivial symmetries) to the linear Transformer that generated
the data, thereby guaranteeing the learned model will correctly generalize
across all inputs. Finally, we provide examples of computations expressible via
linear attention and therefore polynomial-time learnable, including associative
memories, finite automata, and a class of Universal Turing Machine (UTMs) with
polynomially bounded computation histories. We empirically validate our
theoretical findings on three tasks: learning random linear attention networks,
key--value associations, and learning to execute finite automata. Our findings
bridge a critical gap between theoretical expressivity and learnability of
Transformers, and show that flexible and general models of computation are
efficiently learnable.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ One size doesn't fit all: Predicting the Number of Examples for
  In-Context Learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2403.06402v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2403.06402v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Manish Chandra, Debasis Ganguly, Iadh Ounis
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In-context learning (ICL) refers to the process of adding a small number of
localized examples (ones that are semantically similar to the input) from a
training set of labelled data to an LLM's prompt with an objective to
effectively control the generative process seeking to improve the downstream
task performance. Existing ICL approaches use an identical number of examples
(a pre-configured hyper-parameter) for each data instance. Our work alleviates
the limitations of this 'one fits all' approach by dynamically predicting the
number of examples for each data instance to be used in few-shot inference with
LLMs. In particular, we employ a multi-label classifier, the parameters of
which are fitted using a training set, where the label for each instance in the
training set indicates if using a specific value of k (number of most similar
examples from 0 up to a maximum value) leads to correct k-shot downstream
predictions. Our experiments on a number of text classification benchmarks show
that AICL substantially outperforms standard ICL by up to 17%.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Modular Boundaries in Recurrent Neural Networks 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2310.20601v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2310.20601v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jacob Tanner, Sina Mansour L., Ludovico Coletta, Alessandro Gozzi, Richard F. Betzel
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent theoretical and experimental work in neuroscience has focused on the
representational and dynamical character of neural manifolds --subspaces in
neural activity space wherein many neurons coactivate. Importantly, neural
populations studied under this "neural manifold hypothesis" are continuous and
not cleanly divided into separate neural populations. This perspective clashes
with the "modular hypothesis" of brain organization, wherein neural elements
maintain an "all-or-nothing" affiliation with modules. In line with this
modular hypothesis, recent research on recurrent neural networks suggests that
multi-task networks become modular across training, such that different modules
specialize for task-general dynamical motifs. If the modular hypothesis is
true, then it would be important to use a dimensionality reduction technique
that captures modular structure. Here, we investigate the features of such a
method. We leverage RNNs as a model system to study the character of modular
neural populations, using a community detection method from network science
known as modularity maximization to partition neurons into distinct modules.
These partitions allow us to ask the following question: do these modular
boundaries matter to the system? ...
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ TGB 2.0: A Benchmark for Learning on Temporal Knowledge Graphs and
  Heterogeneous Graphs <span class="chip">NeurIPS 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.09639v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.09639v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Julia Gastinger, Shenyang Huang, Mikhail Galkin, Erfan Loghmani, Ali Parviz, Farimah Poursafaei, Jacob Danovitch, Emanuele Rossi, Ioannis Koutis, Heiner Stuckenschmidt, Reihaneh Rabbany, Guillaume Rabusseau
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Multi-relational temporal graphs are powerful tools for modeling real-world
data, capturing the evolving and interconnected nature of entities over time.
Recently, many novel models are proposed for ML on such graphs intensifying the
need for robust evaluation and standardized benchmark datasets. However, the
availability of such resources remains scarce and evaluation faces added
complexity due to reproducibility issues in experimental protocols. To address
these challenges, we introduce Temporal Graph Benchmark 2.0 (TGB 2.0), a novel
benchmarking framework tailored for evaluating methods for predicting future
links on Temporal Knowledge Graphs and Temporal Heterogeneous Graphs with a
focus on large-scale datasets, extending the Temporal Graph Benchmark. TGB 2.0
facilitates comprehensive evaluations by presenting eight novel datasets
spanning five domains with up to 53 million edges. TGB 2.0 datasets are
significantly larger than existing datasets in terms of number of nodes, edges,
or timestamps. In addition, TGB 2.0 provides a reproducible and realistic
evaluation pipeline for multi-relational temporal graphs. Through extensive
experimentation, we observe that 1) leveraging edge-type information is crucial
to obtain high performance, 2) simple heuristic baselines are often competitive
with more complex methods, 3) most methods fail to run on our largest datasets,
highlighting the need for research on more scalable methods.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>29 pages, 8 figures, 11 tables, accepted at NeurIPS 2024 Track on
  Datasets and Benchmarks</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Scalable Drift Monitoring in Medical Imaging AI 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.13174v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.13174v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jameson Merkow, Felix J. Dorfner, Xiyu Yang, Alexander Ersoy, Giridhar Dasegowda, Mannudeep Kalra, Matthew P. Lungren, Christopher P. Bridge, Ivan Tarapov
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The integration of artificial intelligence (AI) into medical imaging has
advanced clinical diagnostics but poses challenges in managing model drift and
ensuring long-term reliability. To address these challenges, we develop MMC+,
an enhanced framework for scalable drift monitoring, building upon the
CheXstray framework that introduced real-time drift detection for medical
imaging AI models using multi-modal data concordance. This work extends the
original framework's methodologies, providing a more scalable and adaptable
solution for real-world healthcare settings and offers a reliable and
cost-effective alternative to continuous performance monitoring addressing
limitations of both continuous and periodic monitoring methods. MMC+ introduces
critical improvements to the original framework, including more robust handling
of diverse data streams, improved scalability with the integration of
foundation models like MedImageInsight for high-dimensional image embeddings
without site-specific training, and the introduction of uncertainty bounds to
better capture drift in dynamic clinical environments. Validated with
real-world data from Massachusetts General Hospital during the COVID-19
pandemic, MMC+ effectively detects significant data shifts and correlates them
with model performance changes. While not directly predicting performance
degradation, MMC+ serves as an early warning system, indicating when AI systems
may deviate from acceptable performance bounds and enabling timely
interventions. By emphasizing the importance of monitoring diverse data streams
and evaluating data shifts alongside model performance, this work contributes
to the broader adoption and integration of AI solutions in clinical settings.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Learning diffusion at lightspeed <span class="chip">NeurIPS 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.12616v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.12616v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Antonio Terpin, Nicolas Lanzetti, Martin Gadea, Florian Dörfler
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Diffusion regulates numerous natural processes and the dynamics of many
successful generative models. Existing models to learn the diffusion terms from
observational data rely on complex bilevel optimization problems and model only
the drift of the system. We propose a new simple model, JKOnet*, which bypasses
the complexity of existing architectures while presenting significantly
enhanced representational capabilities: JKOnet* recovers the potential,
interaction, and internal energy components of the underlying diffusion
process. JKOnet* minimizes a simple quadratic loss and outperforms other
baselines in terms of sample efficiency, computational complexity, and
accuracy. Additionally, JKOnet* provides a closed-form optimal solution for
linearly parametrized functionals, and, when applied to predict the evolution
of cellular processes from real-world data, it achieves state-of-the-art
accuracy at a fraction of the computational cost of all existing methods. Our
methodology is based on the interpretation of diffusion processes as
energy-minimizing trajectories in the probability space via the so-called JKO
scheme, which we study via its first-order optimality conditions.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted for presentation at, and publication in the proceedings of,
  the 38th Conference on Neural Information Processing Systems (NeurIPS 2024,
  oral)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ English offensive text detection using CNN based Bi-GRU model 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.15652v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.15652v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Tonmoy Roy, Md Robiul Islam, Asif Ahammad Miazee, Anika Antara, Al Amin, Sunjim Hossain
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Over the years, the number of users of social media has increased
drastically. People frequently share their thoughts through social platforms,
and this leads to an increase in hate content. In this virtual community,
individuals share their views, express their feelings, and post photos, videos,
blogs, and more. Social networking sites like Facebook and Twitter provide
platforms to share vast amounts of content with a single click. However, these
platforms do not impose restrictions on the uploaded content, which may include
abusive language and explicit images unsuitable for social media. To resolve
this issue, a new idea must be implemented to divide the inappropriate content.
Numerous studies have been done to automate the process. In this paper, we
propose a new Bi-GRU-CNN model to classify whether the text is offensive or
not. The combination of the Bi-GRU and CNN models outperforms the existing
model.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>5 pages and 6 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Retraining with Predicted Hard Labels Provably Increases Model Accuracy 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.11206v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.11206v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Rudrajit Das, Inderjit S. Dhillon, Alessandro Epasto, Adel Javanmard, Jieming Mao, Vahab Mirrokni, Sujay Sanghavi, Peilin Zhong
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The performance of a model trained with \textit{noisy labels} is often
improved by simply \textit{retraining} the model with its own predicted
\textit{hard} labels (i.e., $1$/$0$ labels). Yet, a detailed theoretical
characterization of this phenomenon is lacking. In this paper, we theoretically
analyze retraining in a linearly separable setting with randomly corrupted
labels given to us and prove that retraining can improve the population
accuracy obtained by initially training with the given (noisy) labels. To the
best of our knowledge, this is the first such theoretical result. Retraining
finds application in improving training with local label differential privacy
(DP) which involves training with noisy labels. We empirically show that
retraining selectively on the samples for which the predicted label matches the
given label significantly improves label DP training at \textit{no extra
privacy cost}; we call this \textit{consensus-based retraining}. As an example,
when training ResNet-18 on CIFAR-100 with $\epsilon=3$ label DP, we obtain
$6.4\%$ improvement in accuracy with consensus-based retraining.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Clustering of timed sequences -- Application to the analysis of care
  pathways 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2404.15379v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2404.15379v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Thomas Guyet, Pierre Pinson, Enoal Gesny
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Improving the future of healthcare starts by better understanding the current
actual practices in hospital settings. This motivates the objective of
discovering typical care pathways from patient data. Revealing typical care
pathways can be achieved through clustering. The difficulty in clustering care
pathways, represented by sequences of timestamped events, lies in defining a
semantically appropriate metric and clustering algorithms. In this article, we
adapt two methods developed for time series to the clustering of timed
sequences: the drop-DTW metric and the DBA approach for the construction of
averaged time sequences. These methods are then applied in clustering
algorithms to propose original and sound clustering algorithms for timed
sequences. This approach is experimented with and evaluated on synthetic and
real-world data.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ On Debiasing Text Embeddings Through Context Injection 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12874v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12874v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Thomas Uriot
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Current advances in Natural Language Processing (NLP) have made it
increasingly feasible to build applications leveraging textual data. Generally,
the core of these applications rely on having a good semantic representation of
text into vectors, via embedding models. However, it has been shown that these
embeddings capture and perpetuate biases already present in text. While a few
techniques have been proposed to debias embeddings, they do not take advantage
of the recent advances in context understanding of modern embedding models. In
this paper, we fill this gap by conducting a review of 19 embedding models by
quantifying their biases and how well they respond to context injection as a
mean of debiasing. We show that higher performing models are more prone to
capturing biases, but are also better at incorporating context. Surprisingly,
we find that while models can easily embed affirmative semantics, they fail at
embedding neutral semantics. Finally, in a retrieval task, we show that biases
in embeddings can lead to non-desirable outcomes. We use our new-found insights
to design a simple algorithm for top $k$ retrieval, where $k$ is dynamically
selected. We show that our algorithm is able to retrieve all relevant gendered
and neutral chunks.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Inferring Change Points in High-Dimensional Regression via Approximate
  Message Passing <span class="chip">ICML 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2404.07864v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2404.07864v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Gabriel Arpino, Xiaoqi Liu, Julia Gontarek, Ramji Venkataramanan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We consider the problem of localizing change points in a generalized linear
model (GLM), a model that covers many widely studied problems in statistical
learning including linear, logistic, and rectified linear regression. We
propose a novel and computationally efficient Approximate Message Passing (AMP)
algorithm for estimating both the signals and the change point locations, and
rigorously characterize its performance in the high-dimensional limit where the
number of parameters $p$ is proportional to the number of samples $n$. This
characterization is in terms of a state evolution recursion, which allows us to
precisely compute performance measures such as the asymptotic Hausdorff error
of our change point estimates, and allows us to tailor the algorithm to take
advantage of any prior structural information on the signals and change points.
Moreover, we show how our AMP iterates can be used to efficiently compute a
Bayesian posterior distribution over the change point locations in the
high-dimensional limit. We validate our theory via numerical experiments, and
demonstrate the favorable performance of our estimators on both synthetic and
real data in the settings of linear, logistic, and rectified linear regression.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>43 pages, 9 figures. A preliminary version of this paper appeared in
  ICML 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Kernel Density Estimators in Large Dimensions 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2408.05807v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2408.05807v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Giulio Biroli, Marc Mézard
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper studies Kernel Density Estimation for a high-dimensional
distribution $\rho(x)$. Traditional approaches have focused on the limit of
large number of data points $n$ and fixed dimension $d$. We analyze instead the
regime where both the number $n$ of data points $y_i$ and their dimensionality
$d$ grow with a fixed ratio $\alpha=(\log n)/d$. Our study reveals three
distinct statistical regimes for the kernel-based estimate of the density $\hat
\rho_h^{\mathcal {D}}(x)=\frac{1}{n h^d}\sum_{i=1}^n
K\left(\frac{x-y_i}{h}\right)$, depending on the bandwidth $h$: a classical
regime for large bandwidth where the Central Limit Theorem (CLT) holds, which
is akin to the one found in traditional approaches. Below a certain value of
the bandwidth, $h_{CLT}(\alpha)$, we find that the CLT breaks down. The
statistics of $\hat\rho_h^{\mathcal {D}}(x)$ for a fixed $x$ drawn from
$\rho(x)$ is given by a heavy-tailed distribution (an alpha-stable
distribution). In particular below a value $h_G(\alpha)$, we find that
$\hat\rho_h^{\mathcal {D}}(x)$ is governed by extreme value statistics: only a
few points in the database matter and give the dominant contribution to the
density estimator. We provide a detailed analysis for high-dimensional
multivariate Gaussian data. We show that the optimal bandwidth threshold based
on Kullback-Leibler divergence lies in the new statistical regime identified in
this paper. As known by practitioners, when decreasing the bandwidth a
Kernel-estimated estimated changes from a smooth curve to a collections of
peaks centred on the data points. Our findings reveal that this general
phenomenon is related to sharp transitions between phases characterized by
different statistical properties, and offer new insights for Kernel density
estimation in high-dimensional settings.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Deep Implicit Optimization for Robust and Flexible Image Registration 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.07361v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.07361v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Rohit Jena, Pratik Chaudhari, James C. Gee
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Deep Learning in Image Registration (DLIR) methods have been tremendously
successful in image registration due to their speed and ability to incorporate
weak label supervision at training time. However, DLIR methods forego many of
the benefits of classical optimization-based methods. The functional nature of
deep networks do not guarantee that the predicted transformation is a local
minima of the registration objective, the representation of the transformation
(displacement/velocity field/affine) is fixed, and the networks are not robust
to domain shift. Our method aims to bridge this gap between classical and
learning methods by incorporating optimization as a layer in a deep network. A
deep network is trained to predict multi-scale dense feature images that are
registered using a black box iterative optimization solver. This optimal warp
is then used to minimize image and label alignment errors. By implicitly
differentiating end-to-end through an iterative optimization solver, our
learned features are registration and label-aware, and the warp functions are
guaranteed to be local minima of the registration objective in the feature
space. Our framework shows excellent performance on in-domain datasets, and is
agnostic to domain shift such as anisotropy and varying intensity profiles. For
the first time, our method allows switching between arbitrary transformation
representations (free-form to diffeomorphic) at test time with zero retraining.
End-to-end feature learning also facilitates interpretability of features, and
out-of-the-box promptability using additional label-fidelity terms at
inference.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Overcoming Slow Decision Frequencies in Continuous Control: Model-Based
  Sequence Reinforcement Learning for Model-Free Control 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.08979v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.08979v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Devdhar Patel, Hava Siegelmann
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Reinforcement learning (RL) is rapidly reaching and surpassing human-level
control capabilities. However, state-of-the-art RL algorithms often require
timesteps and reaction times significantly faster than human capabilities,
which is impractical in real-world settings and typically necessitates
specialized hardware. Such speeds are difficult to achieve in the real world
and often requires specialized hardware. We introduce Sequence Reinforcement
Learning (SRL), an RL algorithm designed to produce a sequence of actions for a
given input state, enabling effective control at lower decision frequencies.
SRL addresses the challenges of learning action sequences by employing both a
model and an actor-critic architecture operating at different temporal scales.
We propose a "temporal recall" mechanism, where the critic uses the model to
estimate intermediate states between primitive actions, providing a learning
signal for each individual action within the sequence. Once training is
complete, the actor can generate action sequences independently of the model,
achieving model-free control at a slower frequency. We evaluate SRL on a suite
of continuous control tasks, demonstrating that it achieves performance
comparable to state-of-the-art algorithms while significantly reducing actor
sample complexity. To better assess performance across varying decision
frequencies, we introduce the Frequency-Averaged Score (FAS) metric. Our
results show that SRL significantly outperforms traditional RL algorithms in
terms of FAS, making it particularly suitable for applications requiring
variable decision frequencies. Additionally, we compare SRL with model-based
online planning, showing that SRL achieves superior FAS while leveraging the
same model during training that online planners use for planning.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Sample Compression Scheme Reductions 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.13012v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.13012v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Idan Attias, Steve Hanneke, Arvind Ramaswami
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We present novel reductions from sample compression schemes in multiclass
classification, regression, and adversarially robust learning settings to
binary sample compression schemes. Assuming we have a compression scheme for
binary classes of size $f(d_\mathrm{VC})$, where $d_\mathrm{VC}$ is the VC
dimension, then we have the following results: (1) If the binary compression
scheme is a majority-vote or a stable compression scheme, then there exists a
multiclass compression scheme of size $O(f(d_\mathrm{G}))$, where
$d_\mathrm{G}$ is the graph dimension. Moreover, for general binary compression
schemes, we obtain a compression of size $O(f(d_\mathrm{G})\log|Y|)$, where $Y$
is the label space. (2) If the binary compression scheme is a majority-vote or
a stable compression scheme, then there exists an $\epsilon$-approximate
compression scheme for regression over $[0,1]$-valued functions of size
$O(f(d_\mathrm{P}))$, where $d_\mathrm{P}$ is the pseudo-dimension. For general
binary compression schemes, we obtain a compression of size
$O(f(d_\mathrm{P})\log(1/\epsilon))$. These results would have significant
implications if the sample compression conjecture, which posits that any binary
concept class with a finite VC dimension admits a binary compression scheme of
size $O(d_\mathrm{VC})$, is resolved (Littlestone and Warmuth, 1986; Floyd and
Warmuth, 1995; Warmuth, 2003). Our results would then extend the proof of the
conjecture immediately to other settings. We establish similar results for
adversarially robust learning and also provide an example of a concept class
that is robustly learnable but has no bounded-size compression scheme,
demonstrating that learnability is not equivalent to having a compression
scheme independent of the sample size, unlike in binary classification, where
compression of size $2^{O(d_\mathrm{VC})}$ is attainable (Moran and Yehudayoff,
2016).
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ BlackDAN: A Black-Box Multi-Objective Approach for Effective and
  Contextual Jailbreaking of Large Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.09804v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.09804v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xinyuan Wang, Victor Shea-Jay Huang, Renmiao Chen, Hao Wang, Chengwei Pan, Lei Sha, Minlie Huang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  While large language models (LLMs) exhibit remarkable capabilities across
various tasks, they encounter potential security risks such as jailbreak
attacks, which exploit vulnerabilities to bypass security measures and generate
harmful outputs. Existing jailbreak strategies mainly focus on maximizing
attack success rate (ASR), frequently neglecting other critical factors,
including the relevance of the jailbreak response to the query and the level of
stealthiness. This narrow focus on single objectives can result in ineffective
attacks that either lack contextual relevance or are easily recognizable. In
this work, we introduce BlackDAN, an innovative black-box attack framework with
multi-objective optimization, aiming to generate high-quality prompts that
effectively facilitate jailbreaking while maintaining contextual relevance and
minimizing detectability. BlackDAN leverages Multiobjective Evolutionary
Algorithms (MOEAs), specifically the NSGA-II algorithm, to optimize jailbreaks
across multiple objectives including ASR, stealthiness, and semantic relevance.
By integrating mechanisms like mutation, crossover, and Pareto-dominance,
BlackDAN provides a transparent and interpretable process for generating
jailbreaks. Furthermore, the framework allows customization based on user
preferences, enabling the selection of prompts that balance harmfulness,
relevance, and other factors. Experimental results demonstrate that BlackDAN
outperforms traditional single-objective methods, yielding higher success rates
and improved robustness across various LLMs and multimodal LLMs, while ensuring
jailbreak responses are both relevant and less detectable.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ IncidentResponse<span class="highlight-title">GPT</span>: Generating Traffic Incident Response Plans with
  Generative Artificial Intelligence 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2404.18550v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2404.18550v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Artur Grigorev, Adriana-Simona Mihaita Khaled Saleh, Yuming Ou
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The proposed IncidentResponseGPT framework - a novel system that applies
generative artificial intelligence (AI) to potentially enhance the efficiency
and effectiveness of traffic incident response. This model allows for synthesis
of region-specific incident response guidelines and generates incident response
plans adapted to specific area, aiming to expedite decision-making for traffic
management authorities. This approach aims to accelerate incident resolution
times by suggesting various recommendations (e.g. optimal rerouting strategies,
estimating resource needs) to minimize the overall impact on the urban traffic
network. The system suggests specific actions, including dynamic lane closures,
optimized rerouting and dispatching appropriate emergency resources. We utilize
the Technique for Order Preference by Similarity to Ideal Solution (TOPSIS) to
rank generated response plans based on criteria like impact minimization and
resource efficiency based on their proximity to an human-proposed solution.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Model Internals-based Answer Attribution for Trustworthy
  Retrieval-Augmented Generation <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.13663v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.13663v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jirui Qi, Gabriele Sarti, Raquel Fernández, Arianna Bisazza
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Ensuring the verifiability of model answers is a fundamental challenge for
retrieval-augmented generation (RAG) in the question answering (QA) domain.
Recently, self-citation prompting was proposed to make large language models
(LLMs) generate citations to supporting documents along with their answers.
However, self-citing LLMs often struggle to match the required format, refer to
non-existent sources, and fail to faithfully reflect LLMs' context usage
throughout the generation. In this work, we present MIRAGE --Model
Internals-based RAG Explanations -- a plug-and-play approach using model
internals for faithful answer attribution in RAG applications. MIRAGE detects
context-sensitive answer tokens and pairs them with retrieved documents
contributing to their prediction via saliency methods. We evaluate our proposed
approach on a multilingual extractive QA dataset, finding high agreement with
human answer attribution. On open-ended QA, MIRAGE achieves citation quality
and efficiency comparable to self-citation while also allowing for a
finer-grained control of attribution parameters. Our qualitative evaluation
highlights the faithfulness of MIRAGE's attributions and underscores the
promising application of model internals for RAG answer attribution.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by EMNLP 2024 Main Conference. Code and data released at
  https://github.com/Betswish/MIRAGE</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Hip Fracture Patient Pathways and Agent-based Modelling 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12804v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12804v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Alison N. O'Connor, Stephen E. Ryan, Gauri Vaidya, Paul Harford, Meghana Kshirsagar
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Increased healthcare demand is significantly straining European services.
Digital solutions including advanced modelling techniques offer a promising
solution to optimising patient flow without impacting day-to-day healthcare
provision. In this work we outline an ongoing project that aims to optimise
healthcare resources using agent-based simulations.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>6 pages, 2 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Are High-Degree Representations Really Unnecessary in Equivariant Graph
  Neural Networks? 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.11443v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.11443v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jiacheng Cen, Anyi Li, Ning Lin, Yuxiang Ren, Zihe Wang, Wenbing Huang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Equivariant Graph Neural Networks (GNNs) that incorporate E(3) symmetry have
achieved significant success in various scientific applications. As one of the
most successful models, EGNN leverages a simple scalarization technique to
perform equivariant message passing over only Cartesian vectors (i.e.,
1st-degree steerable vectors), enjoying greater efficiency and efficacy
compared to equivariant GNNs using higher-degree steerable vectors. This
success suggests that higher-degree representations might be unnecessary. In
this paper, we disprove this hypothesis by exploring the expressivity of
equivariant GNNs on symmetric structures, including $k$-fold rotations and
regular polyhedra. We theoretically demonstrate that equivariant GNNs will
always degenerate to a zero function if the degree of the output
representations is fixed to 1 or other specific values. Based on this
theoretical insight, we propose HEGNN, a high-degree version of EGNN to
increase the expressivity by incorporating high-degree steerable vectors while
maintaining EGNN's efficiency through the scalarization trick. Our extensive
experiments demonstrate that HEGNN not only aligns with our theoretical
analyses on toy datasets consisting of symmetric structures, but also shows
substantial improvements on more complicated datasets such as $N$-body and
MD17. Our theoretical findings and empirical results potentially open up new
possibilities for the research of equivariant GNNs.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ A Novel Cartography-Based Curriculum Learning Method Applied on RoNLI:
  The First Romanian Natural Language Inference Corpus <span class="chip">ACL 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.11877v5">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.11877v5.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Eduard Poesina, Cornelia Caragea, Radu Tudor Ionescu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Natural language inference (NLI), the task of recognizing the entailment
relationship in sentence pairs, is an actively studied topic serving as a proxy
for natural language understanding. Despite the relevance of the task in
building conversational agents and improving text classification, machine
translation and other NLP tasks, to the best of our knowledge, there is no
publicly available NLI corpus for the Romanian language. To this end, we
introduce the first Romanian NLI corpus (RoNLI) comprising 58K training
sentence pairs, which are obtained via distant supervision, and 6K validation
and test sentence pairs, which are manually annotated with the correct labels.
We conduct experiments with multiple machine learning methods based on distant
learning, ranging from shallow models based on word embeddings to
transformer-based neural networks, to establish a set of competitive baselines.
Furthermore, we improve on the best model by employing a new curriculum
learning strategy based on data cartography. Our dataset and code to reproduce
the baselines are available at https://github.com/Eduard6421/RONLI.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted at ACL 2024 (Main)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Plug-and-Play Posterior Sampling under Mismatched Measurement and Prior
  Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2310.03546v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2310.03546v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Marien Renaud, Jiaming Liu, Valentin de Bortoli, Andrés Almansa, Ulugbek S. Kamilov
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Posterior sampling has been shown to be a powerful Bayesian approach for
solving imaging inverse problems. The recent plug-and-play unadjusted Langevin
algorithm (PnP-ULA) has emerged as a promising method for Monte Carlo sampling
and minimum mean squared error (MMSE) estimation by combining physical
measurement models with deep-learning priors specified using image denoisers.
However, the intricate relationship between the sampling distribution of
PnP-ULA and the mismatched data-fidelity and denoiser has not been
theoretically analyzed. We address this gap by proposing a posterior-L2
pseudometric and using it to quantify an explicit error bound for PnP-ULA under
mismatched posterior distribution. We numerically validate our theory on
several inverse problems such as sampling from Gaussian mixture models and
image deblurring. Our results suggest that the sensitivity of the sampling
distribution of PnP-ULA to a mismatch in the measurement model and the denoiser
can be precisely characterized.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Multi-LLM QA with Embodied Exploration 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.10918v5">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.10918v5.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Bhrij Patel, Vishnu Sashank Dorbala, Amrit Singh Bedi, Dinesh Manocha
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large language models (LLMs) have grown in popularity due to their natural
language interface and pre trained knowledge, leading to rapidly increasing
success in question-answering (QA) tasks. More recently, multi-agent systems
with LLM-based agents (Multi-LLM) have been utilized increasingly more for QA.
In these scenarios, the models may each answer the question and reach a
consensus or each model is specialized to answer different domain questions.
However, most prior work dealing with Multi-LLM QA has focused on scenarios
where the models are asked in a zero-shot manner or are given information
sources to extract the answer. For question answering of an unknown
environment, embodied exploration of the environment is first needed to answer
the question. This skill is necessary for personalizing embodied AI to
environments such as households. There is a lack of insight into whether a
Multi-LLM system can handle question-answering based on observations from
embodied exploration. In this work, we address this gap by investigating the
use of Multi-Embodied LLM Explorers (MELE) for QA in an unknown environment.
Multiple LLM-based agents independently explore and then answer queries about a
household environment. We analyze different aggregation methods to generate a
single, final answer for each query: debating, majority voting, and training a
central answer module (CAM). Using CAM, we observe a $46\%$ higher accuracy
compared against the other non-learning-based aggregation methods. We provide
code and the query dataset for further research.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>16 pages, 9 Figures, 5 Tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Learning Social Cost Functions for Human-Aware Path Planning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.10547v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.10547v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Andrea Eirale, Matteo Leonetti, Marcello Chiaberge
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Achieving social acceptance is one of the main goals of Social Robotic
Navigation. Despite this topic has received increasing interest in recent
years, most of the research has focused on driving the robotic agent along
obstacle-free trajectories, planning around estimates of future human motion to
respect personal distances and optimize navigation. However, social
interactions in everyday life are also dictated by norms that do not strictly
depend on movement, such as when standing at the end of a queue rather than
cutting it. In this paper, we propose a novel method to recognize common social
scenarios and modify a traditional planner's cost function to adapt to them.
This solution enables the robot to carry out different social navigation
behaviors that would not arise otherwise, maintaining the robustness of
traditional navigation. Our approach allows the robot to learn different social
norms with a single learned model, rather than having different modules for
each task. As a proof of concept, we consider the tasks of queuing and respect
interaction spaces of groups of people talking to one another, but the method
can be extended to other human activities that do not involve motion.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ An algorithm for clustering with confidence-based must-link and
  cannot-link constraints 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2212.14437v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2212.14437v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Philipp Baumann, Dorit S. Hochbaum
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We study here the semi-supervised $k$-clustering problem where information is
available on whether pairs of objects are in the same or in different clusters.
This information is either available with certainty or with a limited level of
confidence. We introduce the PCCC (Pairwise-Confidence-Constraints-Clustering)
algorithm, which iteratively assigns objects to clusters while accounting for
the information provided on the pairs of objects. Our algorithm uses integer
programming for the assignment of objects which allows to include relationships
as hard constraints that are guaranteed to be satisfied or as soft constraints
that can be violated subject to a penalty. This flexibility distinguishes our
algorithm from the state-of-the-art in which all pairwise constraints are
either considered hard, or all are considered soft. We developed an enhanced
multi-start approach and a model-size reduction technique for the integer
program that contributes to the effectiveness and the efficiency of the
algorithm. Unlike existing algorithms, our algorithm scales to large-scale
instances with up to 60,000 objects, 100 clusters, and millions of cannot-link
constraints (which are the most challenging constraints to incorporate). We
compare the PCCC algorithm with state-of-the-art approaches in an extensive
computational study. Even though the PCCC algorithm is more general than the
state-of-the-art approaches in its applicability, it outperforms the
state-of-the-art approaches on instances with all hard or all soft constraints
both in terms of runtime and various metrics of solution quality. The code of
the PCCC algorithm is publicly available on GitHub.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>To appear in INFORMS Journal on Computing</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Explaining Modern Gated-Linear RNNs via a Unified Implicit Attention
  Formulation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.16504v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.16504v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Itamar Zimerman, Ameen Ali, Lior Wolf
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent advances in efficient sequence modeling have led to attention-free
layers, such as Mamba, RWKV, and various gated RNNs, all featuring
sub-quadratic complexity in sequence length and excellent scaling properties,
enabling the construction of a new type of foundation models. In this paper, we
present a unified view of these models, formulating such layers as implicit
causal self-attention layers. The formulation includes most of their
sub-components and is not limited to a specific part of the architecture. The
framework compares the underlying mechanisms on similar grounds for different
layers and provides a direct means for applying explainability methods. Our
experiments show that our attention matrices and attribution method outperform
an alternative and a more limited formulation that was recently proposed for
Mamba. For the other architectures for which our method is the first to provide
such a view, our method is effective and competitive in the relevant metrics
compared to the results obtained by state-of-the-art Transformer explainability
methods. Our code is publicly available.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Molecular<span class="highlight-title">GPT</span>: Open Large Language Model (LLM) for Few-Shot Molecular
  Property Prediction 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.12950v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.12950v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yuyan Liu, Sirui Ding, Sheng Zhou, Wenqi Fan, Qiaoyu Tan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Molecular property prediction (MPP) is a fundamental and crucial task in drug
discovery. However, prior methods are limited by the requirement for a large
number of labeled molecules and their restricted ability to generalize for
unseen and new tasks, both of which are essential for real-world applications.
To address these challenges, we present MolecularGPT for few-shot MPP. From a
perspective on instruction tuning, we fine-tune large language models (LLMs)
based on curated molecular instructions spanning over 1000 property prediction
tasks. This enables building a versatile and specialized LLM that can be
adapted to novel MPP tasks without any fine-tuning through zero- and few-shot
in-context learning (ICL). MolecularGPT exhibits competitive in-context
reasoning capabilities across 10 downstream evaluation datasets, setting new
benchmarks for few-shot molecular prediction tasks. More importantly, with just
two-shot examples, MolecularGPT can outperform standard supervised graph neural
network methods on 4 out of 7 datasets. It also excels state-of-the-art LLM
baselines by up to 15.7% increase on classification accuracy and decrease of
17.9 on regression metrics (e.g., RMSE) under zero-shot. This study
demonstrates the potential of LLMs as effective few-shot molecular property
predictors. The code is available at https://github.com/NYUSHCS/MolecularGPT.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Timeseria: an object-oriented time series processing library 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.09567v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.09567v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Stefano Alberto Russo, Giuliano Taffoni, Luca Bortolussi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Timeseria is an object-oriented time series processing library implemented in
Python, which aims at making it easier to manipulate time series data and to
build statistical and machine learning models on top of it. Unlike common data
analysis frameworks, it builds up from well defined and reusable logical units
(objects), which can be easily combined together in order to ensure a high
level of consistency. Thanks to this approach, Timeseria can address by design
several non-trivial issues often underestimated, such as handling data losses,
non-uniform sampling rates, differences between aggregated data and punctual
observations, time zones, daylight saving times, and more. Timeseria comes with
a comprehensive set of base data structures, common data manipulation
operations, and extensible models for data reconstruction, forecasting and
anomaly detection. It also integrates a powerful plotting engine capable of
handling even millions of data points.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Spectral and Rhythm Features for Audio Classification with Deep
  Convolutional Neural Networks 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.06927v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.06927v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Friedrich Wolf-Monheim
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Convolutional neural networks (CNNs) are widely used in computer vision. They
can be used not only for conventional digital image material to recognize
patterns, but also for feature extraction from digital imagery representing
spectral and rhythm features extracted from time-domain digital audio signals
for the acoustic classification of sounds. Different spectral and rhythm
feature representations like mel-scaled spectrograms, mel-frequency cepstral
coefficients (MFCCs), cyclic tempograms, short-time Fourier transform (STFT)
chromagrams, constant-Q transform (CQT) chromagrams and chroma energy
normalized statistics (CENS) chromagrams are investigated in terms of the audio
classification performance using a deep convolutional neural network. It can be
clearly shown that the mel-scaled spectrograms and the mel-frequency cepstral
coefficients (MFCCs) perform significantly better than the other spectral and
rhythm features investigated in this research for audio classification tasks
using deep CNNs. The experiments were carried out with the aid of the ESC-50
dataset with 2,000 labeled environmental audio recordings.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Distributionally and Adversarially Robust Logistic Regression via
  Intersecting Wasserstein Balls 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13625v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13625v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Aras Selvi, Eleonora Kreacic, Mohsen Ghassemi, Vamsi Potluru, Tucker Balch, Manuela Veloso
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Adversarially robust optimization (ARO) has become the de facto standard for
training models to defend against adversarial attacks during testing. However,
despite their robustness, these models often suffer from severe overfitting. To
mitigate this issue, several successful approaches have been proposed,
including replacing the empirical distribution in training with: (i) a
worst-case distribution within an ambiguity set, leading to a distributionally
robust (DR) counterpart of ARO; or (ii) a mixture of the empirical distribution
with one derived from an auxiliary dataset (e.g., synthetic, external, or
out-of-domain). Building on the first approach, we explore the Wasserstein DR
counterpart of ARO for logistic regression and show it admits a tractable
convex optimization reformulation. Adopting the second approach, we enhance the
DR framework by intersecting its ambiguity set with one constructed from an
auxiliary dataset, which yields significant improvements when the Wasserstein
distance between the data-generating and auxiliary distributions can be
estimated. We analyze the resulting optimization problem, develop efficient
solutions, and show that our method outperforms benchmark approaches on
standard datasets.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>33 pages, 3 color figures, under review at a conference</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Predicting Accurate Lagrangian Multipliers for Mixed Integer Linear
  Programs 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2310.14659v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2310.14659v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Francesco Demelas, Joseph Le Roux, Mathieu Lacroix, Axel Parmentier
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Lagrangian relaxation stands among the most efficient approaches for solving
a Mixed Integer Linear Programs (MILP) with difficult constraints. Given any
duals for these constraints, called Lagrangian Multipliers (LMs), it returns a
bound on the optimal value of the MILP, and Lagrangian methods seek the LMs
giving the best such bound. But these methods generally rely on iterative
algorithms resembling gradient descent to maximize the concave piecewise linear
dual function: the computational burden grows quickly with the number of
relaxed constraints. We introduce a deep learning approach that bypasses the
descent, effectively amortizing the local, per instance, optimization. A
probabilistic encoder based on a graph convolutional network computes
high-dimensional representations of relaxed constraints in MILP instances. A
decoder then turns these representations into LMs. We train the encoder and
decoder jointly by directly optimizing the bound obtained from the predicted
multipliers. Numerical experiments show that our approach closes up to 85~\% of
the gap between the continuous relaxation and the best Lagrangian bound, and
provides a high quality warm-start for descent based Lagrangian methods.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ 3-D Magnetotelluric Deep Learning Inversion Guided by Pseudo-Physical
  Information 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.09388v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.09388v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Peifan Jiang, Xuben Wang, Shuang Wang, Fei Deng, Kunpeng Wang, Bin Wang, Yuhan Yang, Islam Fadel
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Magnetotelluric deep learning (DL) inversion methods based on joint
data-driven and physics-driven have become a hot topic in recent years. When
mapping observation data (or forward modeling data) to the resistivity model
using neural networks (NNs), incorporating the error (loss) term of the
inversion resistivity's forward modeling response--which introduces physical
information about electromagnetic field propagation--can significantly enhance
the inversion accuracy. To efficiently achieve data-physical dual-driven MT
deep learning inversion for large-scale 3-D MT data, we propose using DL
forward modeling networks to compute this portion of the loss. This approach
introduces pseudo-physical information through the forward modeling of NN
simulation, further guiding the inversion network fitting. Specifically, we
first pre-train the forward modeling networks as fixed forward modeling
operators, then transfer and integrate them into the inversion network
training, and finally optimize the inversion network by minimizing the
multinomial loss. Theoretical experimental results indicate that despite some
simulation errors in DL forward modeling, the introduced pseudo-physical
information still enhances inversion accuracy and significantly mitigates the
overfitting problem during training. Additionally, we propose a new input mode
that involves masking and adding noise to the data, simulating the field data
environment of 3-D MT inversion, thereby making the method more flexible and
effective for practical applications.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ A <span class="highlight-title">Survey</span> of Mamba 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2408.01129v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2408.01129v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Haohao Qu, Liangbo Ning, Rui An, Wenqi Fan, Tyler Derr, Hui Liu, Xin Xu, Qing Li
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  As one of the most representative DL techniques, Transformer architecture has
empowered numerous advanced models, especially the large language models (LLMs)
that comprise billions of parameters, becoming a cornerstone in deep learning.
Despite the impressive achievements, Transformers still face inherent
limitations, particularly the time-consuming inference resulting from the
quadratic computation complexity of attention calculation. Recently, a novel
architecture named Mamba, drawing inspiration from classical state space models
(SSMs), has emerged as a promising alternative for building foundation models,
delivering comparable modeling abilities to Transformers while preserving
near-linear scalability concerning sequence length. This has sparked an
increasing number of studies actively exploring Mamba's potential to achieve
impressive performance across diverse domains. Given such rapid evolution,
there is a critical need for a systematic review that consolidates existing
Mamba-empowered models, offering a comprehensive understanding of this emerging
model architecture. In this survey, we therefore conduct an in-depth
investigation of recent Mamba-associated studies, covering three main aspects:
the advancements of Mamba-based models, the techniques of adapting Mamba to
diverse data, and the applications where Mamba can excel. Specifically, we
first review the foundational knowledge of various representative deep learning
models and the details of Mamba-1&2 as preliminaries. Then, to showcase the
significance of Mamba for AI, we comprehensively review the related studies
focusing on Mamba models' architecture design, data adaptability, and
applications. Finally, we present a discussion of current limitations and
explore various promising research directions to provide deeper insights for
future investigations.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Optimization Dynamics of Equivariant and Augmented Neural Networks 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2303.13458v5">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2303.13458v5.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Oskar Nordenfors, Fredrik Ohlsson, Axel Flinth
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We investigate the optimization of neural networks on symmetric data, and
compare the strategy of constraining the architecture to be equivariant to that
of using data augmentation. Our analysis reveals that that the relative
geometry of the admissible and the equivariant layers, respectively, plays a
key role. Under natural assumptions on the data, network, loss, and group of
symmetries, we show that compatibility of the spaces of admissible layers and
equivariant layers, in the sense that the corresponding orthogonal projections
commute, implies that the sets of equivariant stationary points are identical
for the two strategies. If the linear layers of the network also are given a
unitary parametrization, the set of equivariant layers is even invariant under
the gradient flow for augmented models. Our analysis however also reveals that
even in the latter situation, stationary points may be unstable for augmented
training although they are stable for the manifestly equivariant models.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>v4: Some discussions added, along with an updated experiment section.
  v3: Completely revised manuscript: New framework for neural nets, new main
  result (involving compability condition), new experiments, new author. v2:
  Revised manuscript. Mostly small edits, apart from new experiments (see
  Appendix E)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Entity Matching using Large Language Models <span class="chip">EDBT</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2310.11244v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2310.11244v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ralph Peeters, Aaron Steiner, Christian Bizer
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Entity matching is the task of deciding whether two entity descriptions refer
to the same real-world entity. Entity matching is a central step in most data
integration pipelines. Many state-of-the-art entity matching methods rely on
pre-trained language models (PLMs) such as BERT or RoBERTa. Two major drawbacks
of these models for entity matching are that (i) the models require significant
amounts of task-specific training data and (ii) the fine-tuned models are not
robust concerning out-of-distribution entities. This paper investigates using
generative large language models (LLMs) as a less task-specific training
data-dependent and more robust alternative to PLM-based matchers. The study
covers hosted and open-source LLMs which can be run locally. We evaluate these
models in a zero-shot scenario and a scenario where task-specific training data
is available. We compare different prompt designs and the prompt sensitivity of
the models. We show that there is no single best prompt but that the prompt
needs to be tuned for each model/dataset combination. We further investigate
(i) the selection of in-context demonstrations, (ii) the generation of matching
rules, as well as (iii) fine-tuning LLMs using the same pool of training data.
Our experiments show that the best LLMs require no or only a few training
examples to perform comparably to PLMs that were fine-tuned using thousands of
examples. LLM-based matchers further exhibit higher robustness to unseen
entities. We show that GPT4 can generate structured explanations for matching
decisions and can automatically identify potential causes of matching errors by
analyzing explanations of wrong decisions. We demonstrate that the model can
generate meaningful textual descriptions of the identified error classes, which
can help data engineers to improve entity matching pipelines.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Published in Proceedings of the 28th International Conference on
  Extending Database Technology (EDBT), 25th March-28th March, 2025, ISBN
  978-3-89318-098-1 on OpenProceedings.org</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ A <span class="highlight-title">Survey</span> of Multi-Agent Deep Reinforcement Learning with Communication 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2203.08975v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2203.08975v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Changxi Zhu, Mehdi Dastani, Shihan Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Communication is an effective mechanism for coordinating the behaviors of
multiple agents, broadening their views of the environment, and to support
their collaborations. In the field of multi-agent deep reinforcement learning
(MADRL), agents can improve the overall learning performance and achieve their
objectives by communication. Agents can communicate various types of messages,
either to all agents or to specific agent groups, or conditioned on specific
constraints. With the growing body of research work in MADRL with communication
(Comm-MADRL), there is a lack of a systematic and structural approach to
distinguish and classify existing Comm-MADRL approaches. In this paper, we
survey recent works in the Comm-MADRL field and consider various aspects of
communication that can play a role in designing and developing multi-agent
reinforcement learning systems. With these aspects in mind, we propose 9
dimensions along which Comm-MADRL approaches can be analyzed, developed, and
compared. By projecting existing works into the multi-dimensional space, we
discover interesting trends. We also propose some novel directions for
designing future Comm-MADRL systems through exploring possible combinations of
the dimensions.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>34 pages, 5 figures, 13 tables; published on Autonomous Agents and
  Multi-Agent Systems</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Understanding Likelihood Over-optimisation in Direct Alignment
  Algorithms 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.11677v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.11677v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zhengyan Shi, Sander Land, Acyr Locatelli, Matthieu Geist, Max Bartolo
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Direct Alignment Algorithms (DAAs), such as Direct Preference Optimisation
(DPO) and Identity Preference Optimisation (IPO), have emerged as alternatives
to online Reinforcement Learning from Human Feedback (RLHF) algorithms such as
Proximal Policy Optimisation (PPO) for aligning language models to human
preferences, without the need for explicit reward modelling. These methods
generally aim to increase the likelihood of generating better (preferred)
completions while discouraging worse (non-preferred) ones, while staying close
to the original model's behaviour. In this work, we explore the relationship
between completion likelihood and model performance in state-of-the-art DAAs,
and identify a critical issue of likelihood over-optimisation. Contrary to
expectations, we find that higher likelihood of better completions and larger
margins between better and worse completion likelihoods do not necessarily lead
to better performance, and may even degrade it. Our analysis reveals that while
higher likelihood correlates with better memorisation of factual knowledge
patterns, a slightly lower completion likelihood tends to improve output
diversity, thus leading to better generalisation to unseen scenarios. Moreover,
we identify two key indicators that signal when over-optimised output diversity
begins to harm performance: Decreasing Entropy over Top-k Tokens and
Diminishing Top-k Probability Mass. Our experimental results validate that
these indicators are reliable signs of declining performance under different
regularisations, helping prevent over-optimisation and improve alignment with
human preferences.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Preprint Version</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ GLANCE: Global Actions in a Nutshell for Counterfactual Explainability 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.18921v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.18921v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Loukas Kavouras, Eleni Psaroudaki, Konstantinos Tsopelas, Dimitrios Rontogiannis, Nikolaos Theologitis, Dimitris Sacharidis, Giorgos Giannopoulos, Dimitrios Tomaras, Kleopatra Markou, Dimitrios Gunopulos, Dimitris Fotakis, Ioannis Emiris
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The widespread deployment of machine learning systems in critical real-world
decision-making applications has highlighted the urgent need for counterfactual
explainability methods that operate effectively. Global counterfactual
explanations, expressed as actions to offer recourse, aim to provide succinct
explanations and insights applicable to large population subgroups.
Effectiveness is measured by the fraction of the population that is provided
recourse, ensuring that the actions benefit as many individuals as possible.
Keeping the cost of actions low ensures the proposed recourse actions remain
practical and actionable. Limiting the number of actions that provide global
counterfactuals is essential to maximize interpretability. The primary
challenge, therefore, is balancing these trade-offs, i.e., maximizing
effectiveness, minimizing cost, while maintaining a small number of actions. We
introduce GLANCE, a versatile and adaptive framework, comprising two
algorithms, that allows the careful balancing of the trade-offs among the three
key objectives, with the size objective functioning as a tunable parameter to
keep the actions few and easy to interpret. C-GLANCE employs a clustering
approach that considers both the feature space and the space of counterfactual
actions, thereby accounting for the distribution of points in a way that aligns
with the structure of the model. T-GLANCE provides additional features to
enhance flexibility. It employs a tree-based approach, that allows users to
specify split features, to build a decision tree with a single counterfactual
action at each node that can be used as a subgroup policy. Our extensive
experimental evaluation demonstrates that our method consistently shows greater
robustness and performance compared to existing methods across various datasets
and models.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Dating ancient manuscripts using radiocarbon and AI-based writing style
  analysis 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.12013v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.12013v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mladen Popović, Maruf A. Dhali, Lambert Schomaker, Johannes van der Plicht, Kaare Lund Rasmussen, Jacopo La Nasa, Ilaria Degano, Maria Perla Colombini, Eibert Tigchelaar
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Determining the chronology of ancient handwritten manuscripts is essential
for reconstructing the evolution of ideas. For the Dead Sea Scrolls, this is
particularly important. However, there is an almost complete lack of
date-bearing manuscripts evenly distributed across the timeline and written in
similar scripts available for palaeographic comparison. Here, we present Enoch,
a state-of-the-art AI-based date-prediction model, trained on the basis of new
radiocarbon-dated samples of the scrolls. Enoch uses established
handwriting-style descriptors and applies Bayesian ridge regression. The
challenge of this study is that the number of radiocarbon-dated manuscripts is
small, while current machine learning requires an abundance of training data.
We show that by using combined angular and allographic writing style feature
vectors and applying Bayesian ridge regression, Enoch could predict the
radiocarbon-based dates from style, supported by leave-one-out validation, with
varied MAEs of 27.9 to 30.7 years relative to the radiocarbon dating. Enoch was
then used to estimate the dates of 135 unseen manuscripts, revealing that 79
per cent of the samples were considered 'realistic' upon palaeographic post-hoc
evaluation. We present a new chronology of the scrolls. The radiocarbon ranges
and Enoch's style-based predictions are often older than the traditionally
assumed palaeographic estimates. In the range of 300-50 BCE, Enoch's date
prediction provides an improved granularity. The study is in line with current
developments in multimodal machine-learning techniques, and the methods can be
used for date prediction in other partially-dated manuscript collections. This
research shows how Enoch's quantitative, probability-based approach can be a
tool for palaeographers and historians, re-dating ancient Jewish key texts and
contributing to current debates on Jewish and Christian origins.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>16 pages of main article, 103 pages of supplementary materials; the
  first version of this article is originally prepared in July 2023 after the
  completion of all the experiments</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ MixEval-X: Any-to-Any Evaluations from Real-World Data Mixtures 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.13754v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.13754v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jinjie Ni, Yifan Song, Deepanway Ghosal, Bo Li, David Junhao Zhang, Xiang Yue, Fuzhao Xue, Zian Zheng, Kaichen Zhang, Mahir Shah, Kabir Jain, Yang You, Michael Shieh
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Perceiving and generating diverse modalities are crucial for AI models to
effectively learn from and engage with real-world signals, necessitating
reliable evaluations for their development. We identify two major issues in
current evaluations: (1) inconsistent standards, shaped by different
communities with varying protocols and maturity levels; and (2) significant
query, grading, and generalization biases. To address these, we introduce
MixEval-X, the first any-to-any, real-world benchmark designed to optimize and
standardize evaluations across diverse input and output modalities. We propose
multi-modal benchmark mixture and adaptation-rectification pipelines to
reconstruct real-world task distributions, ensuring evaluations generalize
effectively to real-world use cases. Extensive meta-evaluations show our
approach effectively aligns benchmark samples with real-world task
distributions. Meanwhile, MixEval-X's model rankings correlate strongly with
that of crowd-sourced real-world evaluations (up to 0.98) while being much more
efficient. We provide comprehensive leaderboards to rerank existing models and
organizations and offer insights to enhance understanding of multi-modal
evaluations and inform future research.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ FLEdge: Benchmarking Federated Machine Learning Applications in Edge
  Computing Systems 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2306.05172v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2306.05172v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Herbert Woisetschläger, Alexander Isenko, Ruben Mayer, Shiqiang Wang, Hans-Arno Jacobsen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Federated Learning (FL) has become a viable technique for realizing
privacy-enhancing distributed deep learning on the network edge. Heterogeneous
hardware, unreliable client devices, and energy constraints often characterize
edge computing systems. In this paper, we propose FLEdge, which complements
existing FL benchmarks by enabling a systematic evaluation of client
capabilities. We focus on computational and communication bottlenecks, client
behavior, and data security implications. Our experiments with models varying
from 14K to 80M trainable parameters are carried out on dedicated hardware with
emulated network characteristics and client behavior. We find that
state-of-the-art embedded hardware has significant memory bottlenecks, leading
to 4x longer processing times than on modern data center GPUs.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Paper accepted for publication at the ACM/IFIP Middleware Conference
  2024. Please cite the published version via
  https://doi.org/10.1145/3652892.3700751</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Context-Enhanced Multi-View Trajectory Representation Learning: Bridging
  the Gap through <span class="highlight-title">Self-Supervised</span> Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.13196v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.13196v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Tangwen Qian, Junhe Li, Yile Chen, Gao Cong, Tao Sun, Fei Wang, Yongjun Xu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Modeling trajectory data with generic-purpose dense representations has
become a prevalent paradigm for various downstream applications, such as
trajectory classification, travel time estimation and similarity computation.
However, existing methods typically rely on trajectories from a single spatial
view, limiting their ability to capture the rich contextual information that is
crucial for gaining deeper insights into movement patterns across different
geospatial contexts. To this end, we propose MVTraj, a novel multi-view
modeling method for trajectory representation learning. MVTraj integrates
diverse contextual knowledge, from GPS to road network and points-of-interest
to provide a more comprehensive understanding of trajectory data. To align the
learning process across multiple views, we utilize GPS trajectories as a bridge
and employ self-supervised pretext tasks to capture and distinguish movement
patterns across different spatial views. Following this, we treat trajectories
from different views as distinct modalities and apply a hierarchical
cross-modal interaction module to fuse the representations, thereby enriching
the knowledge derived from multiple sources. Extensive experiments on
real-world datasets demonstrate that MVTraj significantly outperforms existing
baselines in tasks associated with various spatial views, validating its
effectiveness and practical utility in spatio-temporal modeling.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ The Model Openness Framework: Promoting Completeness and Openness for
  Reproducibility, Transparency, and Usability in Artificial Intelligence 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2403.13784v6">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2403.13784v6.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Matt White, Ibrahim Haddad, Cailean Osborne, Xiao-Yang Yanglet Liu, Ahmed Abdelmonsef, Sachin Varghese, Arnaud Le Hors
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Generative artificial intelligence (AI) offers numerous opportunities for
research and innovation, but its commercialization has raised concerns about
the transparency and safety of frontier AI models. Most models lack the
necessary components for full understanding, auditing, and reproducibility, and
some model producers use restrictive licenses whilst claiming that their models
are "open source". To address these concerns, we introduce the Model Openness
Framework (MOF), a three-tiered ranked classification system that rates machine
learning models based on their completeness and openness, following open
science principles. For each MOF class, we specify code, data, and
documentation components of the model development lifecycle that must be
released and under which open licenses. In addition, the Model Openness Tool
(MOT) provides a user-friendly reference implementation to evaluate the
openness and completeness of models against the MOF classification system.
Together, the MOF and MOT provide timely practical guidance for (i) model
producers to enhance the openness and completeness of their publicly-released
models, and (ii) model consumers to identify open models and their constituent
components that can be permissively used, studied, modified, and redistributed.
Through the MOF, we seek to establish completeness and openness as core tenets
of responsible AI research and development, and to promote best practices in
the burgeoning open AI ecosystem.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>28 pages, 4 figures, 2 tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ TotalVibeSegmentator: Full Body MRI Segmentation for the NAKO and UK
  Biobank 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.00125v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.00125v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Robert Graf, Paul-Sören Platzek, Evamaria Olga Riedel, Constanze Ramschütz, Sophie Starck, Hendrik Kristian Möller, Matan Atad, Henry Völzke, Robin Bülow, Carsten Oliver Schmidt, Julia Rüdebusch, Matthias Jung, Marco Reisert, Jakob Weiss, Maximilian Löffler, Fabian Bamberg, Bene Wiestler, Johannes C. Paetzold, Daniel Rueckert, Jan Stefan Kirschke
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Objectives: To present a publicly available torso segmentation network for
large epidemiology datasets on volumetric interpolated breath-hold examination
(VIBE) images. Materials & Methods: We extracted preliminary segmentations from
TotalSegmentator, spine, and body composition networks for VIBE images, then
improved them iteratively and retrained a nnUNet network. Using subsets of NAKO
(85 subjects) and UK Biobank (16 subjects), we evaluated with Dice-score on a
holdout set (12 subjects) and existing organ segmentation approach (1000
subjects), generating 71 semantic segmentation types for VIBE images. We
provide an additional network for the vertebra segments 22 individual vertebra
types. Results: We achieved an average Dice score of 0.89 +- 0.07 overall 71
segmentation labels. We scored > 0.90 Dice-score on the abdominal organs except
for the pancreas with a Dice of 0.70. Conclusion: Our work offers a detailed
and refined publicly available full torso segmentation on VIBE images.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>https://github.com/robert-graf/TotalVibeSegmentator</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Boosting Graph Pooling with Persistent Homology <span class="chip">NeurIPS 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2402.16346v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2402.16346v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Chaolong Ying, Xinjian Zhao, Tianshu Yu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recently, there has been an emerging trend to integrate persistent homology
(PH) into graph neural networks (GNNs) to enrich expressive power. However,
naively plugging PH features into GNN layers always results in marginal
improvement with low interpretability. In this paper, we investigate a novel
mechanism for injecting global topological invariance into pooling layers using
PH, motivated by the observation that filtration operation in PH naturally
aligns graph pooling in a cut-off manner. In this fashion, message passing in
the coarsened graph acts along persistent pooled topology, leading to improved
performance. Experimentally, we apply our mechanism to a collection of graph
pooling methods and observe consistent and substantial performance gain over
several popular datasets, demonstrating its wide applicability and flexibility.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Published at NeurIPS 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Communication-Efficient Distributed Deep Learning via Federated Dynamic
  Averaging <span class="chip">EDBT 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.20988v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.20988v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Michail Theologitis, Georgios Frangias, Georgios Anestis, Vasilis Samoladas, Antonios Deligiannakis
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Driven by the ever-growing volume and decentralized nature of data, coupled
with the need to harness this data and generate knowledge from it, has led to
the extensive use of distributed deep learning (DDL) techniques for training.
These techniques rely on local training that is performed at the distributed
nodes based on locally collected data, followed by a periodic synchronization
process that combines these models to create a global model. However, frequent
synchronization of DL models, encompassing millions to many billions of
parameters, creates a communication bottleneck, severely hindering scalability.
Worse yet, DDL algorithms typically waste valuable bandwidth, and make
themselves less practical in bandwidth-constrained federated settings, by
relying on overly simplistic, periodic, and rigid synchronization schedules.
These drawbacks also have a direct impact on the time required for the training
process, necessitating excessive time for data communication. To address these
shortcomings, we propose Federated Dynamic Averaging (FDA), a
communication-efficient DDL strategy that dynamically triggers synchronization
based on the value of the model variance. In essence, the costly
synchronization step is triggered only if the local models, which are
initialized from a common global model after each synchronization, have
significantly diverged. This decision is facilitated by the communication of a
small local state from each distributed node/worker. Through extensive
experiments across a wide range of learning tasks we demonstrate that FDA
reduces communication cost by orders of magnitude, compared to both traditional
and cutting-edge communication-efficient algorithms. Additionally, we show that
FDA maintains robust performance across diverse data heterogeneity settings.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted as research paper at EDBT 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ FedECA: A Federated External Control Arm Method for Causal Inference
  with Time-To-Event Data in Distributed Settings 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2311.16984v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2311.16984v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jean Ogier du Terrail, Quentin Klopfenstein, Honghao Li, Imke Mayer, Nicolas Loiseau, Mohammad Hallal, Michael Debouver, Thibault Camalon, Thibault Fouqueray, Jorge Arellano Castro, Zahia Yanes, Laetitia Dahan, Julien Taïeb, Pierre Laurent-Puig, Jean-Baptiste Bachet, Shulin Zhao, Remy Nicolle, Jérome Cros, Daniel Gonzalez, Robert Carreras-Torres, Adelaida Garcia Velasco, Kawther Abdilleh, Sudheer Doss, Félix Balazard, Mathieu Andreux
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  External control arms (ECA) can inform the early clinical development of
experimental drugs and provide efficacy evidence for regulatory approval.
However, the main challenge in implementing ECA lies in accessing real-world or
historical clinical trials data. Indeed, regulations protecting patients'
rights by strictly controlling data processing make pooling data from multiple
sources in a central server often difficult. To address these limitations, we
develop a new method, 'FedECA' that leverages federated learning (FL) to enable
inverse probability of treatment weighting (IPTW) for time-to-event outcomes on
separate cohorts without needing to pool data. To showcase the potential of
FedECA, we apply it in different settings of increasing complexity culminating
with a real-world use-case in which FedECA provides evidence for a differential
effect between two drugs that would have otherwise gone unnoticed. By sharing
our code, we hope FedECA will foster the creation of federated research
networks and thus accelerate drug development.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>code available at: https://github.com/owkin/fedeca, bug in SMD
  computation present in v1 and v2 has been fixed, many experiments on real
  data have been added + fix in YODA experiments using imputed data instead of
  raw data as well as typos and affiliations fix</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Simple Opinion Dynamics for No-Regret Learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2306.08670v5">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2306.08670v5.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        John Lazarsfeld, Dan Alistarh
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We study a cooperative multi-agent bandit setting in the distributed GOSSIP
model: in every round, each of $n$ agents chooses an action from a common set,
observes the action's corresponding reward, and subsequently exchanges
information with a single randomly chosen neighbor, which may inform its choice
in the next round. We introduce and analyze families of memoryless and
time-independent protocols for this setting, inspired by opinion dynamics that
are well-studied for other algorithmic tasks in the GOSSIP model. For
stationary reward settings, we prove for the first time that these simple
protocols exhibit best-of-both-worlds behavior, simultaneously obtaining
constant cumulative regret scaling like $R(T)/T = \widetilde O(1/T)$, and also
reaching consensus on the highest-mean action within $\widetilde O(\sqrt{n})$
rounds. We obtain these results by showing a new connection between the global
evolution of these decentralized protocols and a class of zero-sum
multiplicative weights update} processes. Using this connection, we establish a
general framework for analyzing the population-level regret and other
properties of our protocols. Finally, we show our protocols are also
surprisingly robust to adversarial rewards, and in this regime we obtain
sublinear regret scaling like $R(T)/T = \widetilde O(1/\sqrt{T})$ as long as
the number of rounds does not grow too fast as a function of $n$.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Integrating spoken instructions into flight trajectory prediction to
  optimize automation in air traffic control 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2305.01661v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2305.01661v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Dongyue Guo, Zheng Zhang, Bo Yang, Jianwei Zhang, Hongyu Yang, Yi Lin
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The booming air transportation industry inevitably burdens air traffic
controllers' workload, causing unexpected human factor-related incidents.
Current air traffic control systems fail to consider spoken instructions for
traffic prediction, bringing significant challenges in detecting human errors
during real-time traffic operations. Here, we present an automation paradigm
integrating controlling intent into the information processing loop through the
spoken instruction-aware flight trajectory prediction framework. A 3-stage
progressive multi-modal learning paradigm is proposed to address the modality
gap between the trajectory and spoken instructions, as well as minimize the
data requirements. Experiments on a real-world dataset show the proposed
framework achieves flight trajectory prediction with high predictability and
timeliness, obtaining over 20% relative reduction in mean deviation error.
Moreover, the generalizability of the proposed framework is also confirmed by
various model architectures. The proposed framework can formulate
full-automated information processing in real-world air traffic applications,
supporting human error detection and enhancing aviation safety.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>This paper has been accepted in principle by Nature Communications</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Large Language Model Based Generative Error Correction: A Challenge and
  Baselines for Speech Recognition, Speaker Tagging, and Emotion Recognition 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.09785v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.09785v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Chao-Han Huck Yang, Taejin Park, Yuan Gong, Yuanchao Li, Zhehuai Chen, Yen-Ting Lin, Chen Chen, Yuchen Hu, Kunal Dhawan, Piotr Żelasko, Chao Zhang, Yun-Nung Chen, Yu Tsao, Jagadeesh Balam, Boris Ginsburg, Sabato Marco Siniscalchi, Eng Siong Chng, Peter Bell, Catherine Lai, Shinji Watanabe, Andreas Stolcke
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Given recent advances in generative AI technology, a key question is how
large language models (LLMs) can enhance acoustic modeling tasks using text
decoding results from a frozen, pretrained automatic speech recognition (ASR)
model. To explore new capabilities in language modeling for speech processing,
we introduce the generative speech transcription error correction (GenSEC)
challenge. This challenge comprises three post-ASR language modeling tasks: (i)
post-ASR transcription correction, (ii) speaker tagging, and (iii) emotion
recognition. These tasks aim to emulate future LLM-based agents handling
voice-based interfaces while remaining accessible to a broad audience by
utilizing open pretrained language models or agent-based APIs. We also discuss
insights from baseline evaluations, as well as lessons learned for designing
future evaluations.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>IEEE SLT 2024. The initial draft version has been done in December
  2023. Post-ASR Text Processing and Understanding Community and LlaMA-7B
  pre-training correction model:
  https://huggingface.co/GenSEC-LLM/SLT-Task1-Llama2-7b-HyPo-baseline</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ WaterMax: breaking the LLM watermark detectability-robustness-quality
  trade-off 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2403.04808v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2403.04808v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Eva Giboulot, Teddy Furon
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Watermarking is a technical means to dissuade malfeasant usage of Large
Language Models. This paper proposes a novel watermarking scheme, so-called
WaterMax, that enjoys high detectability while sustaining the quality of the
generated text of the original LLM. Its new design leaves the LLM untouched (no
modification of the weights, logits, temperature, or sampling technique).
WaterMax balances robustness and complexity contrary to the watermarking
techniques of the literature inherently provoking a trade-off between quality
and robustness. Its performance is both theoretically proven and experimentally
validated. It outperforms all the SotA techniques under the most complete
benchmark suite. Code available at https://github.com/eva-giboulot/WaterMax.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Towards Satellite Non-IID Imagery: A Spectral Clustering-Assisted
  Federated Learning Approach 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.13602v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.13602v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Luyao Zou, Yu Min Park, Chu Myaet Thwal, Yan Kyaw Tun, Zhu Han, Choong Seon Hong
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Low Earth orbit (LEO) satellites are capable of gathering abundant Earth
observation data (EOD) to enable different Internet of Things (IoT)
applications. However, to accomplish an effective EOD processing mechanism, it
is imperative to investigate: 1) the challenge of processing the observed data
without transmitting those large-size data to the ground because the connection
between the satellites and the ground stations is intermittent, and 2) the
challenge of processing the non-independent and identically distributed
(non-IID) satellite data. In this paper, to cope with those challenges, we
propose an orbit-based spectral clustering-assisted clustered federated
self-knowledge distillation (OSC-FSKD) approach for each orbit of an LEO
satellite constellation, which retains the advantage of FL that the observed
data does not need to be sent to the ground. Specifically, we introduce
normalized Laplacian-based spectral clustering (NLSC) into federated learning
(FL) to create clustered FL in each round to address the challenge resulting
from non-IID data. Particularly, NLSC is adopted to dynamically group clients
into several clusters based on cosine similarities calculated by model updates.
In addition, self-knowledge distillation is utilized to construct each local
client, where the most recent updated local model is used to guide current
local model training. Experiments demonstrate that the observation accuracy
obtained by the proposed method is separately 1.01x, 2.15x, 1.10x, and 1.03x
higher than that of pFedSD, FedProx, FedAU, and FedALA approaches using the
SAT4 dataset. The proposed method also shows superiority when using other
datasets.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>10 pages, 5 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Node Identifiers: Compact, Discrete Representations for Efficient Graph
  Learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.16435v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.16435v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yuankai Luo, Hongkang Li, Qijiong Liu, Lei Shi, Xiao-Ming Wu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We present a novel end-to-end framework that generates highly compact
(typically 6-15 dimensions), discrete (int4 type), and interpretable node
representations, termed node identifiers (node IDs), to tackle inference
challenges on large-scale graphs. By employing vector quantization, we compress
continuous node embeddings from multiple layers of a Graph Neural Network (GNN)
into discrete codes, applicable under both self-supervised and supervised
learning paradigms. These node IDs capture high-level abstractions of graph
data and offer interpretability that traditional GNN embeddings lack. Extensive
experiments on 34 datasets, encompassing node classification, graph
classification, link prediction, and attributed graph clustering tasks,
demonstrate that the generated node IDs significantly enhance speed and memory
efficiency while achieving competitive performance compared to current
state-of-the-art methods.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ ScoreFusion: fusing score-based generative models via Kullback-Leibler
  barycenters 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19619v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19619v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hao Liu, Junze Tony Ye, Jose Blanchet, Nian Si
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We introduce ScoreFusion, a theoretically grounded method for fusing multiple
pre-trained diffusion models that are assumed to generate from auxiliary
populations. ScoreFusion is particularly useful for enhancing the generative
modeling of a target population with limited observed data. Our starting point
considers the family of KL barycenters of the auxiliary populations, which is
proven to be an optimal parametric class in the KL sense, but difficult to
learn. Nevertheless, by recasting the learning problem as score matching in
denoising diffusion, we obtain a tractable way of computing the optimal KL
barycenter weights. We prove a dimension-free sample complexity bound in total
variation distance, provided that the auxiliary models are well fitted for
their own task and the auxiliary tasks combined capture the target well. We
also explain a connection of the practice of checkpoint merging in AI art
creation to an approximation of our KL-barycenter-based fusion approach.
However, our fusion method differs in key aspects, allowing generation of new
populations, as we illustrate in experiments.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>53 pages, 15 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ FedSN: A Federated Learning Framework over Heterogeneous LEO Satellite
  Networks 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2311.01483v5">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2311.01483v5.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zheng Lin, Zhe Chen, Zihan Fang, Xianhao Chen, Xiong Wang, Yue Gao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recently, a large number of Low Earth Orbit (LEO) satellites have been
launched and deployed successfully in space by commercial companies, such as
SpaceX. Due to multimodal sensors equipped by the LEO satellites, they serve
not only for communication but also for various machine learning applications,
such as space modulation recognition, remote sensing image classification, etc.
However, the ground station (GS) may be incapable of downloading such a large
volume of raw sensing data for centralized model training due to the limited
contact time with LEO satellites (e.g. 5 minutes). Therefore, federated
learning (FL) has emerged as the promising solution to address this problem via
on-device training. Unfortunately, to enable FL on LEO satellites, we still
face three critical challenges that are i) heterogeneous computing and memory
capabilities, ii) limited uplink rate, and iii) model staleness. To this end,
we propose FedSN as a general FL framework to tackle the above challenges, and
fully explore data diversity on LEO satellites. Specifically, we first present
a novel sub-structure scheme to enable heterogeneous local model training
considering different computing, memory, and communication constraints on LEO
satellites. Additionally, we propose a pseudo-synchronous model aggregation
strategy to dynamically schedule model aggregation for compensating model
staleness. To further demonstrate the effectiveness of the FedSN, we evaluate
it using space modulation recognition and remote sensing image classification
tasks by leveraging the data from real-world satellite networks. Extensive
experimental results demonstrate that FedSN framework achieves higher accuracy,
lower computing, and communication overhead than the state-of-the-art
benchmarks and the effectiveness of each components in FedSN.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>15 pages, 17 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Social Dynamics of Consumer Response: A Unified Framework Integrating
  Statistical Physics and Marketing Dynamics 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2404.02175v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2404.02175v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Javier Marin
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Understanding how consumers react to advertising inputs is essential for
marketers aiming to optimize advertising strategies and improve campaign
effectiveness. This study examines the complex nature of consumer behaviour by
applying theoretical frameworks derived from physics and social psychology. We
present an innovative equation that captures the relation between spending on
advertising and consumer response, using concepts such as symmetries, scaling
laws, and phase transitions. By validating our equation against well-known
models such as the Michaelis-Menten and Hill equations, we prove its
effectiveness in accurately representing the complexity of consumer response
dynamics. The analysis emphasizes the importance of key model parameters, such
as marketing effectiveness, response sensitivity, and behavioural sensitivity,
in influencing consumer behaviour. The work explores the practical implications
for advertisers and marketers, as well as discussing the limitations and future
research directions. In summary, this study provides a thorough framework for
comprehending and forecasting consumer reactions to advertising, which has
implications for optimizing advertising strategies and allocating resources.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Theories of synaptic memory consolidation and intelligent plasticity for
  continual learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.16922v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.16922v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Friedemann Zenke, Axel Laborieux
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Humans and animals learn throughout life. Such continual learning is crucial
for intelligence. In this chapter, we examine the pivotal role plasticity
mechanisms with complex internal synaptic dynamics could play in enabling this
ability in neural networks. By surveying theoretical research, we highlight two
fundamental enablers for continual learning. First, synaptic plasticity
mechanisms must maintain and evolve an internal state over several behaviorally
relevant timescales. Second, plasticity algorithms must leverage the internal
state to intelligently regulate plasticity at individual synapses to facilitate
the seamless integration of new memories while avoiding detrimental
interference with existing ones. Our chapter covers successful applications of
these principles to deep neural networks and underscores the significance of
synaptic metaplasticity in sustaining continual learning capabilities. Finally,
we outline avenues for further research to understand the brain's superb
continual learning abilities and harness similar mechanisms for artificial
intelligence systems.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>An introductory-level book chapter. 35 pages, 14 figures</span>
                                        </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
            <article>
                <details>
                    <Summary>
                        Multimedia <span class="chip" style="font-size: 60%">7</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Parallel Backpropagation for Inverse of a Convolution with Application
  to Normalizing Flows 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14634v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14634v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Sandeep Nagar, Girish Varma
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Inverse of an invertible convolution is an important operation that comes up
in Normalizing Flows, Image Deblurring, etc. The naive algorithm for
backpropagation of this operation using Gaussian elimination has running time
$O(n^3)$ where $n$ is the number of pixels in the image. We give a fast
parallel backpropagation algorithm with running time $O(\sqrt{n})$ for a square
image and provide a GPU implementation of the same. Inverse Convolutions are
usually used in Normalizing Flows in the sampling pass, making them slow. We
propose to use Inverse Convolutions in the forward (image to latent vector)
pass of the Normalizing flow. Since the sampling pass is the inverse of the
forward pass, it will use convolutions only, resulting in efficient sampling
times. We use our parallel backpropagation algorithm for optimizing the inverse
convolution layer resulting in fast training times also. We implement this
approach in various Normalizing Flow backbones, resulting in our Inverse-Flow
models. We benchmark Inverse-Flow on standard datasets and show significantly
improved sampling times with similar bits per dimension compared to previous
models.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Preprint</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ RA-BLIP: Multimodal Adaptive Retrieval-Augmented Bootstrapping
  Language-Image <span class="highlight-title">Pre-train</span>ing 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14154v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14154v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Muhe Ding, Yang Ma, Pengda Qin, Jianlong Wu, Yuhong Li, Liqiang Nie
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Multimodal Large Language Models (MLLMs) have recently received substantial
interest, which shows their emerging potential as general-purpose models for
various vision-language tasks. MLLMs involve significant external knowledge
within their parameters; however, it is challenging to continually update these
models with the latest knowledge, which involves huge computational costs and
poor interpretability. Retrieval augmentation techniques have proven to be
effective plugins for both LLMs and MLLMs. In this study, we propose multimodal
adaptive Retrieval-Augmented Bootstrapping Language-Image Pre-training
(RA-BLIP), a novel retrieval-augmented framework for various MLLMs. Considering
the redundant information within vision modality, we first leverage the
question to instruct the extraction of visual information through interactions
with one set of learnable queries, minimizing irrelevant interference during
retrieval and generation. Besides, we introduce a pre-trained multimodal
adaptive fusion module to achieve question text-to-multimodal retrieval and
integration of multimodal knowledge by projecting visual and language
modalities into a unified semantic space. Furthermore, we present an Adaptive
Selection Knowledge Generation (ASKG) strategy to train the generator to
autonomously discern the relevance of retrieved knowledge, which realizes
excellent denoising performance. Extensive experiments on open multimodal
question-answering datasets demonstrate that RA-BLIP achieves significant
performance and surpasses the state-of-the-art retrieval-augmented models.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>10 pages, 6 figures, Journal</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Movie101v2: Improved Movie Narration Benchmark 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2404.13370v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2404.13370v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zihao Yue, Yepeng Zhang, Ziheng Wang, Qin Jin
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Automatic movie narration aims to generate video-aligned plot descriptions to
assist visually impaired audiences. Unlike standard video captioning, it
involves not only describing key visual details but also inferring plots that
unfold across multiple movie shots, presenting distinct and complex challenges.
To advance this field, we introduce Movie101v2, a large-scale, bilingual
dataset with enhanced data quality specifically designed for movie narration.
Revisiting the task, we propose breaking down the ultimate goal of automatic
movie narration into three progressive stages, offering a clear roadmap with
corresponding evaluation metrics. Based on our new benchmark, we baseline a
range of large vision-language models, including GPT-4V, and conduct an
in-depth analysis of the challenges in narration generation. Our findings
highlight that achieving applicable movie narration generation is a fascinating
goal that requires significant research.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Perceptual Quality Assessment of Octree-RAHT Encoded 3D Point Clouds 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.06729v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.06729v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Dongshuai Duan, Honglei Su, Qi Liu, Hui Yuan, Wei Gao, Jiarun Song, Zhou Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  No-reference bitstream-layer point cloud quality assessment (PCQA) can be
deployed without full decoding at any network node to achieve real-time quality
monitoring. In this work, we focus on the PCQA problem dedicated to Octree-RAHT
encoding mode. First, to address the issue that existing PCQA databases have a
small scale and limited distortion levels, we establish the WPC5.0 database
which is the first one dedicated to Octree-RAHT encoding mode with a scale of
400 distorted point clouds (PCs) including 4 geometric multiplied by 5 attitude
distortion levels. Then, we propose the first PCQA model dedicated to
Octree-RAHT encoding mode by parsing PC bitstreams without full decoding. The
model introduces texture bitrate (TBPP) to predict texture complexity (TC) and
further derives the texture distortion factor. In addition, the Geometric
Quantization Parameter (PQS) is used to estimate the geometric distortion
factor, which is then integrated into the model along with the texture
distortion factor to obtain the proposed PCQA model named streamPCQ-OR. The
proposed model has been compared with other advanced PCQA methods on the
WPC5.0, BASICS and M-PCCD databases, and experimental results show that our
model has excellent performance while having very low computational complexity,
providing a reliable choice for time-critical applications. To facilitate
subsequent research, the database and source code will be publicly released at
https://github.com/qdushl/Waterloo-Point-Cloud-Database-5.0.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Evaluating Semantic Variation in Text-to-Image Synthesis: A Causal
  Perspective 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.10291v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.10291v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xiangru Zhu, Penglei Sun, Yaoxian Song, Yanghua Xiao, Zhixu Li, Chengyu Wang, Jun Huang, Bei Yang, Xiaoxiao Xu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Accurate interpretation and visualization of human instructions are crucial
for text-to-image (T2I) synthesis. However, current models struggle to capture
semantic variations from word order changes, and existing evaluations, relying
on indirect metrics like text-image similarity, fail to reliably assess these
challenges. This often obscures poor performance on complex or uncommon
linguistic patterns by the focus on frequent word combinations. To address
these deficiencies, we propose a novel metric called SemVarEffect and a
benchmark named SemVarBench, designed to evaluate the causality between
semantic variations in inputs and outputs in T2I synthesis. Semantic variations
are achieved through two types of linguistic permutations, while avoiding
easily predictable literal variations. Experiments reveal that the
CogView-3-Plus and Ideogram 2 performed the best, achieving a score of 0.2/1.
Semantic variations in object relations are less understood than attributes,
scoring 0.07/1 compared to 0.17-0.19/1. We found that cross-modal alignment in
UNet or Transformers plays a crucial role in handling semantic variations, a
factor previously overlooked by a focus on textual encoders. Our work
establishes an effective evaluation framework that advances the T2I synthesis
community's exploration of human instruction understanding. Our benchmark and
code are available at https://github.com/zhuxiangru/SemVarBench .
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>The only change in the current version update is the replacement of
  the template with a more precise one</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ MixEval-X: Any-to-Any Evaluations from Real-World Data Mixtures 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.13754v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.13754v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jinjie Ni, Yifan Song, Deepanway Ghosal, Bo Li, David Junhao Zhang, Xiang Yue, Fuzhao Xue, Zian Zheng, Kaichen Zhang, Mahir Shah, Kabir Jain, Yang You, Michael Shieh
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Perceiving and generating diverse modalities are crucial for AI models to
effectively learn from and engage with real-world signals, necessitating
reliable evaluations for their development. We identify two major issues in
current evaluations: (1) inconsistent standards, shaped by different
communities with varying protocols and maturity levels; and (2) significant
query, grading, and generalization biases. To address these, we introduce
MixEval-X, the first any-to-any, real-world benchmark designed to optimize and
standardize evaluations across diverse input and output modalities. We propose
multi-modal benchmark mixture and adaptation-rectification pipelines to
reconstruct real-world task distributions, ensuring evaluations generalize
effectively to real-world use cases. Extensive meta-evaluations show our
approach effectively aligns benchmark samples with real-world task
distributions. Meanwhile, MixEval-X's model rankings correlate strongly with
that of crowd-sourced real-world evaluations (up to 0.98) while being much more
efficient. We provide comprehensive leaderboards to rerank existing models and
organizations and offer insights to enhance understanding of multi-modal
evaluations and inform future research.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Synthesizing Sentiment-Controlled Feedback For Multimodal Text and Image
  Data 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2402.07640v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2402.07640v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Puneet Kumar, Sarthak Malik, Balasubramanian Raman, Xiaobai Li
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The ability to generate sentiment-controlled feedback in response to
multimodal inputs comprising text and images addresses a critical gap in
human-computer interaction. This capability allows systems to provide
empathetic, accurate, and engaging responses, with useful applications in
education, healthcare, marketing, and customer service. To this end, we have
constructed a large-scale Controllable Multimodal Feedback Synthesis (CMFeed)
dataset and propose a controllable feedback synthesis system. The system
features an encoder, decoder, and controllability block for textual and visual
inputs. It extracts features using a transformer and Faster R-CNN networks,
combining them to generate feedback. The CMFeed dataset includes images, texts,
reactions to the posts, human comments with relevance scores, and reactions to
these comments. These reactions train the model to produce feedback with
specified sentiments, achieving a sentiment classification accuracy of 77.23\%,
which is 18.82\% higher than the accuracy without controllability. The system
also incorporates a similarity module for assessing feedback relevance through
rank-based metrics and an interpretability technique to analyze the
contributions of textual and visual features during feedback generation. Access
to the CMFeed dataset and the system's code is available at
https://github.com/MIntelligence-Group/CMFeed.
</span>
                                    </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
    </section>
    <section class="day-container">
        <div class="date">
            <time datetime="2024-10-17T00:00:00Z">2024-10-17</time>
        </div>
            <article>
                <details>
                    <Summary>
                        Computer Vision and Pattern Recognition <span class="chip" style="font-size: 60%">42</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ MMAD-Purify: A Precision-Optimized Framework for Efficient and Scalable
  Multi-Modal Attacks 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14089v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14089v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xinxin Liu, Zhongliang Guo, Siyuan Huang, Chun Pong Lau
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Neural networks have achieved remarkable performance across a wide range of
tasks, yet they remain susceptible to adversarial perturbations, which pose
significant risks in safety-critical applications. With the rise of
multimodality, diffusion models have emerged as powerful tools not only for
generative tasks but also for various applications such as image editing,
inpainting, and super-resolution. However, these models still lack robustness
due to limited research on attacking them to enhance their resilience.
Traditional attack techniques, such as gradient-based adversarial attacks and
diffusion model-based methods, are hindered by computational inefficiencies and
scalability issues due to their iterative nature. To address these challenges,
we introduce an innovative framework that leverages the distilled backbone of
diffusion models and incorporates a precision-optimized noise predictor to
enhance the effectiveness of our attack framework. This approach not only
enhances the attack's potency but also significantly reduces computational
costs. Our framework provides a cutting-edge solution for multi-modal
adversarial attacks, ensuring reduced latency and the generation of
high-fidelity adversarial examples with superior success rates. Furthermore, we
demonstrate that our framework achieves outstanding transferability and
robustness against purification defenses, outperforming existing gradient-based
attack models in both effectiveness and efficiency.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Your Interest, Your Summaries: Query-Focused Long Video Summarization 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14087v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14087v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Nirav Patel, Payal Prajapati, Maitrik Shah
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Generating a concise and informative video summary from a long video is
important, yet subjective due to varying scene importance. Users' ability to
specify scene importance through text queries enhances the relevance of such
summaries. This paper introduces an approach for query-focused video
summarization, aiming to align video summaries closely with user queries. To
this end, we propose the Fully Convolutional Sequence Network with Attention
(FCSNA-QFVS), a novel approach designed for this task. Leveraging temporal
convolutional and attention mechanisms, our model effectively extracts and
highlights relevant content based on user-specified queries. Experimental
validation on a benchmark dataset for query-focused video summarization
demonstrates the effectiveness of our approach.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>To appear at the 18th International Conference on Control,
  Automation, Robotics and Vision (ICARCV), December 2024, Dubai, UAE</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Self Supervised Deep Learning for Robot Grasping 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14084v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14084v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Danyal Saqib, Wajahat Hussain
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Learning Based Robot Grasping currently involves the use of labeled data.
This approach has two major disadvantages. Firstly, labeling data for grasp
points and angles is a strenuous process, so the dataset remains limited.
Secondly, human labeling is prone to bias due to semantics.
  In order to solve these problems we propose a simpler self-supervised robotic
setup, that will train a Convolutional Neural Network (CNN). The robot will
label and collect the data during the training process. The idea is to make a
robot that is less costly, small and easily maintainable in a lab setup. The
robot will be trained on a large data set for several hundred hours and then
the trained Neural Network can be mapped onto a larger grasping robot.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ SAMReg: SAM-enabled Image Registration with ROI-based Correspondence 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14083v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14083v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Shiqi Huang, Tingfa Xu, Ziyi Shen, Shaheer Ullah Saeed, Wen Yan, Dean Barratt, Yipeng Hu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper describes a new spatial correspondence representation based on
paired regions-of-interest (ROIs), for medical image registration. The distinct
properties of the proposed ROI-based correspondence are discussed, in the
context of potential benefits in clinical applications following image
registration, compared with alternative correspondence-representing approaches,
such as those based on sampled displacements and spatial transformation
functions. These benefits include a clear connection between learning-based
image registration and segmentation, which in turn motivates two cases of image
registration approaches using (pre-)trained segmentation networks. Based on the
segment anything model (SAM), a vision foundation model for segmentation, we
develop a new registration algorithm SAMReg, which does not require any
training (or training data), gradient-based fine-tuning or prompt engineering.
The proposed SAMReg models are evaluated across five real-world applications,
including intra-subject registration tasks with cardiac MR and lung CT,
challenging inter-subject registration scenarios with prostate MR and retinal
imaging, and an additional evaluation with a non-clinical example with aerial
image registration. The proposed methods outperform both intensity-based
iterative algorithms and DDF-predicting learning-based networks across tested
metrics including Dice and target registration errors on anatomical structures,
and further demonstrates competitive performance compared to weakly-supervised
registration approaches that rely on fully-segmented training data. Open source
code and examples are available at: https://github.com/sqhuang0103/SAMReg.git.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Efficient Vision-Language Models by Summarizing Visual Tokens into
  Compact Registers 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14072v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14072v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yuxin Wen, Qingqing Cao, Qichen Fu, Sachin Mehta, Mahyar Najibi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent advancements in vision-language models (VLMs) have expanded their
potential for real-world applications, enabling these models to perform complex
reasoning on images. In the widely used fully autoregressive transformer-based
models like LLaVA, projected visual tokens are prepended to textual tokens.
Oftentimes, visual tokens are significantly more than prompt tokens, resulting
in increased computational overhead during both training and inference. In this
paper, we propose Visual Compact Token Registers (Victor), a method that
reduces the number of visual tokens by summarizing them into a smaller set of
register tokens. Victor adds a few learnable register tokens after the visual
tokens and summarizes the visual information into these registers using the
first few layers in the language tower of VLMs. After these few layers, all
visual tokens are discarded, significantly improving computational efficiency
for both training and inference. Notably, our method is easy to implement and
requires a small number of new trainable parameters with minimal impact on
model performance. In our experiment, with merely 8 visual registers--about 1%
of the original tokens--Victor shows less than a 4% accuracy drop while
reducing the total training time by 43% and boosting the inference throughput
by 3.3X.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ FaceSaliencyAug: Mitigating Geographic, Gender and Stereotypical Biases
  via Saliency-Based Data Augmentation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14070v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14070v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Teerath Kumar, Alessandra Mileo, Malika Bendechache
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Geographical, gender and stereotypical biases in computer vision models pose
significant challenges to their performance and fairness. {In this study, we
present an approach named FaceSaliencyAug aimed at addressing the gender bias
in} {Convolutional Neural Networks (CNNs) and Vision Transformers (ViTs).
Leveraging the salient regions} { of faces detected by saliency, the propose
approach mitigates geographical and stereotypical biases } {in the datasets.
FaceSaliencyAug} randomly selects masks from a predefined search space and
applies them to the salient region of face images, subsequently restoring the
original image with masked salient region. {The proposed} augmentation strategy
enhances data diversity, thereby improving model performance and debiasing
effects. We quantify dataset diversity using Image Similarity Score (ISS)
across five datasets, including Flickr Faces HQ (FFHQ), WIKI, IMDB, Labelled
Faces in the Wild (LFW), UTK Faces, and Diverse Dataset. The proposed approach
demonstrates superior diversity metrics, as evaluated by ISS-intra and
ISS-inter algorithms. Furthermore, we evaluate the effectiveness of our
approach in mitigating gender bias on CEO, Engineer, Nurse, and School Teacher
datasets. We use the Image-Image Association Score (IIAS) to measure gender
bias in these occupations. Our experiments reveal a reduction in gender bias
for both CNNs and ViTs, indicating the efficacy of our method in promoting
fairness and inclusivity in computer vision models.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted at Image Signal and Video processing</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ On Partial Prototype Collapse in the DINO Family of <span class="highlight-title">Self-Supervised</span>
  Methods <span class="chip">BMVC 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14060v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14060v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hariprasath Govindarajan, Per Sidén, Jacob Roll, Fredrik Lindsten
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  A prominent self-supervised learning paradigm is to model the representations
as clusters, or more generally as a mixture model. Learning to map the data
samples to compact representations and fitting the mixture model simultaneously
leads to the representation collapse problem. Regularizing the distribution of
data points over the clusters is the prevalent strategy to avoid this issue.
While this is sufficient to prevent full representation collapse, we show that
a partial prototype collapse problem still exists in the DINO family of
methods, that leads to significant redundancies in the prototypes. Such
prototype redundancies serve as shortcuts for the method to achieve a marginal
latent class distribution that matches the prescribed prior. We show that by
encouraging the model to use diverse prototypes, the partial prototype collapse
can be mitigated. Effective utilization of the prototypes enables the methods
to learn more fine-grained clusters, encouraging more informative
representations. We demonstrate that this is especially beneficial when
pre-training on a long-tailed fine-grained dataset.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>First version of the paper appeared in OpenReview on 22 Sep 2023.
  Accepted to BMVC 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Learning Multimodal Cues of Children's Uncertainty <span class="chip">SIGDIAL 2023</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14050v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14050v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Qi Cheng, Mert İnan, Rahma Mbarki, Grace Grmek, Theresa Choi, Yiming Sun, Kimele Persaud, Jenny Wang, Malihe Alikhani
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Understanding uncertainty plays a critical role in achieving common ground
(Clark et al.,1983). This is especially important for multimodal AI systems
that collaborate with users to solve a problem or guide the user through a
challenging concept. In this work, for the first time, we present a dataset
annotated in collaboration with developmental and cognitive psychologists for
the purpose of studying nonverbal cues of uncertainty. We then present an
analysis of the data, studying different roles of uncertainty and its
relationship with task difficulty and performance. Lastly, we present a
multimodal machine learning model that can predict uncertainty given a
real-time video clip of a participant, which we find improves upon a baseline
multimodal transformer model. This work informs research on cognitive
coordination between human-human and human-AI and has broad implications for
gesture understanding and generation. The anonymized version of our data and
code will be publicly available upon the completion of the required consent
forms and data sheets.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>SIGDIAL 2023</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Human Action Anticipation: A <span class="highlight-title">Survey</span> 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14045v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14045v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Bolin Lai, Sam Toyer, Tushar Nagarajan, Rohit Girdhar, Shengxin Zha, James M. Rehg, Kris Kitani, Kristen Grauman, Ruta Desai, Miao Liu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Predicting future human behavior is an increasingly popular topic in computer
vision, driven by the interest in applications such as autonomous vehicles,
digital assistants and human-robot interactions. The literature on behavior
prediction spans various tasks, including action anticipation, activity
forecasting, intent prediction, goal prediction, and so on. Our survey aims to
tie together this fragmented literature, covering recent technical innovations
as well as the development of new large-scale datasets for model training and
evaluation. We also summarize the widely-used metrics for different tasks and
provide a comprehensive performance comparison of existing approaches on eleven
action anticipation datasets. This survey serves as not only a reference for
contemporary methodologies in action anticipation, but also a guideline for
future research direction of this evolving landscape.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>30 pages, 9 figures, 12 tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Segmentation of Pediatric Brain Tumors using a Radiologically informed,
  Deep Learning Cascade 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14020v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14020v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Timothy Mulvany, Daniel Griffiths-King, Jan Novak, Heather Rose
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Monitoring of Diffuse Intrinsic Pontine Glioma (DIPG) and Diffuse Midline
Glioma (DMG) brain tumors in pediatric patients is key for assessment of
treatment response. Response Assessment in Pediatric Neuro-Oncology (RAPNO)
guidelines recommend the volumetric measurement of these tumors using MRI.
Segmentation challenges, such as the Brain Tumor Segmentation (BraTS)
Challenge, promote development of automated approaches which are replicable,
generalizable and accurate, to aid in these tasks. The current study presents a
novel adaptation of existing nnU-Net approaches for pediatric brain tumor
segmentation, submitted to the BraTS-PEDs 2024 challenge. We apply an adapted
nnU-Net with hierarchical cascades to the segmentation task of the BraTS-PEDs
2024 challenge. The residual encoder variant of nnU-Net, used as our baseline
model, already provides high quality segmentations. We incorporate multiple
changes to the implementation of nnU-Net and devise a novel two-stage cascaded
nnU-Net to segment the substructures of brain tumors from coarse to fine. Using
outputs from the nnU-Net Residual Encoder (trained to segment CC, ED, ET and
NET tumor labels from T1w, T1w-CE, T2w and T2-FLAIR MRI), these are passed to
two additional models one classifying ET versus NET and a second classifying CC
vs ED using cascade learning. We use radiological guidelines to steer which
multi parametric MRI (mpMRI) to use in these cascading models. Compared to a
default nnU-Net and an ensembled nnU-net as baseline approaches, our novel
method provides robust segmentations for the BraTS-PEDs 2024 challenge,
achieving mean Dice scores of 0.657, 0.904, 0.703, and 0.967, and HD95 of 76.2,
10.1, 111.0, and 12.3 for the ET, NET, CC and ED, respectively.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Probabilistic U-Net with Kendall Shape Spaces for Geometry-Aware
  Segmentations of Images 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14017v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14017v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jiyoung Park, Günay Doğan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  One of the fundamental problems in computer vision is image segmentation, the
task of detecting distinct regions or objects in given images. Deep Neural
Networks (DNN) have been shown to be very effective in segmenting challenging
images, producing convincing segmentations. There is further need for
probabilistic DNNs that can reflect the uncertainties from the input images and
the models into the computed segmentations, in other words, new DNNs that can
generate multiple plausible segmentations and their distributions depending on
the input or the model uncertainties. While there are existing probabilistic
segmentation models, many of them do not take into account the geometry or
shape underlying the segmented regions. In this paper, we propose a
probabilistic image segmentation model that can incorporate the geometry of a
segmentation. Our proposed model builds on the Probabilistic U-Net of
\cite{kohl2018probabilistic} to generate probabilistic segmentations, i.e.\!
multiple likely segmentations for an input image. Our model also adopts the
Kendall Shape Variational Auto-Encoder of \cite{vadgama2023kendall} to encode a
Kendall shape space in the latent variable layers of the prior and posterior
networks of the Probabilistic U-Net. Incorporating the shape space in this
manner leads to a more robust segmentation with spatially coherent regions,
respecting the underlying geometry in the input images.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>22 pages, 13 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Reproducibility study of "LICO: Explainable Models with Language-Image
  Consistency" 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.13989v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.13989v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Luan Fletcher, Robert van der Klis, Martin Sedláček, Stefan Vasilev, Christos Athanasiadis
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The growing reproducibility crisis in machine learning has brought forward a
need for careful examination of research findings. This paper investigates the
claims made by Lei et al. (2023) regarding their proposed method, LICO, for
enhancing post-hoc interpretability techniques and improving image
classification performance. LICO leverages natural language supervision from a
vision-language model to enrich feature representations and guide the learning
process. We conduct a comprehensive reproducibility study, employing (Wide)
ResNets and established interpretability methods like Grad-CAM and RISE. We
were mostly unable to reproduce the authors' results. In particular, we did not
find that LICO consistently led to improved classification performance or
improvements in quantitative and qualitative measures of interpretability.
Thus, our findings highlight the importance of rigorous evaluation and
transparent reporting in interpretability research.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>15 pages, 2 figures, Machine Learning Reproducibility Challenge 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Debiasing Large Vision-Language Models by Ablating Protected Attribute
  Representations <span class="chip">NeurIPS</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.13976v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.13976v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Neale Ratzlaff, Matthew Lyle Olson, Musashi Hinck, Shao-Yen Tseng, Vasudev Lal, Phillip Howard
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large Vision Language Models (LVLMs) such as LLaVA have demonstrated
impressive capabilities as general-purpose chatbots that can engage in
conversations about a provided input image. However, their responses are
influenced by societal biases present in their training datasets, leading to
undesirable differences in how the model responds when presented with images
depicting people of different demographics. In this work, we propose a novel
debiasing framework for LVLMs by directly ablating biased attributes during
text generation to avoid generating text related to protected attributes, or
even representing them internally. Our method requires no training and a
relatively small amount of representative biased outputs (~1000 samples). Our
experiments show that not only can we can minimize the propensity of LVLMs to
generate text related to protected attributes, but we can even use synthetic
data to inform the ablation while retaining captioning performance on real data
such as COCO. Furthermore, we find the resulting generations from a debiased
LVLM exhibit similar accuracy as a baseline biased model, showing that
debiasing effects can be achieved without sacrificing model performance.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>NeurIPS workshop on SafeGenAI, 10 pages, 2 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Satellite Streaming Video QoE Prediction: A Real-World Subjective
  Database and Network-Level Prediction Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.13952v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.13952v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Bowen Chen, Zaixi Shang, Jae Won Chung, David Lerner, Werner Robitza, Rakesh Rao Ramachandra Rao, Alexander Raake, Alan C. Bovik
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Demand for streaming services, including satellite, continues to exhibit
unprecedented growth. Internet Service Providers find themselves at the
crossroads of technological advancements and rising customer expectations. To
stay relevant and competitive, these ISPs must ensure their networks deliver
optimal video streaming quality, a key determinant of user satisfaction.
Towards this end, it is important to have accurate Quality of Experience
prediction models in place. However, achieving robust performance by these
models requires extensive data sets labeled by subjective opinion scores on
videos impaired by diverse playback disruptions. To bridge this data gap, we
introduce the LIVE-Viasat Real-World Satellite QoE Database. This database
consists of 179 videos recorded from real-world streaming services affected by
various authentic distortion patterns. We also conducted a comprehensive
subjective study involving 54 participants, who contributed both
continuous-time opinion scores and endpoint (retrospective) QoE scores. Our
analysis sheds light on various determinants influencing subjective QoE, such
as stall events, spatial resolutions, bitrate, and certain network parameters.
We demonstrate the usefulness of this unique new resource by evaluating the
efficacy of prevalent QoE-prediction models on it. We also created a new model
that maps the network parameters to predicted human perception scores, which
can be used by ISPs to optimize the video streaming quality of their networks.
Our proposed model, which we call SatQA, is able to accurately predict QoE
using only network parameters, without any access to pixel data or
video-specific metadata, estimated by Spearman's Rank Order Correlation
Coefficient (SROCC), Pearson Linear Correlation Coefficient (PLCC), and Root
Mean Squared Error (RMSE), indicating high accuracy and reliability.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Fluid: Scaling Autoregressive Text-to-image Generative Models with
  Continuous Tokens 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.13863v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.13863v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Lijie Fan, Tianhong Li, Siyang Qin, Yuanzhen Li, Chen Sun, Michael Rubinstein, Deqing Sun, Kaiming He, Yonglong Tian
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Scaling up autoregressive models in vision has not proven as beneficial as in
large language models. In this work, we investigate this scaling problem in the
context of text-to-image generation, focusing on two critical factors: whether
models use discrete or continuous tokens, and whether tokens are generated in a
random or fixed raster order using BERT- or GPT-like transformer architectures.
Our empirical results show that, while all models scale effectively in terms of
validation loss, their evaluation performance -- measured by FID, GenEval
score, and visual quality -- follows different trends. Models based on
continuous tokens achieve significantly better visual quality than those using
discrete tokens. Furthermore, the generation order and attention mechanisms
significantly affect the GenEval score: random-order models achieve notably
better GenEval scores compared to raster-order models. Inspired by these
findings, we train Fluid, a random-order autoregressive model on continuous
tokens. Fluid 10.5B model achieves a new state-of-the-art zero-shot FID of 6.16
on MS-COCO 30K, and 0.69 overall score on the GenEval benchmark. We hope our
findings and results will encourage future efforts to further bridge the
scaling gap between vision and language models.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Tech report</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ UniDrive: Towards Universal Driving Perception Across Camera
  Configurations 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.13864v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.13864v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ye Li, Wenzhao Zheng, Xiaonan Huang, Kurt Keutzer
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Vision-centric autonomous driving has demonstrated excellent performance with
economical sensors. As the fundamental step, 3D perception aims to infer 3D
information from 2D images based on 3D-2D projection. This makes driving
perception models susceptible to sensor configuration (e.g., camera intrinsics
and extrinsics) variations. However, generalizing across camera configurations
is important for deploying autonomous driving models on different car models.
In this paper, we present UniDrive, a novel framework for vision-centric
autonomous driving to achieve universal perception across camera
configurations. We deploy a set of unified virtual cameras and propose a
ground-aware projection method to effectively transform the original images
into these unified virtual views. We further propose a virtual configuration
optimization method by minimizing the expected projection error between
original cameras and virtual cameras. The proposed virtual camera projection
can be applied to existing 3D perception methods as a plug-and-play module to
mitigate the challenges posed by camera parameter variability, resulting in
more adaptable and reliable driving perception models. To evaluate the
effectiveness of our framework, we collect a dataset on Carla by driving the
same routes while only modifying the camera configurations. Experimental
results demonstrate that our method trained on one specific camera
configuration can generalize to varying configurations with minor performance
degradation.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Preprint; 14 pages, 5 figures, 2 tables; Code at
  https://github.com/ywyeli/UniDrive</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ DepthSplat: Connecting Gaussian Splatting and Depth 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.13862v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.13862v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Haofei Xu, Songyou Peng, Fangjinhua Wang, Hermann Blum, Daniel Barath, Andreas Geiger, Marc Pollefeys
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Gaussian splatting and single/multi-view depth estimation are typically
studied in isolation. In this paper, we present DepthSplat to connect Gaussian
splatting and depth estimation and study their interactions. More specifically,
we first contribute a robust multi-view depth model by leveraging pre-trained
monocular depth features, leading to high-quality feed-forward 3D Gaussian
splatting reconstructions. We also show that Gaussian splatting can serve as an
unsupervised pre-training objective for learning powerful depth models from
large-scale unlabelled datasets. We validate the synergy between Gaussian
splatting and depth estimation through extensive ablation and cross-task
transfer experiments. Our DepthSplat achieves state-of-the-art performance on
ScanNet, RealEstate10K and DL3DV datasets in terms of both depth estimation and
novel view synthesis, demonstrating the mutual benefits of connecting both
tasks. Our code, models, and video results are available at
https://haofeixu.github.io/depthsplat/.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Project page: https://haofeixu.github.io/depthsplat/</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ PUMA: Empowering Unified MLLM with Multi-granular Visual Generation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.13861v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.13861v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Rongyao Fang, Chengqi Duan, Kun Wang, Hao Li, Hao Tian, Xingyu Zeng, Rui Zhao, Jifeng Dai, Hongsheng Li, Xihui Liu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent advancements in multimodal foundation models have yielded significant
progress in vision-language understanding. Initial attempts have also explored
the potential of multimodal large language models (MLLMs) for visual content
generation. However, existing works have insufficiently addressed the varying
granularity demands of different image generation tasks within a unified MLLM
paradigm - from the diversity required in text-to-image generation to the
precise controllability needed in image manipulation. In this work, we propose
PUMA, emPowering Unified MLLM with Multi-grAnular visual generation. PUMA
unifies multi-granular visual features as both inputs and outputs of MLLMs,
elegantly addressing the different granularity requirements of various image
generation tasks within a unified MLLM framework. Following multimodal
pretraining and task-specific instruction tuning, PUMA demonstrates proficiency
in a wide range of multimodal tasks. This work represents a significant step
towards a truly unified MLLM capable of adapting to the granularity demands of
various visual tasks. The code and model will be released in
https://github.com/rongyaofang/PUMA.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Project page: https://rongyaofang.github.io/puma/</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ VLM-Grounder: A VLM Agent for Zero-Shot 3D Visual Grounding 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.13860v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.13860v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Runsen Xu, Zhiwei Huang, Tai Wang, Yilun Chen, Jiangmiao Pang, Dahua Lin
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  3D visual grounding is crucial for robots, requiring integration of natural
language and 3D scene understanding. Traditional methods depending on
supervised learning with 3D point clouds are limited by scarce datasets.
Recently zero-shot methods leveraging LLMs have been proposed to address the
data issue. While effective, these methods only use object-centric information,
limiting their ability to handle complex queries. In this work, we present
VLM-Grounder, a novel framework using vision-language models (VLMs) for
zero-shot 3D visual grounding based solely on 2D images. VLM-Grounder
dynamically stitches image sequences, employs a grounding and feedback scheme
to find the target object, and uses a multi-view ensemble projection to
accurately estimate 3D bounding boxes. Experiments on ScanRefer and Nr3D
datasets show VLM-Grounder outperforms previous zero-shot methods, achieving
51.6% Acc@0.25 on ScanRefer and 48.0% Acc on Nr3D, without relying on 3D
geometry or object priors. Codes are available at
https://github.com/OpenRobotLab/VLM-Grounder .
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>CoRL 2024 Camera Ready. 25 pages. A novel zero-shot 3D visual
  grounding framework based solely on 2D images</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ $γ-$MoD: Exploring Mixture-of-Depth Adaptation for Multimodal Large
  Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.13859v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.13859v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yaxin Luo, Gen Luo, Jiayi Ji, Yiyi Zhou, Xiaoshuai Sun, Zhiqiang Shen, Rongrong Ji
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Despite the significant progress in multimodal large language models (MLLMs),
their high computational cost remains a barrier to real-world deployment.
Inspired by the mixture of depths (MoDs) in natural language processing, we aim
to address this limitation from the perspective of ``activated tokens''. Our
key insight is that if most tokens are redundant for the layer computation,
then can be skipped directly via the MoD layer. However, directly converting
the dense layers of MLLMs to MoD layers leads to substantial performance
degradation. To address this issue, we propose an innovative MoD adaptation
strategy for existing MLLMs called $\gamma$-MoD. In $\gamma$-MoD, a novel
metric is proposed to guide the deployment of MoDs in the MLLM, namely rank of
attention maps (ARank). Through ARank, we can effectively identify which layer
is redundant and should be replaced with the MoD layer. Based on ARank, we
further propose two novel designs to maximize the computational sparsity of
MLLM while maintaining its performance, namely shared vision-language router
and masked routing learning. With these designs, more than 90% dense layers of
the MLLM can be effectively converted to the MoD ones. To validate our method,
we apply it to three popular MLLMs, and conduct extensive experiments on 9
benchmark datasets. Experimental results not only validate the significant
efficiency benefit of $\gamma$-MoD to existing MLLMs but also confirm its
generalization ability on various MLLMs. For example, with a minor performance
drop, i.e., -1.5%, $\gamma$-MoD can reduce the training and inference time of
LLaVA-HR by 31.0% and 53.2%, respectively.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Can MLLMs Understand the Deep Implication Behind Chinese Images? 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.13854v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.13854v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Chenhao Zhang, Xi Feng, Yuelin Bai, Xinrun Du, Jinchang Hou, Kaixin Deng, Guangzeng Han, Qinrui Li, Bingli Wang, Jiaheng Liu, Xingwei Qu, Yifei Zhang, Qixuan Zhao, Yiming Liang, Ziqiang Liu, Feiteng Fang, Min Yang, Wenhao Huang, Chenghua Lin, Ge Zhang, Shiwen Ni
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  As the capabilities of Multimodal Large Language Models (MLLMs) continue to
improve, the need for higher-order capability evaluation of MLLMs is
increasing. However, there is a lack of work evaluating MLLM for higher-order
perception and understanding of Chinese visual content. To fill the gap, we
introduce the **C**hinese **I**mage **I**mplication understanding
**Bench**mark, **CII-Bench**, which aims to assess the higher-order perception
and understanding capabilities of MLLMs for Chinese images. CII-Bench stands
out in several ways compared to existing benchmarks. Firstly, to ensure the
authenticity of the Chinese context, images in CII-Bench are sourced from the
Chinese Internet and manually reviewed, with corresponding answers also
manually crafted. Additionally, CII-Bench incorporates images that represent
Chinese traditional culture, such as famous Chinese traditional paintings,
which can deeply reflect the model's understanding of Chinese traditional
culture. Through extensive experiments on CII-Bench across multiple MLLMs, we
have made significant findings. Initially, a substantial gap is observed
between the performance of MLLMs and humans on CII-Bench. The highest accuracy
of MLLMs attains 64.4%, where as human accuracy averages 78.2%, peaking at an
impressive 81.0%. Subsequently, MLLMs perform worse on Chinese traditional
culture images, suggesting limitations in their ability to understand
high-level semantics and lack a deep knowledge base of Chinese traditional
culture. Finally, it is observed that most models exhibit enhanced accuracy
when image emotion hints are incorporated into the prompts. We believe that
CII-Bench will enable MLLMs to gain a better understanding of Chinese semantics
and Chinese-specific images, advancing the journey towards expert artificial
general intelligence (AGI). Our project is publicly available at
https://cii-bench.github.io/.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>32 pages,18 figures. Project Page: https://cii-bench.github.io/ Code:
  https://github.com/MING_X/CII-Bench Dataset:
  https://huggingface.co/datasets/m-a-p/CII-Bench</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Retrospective Learning from Interactions 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.13852v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.13852v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zizhao Chen, Mustafa Omer Gul, Yiwei Chen, Gloria Geng, Anne Wu, Yoav Artzi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Multi-turn interactions between large language models (LLMs) and users
naturally include implicit feedback signals. If an LLM responds in an
unexpected way to an instruction, the user is likely to signal it by rephrasing
the request, expressing frustration, or pivoting to an alternative task. Such
signals are task-independent and occupy a relatively constrained subspace of
language, allowing the LLM to identify them even if it fails on the actual
task. This creates an avenue for continually learning from interactions without
additional annotations. We introduce ReSpect, a method to learn from such
signals in past interactions via retrospection. We deploy ReSpect in a new
multimodal interaction scenario, where humans instruct an LLM to solve an
abstract reasoning task with a combinatorial solution space. Through thousands
of interactions with humans, we show how ReSpect gradually improves task
completion rate from 31% to 82%, all without any external annotation.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Differentiable Robot Rendering 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.13851v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.13851v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ruoshi Liu, Alper Canberk, Shuran Song, Carl Vondrick
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Vision foundation models trained on massive amounts of visual data have shown
unprecedented reasoning and planning skills in open-world settings. A key
challenge in applying them to robotic tasks is the modality gap between visual
data and action data. We introduce differentiable robot rendering, a method
allowing the visual appearance of a robot body to be directly differentiable
with respect to its control parameters. Our model integrates a kinematics-aware
deformable model and Gaussians Splatting and is compatible with any robot form
factors and degrees of freedom. We demonstrate its capability and usage in
applications including reconstruction of robot poses from images and
controlling robots through vision language models. Quantitative and qualitative
results show that our differentiable rendering model provides effective
gradients for robotic control directly from pixels, setting the foundation for
the future applications of vision foundation models in robotics.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Project Page: https://drrobot.cs.columbia.edu/</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Janus: Decoupling Visual Encoding for Unified Multimodal Understanding
  and Generation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.13848v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.13848v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Chengyue Wu, Xiaokang Chen, Zhiyu Wu, Yiyang Ma, Xingchao Liu, Zizheng Pan, Wen Liu, Zhenda Xie, Xingkai Yu, Chong Ruan, Ping Luo
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this paper, we introduce Janus, an autoregressive framework that unifies
multimodal understanding and generation. Prior research often relies on a
single visual encoder for both tasks, such as Chameleon. However, due to the
differing levels of information granularity required by multimodal
understanding and generation, this approach can lead to suboptimal performance,
particularly in multimodal understanding. To address this issue, we decouple
visual encoding into separate pathways, while still leveraging a single,
unified transformer architecture for processing. The decoupling not only
alleviates the conflict between the visual encoder's roles in understanding and
generation, but also enhances the framework's flexibility. For instance, both
the multimodal understanding and generation components can independently select
their most suitable encoding methods. Experiments show that Janus surpasses
previous unified model and matches or exceeds the performance of task-specific
models. The simplicity, high flexibility, and effectiveness of Janus make it a
strong candidate for next-generation unified multimodal models.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Technical Report</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ D-FINE: Redefine Regression Task in DETRs as Fine-grained Distribution
  Refinement 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.13842v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.13842v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yansong Peng, Hebei Li, Peixi Wu, Yueyi Zhang, Xiaoyan Sun, Feng Wu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We introduce D-FINE, a powerful real-time object detector that achieves
outstanding localization precision by redefining the bounding box regression
task in DETR models. D-FINE comprises two key components: Fine-grained
Distribution Refinement (FDR) and Global Optimal Localization Self-Distillation
(GO-LSD). FDR transforms the regression process from predicting fixed
coordinates to iteratively refining probability distributions, providing a
fine-grained intermediate representation that significantly enhances
localization accuracy. GO-LSD is a bidirectional optimization strategy that
transfers localization knowledge from refined distributions to shallower layers
through self-distillation, while also simplifying the residual prediction tasks
for deeper layers. Additionally, D-FINE incorporates lightweight optimizations
in computationally intensive modules and operations, achieving a better balance
between speed and accuracy. Specifically, D-FINE-L / X achieves 54.0% / 55.8%
AP on the COCO dataset at 124 / 78 FPS on an NVIDIA T4 GPU. When pretrained on
Objects365, D-FINE-L / X attains 57.1% / 59.3% AP, surpassing all existing
real-time detectors. Furthermore, our method significantly enhances the
performance of a wide range of DETR models by up to 5.3% AP with negligible
extra parameters and training costs. Our code and pretrained models:
https://github.com/Peterande/D-FINE.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ VidPanos: Generative Panoramic Videos from Casual Panning Videos <span class="chip">SIGGRAPH</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.13832v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.13832v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jingwei Ma, Erika Lu, Roni Paiss, Shiran Zada, Aleksander Holynski, Tali Dekel, Brian Curless, Michael Rubinstein, Forrester Cole
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Panoramic image stitching provides a unified, wide-angle view of a scene that
extends beyond the camera's field of view. Stitching frames of a panning video
into a panoramic photograph is a well-understood problem for stationary scenes,
but when objects are moving, a still panorama cannot capture the scene. We
present a method for synthesizing a panoramic video from a casually-captured
panning video, as if the original video were captured with a wide-angle camera.
We pose panorama synthesis as a space-time outpainting problem, where we aim to
create a full panoramic video of the same length as the input video. Consistent
completion of the space-time volume requires a powerful, realistic prior over
video content and motion, for which we adapt generative video models. Existing
generative models do not, however, immediately extend to panorama completion,
as we show. We instead apply video generation as a component of our panorama
synthesis system, and demonstrate how to exploit the strengths of the models
while minimizing their limitations. Our system can create video panoramas for a
range of in-the-wild scenes including people, vehicles, and flowing water, as
well as stationary background features.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Project page at https://vidpanos.github.io/. To appear at SIGGRAPH
  Asia 2024 (conference track)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ DreamVideo-2: Zero-Shot Subject-Driven Video Customization with Precise
  Motion Control 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.13830v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.13830v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yujie Wei, Shiwei Zhang, Hangjie Yuan, Xiang Wang, Haonan Qiu, Rui Zhao, Yutong Feng, Feng Liu, Zhizhong Huang, Jiaxin Ye, Yingya Zhang, Hongming Shan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent advances in customized video generation have enabled users to create
videos tailored to both specific subjects and motion trajectories. However,
existing methods often require complicated test-time fine-tuning and struggle
with balancing subject learning and motion control, limiting their real-world
applications. In this paper, we present DreamVideo-2, a zero-shot video
customization framework capable of generating videos with a specific subject
and motion trajectory, guided by a single image and a bounding box sequence,
respectively, and without the need for test-time fine-tuning. Specifically, we
introduce reference attention, which leverages the model's inherent
capabilities for subject learning, and devise a mask-guided motion module to
achieve precise motion control by fully utilizing the robust motion signal of
box masks derived from bounding boxes. While these two components achieve their
intended functions, we empirically observe that motion control tends to
dominate over subject learning. To address this, we propose two key designs: 1)
the masked reference attention, which integrates a blended latent mask modeling
scheme into reference attention to enhance subject representations at the
desired positions, and 2) a reweighted diffusion loss, which differentiates the
contributions of regions inside and outside the bounding boxes to ensure a
balance between subject and motion control. Extensive experimental results on a
newly curated dataset demonstrate that DreamVideo-2 outperforms
state-of-the-art methods in both subject customization and motion control. The
dataset, code, and models will be made publicly available.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Project page: https://dreamvideo2.github.io/</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Unearthing Skill-Level Insights for Understanding Trade-Offs of
  Foundation Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.13826v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.13826v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mazda Moayeri, Vidhisha Balachandran, Varun Chandrasekaran, Safoora Yousefi, Thomas Fel, Soheil Feizi, Besmira Nushi, Neel Joshi, Vibhav Vineet
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  With models getting stronger, evaluations have grown more complex, testing
multiple skills in one benchmark and even in the same instance at once.
However, skill-wise performance is obscured when inspecting aggregate accuracy,
under-utilizing the rich signal modern benchmarks contain. We propose an
automatic approach to recover the underlying skills relevant for any evaluation
instance, by way of inspecting model-generated rationales. After validating the
relevance of rationale-parsed skills and inferring skills for $46$k instances
over $12$ benchmarks, we observe many skills to be common across benchmarks,
resulting in the curation of hundreds of skill-slices (i.e. sets of instances
testing a common skill). Inspecting accuracy over these slices yields novel
insights on model trade-offs: e.g., compared to GPT-4o and Claude 3.5 Sonnet,
on average, Gemini 1.5 Pro is $18\%$ more accurate in "computing molar mass",
but $19\%$ less accurate in "applying constitutional law", despite the overall
accuracies of the three models differing by a mere $0.4\%$. Furthermore, we
demonstrate the practical utility of our approach by showing that insights
derived from skill slice analysis can generalize to held-out instances: when
routing each instance to the model strongest on the relevant skills, we see a
$3\%$ accuracy improvement over our $12$ dataset corpus. Our skill-slices and
framework open a new avenue in model evaluation, leveraging skill-specific
analyses to unlock a more granular and actionable understanding of model
capabilities.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Code at: github.com/microsoft/skill-slice-insights</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Deep Generative Models Unveil Patterns in Medical Images Through
  Vision-Language Conditioning <span class="chip">NeurIPS2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.13823v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.13823v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xiaodan Xing, Junzhi Ning, Yang Nan, Guang Yang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Deep generative models have significantly advanced medical imaging analysis
by enhancing dataset size and quality. Beyond mere data augmentation, our
research in this paper highlights an additional, significant capacity of deep
generative models: their ability to reveal and demonstrate patterns in medical
images. We employ a generative structure with hybrid conditions, combining
clinical data and segmentation masks to guide the image synthesis process.
Furthermore, we innovatively transformed the tabular clinical data into textual
descriptions. This approach simplifies the handling of missing values and also
enables us to leverage large pre-trained vision-language models that
investigate the relations between independent clinical entries and comprehend
general terms, such as gender and smoking status. Our approach differs from and
presents a more challenging task than traditional medical report-guided
synthesis due to the less visual correlation of our clinical information with
the images. To overcome this, we introduce a text-visual embedding mechanism
that strengthens the conditions, ensuring the network effectively utilizes the
provided information. Our pipeline is generalizable to both GAN-based and
diffusion models. Experiments on chest CT, particularly focusing on the smoking
status, demonstrated a consistent intensity shift in the lungs which is in
agreement with clinical observations, indicating the effectiveness of our
method in capturing and visualizing the impact of specific attributes on
medical image patterns. Our methods offer a new avenue for the early detection
and precise visualization of complex clinical conditions with deep generative
models. All codes are https://github.com/junzhin/DGM-VLC.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by AIM-FM Workshop of NeurIPS2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Multi-style conversion for semantic segmentation of lesions in fundus
  images by adversarial attacks 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.13822v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.13822v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Clément Playout, Renaud Duval, Marie Carole Boucher, Farida Cheriet
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The diagnosis of diabetic retinopathy, which relies on fundus images, faces
challenges in achieving transparency and interpretability when using a global
classification approach. However, segmentation-based databases are
significantly more expensive to acquire and combining them is often
problematic. This paper introduces a novel method, termed adversarial style
conversion, to address the lack of standardization in annotation styles across
diverse databases. By training a single architecture on combined databases, the
model spontaneously modifies its segmentation style depending on the input,
demonstrating the ability to convert among different labeling styles. The
proposed methodology adds a linear probe to detect dataset origin based on
encoder features and employs adversarial attacks to condition the model's
segmentation style. Results indicate significant qualitative and quantitative
through dataset combination, offering avenues for improved model
generalization, uncertainty estimation and continuous interpolation between
annotation styles. Our approach enables training a segmentation model with
diverse databases while controlling and leveraging annotation styles for
improved retinopathy diagnosis.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>preprint</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ ConsisSR: Delving Deep into Consistency in Diffusion-based Image
  Super-Resolution 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.13807v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.13807v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Junhao Gu, Peng-Tao Jiang, Hao Zhang, Mi Zhou, Jinwei Chen, Wenming Yang, Bo Li
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Real-world image super-resolution (Real-ISR) aims at restoring high-quality
(HQ) images from low-quality (LQ) inputs corrupted by unknown and complex
degradations. In particular, pretrained text-to-image (T2I) diffusion models
provide strong generative priors to reconstruct credible and intricate details.
However, T2I generation focuses on semantic consistency while Real-ISR
emphasizes pixel-level reconstruction, which hinders existing methods from
fully exploiting diffusion priors. To address this challenge, we introduce
ConsisSR to handle both semantic and pixel-level consistency. Specifically,
compared to coarse-grained text prompts, we exploit the more powerful CLIP
image embedding and effectively leverage both modalities through our Hybrid
Prompt Adapter (HPA) for semantic guidance. Secondly, we introduce Time-aware
Latent Augmentation (TALA) to mitigate the inherent gap between T2I generation
and Real-ISR consistency requirements. By randomly mixing LQ and HQ latent
inputs, our model not only handle timestep-specific diffusion noise but also
refine the accumulated latent representations. Last but not least, our
GAN-Embedding strategy employs the pretrained Real-ESRGAN model to refine the
diffusion start point. This accelerates the inference process to 10 steps while
preserving sampling quality, in a training-free manner. Our method demonstrates
state-of-the-art performance among both full-scale and accelerated models. The
code will be made publicly available.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ MotionBank: A Large-scale Video Motion Benchmark with Disentangled
  Rule-based Annotations 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.13790v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.13790v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Liang Xu, Shaoyang Hua, Zili Lin, Yifan Liu, Feipeng Ma, Yichao Yan, Xin Jin, Xiaokang Yang, Wenjun Zeng
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this paper, we tackle the problem of how to build and benchmark a large
motion model (LMM). The ultimate goal of LMM is to serve as a foundation model
for versatile motion-related tasks, e.g., human motion generation, with
interpretability and generalizability. Though advanced, recent LMM-related
works are still limited by small-scale motion data and costly text
descriptions. Besides, previous motion benchmarks primarily focus on pure body
movements, neglecting the ubiquitous motions in context, i.e., humans
interacting with humans, objects, and scenes. To address these limitations, we
consolidate large-scale video action datasets as knowledge banks to build
MotionBank, which comprises 13 video action datasets, 1.24M motion sequences,
and 132.9M frames of natural and diverse human motions. Different from
laboratory-captured motions, in-the-wild human-centric videos contain abundant
motions in context. To facilitate better motion text alignment, we also
meticulously devise a motion caption generation algorithm to automatically
produce rule-based, unbiased, and disentangled text descriptions via the
kinematic characteristics for each motion. Extensive experiments show that our
MotionBank is beneficial for general motion-related tasks of human motion
generation, motion in-context generation, and motion understanding. Video
motions together with the rule-based text annotations could serve as an
efficient alternative for larger LMMs. Our dataset, codes, and benchmark will
be publicly available at https://github.com/liangxuy/MotionBank.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Emphasizing Semantic Consistency of Salient Posture for Speech-Driven
  Gesture Generation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.13786v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.13786v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Fengqi Liu, Hexiang Wang, Jingyu Gong, Ran Yi, Qianyu Zhou, Xuequan Lu, Jiangbo Lu, Lizhuang Ma
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Speech-driven gesture generation aims at synthesizing a gesture sequence
synchronized with the input speech signal. Previous methods leverage neural
networks to directly map a compact audio representation to the gesture
sequence, ignoring the semantic association of different modalities and failing
to deal with salient gestures. In this paper, we propose a novel speech-driven
gesture generation method by emphasizing the semantic consistency of salient
posture. Specifically, we first learn a joint manifold space for the individual
representation of audio and body pose to exploit the inherent semantic
association between two modalities, and propose to enforce semantic consistency
via a consistency loss. Furthermore, we emphasize the semantic consistency of
salient postures by introducing a weakly-supervised detector to identify
salient postures, and reweighting the consistency loss to focus more on
learning the correspondence between salient postures and the high-level
semantics of speech content. In addition, we propose to extract audio features
dedicated to facial expression and body gesture separately, and design separate
branches for face and body gesture synthesis. Extensive experimental results
demonstrate the superiority of our method over the state-of-the-art approaches.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Representing Model Weights with Language using Tree Experts 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.13569v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.13569v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Eliahu Horwitz, Bar Cavia, Jonathan Kahana, Yedid Hoshen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The increasing availability of public models begs the question: can we train
neural networks that use other networks as input? This paper learns to
represent models within a joint space that embeds both model weights and
language. However, machine learning on model weights is challenging as model
weights often exhibit significant variation unrelated to the models' semantic
properties (nuisance variation). We identify a key property of real-world
models: most public models belong to a small set of Model Trees, where all
models within a tree are fine-tuned from a common ancestor (e.g., a foundation
model). Importantly, we find that within each tree there is less nuisance
variation between models. For example, while classifying models according to
their training dataset generally requires complex architectures, in our case,
even a linear classifier trained on a single layer is often effective. While
effective, linear layers are computationally expensive as model weights are
very high dimensional. To address this, we introduce Probing Experts (ProbeX),
a theoretically motivated, lightweight probing method. Notably, ProbeX is the
first probing method designed to learn from the weights of just a single model
layer. We also construct and release a dataset that simulates the structure of
public model repositories. Our results show that ProbeX can effectively map the
weights of large models into a shared weight-language embedding space.
Furthermore, we demonstrate the impressive generalization of our method,
achieving zero-shot model classification and retrieval.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Eyelid Fold Consistency in Facial Modeling 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.13760v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.13760v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Lohit Petikam, Charlie Hewitt, Fatemeh Saleh, Tadas Baltrušaitis
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Eyelid shape is integral to identity and likeness in human facial modeling.
Human eyelids are diverse in appearance with varied skin fold and epicanthal
fold morphology between individuals. Existing parametric face models express
eyelid shape variation to an extent, but do not preserve sufficient likeness
across a diverse range of individuals. We propose a new definition of eyelid
fold consistency and implement geometric processing techniques to model diverse
eyelid shapes in a unified topology. Using this method we reprocess data used
to train a parametric face model and demonstrate significant improvements in
face-related machine learning tasks.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Preserving Cardiac Integrity: A Topology-Infused Approach to Whole Heart
  Segmentation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.10551v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.10551v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Chenyu Zhang, Wenxue Guan, Xiaodan Xing, Guang Yang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Whole heart segmentation (WHS) supports cardiovascular disease (CVD)
diagnosis, disease monitoring, treatment planning, and prognosis. Deep learning
has become the most widely used method for WHS applications in recent years.
However, segmentation of whole-heart structures faces numerous challenges
including heart shape variability during the cardiac cycle, clinical artifacts
like motion and poor contrast-to-noise ratio, domain shifts in multi-center
data, and the distinct modalities of CT and MRI. To address these limitations
and improve segmentation quality, this paper introduces a new
topology-preserving module that is integrated into deep neural networks. The
implementation achieves anatomically plausible segmentation by using learned
topology-preserving fields, which are based entirely on 3D convolution and are
therefore very effective for 3D voxel data. We incorporate natural constraints
between structures into the end-to-end training and enrich the feature
representation of the neural network. The effectiveness of the proposed method
is validated on an open-source medical heart dataset, specifically using the
WHS++ data. The results demonstrate that the architecture performs
exceptionally well, achieving a Dice coefficient of 0.939 during testing. This
indicates full topology preservation for individual structures and
significantly outperforms other baselines in preserving the overall scene
topology.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Suitability of KANs for Computer Vision: A preliminary investigation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.09087v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.09087v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Basim Azam, Naveed Akhtar
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Kolmogorov-Arnold Networks (KANs) introduce a paradigm of neural modeling
that implements learnable functions on the edges of the networks, diverging
from the traditional node-centric activations in neural networks. This work
assesses the applicability and efficacy of KANs in visual modeling, focusing on
fundamental recognition and segmentation tasks. We mainly analyze the
performance and efficiency of different network architectures built using KAN
concepts along with conventional building blocks of convolutional and linear
layers, enabling a comparative analysis with the conventional models. Our
findings are aimed at contributing to understanding the potential of KANs in
computer vision, highlighting both their strengths and areas for further
research. Our evaluation point toward the fact that while KAN-based
architectures perform in line with the original claims, it may often be
important to employ more complex functions on the network edges to retain the
performance advantage of KANs on more complex visual data.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Performance of a GPU- and Time-Efficient Pseudo 3D Network for Magnetic
  Resonance Image Super-Resolution and Motion Artifact Reduction 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2111.14259v5">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2111.14259v5.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hao Li, Jianan Liu, Marianne Schell, Tao Huang, Arne Lauer, Katharina Schregel, Jessica Jesser, Dominik F Vollherbst, Martin Bendszus, Sabine Heiland, Tim Hilgenfeld
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Shortening acquisition time and reducing motion artifacts are the most
critical challenges in magnetic resonance imaging (MRI). Deep learning-based
image restoration has emerged as a promising solution capable of generating
high-resolution and motion-artifact-free MRI images from low-resolution images
acquired with shortened acquisition times or from motion-artifact-corrupted
images. To facilitate clinical integration, a time- and GPU-efficient network
with reliable accuracy is essential. In this study, we adopted a unified 2D
deep learning framework for pseudo-3D MRI image super-resolution reconstruction
(SRR) and motion artifact reduction (MAR). The optimal down-sampling factors to
optimize the acquisition time in SRR were identified. Training for MAR was
performed using publicly available in vivo data, employing a novel standardized
method to induce motion artifacts of varying severity in a controlled way. The
accuracy of the network was evaluated through a pixel-wise uncertainty map, and
performance was benchmarked against state-of-the-art methods. The results
demonstrated that the down-sampling factor of 1x1x2 for x2 acceleration and
2x2x2 for x4 acceleration was optimal. For SRR, the proposed TS-RCAN
outperformed the 3D networks of mDCSRN and ReCNN, with an improvement of more
than 0.01 in SSIM and 1.5 dB in PSNR while reducing GPU load by up to and
inference time by up to 90%. For MAR, TS-RCAN exceeded UNet's performance by up
to 0.014 in SSIM and 1.48 dB in PSNR. Additionally, TS-RCAN provided
uncertainty information, which can be used to estimate the quality of the
reconstructed images. TS-RCAN has potential use for SRR and MAR in the clinical
setting.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>16 pages, 9 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Duoduo CLIP: Efficient 3D Understanding with Multi-View Images 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.11579v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.11579v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Han-Hung Lee, Yiming Zhang, Angel X. Chang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We introduce Duoduo CLIP, a model for 3D representation learning that learns
shape encodings from multi-view images instead of point-clouds. The choice of
multi-view images allows us to leverage 2D priors from off-the-shelf CLIP
models to facilitate fine-tuning with 3D data. Our approach not only shows
better generalization compared to existing point cloud methods, but also
reduces GPU requirements and training time. In addition, the model is modified
with cross-view attention to leverage information across multiple frames of the
object which further boosts performance. Notably, our model is permutation
invariant to the order of multi-view images while being pose-free. Compared to
the current SOTA point cloud method that requires 480 A100 hours to train 1
billion model parameters we only require 57 A5000 hours and 87 million
parameters. Multi-view images also provide more flexibility including being
able to encode objects with a variable number of images, and performance scales
when more views are used. In contrast, point cloud based methods require an
entire scan or model of the object. We showcase this flexibility with
benchmarks from images of real-world objects. Our model also achieves better
performance in more fine-grained text to shape retrieval, demonstrating better
text-and-shape alignment than point cloud based models.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Estimating Body and Hand Motion in an Ego-sensed World 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.03665v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.03665v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Brent Yi, Vickie Ye, Maya Zheng, Lea Müller, Georgios Pavlakos, Yi Ma, Jitendra Malik, Angjoo Kanazawa
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We present EgoAllo, a system for human motion estimation from a head-mounted
device. Using only egocentric SLAM poses and images, EgoAllo guides sampling
from a conditional diffusion model to estimate 3D body pose, height, and hand
parameters that capture the wearer's actions in the allocentric coordinate
frame of the scene. To achieve this, our key insight is in representation: we
propose spatial and temporal invariance criteria for improving model
performance, from which we derive a head motion conditioning parameterization
that improves estimation by up to 18%. We also show how the bodies estimated by
our system can improve the hands: the resulting kinematic and temporal
constraints result in over 40% lower hand estimation errors compared to noisy
monocular estimates. Project page: https://egoallo.github.io/
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>v2: fixed figures for Safari, typos</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Efficient Anatomical Labeling of Pulmonary Tree Structures via Deep
  Point-Graph Representation-based Implicit Fields 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2309.17329v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2309.17329v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Kangxian Xie, Jiancheng Yang, Donglai Wei, Ziqiao Weng, Pascal Fua
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Pulmonary diseases rank prominently among the principal causes of death
worldwide. Curing them will require, among other things, a better understanding
of the complex 3D tree-shaped structures within the pulmonary system, such as
airways, arteries, and veins. Traditional approaches using high-resolution
image stacks and standard CNNs on dense voxel grids face challenges in
computational efficiency, limited resolution, local context, and inadequate
preservation of shape topology. Our method addresses these issues by shifting
from dense voxel to sparse point representation, offering better memory
efficiency and global context utilization. However, the inherent sparsity in
point representation can lead to a loss of crucial connectivity in tree-shaped
structures. To mitigate this, we introduce graph learning on skeletonized
structures, incorporating differentiable feature fusion for improved topology
and long-distance context capture. Furthermore, we employ an implicit function
for efficient conversion of sparse representations into dense reconstructions
end-to-end. The proposed method not only delivers state-of-the-art performance
in labeling accuracy, both overall and at key locations, but also enables
efficient inference and the generation of closed surface shapes. Addressing
data scarcity in this field, we have also curated a comprehensive dataset to
validate our approach. Data and code are available at
\url{https://github.com/M3DV/pulmonary-tree-labeling}.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by Medical Image Analysis</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ CYCLO: Cyclic Graph <span class="highlight-title">Transformer</span> Approach to Multi-Object Relationship
  Modeling in Aerial Videos <span class="chip">NeurIPS 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.01029v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.01029v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Trong-Thuan Nguyen, Pha Nguyen, Xin Li, Jackson Cothren, Alper Yilmaz, Khoa Luu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Video scene graph generation (VidSGG) has emerged as a transformative
approach to capturing and interpreting the intricate relationships among
objects and their temporal dynamics in video sequences. In this paper, we
introduce the new AeroEye dataset that focuses on multi-object relationship
modeling in aerial videos. Our AeroEye dataset features various drone scenes
and includes a visually comprehensive and precise collection of predicates that
capture the intricate relationships and spatial arrangements among objects. To
this end, we propose the novel Cyclic Graph Transformer (CYCLO) approach that
allows the model to capture both direct and long-range temporal dependencies by
continuously updating the history of interactions in a circular manner. The
proposed approach also allows one to handle sequences with inherent cyclical
patterns and process object relationships in the correct sequential order.
Therefore, it can effectively capture periodic and overlapping relationships
while minimizing information loss. The extensive experiments on the AeroEye
dataset demonstrate the effectiveness of the proposed CYCLO model,
demonstrating its potential to perform scene understanding on drone videos.
Finally, the CYCLO method consistently achieves State-of-the-Art (SOTA) results
on two in-the-wild scene graph generation benchmarks, i.e., PVSG and ASPIRe.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to NeurIPS 2024</span>
                                        </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
            <article>
                <details>
                    <Summary>
                        Information Retrieval <span class="chip" style="font-size: 60%">35</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Lightweight Correlation-Aware Table Compression 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14066v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14066v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mihail Stoian, Alexander van Renen, Jan Kobiolka, Ping-Lin Kuo, Josif Grabocka, Andreas Kipf
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The growing adoption of data lakes for managing relational data necessitates
efficient, open storage formats that provide high scan performance and
competitive compression ratios. While existing formats achieve fast scans
through lightweight encoding techniques, they have reached a plateau in terms
of minimizing storage footprint. Recently, correlation-aware compression
schemes have been shown to reduce file sizes further. Yet, current approaches
either incur significant scan overheads or require manual specification of
correlations, limiting their practicability. We present $\texttt{Virtual}$, a
framework that integrates seamlessly with existing open formats to
automatically leverage data correlations, achieving substantial compression
gains while having minimal scan performance overhead. Experiments on
$\texttt{data.gov}$ datasets show that $\texttt{Virtual}$ reduces file sizes by
up to 40% compared to Apache Parquet.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Third Table Representation Learning Workshop (TRL 2024)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Best in Tau@LLMJudge: Criteria-Based Relevance Evaluation with Llama3 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14044v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14044v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Naghmeh Farzi, Laura Dietz
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Traditional evaluation of information retrieval (IR) systems relies on
human-annotated relevance labels, which can be both biased and costly at scale.
In this context, large language models (LLMs) offer an alternative by allowing
us to directly prompt them to assign relevance labels for passages associated
with each query. In this study, we explore alternative methods to directly
prompt LLMs for assigned relevance labels, by exploring two hypotheses:
  Hypothesis 1 assumes that it is helpful to break down "relevance" into
specific criteria - exactness, coverage, topicality, and contextual fit. We
explore different approaches that prompt large language models (LLMs) to obtain
criteria-level grades for all passages, and we consider various ways to
aggregate criteria-level grades into a relevance label. Hypothesis 2 assumes
that differences in linguistic style between queries and passages may
negatively impact the automatic relevance label prediction. We explore whether
improvements can be achieved by first synthesizing a summary of the passage in
the linguistic style of a query, and then using this summary in place of the
passage to assess its relevance.
  We include an empirical evaluation of our approaches based on data from the
LLMJudge challenge run in Summer 2024, where our "Four Prompts" approach
obtained the highest scores in Kendall's tau.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Efficient Retrieval of Temporal Event Sequences from Textual
  Descriptions 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14043v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14043v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zefang Liu, Yinzhu Quan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Retrieving temporal event sequences from textual descriptions is essential
for applications such as analyzing e-commerce behavior, monitoring social media
activities, and tracking criminal incidents. In this paper, we introduce
TPP-LLM-Embedding, a unified model for efficiently embedding and retrieving
event sequences based on natural language descriptions. Built on the TPP-LLM
framework, which integrates large language models with temporal point
processes, our model encodes both event types and times, generating a
sequence-level representation through pooling. Textual descriptions are
embedded using the same architecture, ensuring a shared embedding space for
both sequences and descriptions. We optimize a contrastive loss based on
similarity between these embeddings, bringing matching pairs closer and
separating non-matching ones. TPP-LLM-Embedding enables efficient retrieval and
demonstrates superior performance compared to baseline models across diverse
datasets.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ FinQAPT: Empowering Financial Decisions with End-to-End LLM-driven
  Question Answering Pipeline 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.13959v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.13959v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Kuldeep Singh, Simerjot Kaur, Charese Smiley
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Financial decision-making hinges on the analysis of relevant information
embedded in the enormous volume of documents in the financial domain. To
address this challenge, we developed FinQAPT, an end-to-end pipeline that
streamlines the identification of relevant financial reports based on a query,
extracts pertinent context, and leverages Large Language Models (LLMs) to
perform downstream tasks. To evaluate the pipeline, we experimented with
various techniques to optimize the performance of each module using the FinQA
dataset. We introduced a novel clustering-based negative sampling technique to
enhance context extraction and a novel prompting method called Dynamic N-shot
Prompting to boost the numerical question-answering capabilities of LLMs. At
the module level, we achieved state-of-the-art accuracy on FinQA, attaining an
accuracy of 80.6\%. However, at the pipeline level, we observed decreased
performance due to challenges in extracting relevant context from financial
reports. We conducted a detailed error analysis of each module and the
end-to-end pipeline, pinpointing specific challenges that must be addressed to
develop a robust solution for handling complex financial tasks.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted in ICAIF 2024, 8 pages, 5 figures, 4 tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Identifying High Consideration E-Commerce Search Queries <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.13951v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.13951v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zhiyu Chen, Jason Choi, Besnik Fetahu, Shervin Malmasi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In e-commerce, high consideration search missions typically require careful
and elaborate decision making, and involve a substantial research investment
from customers. We consider the task of identifying High Consideration (HC)
queries. Identifying such queries enables e-commerce sites to better serve user
needs using targeted experiences such as curated QA widgets that help users
reach purchase decisions. We explore the task by proposing an Engagement-based
Query Ranking (EQR) approach, focusing on query ranking to indicate potential
engagement levels with query-related shopping knowledge content during product
search. Unlike previous studies on predicting trends, EQR prioritizes
query-level features related to customer behavior, finance, and catalog
information rather than popularity signals. We introduce an accurate and
scalable method for EQR and present experimental results demonstrating its
effectiveness. Offline experiments show strong ranking performance. Human
evaluation shows a precision of 96% for HC queries identified by our model. The
model was commercially deployed, and shown to outperform human-selected queries
in terms of downstream customer impact, as measured through engagement.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by EMNLP 2024 (Industry Track)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Knowledge-Aware Query Expansion with Large Language Models for Textual
  and Relational Retrieval 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.13765v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.13765v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yu Xia, Junda Wu, Sungchul Kim, Tong Yu, Ryan A. Rossi, Haoliang Wang, Julian McAuley
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large language models (LLMs) have been used to generate query expansions
augmenting original queries for improving information search. Recent studies
also explore providing LLMs with initial retrieval results to generate query
expansions more grounded to document corpus. However, these methods mostly
focus on enhancing textual similarities between search queries and target
documents, overlooking document relations. For queries like "Find me a highly
rated camera for wildlife photography compatible with my Nikon F-Mount lenses",
existing methods may generate expansions that are semantically similar but
structurally unrelated to user intents. To handle such semi-structured queries
with both textual and relational requirements, in this paper we propose a
knowledge-aware query expansion framework, augmenting LLMs with structured
document relations from knowledge graph (KG). To further address the limitation
of entity-based scoring in existing KG-based methods, we leverage document
texts as rich KG node representations and use document-based relation filtering
for our Knowledge-Aware Retrieval (KAR). Extensive experiments on three
datasets of diverse domains show the advantages of our method compared against
state-of-the-art baselines on textual and relational semi-structured retrieval.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Disjointness Violations in Wikidata 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.13707v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.13707v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ege Atacan Doğan, Peter F. Patel-Schneider
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Disjointness checks are among the most important constraint checks in a
knowledge base and can be used to help detect and correct incorrect statements
and internal contradictions. Wikidata is a very large, community-managed
knowledge base. Because of both its size and construction, Wikidata contains
many incorrect statements and internal contradictions. We analyze the current
modeling of disjointness on Wikidata, identify patterns that cause these
disjointness violations and categorize them. We use SPARQL queries to identify
each ``culprit'' causing a disjointness violation and lay out formulas to
identify and fix conflicting information. We finally discuss how disjointness
information could be better modeled and expanded in Wikidata in the future.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Sixth International Knowledge Graph and Semantic Web Conference</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Pessimistic Evaluation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.13680v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.13680v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Fernando Diaz
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Traditional evaluation of information access systems has focused primarily on
average utility across a set of information needs (information retrieval) or
users (recommender systems). In this work, we argue that evaluating only with
average metric measurements assumes utilitarian values not aligned with
traditions of information access based on equal access. We advocate for
pessimistic evaluation of information access systems focusing on worst case
utility. These methods are (a) grounded in ethical and pragmatic concepts, (b)
theoretically complementary to existing robustness and fairness methods, and
(c) empirically validated across a set of retrieval and recommendation tasks.
These results suggest that pessimistic evaluation should be included in
existing experimentation processes to better understand the behavior of
systems, especially when concerned with principles of social good.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Large Language Models as Narrative-Driven Recommenders 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.13604v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.13604v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Lukas Eberhard, Thorsten Ruprechter, Denis Helic
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Narrative-driven recommenders aim to provide personalized suggestions for
user requests expressed in free-form text such as "I want to watch a thriller
with a mind-bending story, like Shutter Island." Although large language models
(LLMs) have been shown to excel in processing general natural language queries,
their effectiveness for handling such recommendation requests remains
relatively unexplored. To close this gap, we compare the performance of 38
open- and closed-source LLMs of various sizes, such as LLama 3.2 and GPT-4o, in
a movie recommendation setting. For this, we utilize a gold-standard,
crowdworker-annotated dataset of posts from reddit's movie suggestion community
and employ various prompting strategies, including zero-shot, identity, and
few-shot prompting. Our findings demonstrate the ability of LLMs to generate
contextually relevant movie recommendations, significantly outperforming other
state-of-the-art approaches, such as doc2vec. While we find that closed-source
and large-parameterized models generally perform best, medium-sized open-source
models remain competitive, being only slightly outperformed by their more
computationally expensive counterparts. Furthermore, we observe no significant
differences across prompting strategies for most models, underscoring the
effectiveness of simple approaches such as zero-shot prompting for
narrative-driven recommendations. Overall, this work offers valuable insights
for recommender system researchers as well as practitioners aiming to integrate
LLMs into real-world recommendation tools.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Under review; 19 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Cross-Domain Sequential Recommendation via Neural Process 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.13588v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.13588v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Haipeng Li, Jiangxia Cao, Yiwen Gao, Yunhuai Liu, Shuchao Pang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Cross-Domain Sequential Recommendation (CDSR) is a hot topic in
sequence-based user interest modeling, which aims at utilizing a single model
to predict the next items for different domains. To tackle the CDSR, many
methods are focused on domain overlapped users' behaviors fitting, which
heavily relies on the same user's different-domain item sequences collaborating
signals to capture the synergy of cross-domain item-item correlation. Indeed,
these overlapped users occupy a small fraction of the entire user set only,
which introduces a strong assumption that the small group of domain overlapped
users is enough to represent all domain user behavior characteristics. However,
intuitively, such a suggestion is biased, and the insufficient learning
paradigm in non-overlapped users will inevitably limit model performance.
Further, it is not trivial to model non-overlapped user behaviors in CDSR
because there are no other domain behaviors to collaborate with, which causes
the observed single-domain users' behavior sequences to be hard to contribute
to cross-domain knowledge mining. Considering such a phenomenon, we raise a
challenging and unexplored question: How to unleash the potential of
non-overlapped users' behaviors to empower CDSR?
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Work in progress</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Context-aware adaptive personalised recommendation: a meta-hybrid 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.13374v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.13374v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Peter Tibensky, Michal Kompan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recommenders take place on a wide scale of e-commerce systems, reducing the
problem of information overload. The most common approach is to choose a
recommender used by the system to make predictions. However, users vary from
each other; thus, a one-fits-all approach seems to be sub-optimal. In this
paper, we propose a meta-hybrid recommender that uses machine learning to
predict an optimal algorithm. In this way, the best-performing recommender is
used for each specific session and user. This selection depends on contextual
and preferential information collected about the user. We use standard
MovieLens and The Movie DB datasets for offline evaluation. We show that based
on the proposed model, it is possible to predict which recommender will provide
the most precise recommendations to a user. The theoretical performance of our
meta-hybrid outperforms separate approaches by 20-50% in normalized Discounted
Gain and Root Mean Square Error metrics. However, it is hard to obtain the
optimal performance based on widely-used standard information stored about
users.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Comparing the Utility, Preference, and Performance of Course Material
  Search Functionality and Retrieval-Augmented Generation Large Language Model
  (RAG-LLM) AI Chatbots in Information-Seeking Tasks 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.13326v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.13326v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Leonardo Pasquarelli, Charles Koutcheme, Arto Hellas
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Providing sufficient support for students requires substantial resources,
especially considering the growing enrollment numbers. Students need help in a
variety of tasks, ranging from information-seeking to requiring support with
course assignments. To explore the utility of recent large language models
(LLMs) as a support mechanism, we developed an LLM-powered AI chatbot that
augments the answers that are produced with information from the course
materials. To study the effect of the LLM-powered AI chatbot, we conducted a
lab-based user study (N=14), in which the participants worked on tasks from a
web software development course. The participants were divided into two groups,
where one of the groups first had access to the chatbot and then to a more
traditional search functionality, while another group started with the search
functionality and was then given the chatbot. We assessed the participants'
performance and perceptions towards the chatbot and the search functionality
and explored their preferences towards the support functionalities. Our
findings highlight that both support mechanisms are seen as useful and that
support mechanisms work well for specific tasks, while less so for other tasks.
We also observe that students tended to prefer the second support mechanism
more, where students who were first given the chatbot tended to prefer the
search functionality and vice versa.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>12 pages, 4 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ SBI-RAG: Enhancing Math Word Problem Solving for Students through
  Schema-Based Instruction and Retrieval-Augmented Generation <span class="chip">NeurIPS'24</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.13293v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.13293v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Prakhar Dixit, Tim Oates
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Many students struggle with math word problems (MWPs), often finding it
difficult to identify key information and select the appropriate mathematical
operations.Schema-based instruction (SBI) is an evidence-based strategy that
helps students categorize problems based on their structure, improving
problem-solving accuracy. Building on this, we propose a Schema-Based
Instruction Retrieval-Augmented Generation (SBI-RAG) framework that
incorporates a large language model (LLM).Our approach emphasizes step-by-step
reasoning by leveraging schemas to guide solution generation. We evaluate its
performance on the GSM8K dataset, comparing it with GPT-4 and GPT-3.5 Turbo,
and introduce a "reasoning score" metric to assess solution quality. Our
findings suggest that SBI-RAG enhances reasoning clarity and problem-solving
accuracy, potentially providing educational benefits for students
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to the 4th MATH-AI Workshop at NeurIPS'24</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Disentangling Likes and Dislikes in Personalized Generative Explainable
  Recommendation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.13248v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.13248v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ryotaro Shimizu, Takashi Wada, Yu Wang, Johannes Kruse, Sean O'Brien, Sai HtaungKham, Linxin Song, Yuya Yoshikawa, Yuki Saito, Fugee Tsung, Masayuki Goto, Julian McAuley
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent research on explainable recommendation generally frames the task as a
standard text generation problem, and evaluates models simply based on the
textual similarity between the predicted and ground-truth explanations.
However, this approach fails to consider one crucial aspect of the systems:
whether their outputs accurately reflect the users' (post-purchase) sentiments,
i.e., whether and why they would like and/or dislike the recommended items. To
shed light on this issue, we introduce new datasets and evaluation methods that
focus on the users' sentiments. Specifically, we construct the datasets by
explicitly extracting users' positive and negative opinions from their
post-purchase reviews using an LLM, and propose to evaluate systems based on
whether the generated explanations 1) align well with the users' sentiments,
and 2) accurately identify both positive and negative opinions of users on the
target items. We benchmark several recent models on our datasets and
demonstrate that achieving strong performance on existing metrics does not
ensure that the generated explanations align well with the users' sentiments.
Lastly, we find that existing models can provide more sentiment-aware
explanations when the users' (predicted) ratings for the target items are
directly fed into the models as input. We will release our code and datasets
upon acceptance.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Research on Travel Route Planing Problems Based on Greedy Algorithm 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.13226v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.13226v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yiquan Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The greedy algorithm based route planning problem is a method of finding the
optimal or near optimal route between a given starting and ending point. This
article first uses PCA method to reduce the dimensionality of urban evaluation
indicators, extracts key principal components, and KMO and TOPSIS algorithms to
reduce the dimensionality of the data. Secondly, for datasets that have not
passed the KMO test, a comprehensive evaluation will be conducted using the
entropy weight method and TOPSIS method. Finally, based on the greedy
algorithm, a route planning algorithm was proposed and optimized to provide
personalized route customization according to the different needs of tourists.
We also took into account the local travel efficiency, the time required to
visit tourist attractions, and necessary daily rest time to reduce costs and
avoid falling into the local optimal solution.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ MixEHR-Nest: Identifying Subphenotypes within Electronic Health Records
  through Hierarchical Guided-Topic Modeling 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.13217v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.13217v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ruohan Wang, Zilong Wang, Ziyang Song, David Buckeridge, Yue Li
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Automatic subphenotyping from electronic health records (EHRs)provides
numerous opportunities to understand diseases with unique subgroups and enhance
personalized medicine for patients. However, existing machine learning
algorithms either focus on specific diseases for better interpretability or
produce coarse-grained phenotype topics without considering nuanced disease
patterns. In this study, we propose a guided topic model, MixEHR-Nest, to infer
sub-phenotype topics from thousands of disease using multi-modal EHR data.
Specifically, MixEHR-Nest detects multiple subtopics from each phenotype topic,
whose prior is guided by the expert-curated phenotype concepts such as
Phenotype Codes (PheCodes) or Clinical Classification Software (CCS) codes. We
evaluated MixEHR-Nest on two EHR datasets: (1) the MIMIC-III dataset consisting
of over 38 thousand patients from intensive care unit (ICU) from Beth Israel
Deaconess Medical Center (BIDMC) in Boston, USA; (2) the healthcare
administrative database PopHR, comprising 1.3 million patients from Montreal,
Canada. Experimental results demonstrate that MixEHR-Nest can identify
subphenotypes with distinct patterns within each phenotype, which are
predictive for disease progression and severity. Consequently, MixEHR-Nest
distinguishes between type 1 and type 2 diabetes by inferring subphenotypes
using CCS codes, which do not differentiate these two subtype concepts.
Additionally, MixEHR-Nest not only improved the prediction accuracy of
short-term mortality of ICU patients and initial insulin treatment in diabetic
patients but also revealed the contributions of subphenotypes. For longitudinal
analysis, MixEHR-Nest identified subphenotypes of distinct age prevalence under
the same phenotypes, such as asthma, leukemia, epilepsy, and depression. The
MixEHR-Nest software is available at GitHub:
https://github.com/li-lab-mcgill/MixEHR-Nest.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ <span class="highlight-title">Transformer</span>s4NewsRec: A <span class="highlight-title">Transformer</span>-based News Recommendation Framework 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.13125v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.13125v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Dairui Liu, Honghui Du, Boming Yang, Neil Hurley, Aonghus Lawlor, Irene Li, Derek Greene, Ruihai Dong
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Pre-trained transformer models have shown great promise in various natural
language processing tasks, including personalized news recommendations. To
harness the power of these models, we introduce Transformers4NewsRec, a new
Python framework built on the \textbf{Transformers} library. This framework is
designed to unify and compare the performance of various news recommendation
models, including deep neural networks and graph-based models.
Transformers4NewsRec offers flexibility in terms of model selection, data
preprocessing, and evaluation, allowing both quantitative and qualitative
analysis.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Retrieval-Enhanced Named Entity Recognition 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.13118v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.13118v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Enzo Shiraishi, Raphael Y. de Camargo, Henrique L. P. Silva, Ronaldo C. Prati
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  When combined with In-Context Learning, a technique that enables models to
adapt to new tasks by incorporating task-specific examples or demonstrations
directly within the input prompt, autoregressive language models have achieved
good performance in a wide range of tasks and applications. However, this
combination has not been properly explored in the context of named entity
recognition, where the structure of this task poses unique challenges. We
propose RENER (Retrieval-Enhanced Named Entity Recognition), a technique for
named entity recognition using autoregressive language models based on
In-Context Learning and information retrieval techniques. When presented with
an input text, RENER fetches similar examples from a dataset of training
examples that are used to enhance a language model to recognize named entities
from this input text. RENER is modular and independent of the underlying
language model and information retrieval algorithms. Experimental results show
that in the CrossNER collection we achieve state-of-the-art performance with
the proposed technique and that information retrieval can increase the F-score
by up to 11 percentage points.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>13 pages, 6 figures, 3 tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Preference Diffusion for Recommendation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.13117v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.13117v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Shuo Liu, An Zhang, Guoqing Hu, Hong Qian, Tat-seng Chua
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recommender systems predict personalized item rankings based on user
preference distributions derived from historical behavior data. Recently,
diffusion models (DMs) have gained attention in recommendation for their
ability to model complex distributions, yet current DM-based recommenders often
rely on traditional objectives like mean squared error (MSE) or recommendation
objectives, which are not optimized for personalized ranking tasks or fail to
fully leverage DM's generative potential. To address this, we propose
PreferDiff, a tailored optimization objective for DM-based recommenders.
PreferDiff transforms BPR into a log-likelihood ranking objective and
integrates multiple negative samples to better capture user preferences.
Specifically, we employ variational inference to handle the intractability
through minimizing the variational upper bound and replaces MSE with cosine
error to improve alignment with recommendation tasks. Finally, we balance
learning generation and preference to enhance the training stability of DMs.
PreferDiff offers three key benefits: it is the first personalized ranking loss
designed specifically for DM-based recommenders and it improves ranking and
faster convergence by addressing hard negatives. We also prove that it is
theoretically connected to Direct Preference Optimization which indicates that
it has the potential to align user preferences in DM-based recommenders via
generative modeling. Extensive experiments across three benchmarks validate its
superior recommendation performance and commendable general sequential
recommendation capabilities. Our codes are available at
\url{https://github.com/lswhim/PreferDiff}.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Improving Bilingual Lexicon Induction with Cross-Encoder Reranking <span class="chip">EMNLP 2022</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2210.16953v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2210.16953v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yaoyiran Li, Fangyu Liu, Ivan Vulić, Anna Korhonen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Bilingual lexicon induction (BLI) with limited bilingual supervision is a
crucial yet challenging task in multilingual NLP. Current state-of-the-art BLI
methods rely on the induction of cross-lingual word embeddings (CLWEs) to
capture cross-lingual word similarities; such CLWEs are obtained 1) via
traditional static models (e.g., VecMap), or 2) by extracting type-level CLWEs
from multilingual pretrained language models (mPLMs), or 3) through combining
the former two options. In this work, we propose a novel semi-supervised
post-hoc reranking method termed BLICEr (BLI with Cross-Encoder Reranking),
applicable to any precalculated CLWE space, which improves their BLI
capability. The key idea is to 'extract' cross-lingual lexical knowledge from
mPLMs, and then combine it with the original CLWEs. This crucial step is done
via 1) creating a word similarity dataset, comprising positive word pairs
(i.e., true translations) and hard negative pairs induced from the original
CLWE space, and then 2) fine-tuning an mPLM (e.g., mBERT or XLM-R) in a
cross-encoder manner to predict the similarity scores. At inference, we 3)
combine the similarity score from the original CLWE space with the score from
the BLI-tuned cross-encoder. BLICEr establishes new state-of-the-art results on
two standard BLI benchmarks spanning a wide spectrum of diverse languages: it
substantially outperforms a series of strong baselines across the board. We
also validate the robustness of BLICEr with different CLWEs.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Findings of EMNLP 2022</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ The Moral Case for Using Language Model Agents for Recommendation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12123v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12123v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Seth Lazar, Luke Thorburn, Tian Jin, Luca Belli
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Our information and communication environment has fallen short of the ideals
that networked global communication might have served. Identifying all the
causes of its pathologies is difficult, but existing recommender systems very
likely play a contributing role. In this paper, which draws on the normative
tools of philosophy of computing, informed by empirical and technical insights
from natural language processing and recommender systems, we make the moral
case for an alternative approach. We argue that existing recommenders
incentivise mass surveillance, concentrate power, fall prey to narrow
behaviourism, and compromise user agency. Rather than just trying to avoid
algorithms entirely, or to make incremental improvements to the current
paradigm, researchers and engineers should explore an alternative paradigm: the
use of language model (LM) agents to source and curate content that matches
users' preferences and values, expressed in natural language. The use of LM
agents for recommendation poses its own challenges, including those related to
candidate generation, computational efficiency, preference modelling, and
prompt injection. Nonetheless, if implemented successfully LM agents could:
guide us through the digital public sphere without relying on mass
surveillance; shift power away from platforms towards users; optimise for what
matters instead of just for behavioural proxies; and scaffold our agency
instead of undermining it.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Improving Word Translation via Two-Stage Contrastive Learning <span class="chip">ACL 2022</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2203.08307v5">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2203.08307v5.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yaoyiran Li, Fangyu Liu, Nigel Collier, Anna Korhonen, Ivan Vulić
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Word translation or bilingual lexicon induction (BLI) is a key cross-lingual
task, aiming to bridge the lexical gap between different languages. In this
work, we propose a robust and effective two-stage contrastive learning
framework for the BLI task. At Stage C1, we propose to refine standard
cross-lingual linear maps between static word embeddings (WEs) via a
contrastive learning objective; we also show how to integrate it into the
self-learning procedure for even more refined cross-lingual maps. In Stage C2,
we conduct BLI-oriented contrastive fine-tuning of mBERT, unlocking its word
translation capability. We also show that static WEs induced from the
`C2-tuned' mBERT complement static WEs from Stage C1. Comprehensive experiments
on standard BLI datasets for diverse languages and different experimental
setups demonstrate substantial gains achieved by our framework. While the BLI
method from Stage C1 already yields substantial gains over all state-of-the-art
BLI methods in our comparison, even stronger improvements are met with the full
two-stage framework: e.g., we report gains for 112/112 BLI setups, spanning 28
language pairs.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>ACL 2022 Main</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Into the Unknown Unknowns: Engaged Human Learning through Participation
  in Language Model Agent Conversations <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2408.15232v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2408.15232v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yucheng Jiang, Yijia Shao, Dekun Ma, Sina J. Semnani, Monica S. Lam
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  While language model (LM)-powered chatbots and generative search engines
excel at answering concrete queries, discovering information in the terrain of
unknown unknowns remains challenging for users. To emulate the common
educational scenario where children/students learn by listening to and
participating in conversations of their parents/teachers, we create
Collaborative STORM (Co-STORM). Unlike QA systems that require users to ask all
the questions, Co-STORM lets users observe and occasionally steer the discourse
among several LM agents. The agents ask questions on the user's behalf,
allowing the user to discover unknown unknowns serendipitously. To facilitate
user interaction, Co-STORM assists users in tracking the discourse by
organizing the uncovered information into a dynamic mind map, ultimately
generating a comprehensive report as takeaways. For automatic evaluation, we
construct the WildSeek dataset by collecting real information-seeking records
with user goals. Co-STORM outperforms baseline methods on both discourse trace
and report quality. In a further human evaluation, 70% of participants prefer
Co-STORM over a search engine, and 78% favor it over a RAG chatbot.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>EMNLP 2024 Main</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Mixed-initiative Query Rewriting in Conversational Passage Retrieval 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2307.08803v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2307.08803v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Dayu Yang, Yue Zhang, Hui Fang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this paper, we report our methods and experiments for the TREC
Conversational Assistance Track (CAsT) 2022. In this work, we aim to reproduce
multi-stage retrieval pipelines and explore one of the potential benefits of
involving mixed-initiative interaction in conversational passage retrieval
scenarios: reformulating raw queries. Before the first ranking stage of a
multi-stage retrieval pipeline, we propose a mixed-initiative query rewriting
module, which achieves query rewriting based on the mixed-initiative
interaction between the users and the system, as the replacement for the neural
rewriting method. Specifically, we design an algorithm to generate appropriate
questions related to the ambiguities in raw queries, and another algorithm to
reformulate raw queries by parsing users' feedback and incorporating it into
the raw query. For the first ranking stage of our multi-stage pipelines, we
adopt a sparse ranking function: BM25, and a dense retrieval method:
TCT-ColBERT. For the second-ranking step, we adopt a pointwise reranker:
MonoT5, and a pairwise reranker: DuoT5. Experiments on both TREC CAsT 2021 and
TREC CAsT 2022 datasets show the effectiveness of our mixed-initiative-based
query rewriting (or query reformulation) method on improving retrieval
performance compared with two popular reformulators: a neural reformulator:
CANARD-T5 and a rule-based reformulator: historical query reformulator(HQE).
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>https://trec.nist.gov/pubs/trec31/papers/udel_fang.C.pdf</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Behavior Alignment: A New Perspective of Evaluating LLM-based
  Conversational Recommender Systems <span class="chip">SIGIR</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2404.11773v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2404.11773v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Dayu Yang, Fumian Chen, Hui Fang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large Language Models (LLMs) have demonstrated great potential in
Conversational Recommender Systems (CRS). However, the application of LLMs to
CRS has exposed a notable discrepancy in behavior between LLM-based CRS and
human recommenders: LLMs often appear inflexible and passive, frequently
rushing to complete the recommendation task without sufficient inquiry.This
behavior discrepancy can lead to decreased accuracy in recommendations and
lower user satisfaction. Despite its importance, existing studies in CRS lack a
study about how to measure such behavior discrepancy. To fill this gap, we
propose Behavior Alignment, a new evaluation metric to measure how well the
recommendation strategies made by a LLM-based CRS are consistent with human
recommenders'. Our experiment results show that the new metric is better
aligned with human preferences and can better differentiate how systems perform
than existing evaluation metrics. As Behavior Alignment requires explicit and
costly human annotations on the recommendation strategies, we also propose a
classification-based method to implicitly measure the Behavior Alignment based
on the responses. The evaluation results confirm the robustness of the method.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by the 47th International ACM SIGIR Conference on Research
  and Development in Information Retrieval</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ ZeQR: Zero-shot Query Reformulation for Conversational Search <span class="chip">SIGIR</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2307.09384v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2307.09384v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Dayu Yang, Yue Zhang, Hui Fang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  As the popularity of voice assistants continues to surge, conversational
search has gained increased attention in Information Retrieval. However, data
sparsity issues in conversational search significantly hinder the progress of
supervised conversational search methods. Consequently, researchers are
focusing more on zero-shot conversational search approaches. Nevertheless,
existing zero-shot methods face three primary limitations: they are not
universally applicable to all retrievers, their effectiveness lacks sufficient
explainability, and they struggle to resolve common conversational ambiguities
caused by omission. To address these limitations, we introduce a novel
Zero-shot Query Reformulation (or Query Rewriting) (ZeQR) framework that
reformulates queries based on previous dialogue contexts without requiring
supervision from conversational search data. Specifically, our framework
utilizes language models designed for machine reading comprehension tasks to
explicitly resolve two common ambiguities: coreference and omission, in raw
queries. In comparison to existing zero-shot methods, our approach is
universally applicable to any retriever without additional adaptation or
indexing. It also provides greater explainability and effectively enhances
query intent understanding because ambiguities are explicitly and proactively
resolved. Through extensive experiments on four TREC conversational datasets,
we demonstrate the effectiveness of our method, which consistently outperforms
state-of-the-art baselines.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by the 9th ACM SIGIR International Conference on the Theory
  of Information Retrieval</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ <span class="highlight-title">Dataset</span> Condensation for Recommendation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2310.01038v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2310.01038v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jiahao Wu, Wenqi Fan, Jingfan Chen, Shengcai Liu, Qijiong Liu, Rui He, Qing Li, Ke Tang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Training recommendation models on large datasets requires significant time
and resources. It is desired to construct concise yet informative datasets for
efficient training. Recent advances in dataset condensation show promise in
addressing this problem by synthesizing small datasets. However, applying
existing methods of dataset condensation to recommendation has limitations: (1)
they fail to generate discrete user-item interactions, and (2) they could not
preserve users' potential preferences. To address the limitations, we propose a
lightweight condensation framework tailored for recommendation (DConRec),
focusing on condensing user-item historical interaction sets. Specifically, we
model the discrete user-item interactions via a probabilistic approach and
design a pre-augmentation module to incorporate the potential preferences of
users into the condensed datasets. While the substantial size of datasets leads
to costly optimization, we propose a lightweight policy gradient estimation to
accelerate the data synthesis. Experimental results on multiple real-world
datasets have demonstrated the effectiveness and efficiency of our framework.
Besides, we provide a theoretical analysis of the provable convergence of
DConRec. Our implementation is available at:
https://github.com/JiahaoWuGit/DConRec.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by IEEE TKDE. Also titled as "Condensing Pre-augmented
  Recommendation Data via Lightweight Policy Gradient Estimation"</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Mixed-Precision Embeddings for Large-Scale Recommendation Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.20305v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.20305v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Shiwei Li, Zhuoqi Hu, Xing Tang, Haozhao Wang, Shijie Xu, Weihong Luo, Yuhua Li, Xiuqiang He, Ruixuan Li
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Embedding techniques have become essential components of large databases in
the deep learning era. By encoding discrete entities, such as words, items, or
graph nodes, into continuous vector spaces, embeddings facilitate more
efficient storage, retrieval, and processing in large databases. Especially in
the domain of recommender systems, millions of categorical features are encoded
as unique embedding vectors, which facilitates the modeling of similarities and
interactions among features. However, numerous embedding vectors can result in
significant storage overhead. In this paper, we aim to compress the embedding
table through quantization techniques. Given that features vary in importance
levels, we seek to identify an appropriate precision for each feature to
balance model accuracy and memory usage. To this end, we propose a novel
embedding compression method, termed Mixed-Precision Embeddings (MPE).
Specifically, to reduce the size of the search space, we first group features
by frequency and then search precision for each feature group. MPE further
learns the probability distribution over precision levels for each feature
group, which can be used to identify the most suitable precision with a
specially designed sampling strategy. Extensive experiments on three public
datasets demonstrate that MPE significantly outperforms existing embedding
compression methods. Remarkably, MPE achieves about 200x compression on the
Criteo dataset without comprising the prediction accuracy.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>under submision</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ A <span class="highlight-title">Survey</span> on Intent-aware Recommender Systems 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.16350v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.16350v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Dietmar Jannach, Markus Zanker
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Many modern online services feature personalized recommendations. A central
challenge when providing such recommendations is that the reason why an
individual user accesses the service may change from visit to visit or even
during an ongoing usage session. To be effective, a recommender system should
therefore aim to take the users' probable intent of using the service at a
certain point in time into account. In recent years, researchers have thus
started to address this challenge by incorporating intent-awareness into
recommender systems. Correspondingly, a number of technical approaches were put
forward, including diversification techniques, intent prediction models or
latent intent modeling approaches. In this paper, we survey and categorize
existing approaches to building the next generation of Intent-Aware Recommender
Systems (IARS). Based on an analysis of current evaluation practices, we
outline open gaps and possible future directions in this area, which in
particular include the consideration of additional interaction signals and
contextual information to further improve the effectiveness of such systems.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Chatbot-Based Ontology Interaction Using Large Language Models and
  Domain-Specific Standards 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2408.00800v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2408.00800v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jonathan Reif, Tom Jeleniewski, Milapji Singh Gill, Felix Gehlhoff, Alexander Fay
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The following contribution introduces a concept that employs Large Language
Models (LLMs) and a chatbot interface to enhance SPARQL query generation for
ontologies, thereby facilitating intuitive access to formalized knowledge.
Utilizing natural language inputs, the system converts user inquiries into
accurate SPARQL queries that strictly query the factual content of the
ontology, effectively preventing misinformation or fabrication by the LLM. To
enhance the quality and precision of outcomes, additional textual information
from established domain-specific standards is integrated into the ontology for
precise descriptions of its concepts and relationships. An experimental study
assesses the accuracy of generated SPARQL queries, revealing significant
benefits of using LLMs for querying ontologies and highlighting areas for
future research.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>\c{opyright} 2024 IEEE. Personal use of this material is permitted.
  Permission from IEEE must be obtained for all other uses, in any current or
  future media, including reprinting/republishing this material for advertising
  or promotional purposes, creating new collective works, for resale or
  redistribution to servers or lists, or reuse of any copyrighted component of
  this work in other works</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ DiffATR: Diffusion-based Generative Modeling for Audio-Text Retrieval 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.10025v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.10025v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yifei Xin, Xuxin Cheng, Zhihong Zhu, Xusheng Yang, Yuexian Zou
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Existing audio-text retrieval (ATR) methods are essentially discriminative
models that aim to maximize the conditional likelihood, represented as
p(candidates|query). Nevertheless, this methodology fails to consider the
intrinsic data distribution p(query), leading to difficulties in discerning
out-of-distribution data. In this work, we attempt to tackle this constraint
through a generative perspective and model the relationship between audio and
text as their joint probability p(candidates,query). To this end, we present a
diffusion-based ATR framework (DiffATR), which models ATR as an iterative
procedure that progressively generates joint distribution from noise.
Throughout its training phase, DiffATR is optimized from both generative and
discriminative viewpoints: the generator is refined through a generation loss,
while the feature extractor benefits from a contrastive loss, thus combining
the merits of both methodologies. Experiments on the AudioCaps and Clotho
datasets with superior performances, verify the effectiveness of our approach.
Notably, without any alterations, our DiffATR consistently exhibits strong
performance in out-of-domain retrieval settings.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by Interspeech2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Probability Distribution Learning: A theoretical framework for Deep
  Learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.05666v7">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.05666v7.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Binchuan Qi, Wei Gong, Li Li
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper introduces probability distribution learning (PD learning), a
novel theoretical learning framework. Departing from the traditional
statistical learning framework, PD learning focuses on learning the underlying
probability distribution, which is modeled as a random variable within the
probability simplex. Within this framework, the learning error is decomposed
into uncertainty, estimation error, and the model's fitting error.
Subsequently, we present the methodology for calculating uncertainty, along
with optimization strategies for both estimation error and fitting error. Given
that minimizing the fitting error typically constitutes a non-convex
optimization problem, we introduce a standard loss function and the gradient
structural control (GSC) algorithm, and demonstrate that by employing this
function, the optima of fitting error minimization can be approached by
reducing the gradient norm and structural error. Furthermore, we apply the PD
learning framework to deep learning, elucidating the mechanisms by which
techniques such as random parameter initialization, over-parameterization,
bias-variance trade-off, and dropout influence deep model training. Finally,
experimental results on various models validate the effectiveness of the
proposed framework.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>arXiv admin note: text overlap with arXiv:2105.04026 by other
  authors. arXiv admin note: text overlap with arXiv:2105.04026 by other
  authors</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ NFT1000: A Cross-Modal <span class="highlight-title">Dataset</span> for Non-Fungible Token Retrieval 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2402.16872v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2402.16872v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Shuxun Wang, Yunfei Lei, Ziqi Zhang, Wei Liu, Haowei Liu, Li Yang, Wenjuan Li, Bing Li, Weiming Hu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  With the rise of "Metaverse" and "Web 3.0", Non-Fungible Token (NFT) has
emerged as a kind of pivotal digital asset, garnering significant attention. By
the end of March 2024, more than 1.7 billion NFTs have been minted across
various blockchain platforms. To effectively locate a desired NFT, conducting
searches within a vast array of NFTs is essential. The challenge in NFT
retrieval is heightened due to the high degree of similarity among different
NFTs, regarding regional and semantic aspects. In this paper, we will introduce
a benchmark dataset named "NFT Top1000 Visual-Text Dataset" (NFT1000),
containing 7.56 million image-text pairs, and being collected from 1000 most
famous PFP1 NFT collections2 by sales volume on the Ethereum blockchain. Based
on this dataset and leveraging the CLIP series of pre-trained models as our
foundation, we propose the dynamic masking fine-tuning scheme. This innovative
approach results in a 7.4\% improvement in the top1 accuracy rate, while
utilizing merely 13\% of the total training data (0.79 million vs. 6.1
million). We also propose a robust metric Comprehensive Variance Index (CVI) to
assess the similarity and retrieval difficulty of visual-text pairs data. The
dataset will be released as an open-source resource. For more details, please
refer to: https://github.com/ShuxunoO/NFT-Net.git.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>11 pages,12figures to be published in ACM Multimedia 2024, see
  https://openreview.net/forum?id=xUtNrKH8iB&noteId=xUtNrKH8iB</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ RAGEval: Scenario Specific RAG Evaluation <span class="highlight-title">Dataset</span> Generation Framework 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2408.01262v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2408.01262v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Kunlun Zhu, Yifan Luo, Dingling Xu, Ruobing Wang, Shi Yu, Shuo Wang, Yukun Yan, Zhenghao Liu, Xu Han, Zhiyuan Liu, Maosong Sun
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Retrieval-Augmented Generation (RAG) is a powerful approach that enables
large language models (LLMs) to incorporate external knowledge. However,
evaluating the effectiveness of RAG systems in specialized scenarios remains
challenging due to the high costs of data construction and the lack of suitable
evaluation metrics. This paper introduces RAGEval, a framework designed to
assess RAG systems across diverse scenarios by generating high-quality
documents, questions, answers, and references through a schema-based pipeline.
With a focus on factual accuracy, we propose three novel metrics Completeness,
Hallucination, and Irrelevance to rigorously evaluate LLM-generated responses.
Experimental results show that RAGEval outperforms zero-shot and one-shot
methods in terms of clarity, safety, conformity, and richness of generated
samples. Furthermore, the use of LLMs for scoring the proposed metrics
demonstrates a high level of consistency with human evaluations. RAGEval
establishes a new paradigm for evaluating RAG systems in real-world
applications.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>https://github.com/OpenBMB/RAGEval</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ A Theory for Token-Level Harmonization in Retrieval-Augmented Generation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.00944v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.00944v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Shicheng Xu, Liang Pang, Huawei Shen, Xueqi Cheng
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Retrieval-augmented generation (RAG) utilizes retrieved texts to enhance
large language models (LLMs). Studies show that while RAG provides valuable
external information (benefit), it may also mislead LLMs (detriment) with noisy
or incorrect retrieved texts. Although many existing methods attempt to
preserve benefit and avoid detriment, they lack a theoretical explanation for
RAG. The benefit and detriment in the next token prediction of RAG remain a
black box that cannot be quantified or compared in an explainable manner, so
existing methods are data-driven, need additional utility evaluators or
post-hoc. This paper takes the first step towards providing a theory to explain
and trade off the benefit and detriment in RAG. First, we model RAG as the
fusion between distribution of LLMs knowledge and distribution of retrieved
texts. Then, we formalize the trade-off between the value of external knowledge
(benefit) and its potential risk of misleading LLMs (detriment) in next token
prediction of RAG by distribution difference in this fusion. Finally, we prove
that the actual effect of RAG on the token, which is the comparison between
benefit and detriment, can be predicted without any training or accessing the
utility of retrieval. Based on our theory, we propose a practical novel method,
Tok-RAG, which achieves collaborative generation between the pure LLM and RAG
at token level to preserve benefit and avoid detriment. Experiments in
real-world tasks using LLMs such as OPT, LLaMA-2, and Mistral show the
effectiveness of our method and support our theoretical findings.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>25 pages</span>
                                        </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
            <article>
                <details>
                    <Summary>
                        Multimedia <span class="chip" style="font-size: 60%">7</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Improving Multi-modal Large Language Model through Boosting Vision
  Capabilities 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.13733v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.13733v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yanpeng Sun, Huaxin Zhang, Qiang Chen, Xinyu Zhang, Nong Sang, Gang Zhang, Jingdong Wang, Zechao Li
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We focus on improving the visual understanding capability for boosting the
vision-language models. We propose \textbf{Arcana}, a multiModal language
model, which introduces two crucial techniques. First, we present Multimodal
LoRA (MM-LoRA), a module designed to enhance the decoder. Unlike traditional
language-driven decoders, MM-LoRA consists of two parallel LoRAs -- one for
vision and one for language -- each with its own parameters. This disentangled
parameters design allows for more specialized learning in each modality and
better integration of multimodal information. Second, we introduce the Query
Ladder adapter (QLadder) to improve the visual encoder. QLadder employs a
learnable ``\textit{ladder}'' structure to deeply aggregates the intermediate
representations from the frozen pretrained visual encoder (e.g., CLIP image
encoder). This enables the model to learn new and informative visual features,
as well as remaining the powerful capabilities of the pretrained visual
encoder. These techniques collectively enhance Arcana's visual perception
power, enabling it to leverage improved visual information for more accurate
and contextually relevant outputs across various multimodal scenarios.
Extensive experiments and ablation studies demonstrate the effectiveness and
generalization capability of our Arcana. The code and re-annotated data are
available at \url{https://arcana-project-page.github.io}.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Multimodal growth and development assessment model 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.13647v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.13647v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ying Li, Zichen Song, Zijie Gong, Sitan Huang, Jiewei Ge
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  With the development of social economy and the improvement of people's
attention to health, the growth and development of children and adolescents has
become an important indicator to measure the level of national health.
Therefore, accurate and timely assessment of children's growth and development
has become increasingly important. At the same time, global health
inequalities, especially child malnutrition and stunting in developing
countries, urgently require effective assessment tools to monitor and
intervene. In recent years, the rapid development of technologies such as big
data, artificial intelligence, and cloud computing, and the cross-integration
of multiple disciplines such as biomedicine, statistics, and computer science
have promoted the rapid development of large-scale models for growth and
development assessment. However, there are still problems such as too single
evaluation factors, inaccurate diagnostic results, and inability to give
accurate and reasonable recommendations. The multi-modal growth and development
assessment model uses the public data set of RSNA ( North American College of
Radiology ) as the training set, and the data set of the Department of
Pediatrics of Huaibei People's Hospital as the open source test set. The
embedded ICL module enables the model to quickly adapt and identify the tasks
that need to be done to ensure that under the premise of considering multiple
evaluation factors, accurate diagnosis results and reasonable medical
recommendations are given, so as to provide solutions to the above problems and
promote the development of the medical field.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>7 Pages 7 Figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ MeloTrans: A Text to Symbolic Music Generation Model Following Human
  Composition Habit 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.13419v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.13419v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yutian Wang, Wanyin Yang, Zhenrong Dai, Yilong Zhang, Kun Zhao, Hui Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  At present, neural network models show powerful sequence prediction ability
and are used in many automatic composition models. In comparison, the way
humans compose music is very different from it. Composers usually start by
creating musical motifs and then develop them into music through a series of
rules. This process ensures that the music has a specific structure and
changing pattern. However, it is difficult for neural network models to learn
these composition rules from training data, which results in a lack of
musicality and diversity in the generated music. This paper posits that
integrating the learning capabilities of neural networks with human-derived
knowledge may lead to better results. To archive this, we develop the
POP909$\_$M dataset, the first to include labels for musical motifs and their
variants, providing a basis for mimicking human compositional habits. Building
on this, we propose MeloTrans, a text-to-music composition model that employs
principles of motif development rules. Our experiments demonstrate that
MeloTrans excels beyond existing music generation models and even surpasses
Large Language Models (LLMs) like ChatGPT-4. This highlights the importance of
merging human insights with neural network capabilities to achieve superior
symbolic music generation.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Remember, Retrieve and Generate: Understanding Infinite Visual Concepts
  as Your Personalized Assistant 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.13360v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.13360v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Haoran Hao, Jiaming Han, Changsheng Li, Yu-Feng Li, Xiangyu Yue
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The development of large language models (LLMs) has significantly enhanced
the capabilities of multimodal LLMs (MLLMs) as general assistants. However,
lack of user-specific knowledge still restricts their application in human's
daily life. In this paper, we introduce the Retrieval Augmented Personalization
(RAP) framework for MLLMs' personalization. Starting from a general MLLM, we
turn it into a personalized assistant in three steps. (a) Remember: We design a
key-value database to store user-related information, e.g., user's name, avatar
and other attributes. (b) Retrieve: When the user initiates a conversation, RAP
will retrieve relevant information from the database using a multimodal
retriever. (c) Generate: The input query and retrieved concepts' information
are fed into MLLMs to generate personalized, knowledge-augmented responses.
Unlike previous methods, RAP allows real-time concept editing via updating the
external database. To further improve generation quality and alignment with
user-specific information, we design a pipeline for data collection and create
a specialized dataset for personalized training of MLLMs. Based on the dataset,
we train a series of MLLMs as personalized multimodal assistants. By
pretraining on large-scale dataset, RAP-MLLMs can generalize to infinite visual
concepts without additional finetuning. Our models demonstrate outstanding
flexibility and generation quality across a variety of tasks, such as
personalized image captioning, question answering and visual recognition. The
code, data and models are available at https://github.com/Hoar012/RAP-MLLM.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Beyond Coarse-Grained Matching in Video-Text Retrieval <span class="chip">ACCV 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12407v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12407v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Aozhu Chen, Hazel Doughty, Xirong Li, Cees G. M. Snoek
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Video-text retrieval has seen significant advancements, yet the ability of
models to discern subtle differences in captions still requires verification.
In this paper, we introduce a new approach for fine-grained evaluation. Our
approach can be applied to existing datasets by automatically generating hard
negative test captions with subtle single-word variations across nouns, verbs,
adjectives, adverbs, and prepositions. We perform comprehensive experiments
using four state-of-the-art models across two standard benchmarks (MSR-VTT and
VATEX) and two specially curated datasets enriched with detailed descriptions
(VLN-UVO and VLN-OOPS), resulting in a number of novel insights: 1) our
analyses show that the current evaluation benchmarks fall short in detecting a
model's ability to perceive subtle single-word differences, 2) our fine-grained
evaluation highlights the difficulty models face in distinguishing such subtle
variations. To enhance fine-grained understanding, we propose a new baseline
that can be easily combined with current methods. Experiments on our
fine-grained evaluations demonstrate that this approach enhances a model's
ability to understand fine-grained differences.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to ACCV 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ SaMoye: Zero-shot Singing Voice Conversion Model Based on Feature
  Disentanglement and Enhancement 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.07728v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.07728v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zihao Wang, Le Ma, Yongsheng Feng, Xin Pan, Yuhang Jin, Kejun Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Singing voice conversion (SVC) aims to convert a singer's voice to another
singer's from a reference audio while keeping the original semantics. However,
existing SVC methods can hardly perform zero-shot due to incomplete feature
disentanglement or dependence on the speaker look-up table. We propose the
first open-source high-quality zero-shot SVC model SaMoye that can convert
singing to human and non-human timbre. SaMoye disentangles the singing voice's
features into content, timbre, and pitch features, where we combine multiple
ASR models and compress the content features to reduce timbre leaks. Besides,
we enhance the timbre features by unfreezing the speaker encoder and mixing the
speaker embedding with top-3 similar speakers. We also establish an
unparalleled large-scale dataset to guarantee zero-shot performance, which
comprises more than 1,815 hours of pure singing voice and 6,367 speakers. We
conduct objective and subjective experiments to find that SaMoye outperforms
other models in zero-shot SVC tasks even under extreme conditions like
converting singing to animals' timbre. The code and weight of SaMoye are
available on https://github.com/CarlWangChina/SaMoye-SVC. The weights, code,
dataset, and documents of SaMoye are publicly available on
\url{https://github.com/CarlWangChina/SaMoye-SVC}.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>7 pages, 4 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Leveraging LLM Embeddings for Cross <span class="highlight-title">Dataset</span> Label Alignment and Zero
  Shot Music Emotion Prediction 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.11522v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.11522v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Renhang Liu, Abhinaba Roy, Dorien Herremans
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this work, we present a novel method for music emotion recognition that
leverages Large Language Model (LLM) embeddings for label alignment across
multiple datasets and zero-shot prediction on novel categories. First, we
compute LLM embeddings for emotion labels and apply non-parametric clustering
to group similar labels, across multiple datasets containing disjoint labels.
We use these cluster centers to map music features (MERT) to the LLM embedding
space. To further enhance the model, we introduce an alignment regularization
that enables dissociation of MERT embeddings from different clusters. This
further enhances the model's ability to better adaptation to unseen datasets.
We demonstrate the effectiveness of our approach by performing zero-shot
inference on a new dataset, showcasing its ability to generalize to unseen
labels without additional training.
</span>
                                    </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
    </section>
    <section class="day-container">
        <div class="date">
            <time datetime="2024-10-16T00:00:00Z">2024-10-16</time>
        </div>
            <article>
                <details>
                    <Summary>
                        Information Retrieval <span class="chip" style="font-size: 60%">23</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Is Semantic Chunking Worth the Computational Cost? 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.13070v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.13070v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Renyi Qu, Ruixuan Tu, Forrest Bao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent advances in Retrieval-Augmented Generation (RAG) systems have
popularized semantic chunking, which aims to improve retrieval performance by
dividing documents into semantically coherent segments. Despite its growing
adoption, the actual benefits over simpler fixed-size chunking, where documents
are split into consecutive, fixed-size segments, remain unclear. This study
systematically evaluates the effectiveness of semantic chunking using three
common retrieval-related tasks: document retrieval, evidence retrieval, and
retrieval-based answer generation. The results show that the computational
costs associated with semantic chunking are not justified by consistent
performance gains. These findings challenge the previous assumptions about
semantic chunking and highlight the need for more efficient chunking strategies
in RAG systems.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Supply Chain Network Extraction and Entity Classification Leveraging
  Large Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.13051v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.13051v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Tong Liu, Hadi Meidani
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Supply chain networks are critical to the operational efficiency of
industries, yet their increasing complexity presents significant challenges in
mapping relationships and identifying the roles of various entities.
Traditional methods for constructing supply chain networks rely heavily on
structured datasets and manual data collection, limiting their scope and
efficiency. In contrast, recent advancements in Natural Language Processing
(NLP) and large language models (LLMs) offer new opportunities for discovering
and analyzing supply chain networks using unstructured text data. This paper
proposes a novel approach that leverages LLMs to extract and process raw
textual information from publicly available sources to construct a
comprehensive supply chain graph. We focus on the civil engineering sector as a
case study, demonstrating how LLMs can uncover hidden relationships among
companies, projects, and other entities. Additionally, we fine-tune an LLM to
classify entities within the supply chain graph, providing detailed insights
into their roles and relationships. The results show that domain-specific
fine-tuning improves classification accuracy, highlighting the potential of
LLMs for industry-specific supply chain analysis. Our contributions include the
development of a supply chain graph for the civil engineering sector, as well
as a fine-tuned LLM model that enhances entity classification and understanding
of supply chain networks.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>11 pages, 4 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ LLM Confidence Evaluation Measures in Zero-Shot CSS Classification 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.13047v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.13047v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        David Farr, Iain Cruickshank, Nico Manzonelli, Nicholas Clark, Kate Starbird, Jevin West
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Assessing classification confidence is critical for leveraging large language
models (LLMs) in automated labeling tasks, especially in the sensitive domains
presented by Computational Social Science (CSS) tasks. In this paper, we make
three key contributions: (1) we propose an uncertainty quantification (UQ)
performance measure tailored for data annotation tasks, (2) we compare, for the
first time, five different UQ strategies across three distinct LLMs and CSS
data annotation tasks, (3) we introduce a novel UQ aggregation strategy that
effectively identifies low-confidence LLM annotations and disproportionately
uncovers data incorrectly labeled by the LLMs. Our results demonstrate that our
proposed UQ aggregation strategy improves upon existing methods andcan be used
to significantly improve human-in-the-loop data annotation processes.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ LFOSum: Summarizing Long-form Opinions with Large Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.13037v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.13037v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mir Tafseer Nayeem, Davood Rafiei
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Online reviews play a pivotal role in influencing consumer decisions across
various domains, from purchasing products to selecting hotels or restaurants.
However, the sheer volume of reviews -- often containing repetitive or
irrelevant content -- leads to information overload, making it challenging for
users to extract meaningful insights. Traditional opinion summarization models
face challenges in handling long inputs and large volumes of reviews, while
newer Large Language Model (LLM) approaches often fail to generate accurate and
faithful summaries. To address those challenges, this paper introduces (1) a
new dataset of long-form user reviews, each entity comprising over a thousand
reviews, (2) two training-free LLM-based summarization approaches that scale to
long inputs, and (3) automatic evaluation metrics. Our dataset of user reviews
is paired with in-depth and unbiased critical summaries by domain experts,
serving as a reference for evaluation. Additionally, our novel reference-free
evaluation metrics provide a more granular, context-sensitive assessment of
summary faithfulness. We benchmark several open-source and closed-source LLMs
using our methods. Our evaluation reveals that LLMs still face challenges in
balancing sentiment and format adherence in long-form summaries, though
open-source models can narrow the gap when relevant information is retrieved in
a focused manner.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Towards Computational Analysis of Pansori Singing 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12956v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12956v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Sangheon Park, Danbinaerin Han, Dasaem Jeong
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Pansori is one of the most representative vocal genres of Korean traditional
music, which has an elaborated vocal melody line with strong vibrato. Although
the music is transmitted orally without any music notation, transcribing
pansori music in Western staff notation has been introduced for several
purposes, such as documentation of music, education, or research. In this
paper, we introduce computational analysis of pansori based on both audio and
corresponding transcription, how modern Music Information Retrieval tasks can
be used in analyzing traditional music and how it revealed different audio
characteristics of what pansori contains.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Late-Breaking Demo Session of the 25th International Society for
  Music Information Retrieval (ISMIR) Conference, 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ RosePO: Aligning LLM-based Recommenders with Human Values 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12519v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12519v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jiayi Liao, Xiangnan He, Ruobing Xie, Jiancan Wu, Yancheng Yuan, Xingwu Sun, Zhanhui Kang, Xiang Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recently, there has been a growing interest in leveraging Large Language
Models (LLMs) for recommendation systems, which usually adapt a pre-trained LLM
to the recommendation scenario through supervised fine-tuning (SFT). However,
both the pre-training and SFT stages fail to explicitly model the comparative
relationships of a user's preferences on different items. To construct a
"helpful and harmless" LLM-based recommender, we propose a general framework --
Recommendation with smoothing personalized Preference Optimization (RosePO),
which better aligns with customized human values during the post-training
stage. Specifically, in addition to the input and chosen response that
naturally align with SFT data, we design a rejected sampling strategy tailored
for enhancing helpfulness, along with two strategies aimed at mitigating biases
to promote harmlessness. To ensure robustness against uncertain labels present
in automatically constructed preference data, we introduce a personalized
smoothing factor predicted by a preference oracle into the optimization
objective. Evaluation on three real-world datasets demonstrates the
effectiveness of our method, showcasing not only improved recommendation
performance but also mitigation of semantic hallucination and popularity bias.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ P4GCN: Vertical Federated Social Recommendation with Privacy-Preserving
  Two-Party Graph Convolution Networks 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.13905v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.13905v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zheng Wang, Wanwan Wang, Yimin Huang, Zhaopeng Peng, Ziqi Yang, Cheng Wang, Xiaoliang Fan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In recent years, graph neural networks (GNNs) have been commonly utilized for
social recommendation systems. However, real-world scenarios often present
challenges related to user privacy and business constraints, inhibiting direct
access to valuable social information from other platforms. While many existing
methods have tackled matrix factorization-based social recommendations without
direct social data access, developing GNN-based federated social recommendation
models under similar conditions remains largely unexplored. To address this
issue, we propose a novel vertical federated social recommendation method
leveraging privacy-preserving two-party graph convolution networks (P4GCN) to
enhance recommendation accuracy without requiring direct access to sensitive
social information. First, we introduce a Sandwich-Encryption module to ensure
comprehensive data privacy during the collaborative computing process. Second,
we provide a thorough theoretical analysis of the privacy guarantees,
considering the participation of both curious and honest parties. Extensive
experiments on four real-world datasets demonstrate that P4GCN outperforms
state-of-the-art methods in terms of recommendation accuracy. The code is
available at https://github.com/WwZzz/P4GCN.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Unifying Economic and Language Models for Enhanced Sentiment Analysis of
  the Oil Market 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12473v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12473v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Himmet Kaplan, Ralf-Peter Mundani, Heiko Rölke, Albert Weichselbraun, Martin Tschudy
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Crude oil, a critical component of the global economy, has its prices
influenced by various factors such as economic trends, political events, and
natural disasters. Traditional prediction methods based on historical data have
their limits in forecasting, but recent advancements in natural language
processing bring new possibilities for event-based analysis. In particular,
Language Models (LM) and their advancement, the Generative Pre-trained
Transformer (GPT), have shown potential in classifying vast amounts of natural
language. However, these LMs often have difficulty with domain-specific
terminology, limiting their effectiveness in the crude oil sector. Addressing
this gap, we introduce CrudeBERT, a fine-tuned LM specifically for the crude
oil market. The results indicate that CrudeBERT's sentiment scores align more
closely with the WTI Futures curve and significantly enhance price predictions,
underscoring the crucial role of integrating economic principles into LMs.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Mitigating Dual Latent Confounding Biases in Recommender Systems 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12451v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12451v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jianfeng Deng, Qingfeng Chen, Debo Cheng, Jiuyong Li, Lin Liu, Xiaojing Du
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recommender systems are extensively utilised across various areas to predict
user preferences for personalised experiences and enhanced user engagement and
satisfaction. Traditional recommender systems, however, are complicated by
confounding bias, particularly in the presence of latent confounders that
affect both item exposure and user feedback. Existing debiasing methods often
fail to capture the complex interactions caused by latent confounders in
interaction data, especially when dual latent confounders affect both the user
and item sides. To address this, we propose a novel debiasing method that
jointly integrates the Instrumental Variables (IV) approach and identifiable
Variational Auto-Encoder (iVAE) for Debiased representation learning in
Recommendation systems, referred to as IViDR. Specifically, IViDR leverages the
embeddings of user features as IVs to address confounding bias caused by latent
confounders between items and user feedback, and reconstructs the embedding of
items to obtain debiased interaction data. Moreover, IViDR employs an
Identifiable Variational Auto-Encoder (iVAE) to infer identifiable
representations of latent confounders between item exposure and user feedback
from both the original and debiased interaction data. Additionally, we provide
theoretical analyses of the soundness of using IV and the identifiability of
the latent representations. Extensive experiments on both synthetic and
real-world datasets demonstrate that IViDR outperforms state-of-the-art models
in reducing bias and providing reliable recommendations.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ QUIDS: Query Intent Generation via Dual Space Modeling 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12400v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12400v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yumeng Wang, Xiuying Chen, Suzan Verberne
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Query understanding is a crucial component of Information Retrieval (IR),
aimed at identifying the underlying search intent of textual queries. However,
most existing approaches oversimplify this task into query classification or
clustering, which fails to fully capture the nuanced intent behind the query.
In this paper, we address the task of query intent generation: to automatically
generate detailed and precise intent descriptions for search queries using
relevant and irrelevant documents given a query. These intent descriptions can
help users understand why the search engine considered the top-ranked documents
relevant, and provide more transparency to the retrieval process. We propose a
dual-space model that uses semantic relevance and irrelevance information in
the returned documents to explain the understanding of the query intent.
Specifically, in the encoding process, we project, separate, and distinguish
relevant and irrelevant documents in the representation space. Then, we
introduce a semantic decoupling model in the novel disentangling space, where
the semantics of irrelevant information are removed from the relevant space,
ensuring that only the essential and relevant intent is captured. This process
refines the understanding of the query and provides more accurate explanations
for the search results. Experiments on benchmark data demonstrate that our
methods produce high-quality query intent descriptions, outperforming existing
methods for this task, as well as state-of-the-art query-based summarization
methods. A token-level visualization of attention scores reveals that our model
effectively reduces the focus on irrelevant intent topics. Our findings open up
promising research and application directions for query intent generation,
particularly in exploratory search.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ REFINE on Scarce Data: Retrieval Enhancement through Fine-Tuning via
  Model Fusion of Embedding Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12890v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12890v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ambuje Gupta, Mrinal Rawat, Andreas Stolcke, Roberto Pieraccini
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Retrieval augmented generation (RAG) pipelines are commonly used in tasks
such as question-answering (QA), relying on retrieving relevant documents from
a vector store computed using a pretrained embedding model. However, if the
retrieved context is inaccurate, the answers generated using the large language
model (LLM) may contain errors or hallucinations. Although pretrained embedding
models have advanced, adapting them to new domains remains challenging.
Fine-tuning is a potential solution, but industry settings often lack the
necessary fine-tuning data. To address these challenges, we propose REFINE, a
novel technique that generates synthetic data from available documents and then
uses a model fusion approach to fine-tune embeddings for improved retrieval
performance in new domains, while preserving out-of-domain capability. We
conducted experiments on the two public datasets: SQUAD and RAG-12000 and a
proprietary TOURISM dataset. Results demonstrate that even the standard
fine-tuning with the proposed data augmentation technique outperforms the
vanilla pretrained model. Furthermore, when combined with model fusion, the
proposed approach achieves superior performance, with a 5.76% improvement in
recall on the TOURISM dataset, and 6.58 % and 0.32% enhancement on SQUAD and
RAG-12000 respectively.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted in AJCAI'24</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Multi-Cause Deconfounding for Recommender Systems with Latent
  Confounders 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12366v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12366v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zhirong Huang, Shichao Zhang, Debo Cheng, Jiuyong Li, Lin Liu, Guixian Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In recommender systems, various latent confounding factors (e.g., user social
environment and item public attractiveness) can affect user behavior, item
exposure, and feedback in distinct ways. These factors may directly or
indirectly impact user feedback and are often shared across items or users,
making them multi-cause latent confounders. However, existing methods typically
fail to account for latent confounders between users and their feedback, as
well as those between items and user feedback simultaneously. To address the
problem of multi-cause latent confounders, we propose a multi-cause
deconfounding method for recommender systems with latent confounders (MCDCF).
MCDCF leverages multi-cause causal effect estimation to learn substitutes for
latent confounders associated with both users and items, using user behaviour
data. Specifically, MCDCF treats the multiple items that users interact with
and the multiple users that interact with items as treatment variables,
enabling it to learn substitutes for the latent confounders that influence the
estimation of causality between users and their feedback, as well as between
items and user feedback. Additionally, we theoretically demonstrate the
soundness of our MCDCF method. Extensive experiments on three real-world
datasets demonstrate that our MCDCF method effectively recovers latent
confounders related to users and items, reducing bias and thereby improving
recommendation accuracy.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Comprehending Knowledge Graphs with Large Language Models for
  Recommender Systems 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12229v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12229v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ziqiang Cui, Yunpeng Weng, Xing Tang, Fuyuan Lyu, Dugang Liu, Xiuqiang He, Chen Ma
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recently, the introduction of knowledge graphs (KGs) has significantly
advanced recommender systems by facilitating the discovery of potential
associations between items. However, existing methods still face several
limitations. First, most KGs suffer from missing facts or limited scopes. This
can lead to biased knowledge representations, thereby constraining the model's
performance. Second, existing methods typically convert textual information
into IDs, resulting in the loss of natural semantic connections between
different items. Third, existing methods struggle to capture high-order
relationships in global KGs due to their inefficient layer-by-layer information
propagation mechanisms, which are prone to introducing significant noise. To
address these limitations, we propose a novel method called CoLaKG, which
leverages large language models (LLMs) for knowledge-aware recommendation. The
extensive world knowledge and remarkable reasoning capabilities of LLMs enable
them to supplement KGs. Additionally, the strong text comprehension abilities
of LLMs allow for a better understanding of semantic information. Based on
this, we first extract subgraphs centered on each item from the KG and convert
them into textual inputs for the LLM. The LLM then outputs its comprehension of
these item-centered subgraphs, which are subsequently transformed into semantic
embeddings. Furthermore, to utilize the global information of the KG, we
construct an item-item graph using these semantic embeddings, which can
directly capture higher-order associations between items. Both the semantic
embeddings and the structural information from the item-item graph are
effectively integrated into the recommendation model through our designed
representation alignment and neighbor augmentation modules. Extensive
experiments on four real-world datasets demonstrate the superiority of our
method.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Triple Modality Fusion: Aligning Visual, Textual, and Graph Data with
  Large Language Models for Multi-Behavior Recommendations 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12228v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12228v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Luyi Ma, Xiaohan Li, Zezhong Fan, Jianpeng Xu, Jason Cho, Praveen Kanumala, Kaushiki Nag, Sushant Kumar, Kannan Achan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Integrating diverse data modalities is crucial for enhancing the performance
of personalized recommendation systems. Traditional models, which often rely on
singular data sources, lack the depth needed to accurately capture the
multifaceted nature of item features and user behaviors. This paper introduces
a novel framework for multi-behavior recommendations, leveraging the fusion of
triple-modality, which is visual, textual, and graph data through alignment
with large language models (LLMs). By incorporating visual information, we
capture contextual and aesthetic item characteristics; textual data provides
insights into user interests and item features in detail; and graph data
elucidates relationships within the item-behavior heterogeneous graphs. Our
proposed model called Triple Modality Fusion (TMF) utilizes the power of LLMs
to align and integrate these three modalities, achieving a comprehensive
representation of user behaviors. The LLM models the user's interactions
including behaviors and item features in natural languages. Initially, the LLM
is warmed up using only natural language-based prompts. We then devise the
modality fusion module based on cross-attention and self-attention mechanisms
to integrate different modalities from other models into the same embedding
space and incorporate them into an LLM. Extensive experiments demonstrate the
effectiveness of our approach in improving recommendation accuracy. Further
ablation studies validate the effectiveness of our model design and benefits of
the TMF.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ AT-RAG: An Adaptive RAG Model Enhancing Query Efficiency with Topic
  Filtering and Iterative Reasoning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12886v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12886v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mohammad Reza Rezaei, Maziar Hafezi, Amit Satpathy, Lovell Hodge, Ebrahim Pourjafari
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent advancements in QA with LLM, like GPT-4, have shown limitations in
handling complex multi-hop queries. We propose AT-RAG, a novel multistep RAG
incorporating topic modeling for efficient document retrieval and reasoning.
Using BERTopic, our model dynamically assigns topics to queries, improving
retrieval accuracy and efficiency. We evaluated AT-RAG on multihop benchmark
datasets QA and a medical case study QA. Results show significant improvements
in correctness, completeness, and relevance compared to existing methods.
AT-RAG reduces retrieval time while maintaining high precision, making it
suitable for general tasks QA and complex domain-specific challenges such as
medical QA. The integration of topic filtering and iterative reasoning enables
our model to handle intricate queries efficiently, which makes it suitable for
applications that require nuanced information retrieval and decision-making.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ LitSearch: A Retrieval Benchmark for Scientific Literature Search <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.18940v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.18940v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Anirudh Ajith, Mengzhou Xia, Alexis Chevalier, Tanya Goyal, Danqi Chen, Tianyu Gao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Literature search questions, such as "Where can I find research on the
evaluation of consistency in generated summaries?" pose significant challenges
for modern search engines and retrieval systems. These questions often require
a deep understanding of research concepts and the ability to reason across
entire articles. In this work, we introduce LitSearch, a retrieval benchmark
comprising 597 realistic literature search queries about recent ML and NLP
papers. LitSearch is constructed using a combination of (1) questions generated
by GPT-4 based on paragraphs containing inline citations from research papers
and (2) questions manually written by authors about their recently published
papers. All LitSearch questions were manually examined or edited by experts to
ensure high quality. We extensively benchmark state-of-the-art retrieval models
and also evaluate two LLM-based reranking pipelines. We find a significant
performance gap between BM25 and state-of-the-art dense retrievers, with a
24.8% absolute difference in recall@5. The LLM-based reranking strategies
further improve the best-performing dense retriever by 4.4%. Additionally,
commercial search engines and research tools like Google Search perform poorly
on LitSearch, lagging behind the best dense retriever by up to 32 recall
points. Taken together, these results show that LitSearch is an informative new
testbed for retrieval systems while catering to a real-world use case.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by EMNLP 2024. Dataset and code are available at
  https://github.com/princeton-nlp/LitSearch</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ <span class="highlight-title">Prompt</span>DSI: <span class="highlight-title">Prompt</span>-based Rehearsal-free Instance-wise Incremental
  Learning for Document Retrieval 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.12593v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.12593v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Tuan-Luc Huynh, Thuy-Trang Vu, Weiqing Wang, Yinwei Wei, Trung Le, Dragan Gasevic, Yuan-Fang Li, Thanh-Toan Do
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Differentiable Search Index (DSI) utilizes Pre-trained Language Models (PLMs)
for efficient document retrieval without relying on external indexes. However,
DSI needs full re-training to handle updates in dynamic corpora, causing
significant computational inefficiencies. We introduce PromptDSI, a
prompt-based rehearsal-free approach for instance-wise incremental learning
document retrieval. PromptDSI attaches prompts to the frozen PLM's encoder of
DSI, leveraging its powerful representation to efficiently index new corpora
while maintaining a balance between stability and plasticity. We eliminate the
initial forward pass of prompt-based continual learning methods that doubles
training and inference time. Moreover, we propose a topic-aware prompt pool
that employs neural topic embeddings as fixed keys. This strategy ensures
diverse and effective prompt usage, addressing the challenge of parameter
underutilization caused by the collapse of the query-key matching mechanism.
Our empirical evaluations demonstrate that BERT-based PromptDSI matches IncDSI
in managing forgetting while improving new corpora performance by more than 4%
Hits@10 on NQ320k and upto 3% MRR@10 on MS MARCO 300k.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>20 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ DIRAS: Efficient LLM Annotation of Document Relevance in Retrieval
  Augmented Generation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.14162v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.14162v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jingwei Ni, Tobias Schimanski, Meihong Lin, Mrinmaya Sachan, Elliott Ash, Markus Leippold
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Retrieval Augmented Generation (RAG) is widely employed to ground responses
to queries on domain-specific documents. But do RAG implementations leave out
important information when answering queries that need an integrated analysis
of information (e.g., Tell me good news in the stock market today.)? To address
these concerns, RAG developers need to annotate information retrieval (IR) data
for their domain of interest, which is challenging because (1) domain-specific
queries usually need nuanced definitions of relevance beyond shallow semantic
relevance; and (2) human or GPT-4 annotation is costly and cannot cover all
(query, document) pairs (i.e., annotation selection bias), thus harming the
effectiveness in evaluating IR recall. To address these challenges, we propose
DIRAS (Domain-specific Information Retrieval Annotation with Scalability), a
manual-annotation-free schema that fine-tunes open-sourced LLMs to consider
nuanced relevance definition and annotate (partial) relevance labels with
calibrated relevance scores. Extensive evaluation shows that DIRAS enables
smaller (8B) LLMs to achieve GPT-4-level performance on annotating and ranking
unseen (query, document) pairs, and is helpful for real-world RAG development.
All code, LLM generations, and human annotations can be found in
\url{https://github.com/EdisonNi-hku/DIRAS}.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ FLEX: Expert-level False-Less EXecution Metric for Reliable Text-to-SQL
  Benchmark 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.19014v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.19014v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Heegyu Kim, Taeyang Jeon, Seunghwan Choi, Seungtaek Choi, Hyunsouk Cho
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Text-to-SQL systems have become crucial for translating natural language into
SQL queries in various industries, enabling non-technical users to perform
complex data operations. The need for accurate evaluation methods has increased
as these systems have grown more sophisticated. However, the Execution Accuracy
(EX), the most prevalent evaluation metric, still shows many false positives
and negatives. Thus, this paper introduces FLEX (False-Less EXecution), a novel
approach to evaluating text-to-SQL systems using large language models (LLMs)
to emulate human expert-level evaluation of SQL queries. Our metric improves
agreement with human experts (from 62 to 87.04 in Cohen's kappa) with
comprehensive context and sophisticated criteria. Our extensive experiments
yield several key insights: (1) Models' performance increases by over 2.6
points on average, substantially affecting rankings on Spider and BIRD
benchmarks; (2) The underestimation of models in EX primarily stems from
annotation quality issues; and (3) Model performance on particularly
challenging questions tends to be overestimated. This work contributes to a
more accurate and nuanced evaluation of text-to-SQL systems, potentially
reshaping our understanding of state-of-the-art performance in this field.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>preprint, under review</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ A Practice-Friendly LLM-Enhanced Paradigm with Preference Parsing for
  Sequential Recommendation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.00333v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.00333v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Dugang Liu, Shenxian Xian, Xiaolin Lin, Xiaolian Zhang, Hong Zhu, Yuan Fang, Zhen Chen, Zhong Ming
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The training paradigm integrating large language models (LLM) is gradually
reshaping sequential recommender systems (SRS) and has shown promising results.
However, most existing LLM-enhanced methods rely on rich textual information on
the item side and instance-level supervised fine-tuning (SFT) to inject
collaborative information into LLM, which is inefficient and limited in many
applications. To alleviate these problems, this paper proposes a
practice-friendly LLM-enhanced paradigm with preference parsing (P2Rec) for
SRS. Specifically, in the information reconstruction stage, we design a new
user-level SFT task for collaborative information injection with the assistance
of a pre-trained SRS model, which is more efficient and compatible with limited
text information. Our goal is to let LLM learn to reconstruct a corresponding
prior preference distribution from each user's interaction sequence, where LLM
needs to effectively parse the latent category of each item and the
relationship between different items to accomplish this task. In the
information augmentation stage, we feed each item into LLM to obtain a set of
enhanced embeddings that combine collaborative information and LLM inference
capabilities. These embeddings can then be used to help train various future
SRS models. Finally, we verify the effectiveness and efficiency of our TSLRec
on three SRS benchmark datasets.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Knowledge Circuits in <span class="highlight-title">Pretrain</span>ed <span class="highlight-title">Transformer</span>s <span class="chip">NeurIPS 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.17969v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.17969v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yunzhi Yao, Ningyu Zhang, Zekun Xi, Mengru Wang, Ziwen Xu, Shumin Deng, Huajun Chen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The remarkable capabilities of modern large language models are rooted in
their vast repositories of knowledge encoded within their parameters, enabling
them to perceive the world and engage in reasoning. The inner workings of how
these models store knowledge have long been a subject of intense interest and
investigation among researchers. To date, most studies have concentrated on
isolated components within these models, such as the Multilayer Perceptrons and
attention head. In this paper, we delve into the computation graph of the
language model to uncover the knowledge circuits that are instrumental in
articulating specific knowledge. The experiments, conducted with GPT2 and
TinyLLAMA, have allowed us to observe how certain information heads, relation
heads, and Multilayer Perceptrons collaboratively encode knowledge within the
model. Moreover, we evaluate the impact of current knowledge editing techniques
on these knowledge circuits, providing deeper insights into the functioning and
constraints of these editing methodologies. Finally, we utilize knowledge
circuits to analyze and interpret language model behaviors such as
hallucinations and in-context learning. We believe the knowledge circuits hold
potential for advancing our understanding of Transformers and guiding the
improved design of knowledge editing. Code and data are available in
https://github.com/zjunlp/KnowledgeCircuits.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>NeurIPS 2024, 32 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ $\textit{lucie}$: An Improved Python Package for Loading <span class="highlight-title">Dataset</span>s from
  the UCI Machine Learning Repository 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.09119v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.09119v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Kenneth Ge, Phuc Nguyen, Ramy Arnaout
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The University of California--Irvine (UCI) Machine Learning (ML) Repository
(UCIMLR) is consistently cited as one of the most popular dataset repositories,
hosting hundreds of high-impact datasets. However, a significant portion,
including 28.4% of the top 250, cannot be imported via the $\textit{ucimlrepo}$
package that is provided and recommended by the UCIMLR website. Instead, they
are hosted as .zip files, containing nonstandard formats that are difficult to
import without additional ad hoc processing. To address this issue, here we
present $\textit{lucie}$ -- $\underline{l}oad$ $\underline{U}niversity$
$\underline{C}alifornia$ $\underline{I}rvine$ $\underline{e}xamples$ -- a
utility that automatically determines the data format and imports many of these
previously non-importable datasets, while preserving as much of a tabular data
structure as possible. $\textit{lucie}$ was designed using the top 100 most
popular datasets and benchmarked on the next 130, where it resulted in a
success rate of 95.4% vs. 73.1% for $\textit{ucimlrepo}$. $\textit{lucie}$ is
available as a Python package on PyPI with 98% code coverage.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>5 pages, 3 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Beyond Inter-Item Relations: Dynamic Adaption for Enhancing LLM-Based
  Sequential Recommendation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2408.07427v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2408.07427v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        CanYi Liu, Wei Li,  Youchen,  Zhang, Hui Li, Rongrong Ji
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Sequential recommender systems (SRS) predict the next items that users may
prefer based on user historical interaction sequences. Inspired by the rise of
large language models (LLMs) in various AI applications, there is a surge of
work on LLM-based SRS. Despite their attractive performance, existing LLM-based
SRS still exhibit some limitations, including neglecting intra-item relations,
ignoring long-term collaborative knowledge and using inflexible architecture
designs for adaption. To alleviate these issues, we propose an LLM-based
sequential recommendation model named DARec. Built on top of coarse-grained
adaption for capturing inter-item relations, DARec is further enhanced with (1)
context masking that models intra-item relations to help LLM better understand
token and item semantics in the context of SRS, (2) collaborative knowledge
injection that helps LLM incorporate long-term collaborative knowledge, and (3)
a dynamic adaption mechanism that uses Bayesian optimization to flexibly choose
layer-wise adapter architectures in order to better incorporate different
sequential information. Extensive experiments demonstrate that DARec can
effectively handle sequential recommendation in a dynamic and adaptive manner.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>11 pages, 14 figures</span>
                                        </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
            <article>
                <details>
                    <Summary>
                        Multimedia <span class="chip" style="font-size: 60%">7</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Self-Comparison for <span class="highlight-title">Dataset</span>-Level Membership Inference in Large
  (Vision-)Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.13088v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.13088v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jie Ren, Kangrui Chen, Chen Chen, Vikash Sehwag, Yue Xing, Jiliang Tang, Lingjuan Lyu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large Language Models (LLMs) and Vision-Language Models (VLMs) have made
significant advancements in a wide range of natural language processing and
vision-language tasks. Access to large web-scale datasets has been a key factor
in their success. However, concerns have been raised about the unauthorized use
of copyrighted materials and potential copyright infringement. Existing
methods, such as sample-level Membership Inference Attacks (MIA) and
distribution-based dataset inference, distinguish member data (data used for
training) and non-member data by leveraging the common observation that models
tend to memorize and show greater confidence in member data. Nevertheless,
these methods face challenges when applied to LLMs and VLMs, such as the
requirement for ground-truth member data or non-member data that shares the
same distribution as the test data. In this paper, we propose a novel
dataset-level membership inference method based on Self-Comparison. We find
that a member prefix followed by a non-member suffix (paraphrased from a member
suffix) can further trigger the model's memorization on training data. Instead
of directly comparing member and non-member data, we introduce paraphrasing to
the second half of the sequence and evaluate how the likelihood changes before
and after paraphrasing. Unlike prior approaches, our method does not require
access to ground-truth member data or non-member data in identical
distribution, making it more practical. Extensive experiments demonstrate that
our proposed method outperforms traditional MIA and dataset inference
techniques across various datasets and models, including including public
models, fine-tuned models, and API-based commercial models.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ MuVi: Video-to-Music Generation with Semantic Alignment and Rhythmic
  Synchronization 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12957v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12957v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ruiqi Li, Siqi Zheng, Xize Cheng, Ziang Zhang, Shengpeng Ji, Zhou Zhao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Generating music that aligns with the visual content of a video has been a
challenging task, as it requires a deep understanding of visual semantics and
involves generating music whose melody, rhythm, and dynamics harmonize with the
visual narratives. This paper presents MuVi, a novel framework that effectively
addresses these challenges to enhance the cohesion and immersive experience of
audio-visual content. MuVi analyzes video content through a specially designed
visual adaptor to extract contextually and temporally relevant features. These
features are used to generate music that not only matches the video's mood and
theme but also its rhythm and pacing. We also introduce a contrastive
music-visual pre-training scheme to ensure synchronization, based on the
periodicity nature of music phrases. In addition, we demonstrate that our
flow-matching-based music generator has in-context learning ability, allowing
us to control the style and genre of the generated music. Experimental results
show that MuVi demonstrates superior performance in both audio quality and
temporal synchronization. The generated music video samples are available at
https://muvi-v2m.github.io.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Working in progress</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Embedding an Ethical Mind: Aligning Text-to-Image Synthesis via
  Lightweight Value Optimization 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12700v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12700v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xingqi Wang, Xiaoyuan Yi, Xing Xie, Jia Jia
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent advancements in diffusion models trained on large-scale data have
enabled the generation of indistinguishable human-level images, yet they often
produce harmful content misaligned with human values, e.g., social bias, and
offensive content. Despite extensive research on Large Language Models (LLMs),
the challenge of Text-to-Image (T2I) model alignment remains largely
unexplored. Addressing this problem, we propose LiVO (Lightweight Value
Optimization), a novel lightweight method for aligning T2I models with human
values. LiVO only optimizes a plug-and-play value encoder to integrate a
specified value principle with the input prompt, allowing the control of
generated images over both semantics and values. Specifically, we design a
diffusion model-tailored preference optimization loss, which theoretically
approximates the Bradley-Terry model used in LLM alignment but provides a more
flexible trade-off between image quality and value conformity. To optimize the
value encoder, we also develop a framework to automatically construct a
text-image preference dataset of 86k (prompt, aligned image, violating image,
value principle) samples. Without updating most model parameters and through
adaptive value selection from the input prompt, LiVO significantly reduces
harmful outputs and achieves faster convergence, surpassing several strong
baselines and taking an initial step towards ethically aligned T2I models.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by ACM Multimedia 2024. The dataset and code can be found at
  https://github.com/achernarwang/LiVO</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Rethinking Bjøntegaard Delta for Compression Efficiency Evaluation:
  Are We Calculating It Precisely and Reliably? 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12220v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12220v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xinyu Hang, Shenpeng Song, Zhimeng Huang, Chuanmin Jia, Siwei Ma, Wen Gao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  For decades, the Bj{\o}ntegaard Delta (BD) has been the metric for evaluating
codec Rate-Distortion (R-D) performance. Yet, in most studies, BD is determined
using just 4-5 R-D data points, could this be sufficient? As codecs and quality
metrics advance, does the conventional BD estimation still hold up? Crucially,
are the performance improvements of new codecs and tools genuine, or merely
artifacts of estimation flaws? This paper addresses these concerns by
reevaluating BD estimation. We present a novel approach employing a
parameterized deep neural network to model R-D curves with high precision
across various metrics, accompanied by a comprehensive R-D dataset. This
approach both assesses the reliability of BD calculations and serves as a
precise BD estimator. Our findings advocate for the adoption of rigorous R-D
sampling and reliability metrics in future compression research to ensure the
validity and reliability of results.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ OmnixR: Evaluating Omni-modality Language Models on Reasoning across
  Modalities 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12219v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12219v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Lichang Chen, Hexiang Hu, Mingda Zhang, Yiwen Chen, Zifeng Wang, Yandong Li, Pranav Shyam, Tianyi Zhou, Heng Huang, Ming-Hsuan Yang, Boqing Gong
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We introduce OmnixR, an evaluation suite designed to benchmark SoTA
Omni-modality Language Models, such as GPT-4o and Gemini. Evaluating OLMs,
which integrate multiple modalities such as text, vision, and audio, presents
unique challenges. Particularly, the user message might often consist of
multiple modalities, such that OLMs have to establish holistic understanding
and reasoning across modalities to accomplish the task. Existing benchmarks are
limited to single modality or dual-modality tasks, overlooking comprehensive
multi-modal assessments of model reasoning. To address this, OmnixR offers two
evaluation variants: (1)synthetic subset: a synthetic dataset generated
automatically by translating text into multiple modalities--audio, images,
video, and hybrids (Omnify). (2)realistic subset: a real-world dataset,
manually curated and annotated by experts, for evaluating cross-modal reasoning
in natural settings. OmnixR presents a unique evaluation towards assessing OLMs
over a diverse mix of modalities, such as a question that involves video,
audio, and text, providing a rigorous cross-modal reasoning testbed unlike any
existing benchmarks. Our experiments find that all state-of-the-art OLMs
struggle with OmnixR questions that require integrating information from
multiple modalities to answer. Further analysis highlights differences in
reasoning behavior, underscoring the challenges of omni-modal AI alignment.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>19 pages, 6 figures, 12 tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Test-time adaptation for image compression with distribution
  regularization 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12191v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12191v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Kecheng Chen, Pingping Zhang, Tiexin Qin, Shiqi Wang, Hong Yan, Haoliang Li
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Current test- or compression-time adaptation image compression (TTA-IC)
approaches, which leverage both latent and decoder refinements as a two-step
adaptation scheme, have potentially enhanced the rate-distortion (R-D)
performance of learned image compression models on cross-domain compression
tasks, \textit{e.g.,} from natural to screen content images. However, compared
with the emergence of various decoder refinement variants, the latent
refinement, as an inseparable ingredient, is barely tailored to cross-domain
scenarios. To this end, we aim to develop an advanced latent refinement method
by extending the effective hybrid latent refinement (HLR) method, which is
designed for \textit{in-domain} inference improvement but shows noticeable
degradation of the rate cost in \textit{cross-domain} tasks. Specifically, we
first provide theoretical analyses, in a cue of marginalization approximation
from in- to cross-domain scenarios, to uncover that the vanilla HLR suffers
from an underlying mismatch between refined Gaussian conditional and hyperprior
distributions, leading to deteriorated joint probability approximation of
marginal distribution with increased rate consumption. To remedy this issue, we
introduce a simple Bayesian approximation-endowed \textit{distribution
regularization} to encourage learning a better joint probability approximation
in a plug-and-play manner. Extensive experiments on six in- and cross-domain
datasets demonstrate that our proposed method not only improves the R-D
performance compared with other latent refinement counterparts, but also can be
flexibly integrated into existing TTA-IC methods with incremental benefits.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Video-to-Audio Generation with Hidden Alignment 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.07464v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.07464v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Manjie Xu, Chenxing Li, Xinyi Tu, Yong Ren, Rilin Chen, Yu Gu, Wei Liang, Dong Yu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Generating semantically and temporally aligned audio content in accordance
with video input has become a focal point for researchers, particularly
following the remarkable breakthrough in text-to-video generation. In this
work, we aim to offer insights into the video-to-audio generation paradigm,
focusing on three crucial aspects: vision encoders, auxiliary embeddings, and
data augmentation techniques. Beginning with a foundational model built on a
simple yet surprisingly effective intuition, we explore various vision encoders
and auxiliary embeddings through ablation studies. Employing a comprehensive
evaluation pipeline that emphasizes generation quality and video-audio
synchronization alignment, we demonstrate that our model exhibits
state-of-the-art video-to-audio generation capabilities. Furthermore, we
provide critical insights into the impact of different data augmentation
methods on enhancing the generation framework's overall capacity. We showcase
possibilities to advance the challenge of generating synchronized audio from
semantic and temporal perspectives. We hope these insights will serve as a
stepping stone toward developing more realistic and accurate audio-visual
generation models.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>https://sites.google.com/view/vta-ldm</span>
                                        </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
    </section>
    <section class="day-container">
        <div class="date">
            <time datetime="2024-10-15T00:00:00Z">2024-10-15</time>
        </div>
            <article>
                <details>
                    <Summary>
                        Information Retrieval <span class="chip" style="font-size: 60%">16</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ GaVaMoE: Gaussian-Variational Gated Mixture of Experts for Explainable
  Recommendation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.11841v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.11841v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Fei Tang, Yongliang Shen, Hang Zhang, Zeqi Tan, Wenqi Zhang, Guiyang Hou, Kaitao Song, Weiming Lu, Yueting Zhuang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large language model-based explainable recommendation (LLM-based ER) systems
show promise in generating human-like explanations for recommendations.
However, they face challenges in modeling user-item collaborative preferences,
personalizing explanations, and handling sparse user-item interactions. To
address these issues, we propose GaVaMoE, a novel Gaussian-Variational Gated
Mixture of Experts framework for explainable recommendation. GaVaMoE introduces
two key components: (1) a rating reconstruction module that employs Variational
Autoencoder (VAE) with a Gaussian Mixture Model (GMM) to capture complex
user-item collaborative preferences, serving as a pre-trained multi-gating
mechanism; and (2) a set of fine-grained expert models coupled with the
multi-gating mechanism for generating highly personalized explanations. The VAE
component models latent factors in user-item interactions, while the GMM
clusters users with similar behaviors. Each cluster corresponds to a gate in
the multi-gating mechanism, routing user-item pairs to appropriate expert
models. This architecture enables GaVaMoE to generate tailored explanations for
specific user types and preferences, mitigating data sparsity by leveraging
user similarities. Extensive experiments on three real-world datasets
demonstrate that GaVaMoE significantly outperforms existing methods in
explanation quality, personalization, and consistency. Notably, GaVaMoE
exhibits robust performance in scenarios with sparse user-item interactions,
maintaining high-quality explanations even for users with limited historical
data.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Adaptive Coordinators and <span class="highlight-title">Prompt</span>s on Heterogeneous Graphs for
  Cross-Domain Recommendations 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.11719v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.11719v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hengyu Zhang, Chunxu Shen, Xiangguo Sun, Jie Tan, Yu Rong, Chengzhi Piao, Hong Cheng, Lingling Yi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In the online digital world, users frequently engage with diverse items
across multiple domains (e.g., e-commerce platforms, streaming services, and
social media networks), forming complex heterogeneous interaction graphs.
Leveraging this multi-domain information can undoubtedly enhance the
performance of recommendation systems by providing more comprehensive user
insights and alleviating data sparsity in individual domains. However,
integrating multi-domain knowledge for the cross-domain recommendation is very
hard due to inherent disparities in user behavior and item characteristics and
the risk of negative transfer, where irrelevant or conflicting information from
the source domains adversely impacts the target domain's performance. To
address these challenges, we offer HAGO, a novel framework with
$\textbf{H}$eterogeneous $\textbf{A}$daptive $\textbf{G}$raph
co$\textbf{O}$rdinators, which dynamically integrate multi-domain graphs into a
cohesive structure by adaptively adjusting the connections between coordinators
and multi-domain graph nodes, thereby enhancing beneficial inter-domain
interactions while mitigating negative transfer effects. Additionally, we
develop a universal multi-domain graph pre-training strategy alongside HAGO to
collaboratively learn high-quality node representations across domains. To
effectively transfer the learned multi-domain knowledge to the target domain,
we design an effective graph prompting method, which incorporates pre-trained
embeddings with learnable prompts for the recommendation task. Our framework is
compatible with various graph-based models and pre-training techniques,
demonstrating broad applicability and effectiveness. Further experimental
results show that our solutions outperform state-of-the-art methods in
multi-domain recommendation scenarios and highlight their potential for
real-world applications.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Under review</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ CoActionGraphRec: Sequential Multi-Interest Recommendations Using
  Co-Action Graphs 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.11464v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.11464v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yi Sun, Yuri M. Brovman
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  There are unique challenges to developing item recommender systems for
e-commerce platforms like eBay due to sparse data and diverse user interests.
While rich user-item interactions are important, eBay's data sparsity exceeds
other e-commerce sites by an order of magnitude. To address this challenge, we
propose CoActionGraphRec (CAGR), a text based two-tower deep learning model
(Item Tower and User Tower) utilizing co-action graph layers. In order to
enhance user and item representations, a graph-based solution tailored to
eBay's environment is utilized. For the Item Tower, we represent each item
using its co-action items to capture collaborative signals in a co-action graph
that is fully leveraged by the graph neural network component. For the User
Tower, we build a fully connected graph of each user's behavior sequence, with
edges encoding pairwise relationships. Furthermore, an explicit interaction
module learns representations capturing behavior interactions. Extensive
offline and online A/B test experiments demonstrate the effectiveness of our
proposed approach and results show improved performance over state-of-the-art
methods on key metrics.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ LR-SQL: A Supervised Fine-Tuning Method for Text2SQL Tasks under
  Low-Resource Scenarios 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.11457v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.11457v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Wen Wuzhenghong, Zhang Yongpan, Pan Su, Sun Yuwei, Lu Pengwei, Ding Cheng
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large language models revolutionize Text2SQL through supervised fine-tuning,
yet a crucial limitation is overlooked: the complexity of databases leads to an
increased context length, consequently resulting in higher GPU memory demands
for model fine-tuning. To address this issue, we propose LR-SQL. LR-SQL
comprises two supervised fine-tuning models: the schema\_link model and the
SQL\_generation model, with the schema\_link model serving as the focal point
for streamlining the overall process. During the fine-tuning of the
schema\_link model, LR-SQL breaks down the complete database into flexible
combinations of tables with adjustable quantities, enabling the model to learn
the relationships within the entire database from these dispersed slices.
Furthermore, to enhance the model's ability to perceive the relationships among
various discrete slices during inference, LR-SQL trains the model's
Chain-of-Thought capability for this task. Experimental results demonstrate
that LR-SQL can reduce the total GPU memory usage by 40\% compared to existing
fine-tuning methods, while only losing 2\% of table prediction accuracy in
schema\_link task. For the overall Text2SQL task, the Execution Accuracy
decrease by 0.6\%.Our project is now available on
https://github.com/hongWin/LR-SQL
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>12pages, 4 figures,submitting to a journal</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Enhance Graph Alignment for Large Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.11370v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.11370v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Haitong Luo, Xuying Meng, Suhang Wang, Tianxiang Zhao, Fali Wang, Hanyun Cao, Yujun Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Graph-structured data is prevalent in the real world. Recently, due to the
powerful emergent capabilities, Large Language Models (LLMs) have shown
promising performance in modeling graphs. The key to effectively applying LLMs
on graphs is converting graph data into a format LLMs can comprehend.
Graph-to-token approaches are popular in enabling LLMs to process graph
information. They transform graphs into sequences of tokens and align them with
text tokens through instruction tuning, where self-supervised instruction
tuning helps LLMs acquire general knowledge about graphs, and supervised
fine-tuning specializes LLMs for the downstream tasks on graphs. Despite their
initial success, we find that existing methods have a misalignment between
self-supervised tasks and supervised downstream tasks, resulting in negative
transfer from self-supervised fine-tuning to downstream tasks. To address these
issues, we propose Graph Alignment Large Language Models (GALLM) to benefit
from aligned task templates. In the self-supervised tuning stage, we introduce
a novel text matching task using templates aligned with downstream tasks. In
the task-specific tuning stage, we propose two category prompt methods that
learn supervision information from additional explanation with further aligned
templates. Experimental evaluations on four datasets demonstrate substantial
improvements in supervised learning, multi-dataset generalizability, and
particularly in zero-shot capability, highlighting the model's potential as a
graph foundation model.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Under review</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Reducing Labeling Costs in Sentiment Analysis via Semi-Supervised
  Learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.11355v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.11355v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Minoo Jafarlou, Mario M. Kubek
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Labeling datasets is a noteworthy challenge in machine learning, both in
terms of cost and time. This research, however, leverages an efficient answer.
By exploring label propagation in semi-supervised learning, we can
significantly reduce the number of labels required compared to traditional
methods. We employ a transductive label propagation method based on the
manifold assumption for text classification. Our approach utilizes a
graph-based method to generate pseudo-labels for unlabeled data for the text
classification task, which are then used to train deep neural networks. By
extending labels based on cosine proximity within a nearest neighbor graph from
network embeddings, we combine unlabeled data into supervised learning, thereby
reducing labeling costs. Based on previous successes in other domains, this
study builds and evaluates this approach's effectiveness in sentiment analysis,
presenting insights into semi-supervised learning.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>12 pages, 7 figures, accepted at the 2024 8th International
  Conference on Natural Language Processing and Information Retrieval (NLPIR
  2024), Okayama, Japan, 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Sequential LLM Framework for Fashion Recommendation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.11327v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.11327v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Han Liu, Xianfeng Tang, Tianlang Chen, Jiapeng Liu, Indu Indu, Henry Peng Zou, Peng Dai, Roberto Fernandez Galan, Michael D Porter, Dongmei Jia, Ning Zhang, Lian Xiong
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The fashion industry is one of the leading domains in the global e-commerce
sector, prompting major online retailers to employ recommendation systems for
product suggestions and customer convenience. While recommendation systems have
been widely studied, most are designed for general e-commerce problems and
struggle with the unique challenges of the fashion domain. To address these
issues, we propose a sequential fashion recommendation framework that leverages
a pre-trained large language model (LLM) enhanced with recommendation-specific
prompts. Our framework employs parameter-efficient fine-tuning with extensive
fashion data and introduces a novel mix-up-based retrieval technique for
translating text into relevant product suggestions. Extensive experiments show
our proposed framework significantly enhances fashion recommendation
performance.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ On the Capacity of Citation Generation by Large Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.11217v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.11217v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Haosheng Qian, Yixing Fan, Ruqing Zhang, Jiafeng Guo
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Retrieval-augmented generation (RAG) appears as a promising method to
alleviate the "hallucination" problem in large language models (LLMs), since it
can incorporate external traceable resources for response generation. The
essence of RAG in combating the hallucination issue lies in accurately
attributing claims in responses to the corresponding retrieved documents.
However, most of existing works focus on improving the quality of generated
responses from the LLM, while largely overlooked its ability to attribute
sources accurately. In this study, we conduct a systematic analysis about the
capabilities of LLMs in generating citations within response generation, and
further introduce a novel method to enhance their citation generation
abilities. Specifically, we evaluate both the correctness and citation quality
for seven widely-used LLMs on two benchmark datasets. Meanwhile, we introduce
new citation evaluation metrics to eliminate the over-penalization of
unnecessary and excessive citations in existing metrics. Furthermore, we
propose a Generate-then-Refine method that completes relevant citations and
removes irrelevant ones without altering the response text. The results on
WebGLM-QA, ASQA and ELI5 datasets show that our method substantially improves
the quality of citations in responses generated by LLMs.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by CCIR 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Optimizing Encoder-Only <span class="highlight-title">Transformer</span>s for Session-Based Recommendation
  Systems 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.11150v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.11150v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Anis Redjdal, Luis Pinto, Michel Desmarais
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Session-based recommendation is the task of predicting the next item a user
will interact with, often without access to historical user data. In this work,
we introduce Sequential Masked Modeling, a novel approach for encoder-only
transformer architectures to tackle the challenges of single-session
recommendation. Our method combines data augmentation through window sliding
with a unique penultimate token masking strategy to capture sequential
dependencies more effectively. By enhancing how transformers handle session
data, Sequential Masked Modeling significantly improves next-item prediction
performance.
  We evaluate our approach on three widely-used datasets, Yoochoose 1/64,
Diginetica, and Tmall, comparing it to state-of-the-art single-session,
cross-session, and multi-relation approaches. The results demonstrate that our
Transformer-SMM models consistently outperform all models that rely on the same
amount of information, while even rivaling methods that have access to more
extensive user history. This study highlights the potential of encoder-only
transformers in session-based recommendation and opens the door for further
improvements.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ DyVo: Dynamic Vocabularies for Learned Sparse Retrieval with Entities 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.07722v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.07722v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Thong Nguyen, Shubham Chatterjee, Sean MacAvaney, Iain Mackie, Jeff Dalton, Andrew Yates
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Learned Sparse Retrieval (LSR) models use vocabularies from pre-trained
transformers, which often split entities into nonsensical fragments. Splitting
entities can reduce retrieval accuracy and limits the model's ability to
incorporate up-to-date world knowledge not included in the training data. In
this work, we enhance the LSR vocabulary with Wikipedia concepts and entities,
enabling the model to resolve ambiguities more effectively and stay current
with evolving knowledge. Central to our approach is a Dynamic Vocabulary (DyVo)
head, which leverages existing entity embeddings and an entity retrieval
component that identifies entities relevant to a query or document. We use the
DyVo head to generate entity weights, which are then merged with word piece
weights to create joint representations for efficient indexing and retrieval
using an inverted index. In experiments across three entity-rich document
ranking datasets, the resulting DyVo model substantially outperforms
state-of-the-art baselines.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>https://github.com/thongnt99/DyVo</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ GOVERN: Gradient Orientation Vote Ensemble for Multi-Teacher Reinforced
  Distillation <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.03764v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.03764v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Wenjie Zhou, Zhenxin Ding, Xiaodong Zhang, Haibo Shi, Junfeng Wang, Dawei Yin
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Pre-trained language models have become an integral component of
question-answering systems, achieving remarkable performance. However, for
practical deployment, it is crucial to perform knowledge distillation to
maintain high performance while operating under computational constraints. In
this paper, we address a key question: given the importance of unsupervised
distillation for student model performance, how can knowledge from multiple
teacher models be effectively ensemble during this stage without the guidance
of labels? We propose a novel algorithm, GOVERN, to tackle this issue. GOVERN
has demonstrated significant improvements in both offline and online
experiments, enabling the student model to achieve results comparable to that
of teacher ensembles. Our experiments show that GOVERN remarkably requires a
mere 1\% of the ensemble method's inference budget to achieve 99.5\% of
performance. The proposed algorithm has been successfully deployed in a
real-world commercial question-answering system, demonstrating its real-world
applicability.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by EMNLP 2024 Industry Track</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ DISCO: A Hierarchical Disentangled Cognitive Diagnosis Framework for
  Interpretable Job Recommendation <span class="chip">ICDM 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.07671v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.07671v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xiaoshan Yu, Chuan Qin, Qi Zhang, Chen Zhu, Haiping Ma, Xingyi Zhang, Hengshu Zhu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The rapid development of online recruitment platforms has created
unprecedented opportunities for job seekers while concurrently posing the
significant challenge of quickly and accurately pinpointing positions that
align with their skills and preferences. Job recommendation systems have
significantly alleviated the extensive search burden for job seekers by
optimizing user engagement metrics, such as clicks and applications, thus
achieving notable success. In recent years, a substantial amount of research
has been devoted to developing effective job recommendation models, primarily
focusing on text-matching based and behavior modeling based methods. While
these approaches have realized impressive outcomes, it is imperative to note
that research on the explainability of recruitment recommendations remains
profoundly unexplored. To this end, in this paper, we propose DISCO, a
hierarchical Disentanglement based Cognitive diagnosis framework, aimed at
flexibly accommodating the underlying representation learning model for
effective and interpretable job recommendations. Specifically, we first design
a hierarchical representation disentangling module to explicitly mine the
hierarchical skill-related factors implied in hidden representations of job
seekers and jobs. Subsequently, we propose level-aware association modeling to
enhance information communication and robust representation learning both
inter- and intra-level, which consists of the interlevel knowledge influence
module and the level-wise contrastive learning. Finally, we devise an
interaction diagnosis module incorporating a neural diagnosis function for
effectively modeling the multi-level recruitment interaction process between
job seekers and jobs, which introduces the cognitive measurement theory.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by ICDM 2024. 10 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Curriculum-scheduled Knowledge Distillation from Multiple <span class="highlight-title">Pre-train</span>ed
  Teachers for Multi-domain Sequential Recommendation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2401.00797v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2401.00797v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Wenqi Sun, Ruobing Xie, Junjie Zhang, Wayne Xin Zhao, Leyu Lin, Ji-Rong Wen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Pre-trained recommendation models (PRMs) have received increasing interest
recently. However, their intrinsically heterogeneous model structure, huge
model size and computation cost hinder their adoptions in practical recommender
systems. Hence, it is highly essential to explore how to use different
pre-trained recommendation models efficiently in real-world systems. In this
paper, we propose a novel curriculum-scheduled knowledge distillation from
multiple pre-trained teachers for multi-domain sequential recommendation,
called CKD-MDSR, which takes full advantages of different PRMs as multiple
teacher models to boost a small student recommendation model, integrating the
knowledge across multiple domains from PRMs. Specifically, CKD-MDSR first
adopts curriculum-scheduled user behavior sequence sampling and distills
informative knowledge jointly from the representative PRMs such as UniSRec and
Recformer. Then, the knowledge from the above PRMs are selectively integrated
into the student model in consideration of their confidence and consistency.
Finally, we verify the proposed method on multi-domain sequential
recommendation and further demonstrate its universality with multiple types of
student models, including feature interaction and graph based recommendation
models. Extensive experiments on five real-world datasets demonstrate the
effectiveness and efficiency of CKD-MDSR, which can be viewed as an efficient
shortcut using PRMs in real-world systems.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ CoRA: Collaborative Information Perception by Large Language Model's
  Weights for Recommendation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2408.10645v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2408.10645v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yuting Liu, Jinghao Zhang, Yizhou Dang, Yuliang Liang, Qiang Liu, Guibing Guo, Jianzhe Zhao, Xingwei Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Involving collaborative information in Large Language Models (LLMs) is a
promising technique for adapting LLMs for recommendation. Existing methods
achieve this by concatenating collaborative features with text tokens into a
unified sequence input and then fine-tuning to align these features with LLM's
input space. Although effective, in this work, we identify two limitations when
adapting LLMs to recommendation tasks, which hinder the integration of general
knowledge and collaborative information, resulting in sub-optimal
recommendation performance. (1) Fine-tuning LLM with recommendation data can
undermine its inherent world knowledge and fundamental competencies, which are
crucial for interpreting and inferring recommendation text. (2) Incorporating
collaborative features into textual prompts disrupts the semantics of the
original prompts, preventing LLM from generating appropriate outputs. In this
paper, we propose a new paradigm, CoRA (an acronym for Collaborative LoRA),
with a collaborative weights generator. Rather than input space alignment, this
method aligns collaborative information with LLM's parameter space,
representing them as incremental weights to update LLM's output. This way, LLM
perceives collaborative information without altering its general knowledge and
text inference capabilities. Specifically, we employ a collaborative filtering
model to extract user and item embeddings, converting them into collaborative
weights with low-rank properties through the collaborative weights generator.
We then merge the collaborative weights into LLM's weights, enabling LLM to
perceive the collaborative signals and generate personalized recommendations
without fine-tuning or extra collaborative tokens in prompts. Extensive
experiments confirm that CoRA effectively integrates collaborative information
into LLM, enhancing recommendation performance.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Recommenadation aided Caching using Combinatorial Multi-armed Bandits 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.00080v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.00080v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Pavamana K J, Chandramani Kishore Singh
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We study content caching with recommendations in a wireless network where the
users are connected through a base station equipped with a finite-capacity
cache. We assume a fixed set of contents with unknown user preferences and
content popularities. The base station can cache a subset of the contents and
can also recommend subsets of the contents to different users in order to
encourage them to request the recommended contents. Recommendations, depending
on their acceptability, can thus be used to increase cache hits. We first
assume that the users' recommendation acceptabilities are known and formulate
the cache hit optimization problem as a combinatorial multi-armed bandit
(CMAB). We propose a UCB-based algorithm to decide which contents to cache and
recommend and provide an upper bound on the regret of this algorithm.
Subsequently, we consider a more general scenario where the users'
recommendation acceptabilities are also unknown and propose another UCB-based
algorithm that learns these as well. We numerically demonstrate the performance
of our algorithms and compare these to state-of-the-art algorithms.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Spectral-Based Graph Neural Networks for Complementary Item
  Recommendation <span class="chip">AAAI-24</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2401.02130v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2401.02130v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Haitong Luo, Xuying Meng, Suhang Wang, Hanyun Cao, Weiyao Zhang, Yequan Wang, Yujun Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Modeling complementary relationships greatly helps recommender systems to
accurately and promptly recommend the subsequent items when one item is
purchased. Unlike traditional similar relationships, items with complementary
relationships may be purchased successively (such as iPhone and Airpods Pro),
and they not only share relevance but also exhibit dissimilarity. Since the two
attributes are opposites, modeling complementary relationships is challenging.
Previous attempts to exploit these relationships have either ignored or
oversimplified the dissimilarity attribute, resulting in ineffective modeling
and an inability to balance the two attributes. Since Graph Neural Networks
(GNNs) can capture the relevance and dissimilarity between nodes in the
spectral domain, we can leverage spectral-based GNNs to effectively understand
and model complementary relationships. In this study, we present a novel
approach called Spectral-based Complementary Graph Neural Networks (SComGNN)
that utilizes the spectral properties of complementary item graphs. We make the
first observation that complementary relationships consist of low-frequency and
mid-frequency components, corresponding to the relevance and dissimilarity
attributes, respectively. Based on this spectral observation, we design
spectral graph convolutional networks with low-pass and mid-pass filters to
capture the low-frequency and mid-frequency components. Additionally, we
propose a two-stage attention mechanism to adaptively integrate and balance the
two attributes. Experimental results on four e-commerce datasets demonstrate
the effectiveness of our model, with SComGNN significantly outperforming
existing baseline models.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by AAAI-24</span>
                                        </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
            <article>
                <details>
                    <Summary>
                        Multimedia <span class="chip" style="font-size: 60%">9</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Enabling Data-Driven and Empathetic Interactions: A Context-Aware 3D
  Virtual Agent in Mixed Reality for Enhanced Financial Customer Experience 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12051v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12051v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Cindy Xu, Mengyu Chen, Pranav Deshpande, Elvir Azanli, Runqing Yang, Joseph Ligman
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this paper, we introduce a novel system designed to enhance customer
service in the financial and retail sectors through a context-aware 3D virtual
agent, utilizing Mixed Reality (MR) and Vision Language Models (VLMs). Our
approach focuses on enabling data-driven and empathetic interactions that
ensure customer satisfaction by introducing situational awareness of the
physical location, personalized interactions based on customer profiles, and
rigorous privacy and security standards. We discuss our design considerations
critical for deployment in real-world customer service environments, addressing
challenges in user data management and sensitive information handling. We also
outline the system architecture and key features unique to banking and retail
environments. Our work demonstrates the potential of integrating MR and VLMs in
service industries, offering practical insights in customer service delivery
while maintaining high standards of security and personalization.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>to appear at 1st Workshop on Intelligent XR: Harnessing AI for
  Next-Generation XR User Experiences at International Symposium on Mixed and
  Augmented Reality (ISMAR) 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ LocoMotion: Learning Motion-Focused Video-Language Representations <span class="chip">ACCV 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12018v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12018v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hazel Doughty, Fida Mohammad Thoker, Cees G. M. Snoek
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper strives for motion-focused video-language representations.
Existing methods to learn video-language representations use spatial-focused
data, where identifying the objects and scene is often enough to distinguish
the relevant caption. We instead propose LocoMotion to learn from
motion-focused captions that describe the movement and temporal progression of
local object motions. We achieve this by adding synthetic motions to videos and
using the parameters of these motions to generate corresponding captions.
Furthermore, we propose verb-variation paraphrasing to increase the caption
variety and learn the link between primitive motions and high-level verbs. With
this, we are able to learn a motion-focused video-language representation.
Experiments demonstrate our approach is effective for a variety of downstream
tasks, particularly when limited data is available for fine-tuning. Code is
available: https://hazeldoughty.github.io/Papers/LocoMotion/
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>ACCV 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Improving Long-Text Alignment for Text-to-Image Diffusion Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.11817v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.11817v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Luping Liu, Chao Du, Tianyu Pang, Zehan Wang, Chongxuan Li, Dong Xu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The rapid advancement of text-to-image (T2I) diffusion models has enabled
them to generate unprecedented results from given texts. However, as text
inputs become longer, existing encoding methods like CLIP face limitations, and
aligning the generated images with long texts becomes challenging. To tackle
these issues, we propose LongAlign, which includes a segment-level encoding
method for processing long texts and a decomposed preference optimization
method for effective alignment training. For segment-level encoding, long texts
are divided into multiple segments and processed separately. This method
overcomes the maximum input length limits of pretrained encoding models. For
preference optimization, we provide decomposed CLIP-based preference models to
fine-tune diffusion models. Specifically, to utilize CLIP-based preference
models for T2I alignment, we delve into their scoring mechanisms and find that
the preference scores can be decomposed into two components: a text-relevant
part that measures T2I alignment and a text-irrelevant part that assesses other
visual aspects of human preference. Additionally, we find that the
text-irrelevant part contributes to a common overfitting problem during
fine-tuning. To address this, we propose a reweighting strategy that assigns
different weights to these two components, thereby reducing overfitting and
enhancing alignment. After fine-tuning $512 \times 512$ Stable Diffusion (SD)
v1.5 for about 20 hours using our method, the fine-tuned SD outperforms
stronger foundation models in T2I alignment, such as PixArt-$\alpha$ and
Kandinsky v2.2. The code is available at
https://github.com/luping-liu/LongAlign.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ MLLM can see? Dynamic Correction Decoding for Hallucination Mitigation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.11779v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.11779v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Chenxi Wang, Xiang Chen, Ningyu Zhang, Bozhong Tian, Haoming Xu, Shumin Deng, Huajun Chen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Multimodal Large Language Models (MLLMs) frequently exhibit hallucination
phenomena, but the underlying reasons remain poorly understood. In this paper,
we present an empirical analysis and find that, although MLLMs incorrectly
generate the objects in the final output, they are actually able to recognize
visual objects in the preceding layers. We speculate that this may be due to
the strong knowledge priors of the language model suppressing the visual
information, leading to hallucinations. Motivated by this, we propose a novel
dynamic correction decoding method for MLLMs (DeCo), which adaptively selects
the appropriate preceding layers and proportionally integrates knowledge into
the final layer to adjust the output logits. Note that DeCo is model agnostic
and can be seamlessly incorporated with various classic decoding strategies and
applied to different MLLMs. We evaluate DeCo on widely-used benchmarks,
demonstrating that it can reduce hallucination rates by a large margin compared
to baselines, highlighting its potential to mitigate hallucinations. Code is
available at https://github.com/zjunlp/DeCo.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Ongoing work</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Magnifier <span class="highlight-title">Prompt</span>: Tackling Multimodal Hallucination via Extremely Simple
  Instructions 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.11701v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.11701v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yuhan Fu, Ruobing Xie, Jiazhen Liu, Bangxiang Lan, Xingwu Sun, Zhanhui Kang, Xirong Li
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Hallucinations in multimodal large language models (MLLMs) hinder their
practical applications. To address this, we propose a Magnifier Prompt
(MagPrompt), a simple yet effective method to tackle hallucinations in MLLMs
via extremely simple instructions. MagPrompt is based on the following two key
principles, which guide the design of various effective prompts, demonstrating
robustness: (1) MLLMs should focus more on the image. (2) When there are
conflicts between the image and the model's inner knowledge, MLLMs should
prioritize the image. MagPrompt is training-free and can be applied to
open-source and closed-source models, such as GPT-4o and Gemini-pro. It
performs well across many datasets and its effectiveness is comparable or even
better than more complex methods like VCD. Furthermore, our prompt design
principles and experimental analyses provide valuable insights into multimodal
hallucination.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>9 pages, 13 tables, 4 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ On-the-fly Modulation for Balanced Multimodal Learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.11582v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.11582v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yake Wei, Di Hu, Henghui Du, Ji-Rong Wen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Multimodal learning is expected to boost model performance by integrating
information from different modalities. However, its potential is not fully
exploited because the widely-used joint training strategy, which has a uniform
objective for all modalities, leads to imbalanced and under-optimized uni-modal
representations. Specifically, we point out that there often exists modality
with more discriminative information, e.g., vision of playing football and
sound of blowing wind. They could dominate the joint training process,
resulting in other modalities being significantly under-optimized. To alleviate
this problem, we first analyze the under-optimized phenomenon from both the
feed-forward and the back-propagation stages during optimization. Then,
On-the-fly Prediction Modulation (OPM) and On-the-fly Gradient Modulation (OGM)
strategies are proposed to modulate the optimization of each modality, by
monitoring the discriminative discrepancy between modalities during training.
Concretely, OPM weakens the influence of the dominant modality by dropping its
feature with dynamical probability in the feed-forward stage, while OGM
mitigates its gradient in the back-propagation stage. In experiments, our
methods demonstrate considerable improvement across a variety of multimodal
tasks. These simple yet effective strategies not only enhance performance in
vanilla and task-oriented multimodal models, but also in more complex
multimodal tasks, showcasing their effectiveness and flexibility. The source
code is available at \url{https://github.com/GeWu-Lab/BML_TPAMI2024}.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by T-PAMI 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ VidCompress: Memory-Enhanced Temporal Compression for Video
  Understanding in Large Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.11417v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.11417v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xiaohan Lan, Yitian Yuan, Zequn Jie, Lin Ma
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Video-based multimodal large language models (Video-LLMs) possess significant
potential for video understanding tasks. However, most Video-LLMs treat videos
as a sequential set of individual frames, which results in insufficient
temporal-spatial interaction that hinders fine-grained comprehension and
difficulty in processing longer videos due to limited visual token capacity. To
address these challenges, we propose VidCompress, a novel Video-LLM featuring
memory-enhanced temporal compression. VidCompress employs a dual-compressor
approach: a memory-enhanced compressor captures both short-term and long-term
temporal relationships in videos and compresses the visual tokens using a
multiscale transformer with a memory-cache mechanism, while a text-perceived
compressor generates condensed visual tokens by utilizing Q-Former and
integrating temporal contexts into query embeddings with cross attention.
Experiments on several VideoQA datasets and comprehensive benchmarks
demonstrate that VidCompress efficiently models complex temporal-spatial
relations and significantly outperforms existing Video-LLMs.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>9 pages, 4 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ VIA: Unified Spatiotemporal Video Adaptation Framework for Global and
  Local Video Editing 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.12831v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.12831v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jing Gu, Yuwei Fang, Ivan Skorokhodov, Peter Wonka, Xinya Du, Sergey Tulyakov, Xin Eric Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Video editing is a cornerstone of digital media, from entertainment and
education to professional communication. However, previous methods often
overlook the necessity of comprehensively understanding both global and local
contexts, leading to inaccurate and inconsistent edits in the spatiotemporal
dimension, especially for long videos. In this paper, we introduce VIA, a
unified spatiotemporal Video Adaptation framework for global and local video
editing, pushing the limits of consistently editing minute-long videos. First,
to ensure local consistency within individual frames, we designed test-time
editing adaptation to adapt a pre-trained image editing model for improving
consistency between potential editing directions and the text instruction, and
adapt masked latent variables for precise local control. Furthermore, to
maintain global consistency over the video sequence, we introduce
spatiotemporal adaptation that recursively gather consistent attention
variables in key frames and strategically applies them across the whole
sequence to realize the editing effects. Extensive experiments demonstrate
that, compared to baseline methods, our VIA approach produces edits that are
more faithful to the source videos, more coherent in the spatiotemporal
context, and more precise in local control. More importantly, we show that VIA
can achieve consistent long video editing in minutes, unlocking the potential
for advanced video editing tasks over long video sequences.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>19 pages, 14 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ FineFake: A Knowledge-Enriched <span class="highlight-title">Dataset</span> for Fine-Grained Multi-Domain
  Fake News Detection 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2404.01336v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2404.01336v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ziyi Zhou, Xiaoming Zhang, Litian Zhang, Jiacheng Liu, Senzhang Wang, Zheng Liu, Xi Zhang, Chaozhuo Li, Philip S. Yu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Existing benchmarks for fake news detection have significantly contributed to
the advancement of models in assessing the authenticity of news content.
However, these benchmarks typically focus solely on news pertaining to a single
semantic topic or originating from a single platform, thereby failing to
capture the diversity of multi-domain news in real scenarios. In order to
understand fake news across various domains, the external knowledge and
fine-grained annotations are indispensable to provide precise evidence and
uncover the diverse underlying strategies for fabrication, which are also
ignored by existing benchmarks. To address this gap, we introduce a novel
multi-domain knowledge-enhanced benchmark with fine-grained annotations, named
\textbf{FineFake}. FineFake encompasses 16,909 data samples spanning six
semantic topics and eight platforms. Each news item is enriched with
multi-modal content, potential social context, semi-manually verified common
knowledge, and fine-grained annotations that surpass conventional binary
labels. Furthermore, we formulate three challenging tasks based on FineFake and
propose a knowledge-enhanced domain adaptation network. Extensive experiments
are conducted on FineFake under various scenarios, providing accurate and
reliable benchmarks for future endeavors. The entire FineFake project is
publicly accessible as an open-source repository at
\url{https://github.com/Accuser907/FineFake}.
</span>
                                    </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
    </section>
    <section class="day-container">
        <div class="date">
            <time datetime="2024-10-14T00:00:00Z">2024-10-14</time>
        </div>
            <article>
                <details>
                    <Summary>
                        Information Retrieval <span class="chip" style="font-size: 60%">23</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ SGUQ: Staged Graph Convolution Neural Network for Alzheimer's Disease
  Diagnosis using Multi-Omics Data 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.11046v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.11046v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Liang Tao, Yixin Xie, Jeffrey D Deng, Hui Shen, Hong-Wen Deng, Weihua Zhou, Chen Zhao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Alzheimer's disease (AD) is a chronic neurodegenerative disorder and the
leading cause of dementia, significantly impacting cost, mortality, and burden
worldwide. The advent of high-throughput omics technologies, such as genomics,
transcriptomics, proteomics, and epigenomics, has revolutionized the molecular
understanding of AD. Conventional AI approaches typically require the
completion of all omics data at the outset to achieve optimal AD diagnosis,
which are inefficient and may be unnecessary. To reduce the clinical cost and
improve the accuracy of AD diagnosis using multi-omics data, we propose a novel
staged graph convolutional network with uncertainty quantification (SGUQ). SGUQ
begins with mRNA and progressively incorporates DNA methylation and miRNA data
only when necessary, reducing overall costs and exposure to harmful tests.
Experimental results indicate that 46.23% of the samples can be reliably
predicted using only single-modal omics data (mRNA), while an additional 16.04%
of the samples can achieve reliable predictions when combining two omics data
types (mRNA + DNA methylation). In addition, the proposed staged SGUQ achieved
an accuracy of 0.858 on ROSMAP dataset, which outperformed existing methods
significantly. The proposed SGUQ can not only be applied to AD diagnosis using
multi-omics data but also has the potential for clinical decision-making using
multi-viewed data. Our implementation is publicly available at
https://github.com/chenzhao2023/multiomicsuncertainty.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>20 pages, 2 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ GraFPrint: A GNN-Based Approach for Audio Identification <span class="chip">ICASSP 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.10994v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.10994v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Aditya Bhattacharjee, Shubhr Singh, Emmanouil Benetos
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper introduces GraFPrint, an audio identification framework that
leverages the structural learning capabilities of Graph Neural Networks (GNNs)
to create robust audio fingerprints. Our method constructs a k-nearest neighbor
(k-NN) graph from time-frequency representations and applies max-relative graph
convolutions to encode local and global information. The network is trained
using a self-supervised contrastive approach, which enhances resilience to
ambient distortions by optimizing feature representation. GraFPrint
demonstrates superior performance on large-scale datasets at various levels of
granularity, proving to be both lightweight and scalable, making it suitable
for real-world applications with extensive reference databases.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Submitted to IEEE International Conference on Acoustics, Speech, and
  Signal Processing (ICASSP 2025)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Generating Model Parameters for Controlling: Parameter Diffusion for
  Controllable Multi-Task Recommendation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.10639v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.10639v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Chenglei Shen, Jiahao Zhao, Xiao Zhang, Weijie Yu, Ming He, Jianping Fan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Commercial recommender systems face the challenge that task requirements from
platforms or users often change dynamically (e.g., varying preferences for
accuracy or diversity). Ideally, the model should be re-trained after resetting
a new objective function, adapting to these changes in task requirements.
However, in practice, the high computational costs associated with retraining
make this process impractical for models already deployed to online
environments. This raises a new challenging problem: how to efficiently adapt
the learning model to different task requirements by controlling model
parameters after deployment, without the need for retraining. To address this
issue, we propose a novel controllable learning approach via Parameter
Diffusion for controllable multi-task Recommendation (PaDiRec), which allows
the customization and adaptation of recommendation model parameters to new task
requirements without retraining. Specifically, we first obtain the optimized
model parameters through adapter tunning based on the feasible task
requirements. Then, we utilize the diffusion model as a parameter generator,
employing classifier-free guidance in conditional training to learn the
distribution of optimized model parameters under various task requirements.
Finally, the diffusion model is applied to effectively generate model
parameters in a test-time adaptation manner given task requirements. As a
model-agnostic approach, PaDiRec can leverage existing recommendation models as
backbones to enhance their controllability. Extensive experiments on public
datasets and a dataset from a commercial app, indicate that PaDiRec can
effectively enhance controllability through efficient model parameter
generation. The code is released at
https://anonymous.4open.science/r/PaDiRec-DD13.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ VisRAG: Vision-based Retrieval-augmented Generation on Multi-modality
  Documents 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.10594v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.10594v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Shi Yu, Chaoyue Tang, Bokai Xu, Junbo Cui, Junhao Ran, Yukun Yan, Zhenghao Liu, Shuo Wang, Xu Han, Zhiyuan Liu, Maosong Sun
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Retrieval-augmented generation (RAG) is an effective technique that enables
large language models (LLMs) to utilize external knowledge sources for
generation. However, current RAG systems are solely based on text, rendering it
impossible to utilize vision information like layout and images that play
crucial roles in real-world multi-modality documents. In this paper, we
introduce VisRAG, which tackles this issue by establishing a vision-language
model (VLM)-based RAG pipeline. In this pipeline, instead of first parsing the
document to obtain text, the document is directly embedded using a VLM as an
image and then retrieved to enhance the generation of a VLM. Compared to
traditional text-based RAG, VisRAG maximizes the retention and utilization of
the data information in the original documents, eliminating the information
loss introduced during the parsing process. We collect both open-source and
synthetic data to train the retriever in VisRAG and explore a variety of
generation methods. Experiments demonstrate that VisRAG outperforms traditional
RAG in both the retrieval and generation stages, achieving a 25--39\%
end-to-end performance gain over traditional text-based RAG pipeline. Further
analysis reveals that VisRAG is effective in utilizing training data and
demonstrates strong generalization capability, positioning it as a promising
solution for RAG on multi-modality documents. Our code and data are available
at https://github.com/openbmb/visrag .
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Rethinking Legal Judgement Prediction in a Realistic Scenario in the Era
  of Large Language Models <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.10542v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.10542v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Shubham Kumar Nigam, Aniket Deroy, Subhankar Maity, Arnab Bhattacharya
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This study investigates judgment prediction in a realistic scenario within
the context of Indian judgments, utilizing a range of transformer-based models,
including InLegalBERT, BERT, and XLNet, alongside LLMs such as Llama-2 and
GPT-3.5 Turbo. In this realistic scenario, we simulate how judgments are
predicted at the point when a case is presented for a decision in court, using
only the information available at that time, such as the facts of the case,
statutes, precedents, and arguments. This approach mimics real-world
conditions, where decisions must be made without the benefit of hindsight,
unlike retrospective analyses often found in previous studies. For transformer
models, we experiment with hierarchical transformers and the summarization of
judgment facts to optimize input for these models. Our experiments with LLMs
reveal that GPT-3.5 Turbo excels in realistic scenarios, demonstrating robust
performance in judgment prediction. Furthermore, incorporating additional legal
information, such as statutes and precedents, significantly improves the
outcome of the prediction task. The LLMs also provide explanations for their
predictions. To evaluate the quality of these predictions and explanations, we
introduce two human evaluation metrics: Clarity and Linking. Our findings from
both automatic and human evaluations indicate that, despite advancements in
LLMs, they are yet to achieve expert-level performance in judgment prediction
and explanation tasks.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted on NLLP at EMNLP 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Advancing Academic Knowledge Retrieval via LLM-enhanced Representation
  Similarity Fusion <span class="chip">KDD</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.10455v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.10455v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Wei Dai, Peng Fu, Chunjing Gan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In an era marked by robust technological growth and swift information
renewal, furnishing researchers and the populace with top-tier, avant-garde
academic insights spanning various domains has become an urgent necessity. The
KDD Cup 2024 AQA Challenge is geared towards advancing retrieval models to
identify pertinent academic terminologies from suitable papers for scientific
inquiries. This paper introduces the LLM-KnowSimFuser proposed by Robo Space,
which wins the 2nd place in the competition. With inspirations drawed from the
superior performance of LLMs on multiple tasks, after careful analysis of the
provided datasets, we firstly perform fine-tuning and inference using
LLM-enhanced pre-trained retrieval models to introduce the tremendous language
understanding and open-domain knowledge of LLMs into this task, followed by a
weighted fusion based on the similarity matrix derived from the inference
results. Finally, experiments conducted on the competition datasets show the
superiority of our proposal, which achieved a score of 0.20726 on the final
leaderboard.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>The 2nd Place of KDD Cup 2024 OAG-Challenge AQA</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Medico: Towards Hallucination Detection and Correction with Multi-source
  Evidence Fusion <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.10408v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.10408v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xinping Zhao, Jindi Yu, Zhenyu Liu, Jifang Wang, Dongfang Li, Yibin Chen, Baotian Hu, Min Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  As we all know, hallucinations prevail in Large Language Models (LLMs), where
the generated content is coherent but factually incorrect, which inflicts a
heavy blow on the widespread application of LLMs. Previous studies have shown
that LLMs could confidently state non-existent facts rather than answering ``I
don't know''. Therefore, it is necessary to resort to external knowledge to
detect and correct the hallucinated content. Since manual detection and
correction of factual errors is labor-intensive, developing an automatic
end-to-end hallucination-checking approach is indeed a needful thing. To this
end, we present Medico, a Multi-source evidence fusion enhanced hallucination
detection and correction framework. It fuses diverse evidence from multiple
sources, detects whether the generated content contains factual errors,
provides the rationale behind the judgment, and iteratively revises the
hallucinated content. Experimental results on evidence retrieval (0.964 HR@5,
0.908 MRR@5), hallucination detection (0.927-0.951 F1), and hallucination
correction (0.973-0.979 approval rate) manifest the great potential of Medico.
A video demo of Medico can be found at https://youtu.be/RtsO6CSesBI.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>12 pages, 3 figures, 6 tables. Accepted by EMNLP 2024's demo track</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Collaborative filtering based on nonnegative/binary matrix factorization 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.10381v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.10381v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yukino Terui, Yuka Inoue, Yohei Hamakawa, Kosuke Tatsumura, Kazue Kudo
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Collaborative filtering generates recommendations based on user-item
similarities through rating data, which may involve numerous unrated items. To
predict scores for unrated items, matrix factorization techniques, such as
nonnegative matrix factorization (NMF), are often employed to predict scores
for unrated items. Nonnegative/binary matrix factorization (NBMF), which is an
extension of NMF, approximates a nonnegative matrix as the product of
nonnegative and binary matrices. Previous studies have employed NBMF for image
analysis where the data were dense. In this paper, we propose a modified NBMF
algorithm that can be applied to collaborative filtering where data are sparse.
In the modified method, unrated elements in a rating matrix are masked, which
improves the collaborative filtering performance. Utilizing a low-latency Ising
machine in NBMF is advantageous in terms of the computation time, making the
proposed method beneficial.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>12 pages, 7 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ BookWorm: A <span class="highlight-title">Dataset</span> for Character Description and Analysis <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.10372v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.10372v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Argyrios Papoudakis, Mirella Lapata, Frank Keller
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Characters are at the heart of every story, driving the plot and engaging
readers. In this study, we explore the understanding of characters in
full-length books, which contain complex narratives and numerous interacting
characters. We define two tasks: character description, which generates a brief
factual profile, and character analysis, which offers an in-depth
interpretation, including character development, personality, and social
context. We introduce the BookWorm dataset, pairing books from the Gutenberg
Project with human-written descriptions and analyses. Using this dataset, we
evaluate state-of-the-art long-context models in zero-shot and fine-tuning
settings, utilizing both retrieval-based and hierarchical processing for
book-length inputs. Our findings show that retrieval-based approaches
outperform hierarchical ones in both tasks. Additionally, fine-tuned models
using coreference-based retrieval produce the most factual descriptions, as
measured by fact- and entailment-based metrics. We hope our dataset,
experiments, and analysis will inspire further research in character-based
narrative understanding.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>30 pages, 2 figures, EMNLP 2024 Findings</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ A Hybrid Filtering for Micro-video Hashtag Recommendation using
  Graph-based Deep Neural Network 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.10367v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.10367v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Shubhi Bansal, Kushaan Gowda, Mohammad Zia Ur Rehman, Chandravardhan Singh Raghaw, Nagendra Kumar
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Due to the growing volume of user generated content, hashtags are employed as
topic indicators to manage content efficiently on social media platforms.
However, finding these vital topics is challenging in microvideos since they
contain substantial information in a short duration. Existing methods that
recommend hashtags for microvideos primarily focus on content and
personalization while disregarding relatedness among users. Moreover, the cold
start user issue prevails in hashtag recommendation systems. Considering the
above, we propose a hybrid filtering based MIcro-video haSHtag recommendatiON
MISHON technique to recommend hashtags for micro-videos. Besides content based
filtering, we employ user-based collaborative filtering to enhance
recommendations. Since hashtags reflect users topical interests, we find
similar users based on historical tagging behavior to model user relatedness.
We employ a graph-based deep neural network to model user to user, modality to
modality, and user to modality interactions. We then use refined modality
specific and user representations to recommend pertinent hashtags for
microvideos. The empirical results on three real world datasets demonstrate
that MISHON attains a comparative enhancement of 3.6, 2.8, and 6.5 reported in
percentage concerning the F1 score, respectively. Since cold start users exist
whose historical tagging information is unavailable, we also propose a content
and social influence based technique to model the relatedness of cold start
users with influential users. The proposed solution shows a relative
improvement of 15.8 percent in the F1 score over its content only counterpart.
These results show that the proposed framework mitigates the cold start user
problem.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Parenting: Optimizing Knowledge Selection of Retrieval-Augmented
  Language Models with Parameter Decoupling and Tailored Tuning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.10360v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.10360v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yongxin Xu, Ruizhe Zhang, Xinke Jiang, Yujie Feng, Yuzhen Xiao, Xinyu Ma, Runchuan Zhu, Xu Chu, Junfeng Zhao, Yasha Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Retrieval-Augmented Generation (RAG) offers an effective solution to the
issues faced by Large Language Models (LLMs) in hallucination generation and
knowledge obsolescence by incorporating externally retrieved knowledge.
However, due to potential conflicts between internal and external knowledge, as
well as retrieval noise, LLMs often struggle to effectively integrate external
evidence, leading to a decline in performance. Although existing methods
attempt to tackle these challenges, they often struggle to strike a balance
between model adherence and robustness, resulting in significant learning
variance. Inspired by human cognitive processes, we propose Parenting, a novel
framework that decouples adherence and robustness within the parameter space of
LLMs. Specifically, Parenting utilizes a key parameter mining method based on
forward activation gain to identify and isolate the crucial parameter units
that are strongly linked to adherence and robustness. Then, Parenting employs a
type-guided tailored tuning strategy, applying specific and appropriate
fine-tuning methods to parameter units representing different capabilities,
aiming to achieve a balanced enhancement of adherence and robustness. Extensive
experiments on various datasets and models validate the effectiveness and
generalizability of our methods.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Enhancing Attributed Graph Networks with Alignment and Uniformity
  Constraints for Session-based Recommendation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.10296v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.10296v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xinping Zhao, Chaochao Chen, Jiajie Su, Yizhao Zhang, Baotian Hu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Session-based Recommendation (SBR), seeking to predict a user's next action
based on an anonymous session, has drawn increasing attention for its
practicability. Most SBR models only rely on the contextual transitions within
a short session to learn item representations while neglecting additional
valuable knowledge. As such, their model capacity is largely limited by the
data sparsity issue caused by short sessions. A few studies have exploited the
Modeling of Item Attributes (MIA) to enrich item representations. However, they
usually involve specific model designs that can hardly transfer to existing
attribute-agnostic SBR models and thus lack universality. In this paper, we
propose a model-agnostic framework, named AttrGAU (Attributed Graph Networks
with Alignment and Uniformity Constraints), to bring the MIA's superiority into
existing attribute-agnostic models, to improve their accuracy and robustness
for recommendation. Specifically, we first build a bipartite attributed graph
and design an attribute-aware graph convolution to exploit the rich attribute
semantics hidden in the heterogeneous item-attribute relationship. We then
decouple existing attribute-agnostic SBR models into the graph neural network
and attention readout sub-modules to satisfy the non-intrusive requirement.
Lastly, we design two representation constraints, i.e., alignment and
uniformity, to optimize distribution discrepancy in representation between the
attribute semantics and collaborative semantics. Extensive experiments on three
public benchmark datasets demonstrate that the proposed AttrGAU framework can
significantly enhance backbone models' recommendation performance and
robustness against data sparsity and data noise issues. Our implementation
codes will be available at https://github.com/ItsukiFujii/AttrGAU.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>11 pages, 4 figures, 5 tables. Accepted by ICWS 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ FunnelRAG: A Coarse-to-Fine Progressive Retrieval Paradigm for RAG 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.10293v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.10293v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xinping Zhao, Yan Zhong, Zetian Sun, Xinshuo Hu, Zhenyu Liu, Dongfang Li, Baotian Hu, Min Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Retrieval-Augmented Generation (RAG) prevails in Large Language Models. It
mainly consists of retrieval and generation. The retrieval modules (a.k.a.
retrievers) aim to find useful information used to facilitate generation
modules (a.k.a. generators). As such, generators' performance largely depends
on the effectiveness and efficiency of retrievers. However, the retrieval
paradigm that we design and use remains flat, which treats the retrieval
procedures as a one-off deal with constant granularity. Despite effectiveness,
we argue that they suffer from two limitations: (1) flat retrieval exerts a
significant burden on one retriever; (2) constant granularity limits the
ceiling of retrieval performance. In this work, we propose a progressive
retrieval paradigm with coarse-to-fine granularity for RAG, termed FunnelRAG,
so as to balance effectiveness and efficiency. Specifically, FunnelRAG
establishes a progressive retrieval pipeline by collaborating coarse-to-fine
granularity, large-to-small quantity, and low-to-high capacity, which can
relieve the burden on one retriever and also promote the ceiling of retrieval
performance. Extensive experiments manifest that FunnelRAG achieves comparable
retrieval performance while the time overhead is reduced by nearly 40 percent.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>18 pages, 6 figures, 13 tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Back-of-the-Book Index Automation for Arabic Documents 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.10286v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.10286v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Nawal Haidar, Fadi A. Zaraket
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Back-of-the-book indexes are crucial for book readability. Their manual
creation is laborious and error prone. In this paper, we consider automating
back-of-the-book index extraction for Arabic books to help simplify both the
creation and review tasks. Given a back-of-the-book index, we aim to check and
identify the accurate occurrences of index terms relative to the associated
pages. To achieve this, we first define a pool of candidates for each term by
extracting all possible noun phrases from paragraphs appearing on the relevant
index pages. These noun phrases, identified through part-of-speech analysis,
are stored in a vector database for efficient retrieval. We use several
metrics, including exact matches, lexical similarity, and semantic similarity,
to determine the most appropriate occurrence. The candidate with the highest
score based on these metrics is chosen as the occurrence of the term. We
fine-tuned a heuristic method, that considers the above metrics and that
achieves an F1-score of .966 (precision=.966, recall=.966). These excellent
results open the door for future work related to automation of back-of-the-book
index generation and checking.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ DecKG: Decentralized Collaborative Learning with Knowledge Graph
  Enhancement for POI Recommendation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.10130v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.10130v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ruiqi Zheng, Liang Qu, Guanhua Ye, Tong Chen, Yuhui Shi, Hongzhi Yin
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Decentralized collaborative learning for Point-of-Interest (POI)
recommendation has gained research interest due to its advantages in privacy
preservation and efficiency, as it keeps data locally and leverages
collaborative learning among clients to train models in a decentralized manner.
However, since local data is often limited and insufficient for training
accurate models, a common solution is integrating external knowledge as
auxiliary information to enhance model performance. Nevertheless, this solution
poses challenges for decentralized collaborative learning. Due to private
nature of local data, identifying relevant auxiliary information specific to
each user is non-trivial. Furthermore, resource-constrained local devices
struggle to accommodate all auxiliary information, which places heavy burden on
local storage. To fill the gap, we propose a novel decentralized collaborative
learning with knowledge graph enhancement framework for POI recommendation
(DecKG). Instead of directly uploading interacted items, users generate
desensitized check-in data by uploading general categories of interacted items
and sampling similar items from same category. The server then pretrains KG
without sensitive user-item interactions and deploys relevant partitioned
sub-KGs to individual users. Entities are further refined on the device,
allowing client to client communication to exchange knowledge learned from
local data and sub-KGs. Evaluations across two real-world datasets demonstrate
DecKG's effectiveness recommendation performance.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ MAIR: A Massive Benchmark for Evaluating Instructed Retrieval <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.10127v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.10127v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Weiwei Sun, Zhengliang Shi, Jiulong Wu, Lingyong Yan, Xinyu Ma, Yiding Liu, Min Cao, Dawei Yin, Zhaochun Ren
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent information retrieval (IR) models are pre-trained and
instruction-tuned on massive datasets and tasks, enabling them to perform well
on a wide range of tasks and potentially generalize to unseen tasks with
instructions. However, existing IR benchmarks focus on a limited scope of
tasks, making them insufficient for evaluating the latest IR models. In this
paper, we propose MAIR (Massive Instructed Retrieval Benchmark), a
heterogeneous IR benchmark that includes 126 distinct IR tasks across 6
domains, collected from existing datasets. We benchmark state-of-the-art
instruction-tuned text embedding models and re-ranking models. Our experiments
reveal that instruction-tuned models generally achieve superior performance
compared to non-instruction-tuned models on MAIR. Additionally, our results
suggest that current instruction-tuned text embedding models and re-ranking
models still lack effectiveness in specific long-tail tasks. MAIR is publicly
available at https://github.com/sunnweiwei/Mair.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>EMNLP 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ On Feature Decorrelation in Cloth-Changing Person Re-identification 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.05536v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.05536v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hongjun Wang, Jiyuan Chen, Renhe Jiang, Xuan Song, Yinqiang Zheng
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Cloth-changing person re-identification (CC-ReID) poses a significant
challenge in computer vision. A prevailing approach is to prompt models to
concentrate on causal attributes, like facial features and hairstyles, rather
than confounding elements such as clothing appearance. Traditional methods to
achieve this involve integrating multi-modality data or employing manually
annotated clothing labels, which tend to complicate the model and require
extensive human effort. In our study, we demonstrate that simply reducing
feature correlations during training can significantly enhance the baseline
model's performance. We theoretically elucidate this effect and introduce a
novel regularization technique based on density ratio estimation. This
technique aims to minimize feature correlation in the training process of
cloth-changing ReID baselines. Our approach is model-independent, offering
broad enhancements without needing additional data or labels. We validate our
method through comprehensive experiments on prevalent CC-ReID datasets, showing
its effectiveness in improving baseline models' generalization capabilities.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Pure Message Passing Can Estimate Common Neighbor for Link Prediction 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2309.00976v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2309.00976v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Kaiwen Dong, Zhichun Guo, Nitesh V. Chawla
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Message Passing Neural Networks (MPNNs) have emerged as the {\em de facto}
standard in graph representation learning. However, when it comes to link
prediction, they often struggle, surpassed by simple heuristics such as Common
Neighbor (CN). This discrepancy stems from a fundamental limitation: while
MPNNs excel in node-level representation, they stumble with encoding the joint
structural features essential to link prediction, like CN. To bridge this gap,
we posit that, by harnessing the orthogonality of input vectors, pure
message-passing can indeed capture joint structural features. Specifically, we
study the proficiency of MPNNs in approximating CN heuristics. Based on our
findings, we introduce the Message Passing Link Predictor (MPLP), a novel link
prediction model. MPLP taps into quasi-orthogonal vectors to estimate
link-level structural features, all while preserving the node-level
complexities. Moreover, our approach demonstrates that leveraging
message-passing to capture structural features could offset MPNNs'
expressiveness limitations at the expense of estimation variance. We conduct
experiments on benchmark datasets from various domains, where our method
consistently outperforms the baseline methods.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to Neurips'24</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ mGTE: Generalized Long-Context Text Representation and Reranking Models
  for Multilingual Text Retrieval <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.19669v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.19669v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xin Zhang, Yanzhao Zhang, Dingkun Long, Wen Xie, Ziqi Dai, Jialong Tang, Huan Lin, Baosong Yang, Pengjun Xie, Fei Huang, Meishan Zhang, Wenjie Li, Min Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We present systematic efforts in building long-context multilingual text
representation model (TRM) and reranker from scratch for text retrieval. We
first introduce a text encoder (base size) enhanced with RoPE and unpadding,
pre-trained in a native 8192-token context (longer than 512 of previous
multilingual encoders). Then we construct a hybrid TRM and a cross-encoder
reranker by contrastive learning. Evaluations show that our text encoder
outperforms the same-sized previous state-of-the-art XLM-R. Meanwhile, our TRM
and reranker match the performance of large-sized state-of-the-art BGE-M3
models and achieve better results on long-context retrieval benchmarks. Further
analysis demonstrate that our proposed models exhibit higher efficiency during
both training and inference. We believe their efficiency and effectiveness
could benefit various researches and industrial applications.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Camera-ready version of EMNLP 2024: Industry Track</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Personalized Item Representations in Federated Multimodal Recommendation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.08478v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.08478v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zhiwei Li, Guodong Long, Jing Jiang, Chengqi Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Federated recommendation systems are essential for providing personalized
recommendations while protecting user privacy. However, current methods mainly
rely on ID-based item embeddings, neglecting the rich multimodal information of
items. To address this, we propose a Federated Multimodal Recommendation
System, called FedMR. FedMR uses a foundation model on the server to encode
multimodal item data, such as images and text. To handle data heterogeneity
caused by user preference differences, FedMR introduces a Mixing Feature Fusion
Module on each client, which adjusts fusion strategy weights based on user
interaction history to generate personalized item representations that capture
users' fine-grained preferences. FedMR is compatible with existing ID-based
federated recommendation systems, improving performance without modifying the
original framework. Experiments on four real-world multimodal datasets
demonstrate FedMR's effectiveness. The code is available at
https://anonymous.4open.science/r/FedMR.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>12 pages, 4 figures, 5 tables, conference</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ LARA: Linguistic-Adaptive Retrieval-Augmentation for Multi-Turn Intent
  Classification <span class="chip">EMNLP'24</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2403.16504v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2403.16504v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Junhua Liu, Yong Keat Tan, Bin Fu, Kwan Hui Lim
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Multi-turn intent classification is notably challenging due to the complexity
and evolving nature of conversational contexts. This paper introduces LARA, a
Linguistic-Adaptive Retrieval-Augmentation framework to enhance accuracy in
multi-turn classification tasks across six languages, accommodating a large
number of intents in chatbot interactions. LARA combines a fine-tuned smaller
model with a retrieval-augmented mechanism, integrated within the architecture
of LLMs. The integration allows LARA to dynamically utilize past dialogues and
relevant intents, thereby improving the understanding of the context.
Furthermore, our adaptive retrieval techniques bolster the cross-lingual
capabilities of LLMs without extensive retraining and fine-tuning.
Comprehensive experiments demonstrate that LARA achieves state-of-the-art
performance on multi-turn intent classification tasks, enhancing the average
accuracy by 3.67\% from state-of-the-art single-turn intent classifiers.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to EMNLP'24</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Language Model Powered Digital Biology 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.02864v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.02864v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Joshua Pickard, Marc Andrew Choi, Natalie Oliven, Cooper Stansbury, Jillian Cwycyshyn, Nicholas Galioto, Alex Gorodetsky, Alvaro Velasquez, Indika Rajapakse
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent advancements in Large Language Models (LLMs) are transforming biology,
computer science, and many other research fields, as well as impacting everyday
life. While transformer-based technologies are currently being deployed in
biology, no available agentic system has been developed to tackle
bioinformatics workflows. We present a prototype Bioinformatics Retrieval
Augmented Data (BRAD) digital assistant. BRAD is a chatbot and agentic system
that integrates a suite of tools to handle bioinformatics tasks, from code
execution to online search. We demonstrate its capabilities through (1)
improved question-and-answering with retrieval augmented generation (RAG), (2)
the ability to run complex software pipelines, and (3) the ability to organize
and distribute tasks in agentic workflows. We use BRAD for automation,
performing tasks ranging from gene enrichment and searching the archive to
automatic code generation for running biomarker identification pipelines. BRAD
is a step toward autonomous, self-driving labs for digital biology.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>49 pages, 3 tables, 12 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Enhancing Dense Retrievers' Robustness with Group-level Reweighting 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2310.16605v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2310.16605v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Peixuan Han, Zhenghao Liu, Zhiyuan Liu, Chenyan Xiong
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The anchor-document data derived from web graphs offers a wealth of paired
information for training dense retrieval models in an unsupervised manner.
However, unsupervised data contains diverse patterns across the web graph and
often exhibits significant imbalance, leading to suboptimal performance in
underrepresented or difficult groups. In this paper, we introduce WebDRO, an
efficient approach for clustering the web graph data and optimizing group
weights to enhance the robustness of dense retrieval models. Initially, we
build an embedding model for clustering anchor-document pairs. Specifically, we
contrastively train the embedding model for link prediction, which guides the
embedding model in capturing the document features behind the web graph links.
Subsequently, we employ the group distributional robust optimization to
recalibrate the weights across different clusters of anchor-document pairs
during training retrieval models. During training, we direct the model to
assign higher weights to clusters with higher loss and focus more on worst-case
scenarios. This approach ensures that the model has strong generalization
ability on all data patterns. Our experiments on MS MARCO and BEIR demonstrate
that our method can effectively improve retrieval performance in unsupervised
training and finetuning settings. Further analysis confirms the stability and
validity of group weights learned by WebDRO. The code of this paper can be
obtained from https://github.com/Hanpx20/GroupDRO_Dense_Retrieval.
</span>
                                    </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
            <article>
                <details>
                    <Summary>
                        Multimedia <span class="chip" style="font-size: 60%">7</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Spatial-Aware Efficient Projector for MLLMs via Multi-Layer Feature
  Aggregation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.10319v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.10319v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Shun Qian, Bingquan Liu, Chengjie Sun, Zhen Xu, Baoxun Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The projector plays a crucial role in multi-modal language models (MLLMs).
The number of visual tokens it outputs affects the efficiency of the MLLM,
while the quality of the visual tokens influences the visual understanding
capabilities of the MLLM. Current explorations on the projector focus on
reducing the number of visual tokens to improve efficiency, often overlooking
the inherent spatial discrepancy between the serialized 2-dimensional visual
token sequences and natural language token sequences. A Spatial-Aware Efficient
Projector (SAEP) is proposed to address this issue. In detail, our SAEP method
employs an modified separable depthwise convolution module on multi-layer
visual features to enhance the spatial information of visual tokens. As a
result, our SAEP method can not only largely reduce the number of visual tokens
by 75\%, but also significantly improve the multimodal spatial understanding
capability of MLLMs. Moreover, compared to existing projectors, our SAEP gets
best performances on massive multimodal evaluation benchmarks, which denotes
its effectiveness on bridging the modality gap.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>10 pages, 3 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ GUISE: Graph GaUssIan Shading watErmark 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.10178v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.10178v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Renyi Yang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In the expanding field of generative artificial intelligence, integrating
robust watermarking technologies is essential to protect intellectual property
and maintain content authenticity. Traditionally, watermarking techniques have
been developed primarily for rich information media such as images and audio.
However, these methods have not been adequately adapted for graph-based data,
particularly molecular graphs. Latent 3D graph diffusion(LDM-3DG) is an
ascendant approach in the molecular graph generation field. This model
effectively manages the complexities of molecular structures, preserving
essential symmetries and topological features. We adapt the Gaussian Shading, a
proven performance lossless watermarking technique, to the latent graph
diffusion domain to protect this sophisticated new technology. Our adaptation
simplifies the watermark diffusion process through duplication and padding,
making it adaptable and suitable for various message types. We conduct several
experiments using the LDM-3DG model on publicly available datasets QM9 and
Drugs, to assess the robustness and effectiveness of our technique. Our results
demonstrate that the watermarked molecules maintain statistical parity in 9 out
of 10 performance metrics compared to the original. Moreover, they exhibit a
100% detection rate and a 99% extraction rate in a 2D decoded pipeline, while
also showing robustness against post-editing attacks.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Detecting Audio-Visual Deepfakes with Fine-Grained Inconsistencies <span class="chip">BMVC 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2408.06753v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2408.06753v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Marcella Astrid, Enjie Ghorbel, Djamila Aouada
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Existing methods on audio-visual deepfake detection mainly focus on
high-level features for modeling inconsistencies between audio and visual data.
As a result, these approaches usually overlook finer audio-visual artifacts,
which are inherent to deepfakes. Herein, we propose the introduction of
fine-grained mechanisms for detecting subtle artifacts in both spatial and
temporal domains. First, we introduce a local audio-visual model capable of
capturing small spatial regions that are prone to inconsistencies with audio.
For that purpose, a fine-grained mechanism based on a spatially-local distance
coupled with an attention module is adopted. Second, we introduce a
temporally-local pseudo-fake augmentation to include samples incorporating
subtle temporal inconsistencies in our training set. Experiments on the DFDC
and the FakeAVCeleb datasets demonstrate the superiority of the proposed method
in terms of generalization as compared to the state-of-the-art under both
in-dataset and cross-dataset settings.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted in BMVC 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Multi-Track MusicLDM: Towards Versatile Music Generation with Latent
  Diffusion Model 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.02845v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.02845v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Tornike Karchkhadze, Mohammad Rasool Izadi, Ke Chen, Gerard Assayag, Shlomo Dubnov
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Diffusion models have shown promising results in cross-modal generation tasks
involving audio and music, such as text-to-sound and text-to-music generation.
These text-controlled music generation models typically focus on generating
music by capturing global musical attributes like genre and mood. However,
music composition is a complex, multilayered task that often involves musical
arrangement as an integral part of the process. This process involves composing
each instrument to align with existing ones in terms of beat, dynamics,
harmony, and melody, requiring greater precision and control over tracks than
text prompts usually provide. In this work, we address these challenges by
extending the MusicLDM, a latent diffusion model for music, into a multi-track
generative model. By learning the joint probability of tracks sharing a
context, our model is capable of generating music across several tracks that
correspond well to each other, either conditionally or unconditionally.
Additionally, our model is capable of arrangement generation, where the model
can generate any subset of tracks given the others (e.g., generating a piano
track complementing given bass and drum tracks). We compared our model with an
existing multi-track generative model and demonstrated that our model achieves
considerable improvements across objective metrics for both total and
arrangement generation tasks.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Proceedings of The second international workshop on eXplainable AI for
  the Arts (XAIxArts) 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.14485v7">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.14485v7.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Nick Bryan-Kinns, Corey Ford, Shuoyang Zheng, Helen Kennedy, Alan Chamberlain, Makayla Lewis, Drew Hemment, Zijin Li, Qiong Wu, Lanxi Xiao, Gus Xia, Jeba Rezwana, Michael Clemens, Gabriel Vigliensoni
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This second international workshop on explainable AI for the Arts (XAIxArts)
brought together a community of researchers in HCI, Interaction Design, AI,
explainable AI (XAI), and digital arts to explore the role of XAI for the Arts.
Workshop held at the 16th ACM Conference on Creativity and Cognition (C&C
2024), Chicago, USA.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Proceedings of The second international workshop on eXplainable AI
  for the Arts (XAIxArts)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Improving Multimodal Learning with Multi-Loss Gradient Modulation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.07930v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.07930v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Konstantinos Kontras, Christos Chatzichristos, Matthew Blaschko, Maarten De Vos
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Learning from multiple modalities, such as audio and video, offers
opportunities for leveraging complementary information, enhancing robustness,
and improving contextual understanding and performance. However, combining such
modalities presents challenges, especially when modalities differ in data
structure, predictive contribution, and the complexity of their learning
processes. It has been observed that one modality can potentially dominate the
learning process, hindering the effective utilization of information from other
modalities and leading to sub-optimal model performance. To address this issue
the vast majority of previous works suggest to assess the unimodal
contributions and dynamically adjust the training to equalize them. We improve
upon previous work by introducing a multi-loss objective and further refining
the balancing process, allowing it to dynamically adjust the learning pace of
each modality in both directions, acceleration and deceleration, with the
ability to phase out balancing effects upon convergence. We achieve superior
results across three audio-video datasets: on CREMA-D, models with ResNet
backbone encoders surpass the previous best by 1.9% to 12.4%, and Conformer
backbone models deliver improvements ranging from 2.8% to 14.1% across
different fusion methods. On AVE, improvements range from 2.7% to 7.7%, while
on UCF101, gains reach up to 6.1%.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ SceneDreamer360: Text-Driven 3D-Consistent Scene Generation with
  Panoramic Gaussian Splatting 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2408.13711v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2408.13711v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Wenrui Li, Fucheng Cai, Yapeng Mi, Zhe Yang, Wangmeng Zuo, Xingtao Wang, Xiaopeng Fan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Text-driven 3D scene generation has seen significant advancements recently.
However, most existing methods generate single-view images using generative
models and then stitch them together in 3D space. This independent generation
for each view often results in spatial inconsistency and implausibility in the
3D scenes. To address this challenge, we proposed a novel text-driven
3D-consistent scene generation model: SceneDreamer360. Our proposed method
leverages a text-driven panoramic image generation model as a prior for 3D
scene generation and employs 3D Gaussian Splatting (3DGS) to ensure consistency
across multi-view panoramic images. Specifically, SceneDreamer360 enhances the
fine-tuned Panfusion generator with a three-stage panoramic enhancement,
enabling the generation of high-resolution, detail-rich panoramic images.
During the 3D scene construction, a novel point cloud fusion initialization
method is used, producing higher quality and spatially consistent point clouds.
Our extensive experiments demonstrate that compared to other methods,
SceneDreamer360 with its panoramic image generation and 3DGS can produce higher
quality, spatially consistent, and visually appealing 3D scenes from any text
prompt. Our codes are available at
\url{https://github.com/liwrui/SceneDreamer360}.
</span>
                                    </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
    </section>
    <section class="day-container">
        <div class="date">
            <time datetime="2024-10-13T00:00:00Z">2024-10-13</time>
        </div>
            <article>
                <details>
                    <Summary>
                        Information Retrieval <span class="chip" style="font-size: 60%">15</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Leveraging Customer Feedback for Multi-modal Insight Extraction <span class="chip">NAACL 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.09999v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.09999v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Sandeep Sricharan Mukku, Abinesh Kanagarajan, Pushpendu Ghosh, Chetan Aggarwal
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Businesses can benefit from customer feedback in different modalities, such
as text and images, to enhance their products and services. However, it is
difficult to extract actionable and relevant pairs of text segments and images
from customer feedback in a single pass. In this paper, we propose a novel
multi-modal method that fuses image and text information in a latent space and
decodes it to extract the relevant feedback segments using an image-text
grounded text decoder. We also introduce a weakly-supervised data generation
technique that produces training data for this task. We evaluate our model on
unseen data and demonstrate that it can effectively mine actionable insights
from multi-modal customer feedback, outperforming the existing baselines by
$14$ points in F1 score.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>NAACL 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Learning to Rank for Multiple Retrieval-Augmented Models through
  Iterative Utility Maximization 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.09942v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.09942v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Alireza Salemi, Hamed Zamani
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper investigates the design of a unified search engine to serve
multiple retrieval-augmented generation (RAG) agents, each with a distinct
task, backbone large language model (LLM), and retrieval-augmentation strategy.
We introduce an iterative approach where the search engine generates retrieval
results for these RAG agents and gathers feedback on the quality of the
retrieved documents during an offline phase. This feedback is then used to
iteratively optimize the search engine using a novel expectation-maximization
algorithm, with the goal of maximizing each agent's utility function.
Additionally, we adapt this approach to an online setting, allowing the search
engine to refine its behavior based on real-time individual agents feedback to
better serve the results for each of them. Experiments on diverse datasets from
the Knowledge-Intensive Language Tasks (KILT) benchmark demonstrates that our
approach significantly on average outperforms competitive baselines across 18
RAG models. We also demonstrate that our method effectively ``personalizes''
the retrieval process for each RAG agent based on the collected feedback.
Finally, we provide a comprehensive ablation study to explore various aspects
of our method.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ The Role of Fake Users in Sequential Recommender Systems 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.09936v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.09936v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Filippo Betello
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Sequential Recommender Systems (SRSs) are widely used to model user behavior
over time, yet their robustness remains an under-explored area of research. In
this paper, we conduct an empirical study to assess how the presence of fake
users, who engage in random interactions, follow popular or unpopular items, or
focus on a single genre, impacts the performance of SRSs in real-world
scenarios. We evaluate two SRS models across multiple datasets, using
established metrics such as Normalized Discounted Cumulative Gain (NDCG) and
Rank Sensitivity List (RLS) to measure performance. While traditional metrics
like NDCG remain relatively stable, our findings reveal that the presence of
fake users severely degrades RLS metrics, often reducing them to near-zero
values. These results highlight the need for further investigation into the
effects of fake users on training data and emphasize the importance of
developing more resilient SRSs that can withstand different types of
adversarial attacks.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>10 pages, 2 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Analysis and Design of a Personalized Recommendation System Based on a
  Dynamic User Interest Model 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.09923v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.09923v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Chunyan Mao, Shuaishuai Huang, Mingxiu Sui, Haowei Yang, Xueshe Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  With the rapid development of the internet and the explosion of information,
providing users with accurate personalized recommendations has become an
important research topic. This paper designs and analyzes a personalized
recommendation system based on a dynamic user interest model. The system
captures user behavior data, constructs a dynamic user interest model, and
combines multiple recommendation algorithms to provide personalized content to
users. The research results show that this system significantly improves
recommendation accuracy and user satisfaction. This paper discusses the
system's architecture design, algorithm implementation, and experimental
results in detail and explores future research directions.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ ViFi-ReID: A Two-Stream Vision-WiFi Multimodal Approach for Person
  Re-identification 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.09875v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.09875v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Chen Mao, Chong Tan, Jingqi Hu, Min Zheng
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Person re-identification(ReID), as a crucial technology in the field of
security, plays a vital role in safety inspections, personnel counting, and
more. Most current ReID approaches primarily extract features from images,
which are easily affected by objective conditions such as clothing changes and
occlusions. In addition to cameras, we leverage widely available routers as
sensing devices by capturing gait information from pedestrians through the
Channel State Information (CSI) in WiFi signals and contribute a multimodal
dataset. We employ a two-stream network to separately process video
understanding and signal analysis tasks, and conduct multi-modal fusion and
contrastive learning on pedestrian video and WiFi data. Extensive experiments
in real-world scenarios demonstrate that our method effectively uncovers the
correlations between heterogeneous data, bridges the gap between visual and
signal modalities, significantly expands the sensing range, and improves ReID
accuracy across multiple sensors.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ A Comparative Study of PDF Parsing Tools Across Diverse Document
  Categories 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.09871v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.09871v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Narayan S. Adhikari, Shradha Agarwal
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  PDF is one of the most prominent data formats, making PDF parsing crucial for
information extraction and retrieval, particularly with the rise of RAG
systems. While various PDF parsing tools exist, their effectiveness across
different document types remains understudied, especially beyond academic
papers. Our research aims to address this gap by comparing 10 popular PDF
parsing tools across 6 document categories using the DocLayNet dataset. These
tools include PyPDF, pdfminer.six, PyMuPDF, pdfplumber, pypdfium2,
Unstructured, Tabula, Camelot, as well as the deep learning-based tools Nougat
and Table Transformer(TATR). We evaluated both text extraction and table
detection capabilities. For text extraction, PyMuPDF and pypdfium generally
outperformed others, but all parsers struggled with Scientific and Patent
documents. For these challenging categories, learning-based tools like Nougat
demonstrated superior performance. In table detection, TATR excelled in the
Financial, Patent, Law & Regulations, and Scientific categories. Table
detection tool Camelot performed best for tender documents, while PyMuPDF
performed superior in the Manual category. Our findings highlight the
importance of selecting appropriate parsing tools based on document type and
specific tasks, providing valuable insights for researchers and practitioners
working with diverse document sources.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>17 pages,11 figures, 5 tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Generating Driving Simulations via Conversation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.09829v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.09829v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Rimvydas Rubavicius, Antonio Valerio Miceli-Barone, Alex Lascarides, Subramanian Ramamoorthy
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Cyber-physical systems like autonomous vehicles are tested in simulation
before deployment, using domain-specific programs for scenario specification.
To aid the testing of autonomous vehicles in simulation, we design a natural
language interface, using an instruction-following large language model, to
assist a non-coding domain expert in synthesising the desired scenarios and
vehicle behaviours. We show that using it to convert utterances to the symbolic
program is feasible, despite the very small training dataset. Human experiments
show that dialogue is critical to successful simulation generation, leading to
a 4.5 times higher success rate than a generation without engaging in extended
conversation.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>6 pages, 6 figures, 2 tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ ContextWIN: Whittle Index Based Mixture-of-Experts Neural Model For
  Restless Bandits Via Deep RL 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.09781v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.09781v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zhanqiu Guo, Wayne Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This study introduces ContextWIN, a novel architecture that extends the
Neural Whittle Index Network (NeurWIN) model to address Restless Multi-Armed
Bandit (RMAB) problems with a context-aware approach. By integrating a mixture
of experts within a reinforcement learning framework, ContextWIN adeptly
utilizes contextual information to inform decision-making in dynamic
environments, particularly in recommendation systems. A key innovation is the
model's ability to assign context-specific weights to a subset of NeurWIN
networks, thus enhancing the efficiency and accuracy of the Whittle index
computation for each arm. The paper presents a thorough exploration of
ContextWIN, from its conceptual foundation to its implementation and potential
applications. We delve into the complexities of RMABs and the significance of
incorporating context, highlighting how ContextWIN effectively harnesses these
elements. The convergence of both the NeurWIN and ContextWIN models is
rigorously proven, ensuring theoretical robustness. This work lays the
groundwork for future advancements in applying contextual information to
complex decision-making scenarios, recognizing the need for comprehensive
dataset exploration and environment development for full potential realization.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ ChartKG: A Knowledge-Graph-Based Representation for Chart Images 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.09761v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.09761v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zhiguang Zhou, Haoxuan Wang, Zhengqing Zhao, Fengling Zheng, Yongheng Wang, Wei Chen, Yong Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Chart images, such as bar charts, pie charts, and line charts, are
explosively produced due to the wide usage of data visualizations. Accordingly,
knowledge mining from chart images is becoming increasingly important, which
can benefit downstream tasks like chart retrieval and knowledge graph
completion. However, existing methods for chart knowledge mining mainly focus
on converting chart images into raw data and often ignore their visual
encodings and semantic meanings, which can result in information loss for many
downstream tasks. In this paper, we propose ChartKG, a novel knowledge graph
(KG) based representation for chart images, which can model the visual elements
in a chart image and semantic relations among them including visual encodings
and visual insights in a unified manner. Further, we develop a general
framework to convert chart images to the proposed KG-based representation. It
integrates a series of image processing techniques to identify visual elements
and relations, e.g., CNNs to classify charts, yolov5 and optical character
recognition to parse charts, and rule-based methods to construct graphs. We
present four cases to illustrate how our knowledge-graph-based representation
can model the detailed visual elements and semantic relations in charts, and
further demonstrate how our approach can benefit downstream applications such
as semantic-aware chart retrieval and chart question answering. We also conduct
quantitative evaluations to assess the two fundamental building blocks of our
chart-to-KG framework, i.e., object recognition and optical character
recognition. The results provide support for the usefulness and effectiveness
of ChartKG.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Online Digital Investigative Journalism using SociaLens 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.11890v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.11890v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hasan M. Jamil, Sajratul Y. Rubaiat
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Media companies witnessed a significant transformation with the rise of the
internet, bigdata, machine learning (ML) and AI. Recent emergence of large
language models (LLM) have added another aspect to this transformation.
Researchers believe that with the help of these technologies, investigative
digital journalism will enter a new era. Using a smart set of data gathering
and analysis tools, journalists will be able to create data driven contents and
insights in unprecedented ways. In this paper, we introduce a versatile and
autonomous investigative journalism tool, called {\em SociaLens}, for
identifying and extracting query specific data from online sources, responding
to probing queries and drawing conclusions entailed by large volumes of data
using ML analytics fully autonomously. We envision its use in investigative
journalism, law enforcement and social policy planning. The proposed system
capitalizes on the integration of ML technology with LLMs and advanced bigdata
search techniques. We illustrate the functionality of SociaLens using a focused
case study on rape incidents in a developing country and demonstrate that
journalists can gain nuanced insights without requiring coding expertise they
might lack. SociaLens is designed as a ChatBot that is capable of contextual
conversation, find and collect data relevant to queries, initiate ML tasks to
respond to queries, generate textual and visual reports, all fully autonomously
within the ChatBot environment.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Agentic Information Retrieval 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.09713v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.09713v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Weinan Zhang, Junwei Liao, Ning Li, Kounianhua Du
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  What will information entry look like in the next generation of digital
products? Since the 1970s, user access to relevant information has relied on
domain-specific architectures of information retrieval (IR). Over the past two
decades, the advent of modern IR systems, including web search engines and
personalized recommender systems, has greatly improved the efficiency of
retrieving relevant information from vast data corpora. However, the core
paradigm of these IR systems remains largely unchanged, relying on filtering a
predefined set of candidate items. Since 2022, breakthroughs in large language
models (LLMs) have begun transforming how information is accessed, establishing
a new technical paradigm. In this position paper, we introduce Agentic
Information Retrieval (Agentic IR), a novel IR paradigm shaped by the
capabilities of LLM agents. Agentic IR expands the scope of accessible tasks
and leverages a suite of new techniques to redefine information retrieval. We
discuss three types of cutting-edge applications of agentic IR and the
challenges faced. We propose that agentic IR holds promise for generating
innovative applications, potentially becoming a central information entry point
in future digital ecosystems.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>11 pages, position paper</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Col<span class="highlight-title">BERT</span> Retrieval and Ensemble Response Scoring for Language Model
  Question Answering 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2408.10808v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2408.10808v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Alex Gichamba, Tewodros Kederalah Idris, Brian Ebiyau, Eric Nyberg, Teruko Mitamura
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Domain-specific question answering remains challenging for language models,
given the deep technical knowledge required to answer questions correctly. This
difficulty is amplified for smaller language models that cannot encode as much
information in their parameters as larger models. The "Specializing Large
Language Models for Telecom Networks" challenge aimed to enhance the
performance of two small language models, Phi-2 and Falcon-7B in
telecommunication question answering. In this paper, we present our question
answering systems for this challenge. Our solutions achieved leading marks of
81.9% accuracy for Phi-2 and 57.3% for Falcon-7B. We have publicly released our
code and fine-tuned models.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>7 pages, 2 figures, and 8 tables. This paper has been accepted at the
  2024 IEEE Global Communications (GLOBECOM) Workshops</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Evaluating D-MERIT of Partial-annotation on Information Retrieval <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.16048v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.16048v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Royi Rassin, Yaron Fairstein, Oren Kalinsky, Guy Kushilevitz, Nachshon Cohen, Alexander Libov, Yoav Goldberg
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Retrieval models are often evaluated on partially-annotated datasets. Each
query is mapped to a few relevant texts and the remaining corpus is assumed to
be irrelevant. As a result, models that successfully retrieve false negatives
are punished in evaluation. Unfortunately, completely annotating all texts for
every query is not resource efficient. In this work, we show that using
partially-annotated datasets in evaluation can paint a distorted picture. We
curate D-MERIT, a passage retrieval evaluation set from Wikipedia, aspiring to
contain all relevant passages for each query. Queries describe a group (e.g.,
"journals about linguistics") and relevant passages are evidence that entities
belong to the group (e.g., a passage indicating that "Language" is a journal
about linguistics). We show that evaluating on a dataset containing annotations
for only a subset of the relevant passages might result in misleading ranking
of the retrieval systems and that as more relevant texts are included in the
evaluation set, the rankings converge. We propose our dataset as a resource for
evaluation and our study as a recommendation for balance between
resource-efficiency and reliable evaluation when annotating evaluation sets for
text retrieval.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to EMNLP 2024 main track. Our dataset can be downloaded from
  https://D-MERIT.github.io</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Fine-Grained Embedding Dimension Optimization During Training for
  Recommender Systems 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2401.04408v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2401.04408v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Qinyi Luo, Penghan Wang, Wei Zhang, Fan Lai, Jiachen Mao, Xiaohan Wei, Jun Song, Wei-Yu Tsai, Shuai Yang, Yuxi Hu, Xuehai Qian
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Huge embedding tables in modern deep learning recommender models (DLRM)
require prohibitively large memory during training and inference. This paper
proposes FIITED, a system to automatically reduce the memory footprint via
FIne-grained In-Training Embedding Dimension pruning. By leveraging the key
insight that embedding vectors are not equally important, FIITED adaptively
adjusts the dimension of each individual embedding vector during model
training, assigning larger dimensions to more important embeddings while
adapting to dynamic changes in data. We prioritize embedding dimensions with
higher frequencies and gradients as more important. To enable efficient pruning
of embeddings and their dimensions during model training, we propose an
embedding storage system based on virtually-hashed physically-indexed hash
tables. Experiments on two industry models and months of realistic datasets
show that FIITED can reduce DLRM embedding size by more than 65% while
preserving model quality, outperforming state-of-the-art in-training embedding
pruning methods. On public datasets, FIITED can reduce the size of embedding
tables by 2.1x to 800x with negligible accuracy drop, while improving model
throughput.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>12 pages, 15 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ EHI: End-to-end Learning of Hierarchical Index for Efficient Dense
  Retrieval 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2310.08891v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2310.08891v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ramnath Kumar, Anshul Mittal, Nilesh Gupta, Aditya Kusupati, Inderjit Dhillon, Prateek Jain
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Dense embedding-based retrieval is widely used for semantic search and
ranking. However, conventional two-stage approaches, involving contrastive
embedding learning followed by approximate nearest neighbor search (ANNS), can
suffer from misalignment between these stages. This mismatch degrades retrieval
performance. We propose End-to-end Hierarchical Indexing (EHI), a novel method
that directly addresses this issue by jointly optimizing embedding generation
and ANNS structure. EHI leverages a dual encoder for embedding queries and
documents while simultaneously learning an inverted file index (IVF)-style tree
structure. To facilitate the effective learning of this discrete structure, EHI
introduces dense path embeddings that encodes the path traversed by queries and
documents within the tree. Extensive evaluations on standard benchmarks,
including MS MARCO (Dev set) and TREC DL19, demonstrate EHI's superiority over
traditional ANNS index. Under the same computational constraints, EHI
outperforms existing state-of-the-art methods by +1.45% in MRR@10 on MS MARCO
(Dev) and +8.2% in nDCG@10 on TREC DL19, highlighting the benefits of our
end-to-end approach.
</span>
                                    </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
            <article>
                <details>
                    <Summary>
                        Multimedia <span class="chip" style="font-size: 60%">3</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Towards Reproducible Learning-based Compression <span class="chip">SP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.09872v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.09872v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jiahao Pang, Muhammad Asad Lodhi, Junghyun Ahn, Yuning Huang, Dong Tian
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  A deep learning system typically suffers from a lack of reproducibility that
is partially rooted in hardware or software implementation details. The
irreproducibility leads to skepticism in deep learning technologies and it can
hinder them from being deployed in many applications. In this work, the
irreproducibility issue is analyzed where deep learning is employed in
compression systems while the encoding and decoding may be run on devices from
different manufacturers. The decoding process can even crash due to a single
bit difference, e.g., in a learning-based entropy coder. For a given deep
learning-based module with limited resources for protection, we first suggest
that reproducibility can only be assured when the mismatches are bounded. Then
a safeguarding mechanism is proposed to tackle the challenges. The proposed
method may be applied for different levels of protection either at the
reconstruction level or at a selected decoding level. Furthermore, the overhead
introduced for the protection can be scaled down accordingly when the error
bound is being suppressed. Experiments demonstrate the effectiveness of the
proposed approach for learning-based compression systems, e.g., in image
compression and point cloud compression.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted at MMSP 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ VidMuse: A Simple Video-to-Music Generation Framework with
  Long-Short-Term Modeling 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.04321v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.04321v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zeyue Tian, Zhaoyang Liu, Ruibin Yuan, Jiahao Pan, Qifeng Liu, Xu Tan, Qifeng Chen, Wei Xue, Yike Guo
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this work, we systematically study music generation conditioned solely on
the video. First, we present a large-scale dataset comprising 360K video-music
pairs, including various genres such as movie trailers, advertisements, and
documentaries. Furthermore, we propose VidMuse, a simple framework for
generating music aligned with video inputs. VidMuse stands out by producing
high-fidelity music that is both acoustically and semantically aligned with the
video. By incorporating local and global visual cues, VidMuse enables the
creation of musically coherent audio tracks that consistently match the video
content through Long-Short-Term modeling. Through extensive experiments,
VidMuse outperforms existing models in terms of audio quality, diversity, and
audio-visual alignment. The code and datasets will be available at
https://github.com/ZeyueT/VidMuse/.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>The code and datasets will be available at
  https://github.com/ZeyueT/VidMuse/</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Less for More: Enhanced Feedback-aligned Mixed LLMs for Molecule Caption
  Generation and Fine-Grained NLI Evaluation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.13984v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.13984v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Dimitris Gkoumas, Maria Liakata
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Scientific language models drive research innovation but require extensive
fine-tuning on large datasets. This work enhances such models by improving
their inference and evaluation capabilities with minimal or no additional
training. Focusing on molecule caption generation, we explore synergies between
alignment fine-tuning and model merging in a cross-modal setup. We reveal
intriguing insights into the behaviour and suitability of such methods while
significantly surpassing state-of-the-art models. Moreover, we propose a novel
atomic-level evaluation method leveraging off-the-shelf Natural Language
Inference (NLI) models for use in the unseen chemical domain. Our experiments
demonstrate that our evaluation operates at the right level of granularity,
effectively handling multiple content units and subsentence reasoning, while
widely adopted NLI methods consistently misalign with assessment criteria.
</span>
                                    </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
    </section>

</body>

<footer>
    <div>
        <time id="build-timestamp" datetime="2024-10-21T05:27:46.657317584Z">
            2024-10-21 05:27:46 UTC
        </time>
    </div>
</footer>
<script src="index.js"></script>
</html>
